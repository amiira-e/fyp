{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6aee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fd948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917400ef",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ccfec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a74228b",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ffe88c",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74715a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f2b2b",
   "metadata": {},
   "source": [
    "## Noisy samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939913aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdaac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flatten the array using the ravel function\n",
    "# y_train_resampled_final_flattened = np.ravel(y_train_resampled_final)\n",
    "\n",
    "# counts = np.bincount(y_train_resampled_final_flattened)\n",
    "# print(\"Class 0 count:\", counts[0])\n",
    "# print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9187674",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d223e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random.seed(0)\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.01, 'oldbalanceOrg': 0.07, 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "    # Replace the outliers in the test set with the trimmed means obtained from the train set\n",
    "    test_outliers = X_test.loc[X_test[col_name] > np.percentile(X_test[col_name], 100*(1-trim_props[col_name])), col_name]\n",
    "    X_test.loc[test_outliers.index, col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf78d39",
   "metadata": {},
   "source": [
    "## Scale train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c3e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b4b44",
   "metadata": {},
   "source": [
    "## Scale test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83707cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c9b81",
   "metadata": {},
   "source": [
    "## GOOD ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905908fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# create a new model that outputs the hidden layer\n",
    "hidden_layer_output = autoencoder.layers[1].output\n",
    "hidden_layer_model = Model(inputs=autoencoder.input, outputs=hidden_layer_output)\n",
    "\n",
    "# get the hidden layer output for a sample\n",
    "sample_hidden_output = hidden_layer_model.predict(X_train_resampled_final[0].reshape(1, -1))\n",
    "print(sample_hidden_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# extract hidden layer output from autoencoder\n",
    "hidden_layer_output = autoencoder.layers[1].output\n",
    "\n",
    "# create the mediator network with the hidden layer output as input\n",
    "mediator_input_layer = Input(shape=hidden_layer_output.shape[1:])\n",
    "mediator_hidden_layer = Dense(11, activation='relu')(mediator_input_layer)\n",
    "mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "mediator_network.compile(optimizer='adam', loss='mse')\n",
    "mediator_network.fit(hidden_layer_model.predict(X_train_resampled_final), y_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# extract hidden layer output from mediator network\n",
    "agent_hidden_layer_output = mediator_network.layers[1].output\n",
    "\n",
    "agent_input_layer = Input(shape=agent_hidden_layer_output.shape[1:])\n",
    "agent_hidden_layer = Dense(5, activation='relu')(agent_input_layer)\n",
    "agent_output_layer = Dense(2, activation='softmax')(agent_hidden_layer)\n",
    "\n",
    "agent_network = Model(inputs=agent_input_layer, outputs=agent_output_layer)\n",
    "agent_network.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92952ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediator_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c503ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f96cb8",
   "metadata": {},
   "source": [
    "## Agent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62477721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        experience = (state, action, reward, next_state, done)\n",
    "        self.buffer.append(experience)\n",
    "        if len(self.buffer) > self.max_size:\n",
    "            self.buffer.pop(0)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        index = np.random.choice(np.arange(buffer_size), size=batch_size, replace=False)\n",
    "        return [self.buffer[i] for i in index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d602597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def REWARD(action, label, fraud_class='DF', non_fraud_class='DN', reward_fraud=1, reward_non_fraud=0.5, penalty=-1):\n",
    "#     terminal = 0\n",
    "#     if label == fraud_class:\n",
    "#         if action == label:\n",
    "#             reward = reward_fraud\n",
    "#         else:\n",
    "#             reward = penalty\n",
    "#             terminal = 1\n",
    "#     else:\n",
    "#         if action == label:\n",
    "#             reward = reward_non_fraud\n",
    "#         else:\n",
    "#             reward = penalty * reward_non_fraud\n",
    "#     return reward, terminal\n",
    "\n",
    "def REWARD(action, label, lambda_val, is_fraud):\n",
    "    \"\"\"\n",
    "    Calculates the reward for a given action and label.\n",
    "    \n",
    "    Parameters:\n",
    "    - action: The action taken by the agent.\n",
    "    - label: The true label of the transaction.\n",
    "    - lambda_val: The reward value when the agent correctly classifies a non-fraudulent transaction.\n",
    "    - is_fraud: A boolean value indicating whether the transaction is fraudulent or not.\n",
    "    \n",
    "    Returns:\n",
    "    - reward: The reward value.\n",
    "    - terminal: A boolean indicating whether the episode is over or not.\n",
    "    \"\"\"\n",
    "    if is_fraud:\n",
    "        if action == label:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "            terminal = True\n",
    "    else:\n",
    "        if action == label:\n",
    "            reward = lambda_val\n",
    "        else:\n",
    "            reward = -lambda_val\n",
    "        terminal = False\n",
    "    \n",
    "    return reward, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_shape = X_train_resampled_final.shape[1]\n",
    "output_shape =X_train_resampled_final.shape[1]\n",
    "\n",
    "# Set hyperparameters\n",
    "gamma = 0.99\n",
    "epsilon = 1\n",
    "epsilon_decay = 0.9999\n",
    "epsilon_min = 0.01\n",
    "batch_size = 32\n",
    "num_episodes = 2\n",
    "\n",
    "# Initialize replay memory D with M capacity\n",
    "M = 10000\n",
    "replay_memory = ReplayBuffer(M)\n",
    "\n",
    "# Randomly initialize parameters θ\n",
    "theta_agent = np.random.normal(0, 0.1, size=(input_shape, output_shape))\n",
    "\n",
    "# Loop over episodes\n",
    "for episode in range(num_episodes):\n",
    "\n",
    "    # Shuffle D\n",
    "    np.random.shuffle(replay_memory.buffer)\n",
    "\n",
    "\n",
    "    # Initialize state s1\n",
    "    state = X_train_resampled_final[0]\n",
    "\n",
    "    # Reset the episode\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    t = 0\n",
    "\n",
    "    # Loop over time steps\n",
    "    while not done:\n",
    "\n",
    "        # Choose an action: at = πθ(st)\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.choice(output_shape)\n",
    "        else:\n",
    "            q_values = Q(state, theta_agent)\n",
    "            action = np.argmax(q_values)\n",
    "\n",
    "        # Take the action and observe the next state and reward\n",
    "        next_state = X_train_resampled_final[t+1]\n",
    "        reward, terminal = REWARD(action, y[t+1])\n",
    "\n",
    "        # Store (st, at, rt, st+1, terminalt) to M\n",
    "        replay_memory.add(state, action, reward, next_state, terminal)\n",
    "\n",
    "        # Randomly sample (sj, aj, rj, sj+1, terminalj) from M\n",
    "        batch = replay_memory.sample(batch_size)\n",
    "\n",
    "        # Set yj\n",
    "        y = np.zeros(batch_size)\n",
    "        next_state_q_values = np.zeros(batch_size)\n",
    "        for i in range(batch_size):\n",
    "            if batch['terminal'][i]:\n",
    "                y[i] = batch['reward'][i]\n",
    "            else:\n",
    "                next_state_q_values[i] = Q(batch['next_state'][i], theta_agent)\n",
    "                y[i] = batch['reward'][i] + gamma * np.max(next_state_q_values[i])\n",
    "\n",
    "        # Perform a gradient descent step\n",
    "        loss = agent_loss(batch['state'], batch['action'], y, theta_agent)\n",
    "        theta_agent -= 0.001 * loss\n",
    "\n",
    "        # Update the state and total reward\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        t += 1\n",
    "\n",
    "        # Break if the episode is done\n",
    "        if terminal:\n",
    "            break\n",
    "\n",
    "    # Decay epsilon\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "    # Print the total reward for the episode\n",
    "    print('Episode', episode + 1, '- Total Reward:', total_reward)\n",
    "\n",
    "reward, terminal = REWARD(action, y[t+1], lambda_val, X[t+1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7189e47b",
   "metadata": {},
   "source": [
    "# Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef4331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921e136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb3394",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab161b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb12cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', 'type', 'nameDest', 'nameOrig', 'isFraud']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assuming df is your dataframe\n",
    "new_order = ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', 'type', 'nameDest', 'nameOrig', 'isFraud']\n",
    "\n",
    "# create a new dataframe with columns in the desired order\n",
    "df_sample = df_sample.drop(columns=['isFraud']).assign(isFraud=df_sample['isFraud'])\n",
    "\n",
    "# check that the new dataframe has columns in the desired order\n",
    "print(df_sample.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b180cc",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bb067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_resampled_final = df_sample.iloc[:, :10] # extract all rows and first 10 columns\n",
    "# y_train_resampled_final = df_sample.iloc[:, -1] # extract last column of entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14d530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c301a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba4f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9217be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fff50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f0d8e",
   "metadata": {},
   "source": [
    "## Treat outliers on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4e261af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 579201.160023732, 'oldbalanceOrg': 390563.3515248107, 'newbalanceOrig': 419886.064769876, 'oldbalanceDest': 690185.1353598785, 'newbalanceDest': 1032359.747805211}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random.seed(0)\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.01, 'oldbalanceOrg': 0.07, 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "    # Replace the outliers in the test set with the trimmed means obtained from the train set\n",
    "    test_outliers = X_test.loc[X_test[col_name] > np.percentile(X_test[col_name], 100*(1-trim_props[col_name])), col_name]\n",
    "    X_test.loc[test_outliers.index, col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58cbb6c",
   "metadata": {},
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3964bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)\n",
    "\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd27ee8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B947B8A318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B947B8A318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13670/13670 [==============================] - 19s 1ms/step - loss: 0.6171\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B94915E9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B94915E9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[[0.6355696  1.8539131  0.85234    0.76271373 0.61344075 0.77648926\n",
      "  0.8336302  1.8567436  0.33731508 0.8936795  0.         3.191124\n",
      "  2.643464   2.2328446  2.6387894  0.         3.3445065  0.\n",
      "  1.0261217  0.76232606]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# create a new model that outputs the hidden layer\n",
    "hidden_layer_output = autoencoder.layers[1].output\n",
    "hidden_layer_model = Model(inputs=autoencoder.input, outputs=hidden_layer_output)\n",
    "\n",
    "# get the hidden layer output for a sample\n",
    "sample_hidden_output = hidden_layer_model.predict(X_train_resampled_final[0].reshape(1, -1))\n",
    "print(sample_hidden_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4330c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                220       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220\n",
      "Trainable params: 220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Dense\n",
    "# from keras.models import Model\n",
    "\n",
    "# # create the autoencoder\n",
    "# input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "# encoding_dim = 20\n",
    "# decoding_dim = 10\n",
    "\n",
    "# input_layer = Input(shape=(input_dim,))\n",
    "# hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "# output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "# autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "# autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# # extract hidden layer output from autoencoder\n",
    "# hidden_layer_output = autoencoder.layers[1].output\n",
    "\n",
    "# # create the mediator network with the hidden layer output as input\n",
    "# mediator_input_layer = Input(shape=hidden_layer_output.shape[1:])\n",
    "# mediator_hidden_layer = Dense(10, activation='relu')(mediator_input_layer)\n",
    "# mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "# mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "# mediator_network.compile(optimizer='adam', loss='mse')\n",
    "# mediator_network.fit(hidden_layer_model.predict(X_train_resampled_final), y_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# # extract hidden layer output from mediator network\n",
    "# agent_hidden_layer_output = mediator_network.layers[1].output\n",
    "\n",
    "# agent_input_layer = Input(shape=agent_hidden_layer_output.shape[1:])\n",
    "# agent_hidden_layer = Dense(5, activation='relu')(agent_input_layer)\n",
    "# agent_output_layer = Dense(2, activation='softmax')(agent_hidden_layer)\n",
    "\n",
    "# agent_network = Model(inputs=agent_input_layer, outputs=agent_output_layer)\n",
    "# agent_network.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "encoding_dim = 20\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "#MSE is a common choice for reconstruction-based autoencoders.\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# extract hidden layer output from autoencoder\n",
    "hidden_layer_model = Model(inputs=autoencoder.input, outputs=autoencoder.layers[1].output)\n",
    "hidden_layer_output = hidden_layer_model.predict(X_train_resampled_final)\n",
    "\n",
    "# create the mediator network with the hidden layer output as input\n",
    "mediator_input_layer = Input(shape=(encoding_dim,))\n",
    "mediator_hidden_layer = Dense(10, activation='relu')(mediator_input_layer)\n",
    "mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "mediator_network.compile(optimizer='adam', loss='mse')\n",
    "mediator_network.fit(hidden_layer_output, y_train_resampled_final, epochs=1)\n",
    "\n",
    "# extract hidden layer output from mediator network\n",
    "agent_hidden_layer_output = mediator_network.layers[1].output\n",
    "\n",
    "agent_input_layer = Input(shape=agent_hidden_layer_output.shape[1:])\n",
    "agent_hidden_layer = Dense(5, activation='relu')(agent_input_layer)\n",
    "agent_output_layer = Dense(2, activation='softmax')(agent_hidden_layer)\n",
    "\n",
    "agent_network = Model(inputs=agent_input_layer, outputs=agent_output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437faf6",
   "metadata": {},
   "source": [
    "## Check overfitting/underfitting in autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad836b",
   "metadata": {},
   "source": [
    "## Baysian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4740fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from skopt import gp_minimize, space\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the objective function to optimize\n",
    "def objective_function(params):\n",
    "    encoding_dim, learning_rate = params\n",
    "\n",
    "    # create the autoencoder\n",
    "    input_dim = X_train_resampled_final.shape[1]\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(lr=learning_rate), loss='mse')\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    val_losses = []\n",
    "    for train_index, val_index in kf.split(X_train_resampled_final):\n",
    "        X_train_fold, X_val_fold = X_train_resampled_final[train_index], X_train_resampled_final[val_index]\n",
    "        autoencoder.fit(X_train_fold, X_train_fold, epochs=1, batch_size=32, verbose=0)\n",
    "        val_loss = autoencoder.evaluate(X_val_fold, X_val_fold, verbose=0)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    # Return the average validation loss across all folds\n",
    "    return np.mean(val_losses)\n",
    "\n",
    "# Define the search space for the hyperparameters\n",
    "search_space = [\n",
    "    space.Integer(10, 20, name='encoding_dim'),\n",
    "    space.Real(0.001, 0.1, name='learning_rate'),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization to find the optimal hyperparameters\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    search_space,\n",
    "    n_calls=10,\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters and validation loss\n",
    "print(f\"Best Hyperparameters: {result.x}\")\n",
    "print(f\"Validation Loss: {result.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(autoencoder, to_file='autoencoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91728fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(mediator_network, to_file='mediator_network.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54194c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(agent_network, to_file='agent_network.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29bb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediator_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b07ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0c23b",
   "metadata": {},
   "source": [
    "## Best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab06b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Dense\n",
    "# from keras.models import Model\n",
    "# from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "# from sklearn.model_selection import KFold\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "# # Define search space for autoencoder hyperparameters\n",
    "# space = {\n",
    "#     'encoding_dim': hp.quniform('encoding_dim', 10, 50, 1),\n",
    "#     'decoding_dim': hp.quniform('decoding_dim', 5, 20, 1),\n",
    "#     'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
    "#     'learning_rate': hp.loguniform('learning_rate', -5, -1),\n",
    "# }\n",
    "\n",
    "# # Define function to optimize\n",
    "# def optimize(params):\n",
    "#     encoding_dim = int(params['encoding_dim'])\n",
    "#     decoding_dim = int(params['decoding_dim'])\n",
    "#     batch_size = params['batch_size']\n",
    "#     learning_rate = params['learning_rate']\n",
    "    \n",
    "#     # Define autoencoder architecture\n",
    "#     input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "#     input_layer = Input(shape=(input_dim,))\n",
    "#     hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "#     output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "#     autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "#     autoencoder.compile(optimizer=Adam(lr=learning_rate), loss='mse')\n",
    "\n",
    "#     # Define cross-validation parameters\n",
    "#     kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "#     losses = []\n",
    "\n",
    "#     # Train and evaluate model using cross-validation\n",
    "#     for train_idx, val_idx in kf.split(X_train_resampled_final):\n",
    "#         # Split data into training and validation sets\n",
    "#         train_data, val_data = X_train_resampled_final[train_idx], X_train_resampled_final[val_idx]\n",
    "\n",
    "#         # Train model\n",
    "#         autoencoder.fit(train_data, train_data, epochs=1, batch_size=batch_size, validation_data=(val_data, val_data), verbose=0)\n",
    "\n",
    "#         # Evaluate model\n",
    "#         val_loss = autoencoder.evaluate(val_data, val_data, verbose=0)\n",
    "#         losses.append(val_loss)\n",
    "\n",
    "#     # Calculate mean validation loss across folds\n",
    "#     mean_loss = np.mean(losses)\n",
    "\n",
    "#     return {'loss': mean_loss, 'status': STATUS_OK}\n",
    "\n",
    "# # Run hyperparameter optimization\n",
    "# best = fmin(fn=optimize, space=space, algo=tpe.suggest, max_evals=7)\n",
    "\n",
    "# print(\"Best hyperparameters:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ee28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "\n",
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 50, 1),\n",
    "    #'decoding_dim': hp.quniform('decoding_dim', 5, 20, 1),\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -1),\n",
    "}\n",
    "\n",
    "\n",
    "def optimize(params):\n",
    "    encoding_dim = int(params['encoding_dim'])\n",
    "    #decoding_dim = int(params['decoding_dim']) # Change to 10\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    \n",
    "    # Define autoencoder architecture\n",
    "    input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(lr=learning_rate), loss='mse')\n",
    "\n",
    "    # Define cross-validation parameters\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    # Train and evaluate model using cross-validation\n",
    "    for train_idx, val_idx in kf.split(X_train_resampled_final):\n",
    "        # Split data into training and validation sets\n",
    "        train_data, val_data = X_train_resampled_final[train_idx], X_train_resampled_final[val_idx]\n",
    "\n",
    "        # Train model\n",
    "        autoencoder.fit(train_data, train_data, epochs=1, batch_size=batch_size, validation_data=(val_data, val_data), verbose=0)\n",
    "\n",
    "        # Evaluate model\n",
    "        val_loss = autoencoder.evaluate(val_data, val_data, verbose=0)\n",
    "        losses.append(val_loss)\n",
    "\n",
    "    # Calculate mean validation loss across folds\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    return {'loss': mean_loss, 'status': STATUS_OK}\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "best = fmin(fn=optimize, space=space, algo=tpe.suggest, max_evals=2)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2778b7",
   "metadata": {},
   "source": [
    "## Fit the autoencoder on the chosen hyperparameters and check over/under fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Dense\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# # create the autoencoder\n",
    "# input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "# encoding_dim = 46\n",
    "# decoding_dim = 10\n",
    "\n",
    "# input_layer = Input(shape=(input_dim,))\n",
    "# hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "# output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# # define the optimizer with the desired learning rate\n",
    "# opt = Adam(lr=0.014369161327797432)\n",
    "\n",
    "# #MSE is a common choice for reconstruction-based autoencoders.\n",
    "# autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "# autoencoder.compile(optimizer='adam', loss='mse')\n",
    "# autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=10, batch_size=2)\n",
    "\n",
    "# # extract hidden layer output from autoencoder\n",
    "# hidden_layer_model = Model(inputs=autoencoder.input, outputs=autoencoder.layers[1].output)\n",
    "# hidden_layer_output = hidden_layer_model.predict(X_train_resampled_final)\n",
    "\n",
    "# # create the mediator network with the hidden layer output as input\n",
    "# mediator_input_layer = Input(shape=(encoding_dim,))\n",
    "# mediator_hidden_layer = Dense(10, activation='relu')(mediator_input_layer)\n",
    "# mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "# mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "# mediator_network.compile(optimizer='adam', loss='mse')\n",
    "# mediator_network.fit(hidden_layer_output, y_train_resampled_final, epochs=1)\n",
    "\n",
    "# # extract hidden layer output from mediator network\n",
    "# agent_hidden_layer_output = mediator_network.layers[1].output\n",
    "\n",
    "# agent_input_layer = Input(shape=agent_hidden_layer_output.shape[1:])\n",
    "# agent_hidden_layer = Dense(5, activation='relu')(agent_input_layer)\n",
    "# agent_output_layer = Dense(2, activation='softmax')(agent_hidden_layer)\n",
    "\n",
    "# agent_network = Model(inputs=agent_input_layer, outputs=agent_output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89749a66",
   "metadata": {},
   "source": [
    "## R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e76423ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B97A6FBCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B97A6FBCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B9526C2318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B9526C2318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9884\\3449066885.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m# Calculate the mean and standard deviation of MSE for training and validation sets across all folds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mmean_train_mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mstd_train_mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_mse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[0mmean_val_mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mstd_val_mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_mse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstd\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mstd\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m   3580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3581\u001b[0m     return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[1;32m-> 3582\u001b[1;33m                          **kwargs)\n\u001b[0m\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_std\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    261\u001b[0m          where=True):\n\u001b[0;32m    262\u001b[0m     ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[1;32m--> 263\u001b[1;33m                keepdims=keepdims, where=where)\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n\u001b[1;32m--> 223\u001b[1;33m                                  subok=False)\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0marrmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrmean\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 30\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "#hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "# Add L1 regularization to the hidden layer\n",
    "hidden_layer = Dense(encoding_dim, activation='relu', kernel_regularizer=regularizers.l1(0.015))(input_layer)\n",
    "\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# Define the optimizer with the desired learning rate\n",
    "opt = Adam(lr= 0.00874103303583597)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "#autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 2\n",
    "kf = KFold(n_splits=n_splits,shuffle=True,random_state=18)\n",
    "\n",
    "# Define lists to store the MSE of training and validation sets for each fold\n",
    "train_mse = []\n",
    "val_mse = []\n",
    "recon_errors = []\n",
    "\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, val_index in kf.split(X_train_resampled_final):\n",
    "    \n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    X_train_fold, X_val_fold = X_train_resampled_final[train_index], X_train_resampled_final[val_index]\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # Fit the autoencoder on the training set for the current fold\n",
    "    history = autoencoder.fit(X_train_fold, X_train_fold, epochs=10, batch_size=32, verbose=0, validation_data=(X_val_fold, X_val_fold),callbacks=[early_stopping])\n",
    "    \n",
    "    # Append the MSE of training and validation sets for the current fold to the lists\n",
    "    train_mse.append(history.history['loss'])\n",
    "    val_mse.append(history.history['val_loss'])\n",
    "    \n",
    "    # compute the reconstruction error for the test data\n",
    "    recon_error = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "    recon_errors.append(recon_error)\n",
    "\n",
    "# Calculate the mean and standard deviation of MSE for training and validation sets across all folds\n",
    "# mean_train_mse = np.mean(train_mse, axis=0)\n",
    "# std_train_mse = np.std(train_mse, axis=0)\n",
    "# mean_val_mse = np.mean(val_mse, axis=0)\n",
    "# std_val_mse = np.std(val_mse, axis=0)\n",
    "# Calculate the mean and standard deviation of MSE for training and validation sets across all folds\n",
    "mean_train_mse = np.mean(train_mse, axis=0)\n",
    "std_train_mse = np.std(np.array(train_mse), axis=0)\n",
    "mean_val_mse = np.mean(val_mse, axis=0)\n",
    "std_val_mse = np.std(np.array(val_mse), axis=0)\n",
    "\n",
    "\n",
    "# Plot the MSE of training and validation sets against the number of epochs\n",
    "epochs = range(1, len(mean_train_mse)+1)\n",
    "plt.plot(epochs, mean_train_mse, 'b', label='Training MSE')\n",
    "plt.fill_between(epochs, mean_train_mse - std_train_mse, mean_train_mse + std_train_mse, alpha=0.2, color='b')\n",
    "plt.plot(epochs, mean_val_mse, 'r', label='Validation MSE')\n",
    "plt.fill_between(epochs, mean_val_mse - std_val_mse, mean_val_mse + std_val_mse, alpha=0.2, color='r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the distribution of reconstruction errors\n",
    "plt.hist(recon_errors, bins=5)\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Reconstruction Errors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a471e",
   "metadata": {},
   "source": [
    "## More runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 30\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "#hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "# Add L1 regularization to the hidden layer\n",
    "hidden_layer = Dense(encoding_dim, activation='relu', kernel_regularizer=regularizers.l1(0.15))(input_layer)\n",
    "\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# Define the optimizer with the desired learning rate\n",
    "opt = Adam(lr= 0.00874103303583597)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "#autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 2\n",
    "kf = KFold(n_splits=n_splits, random_state=42,shuffle=True)\n",
    "\n",
    "# Define lists to store the MSE of training and validation sets for each fold\n",
    "train_mse = []\n",
    "val_mse = []\n",
    "recon_errors = []\n",
    "\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, val_index in kf.split(X_train_resampled_final):\n",
    "    \n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    X_train_fold, X_val_fold = X_train_resampled_final[train_index], X_train_resampled_final[val_index]\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # Fit the autoencoder on the training set for the current fold\n",
    "    history = autoencoder.fit(X_train_fold, X_train_fold, epochs=10, batch_size=32, verbose=0, validation_data=(X_val_fold, X_val_fold),callbacks=[early_stopping])\n",
    "    \n",
    "    # Append the MSE of training and validation sets for the current fold to the lists\n",
    "    train_mse.append(history.history['loss'])\n",
    "    val_mse.append(history.history['val_loss'])\n",
    "    \n",
    "    # compute the reconstruction error for the test data\n",
    "    recon_error = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "    recon_errors.append(recon_error)\n",
    "\n",
    "# # Convert the train_mse and val_mse lists to numpy arrays\n",
    "# train_mse = np.array(train_mse)\n",
    "# val_mse = np.array(val_mse)\n",
    "\n",
    "mean_train_mse = np.mean(train_mse, axis=0)\n",
    "std_train_mse = np.std(train_mse, axis=0)\n",
    "mean_val_mse = np.mean(val_mse, axis=0)\n",
    "std_val_mse = np.std(val_mse, axis=0)\n",
    "\n",
    "# Plot the MSE of training and validation sets against the number of epochs\n",
    "epochs = range(1, len(mean_train_mse)+1)\n",
    "plt.plot(epochs, mean_train_mse, 'b', label='Training MSE')\n",
    "plt.fill_between(epochs, mean_train_mse - std_train_mse, mean_train_mse + std_train_mse, alpha=0.2, color='b')\n",
    "plt.plot(epochs, mean_val_mse, 'r', label='Validation MSE')\n",
    "plt.fill_between(epochs, mean_val_mse - std_val_mse, mean_val_mse + std_val_mse, alpha=0.2, color='r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56162a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 30\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "#hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "# Add L1 regularization to the hidden layer\n",
    "hidden_layer = Dense(encoding_dim, activation='relu', kernel_regularizer=regularizers.l1(0.08))(input_layer)\n",
    "\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# Define the optimizer with the desired learning rate\n",
    "opt = Adam(lr=0.00874103303583597)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "#autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 2\n",
    "kf = KFold(n_splits=n_splits,shuffle=True,random_state=18)\n",
    "\n",
    "# Define lists to store the MSE of training and validation sets for each fold\n",
    "train_mse = []\n",
    "val_mse = []\n",
    "recon_errors = []\n",
    "\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, val_index in kf.split(X_train_resampled_final):\n",
    "    \n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    X_train_fold, X_val_fold = X_train_resampled_final[train_index], X_train_resampled_final[val_index]\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # Fit the autoencoder on the training set for the current fold\n",
    "    history = autoencoder.fit(X_train_fold, X_train_fold, epochs=10, batch_size=32, verbose=0, validation_data=(X_val_fold, X_val_fold),callbacks=[early_stopping])\n",
    "    \n",
    "    # Append the MSE of training and validation sets for the current fold to the lists\n",
    "    train_mse.append(history.history['loss'])\n",
    "    val_mse.append(history.history['val_loss'])\n",
    "    \n",
    "    # compute the reconstruction error for the test data\n",
    "    recon_error = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "    recon_errors.append(recon_error)\n",
    "\n",
    "# Calculate the mean and standard deviation of MSE for training and validation sets across all folds\n",
    "# mean_train_mse = np.mean(train_mse, axis=0)\n",
    "# std_train_mse = np.std(train_mse, axis=0)\n",
    "\n",
    "# Convert the train_mse and val_mse lists to numpy arrays\n",
    "train_mse = np.array(train_mse)\n",
    "val_mse = np.array(val_mse)\n",
    "\n",
    "mean_train_mse = np.mean(train_mse, axis=0)\n",
    "std_train_mse = np.std(np.array(train_mse), axis=0)\n",
    "mean_val_mse = np.mean(val_mse, axis=0)\n",
    "std_val_mse = np.std(np.array(val_mse), axis=0)\n",
    "\n",
    "# Plot the MSE of training and validation sets against the number of epochs\n",
    "epochs = range(1, len(mean_train_mse)+1)\n",
    "plt.plot(epochs, mean_train_mse, 'b', label='Training MSE')\n",
    "plt.fill_between(epochs, mean_train_mse - std_train_mse, mean_train_mse + std_train_mse, alpha=0.2, color='b')\n",
    "plt.plot(epochs, mean_val_mse, 'r', label='Validation MSE')\n",
    "plt.fill_between(epochs, mean_val_mse - std_val_mse, mean_val_mse + std_val_mse, alpha=0.2, color='r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the distribution of reconstruction errors\n",
    "plt.hist(recon_errors, bins=5)\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Reconstruction Errors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89acd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from keras.layers import Input, Dense\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "# from sklearn.model_selection import KFold\n",
    "# import numpy as np\n",
    "# from keras import regularizers\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# # Define the autoencoder architecture\n",
    "# input_dim = X_train_resampled_final.shape[1]\n",
    "# encoding_dim = 30\n",
    "# decoding_dim = 10\n",
    "\n",
    "# input_layer = Input(shape=(input_dim,))\n",
    "# #hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "# # Add L1 regularization to the hidden layer\n",
    "# hidden_layer = Dense(encoding_dim, activation='relu', kernel_regularizer=regularizers.l1(0.15))(input_layer)\n",
    "\n",
    "# output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# # Define the optimizer with the desired learning rate\n",
    "# opt = Adam(lr= 0.00874103303583597)\n",
    "\n",
    "# # Define the autoencoder model\n",
    "# autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "# #autoencoder.compile(optimizer='adam', loss='mse')\n",
    "# autoencoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# # Define the number of folds for cross-validation\n",
    "# n_splits = 2\n",
    "# kf = KFold(n_splits=n_splits, random_state=42,shuffle=True)\n",
    "\n",
    "# # Define lists to store the MSE of training and validation sets for each fold\n",
    "# train_mse = []\n",
    "# val_mse = []\n",
    "# recon_errors = []\n",
    "\n",
    "\n",
    "# # Loop over each fold\n",
    "# for train_index, val_index in kf.split(X_train_resampled_final):\n",
    "    \n",
    "#     # Split the data into training and validation sets for the current fold\n",
    "#     X_train_fold, X_val_fold = X_train_resampled_final[train_index], X_train_resampled_final[val_index]\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "#     # Fit the autoencoder on the training set for the current fold\n",
    "#     history = autoencoder.fit(X_train_fold, X_train_fold, epochs=10, batch_size=32, verbose=0, validation_data=(X_val_fold, X_val_fold),callbacks=[early_stopping])\n",
    "    \n",
    "#     # Append the MSE of training and validation sets for the current fold to the lists\n",
    "#     train_mse.append(history.history['loss'])\n",
    "#     val_mse.append(history.history['val_loss'])\n",
    "    \n",
    "#     # compute the reconstruction error for the test data\n",
    "#     recon_error = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "#     recon_errors.append(recon_error)\n",
    "\n",
    "# # Convert the train_mse and val_mse lists to numpy arrays\n",
    "# train_mse = np.array(train_mse)\n",
    "# val_mse = np.array(val_mse)\n",
    "\n",
    "# # Calculate the mean and standard deviation of MSE for training and validation sets across all folds\n",
    "# mean_train_mse = np.mean(train_mse, axis=0)\n",
    "# std_train_mse = np.std(train_mse, axis=0)\n",
    "# mean_val_mse = np.mean(val_mse, axis=0)\n",
    "# std_val_mse = np.std(val_mse, axis=0)\n",
    "\n",
    "\n",
    "# # Plot the MSE of training and validation sets against the number of epochs\n",
    "# epochs = range(1, len(mean_train_mse)+1)\n",
    "# plt.plot(epochs, mean_train_mse, 'b', label='Training MSE')\n",
    "# plt.fill_between(epochs, mean_train_mse - std_train_mse, mean_train_mse + std_train_mse, alpha=0.2, color='b')\n",
    "# plt.plot(epochs, mean_val_mse, 'r', label='Validation MSE')\n",
    "# plt.fill_between(epochs, mean_val_mse - std_val_mse, mean_val_mse + std_val_mse, alpha=0.2, color='r')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Mean Squared Error (MSE)')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e577f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca527cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(autoencoder, to_file='autoencoder_new.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd8b5e",
   "metadata": {},
   "source": [
    "## Check if mediator network overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract hidden layer output from autoencoder\n",
    "hidden_layer_model = Model(inputs=autoencoder.input, outputs=autoencoder.layers[1].output)\n",
    "hidden_layer_output = hidden_layer_model.predict(X_train_resampled_final)\n",
    "\n",
    "# create the mediator network with the hidden layer output as input\n",
    "mediator_input_layer = Input(shape=(encoding_dim,))\n",
    "mediator_hidden_layer = Dense(10, activation='relu')(mediator_input_layer)\n",
    "mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "mediator_network.compile(optimizer='adam', loss='mse')\n",
    "mediator_network.fit(hidden_layer_output, y_train_resampled_final, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f52eac",
   "metadata": {},
   "source": [
    "## Reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = autoencoder.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error between the original and reconstructed data\n",
    "mse = np.mean(np.power(X_test- predictions, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reward function\n",
    "def reward_fn(action, label):\n",
    "    DF = [0,1,2]  # indices of fraud class\n",
    "    DN = [81,    787,   2392,   3121,   3449]  # indices of non-fraud class\n",
    "    terminal = 0  # initialize terminal flag to 0\n",
    "    if label in DF:\n",
    "        if action == label:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "            terminal = 1\n",
    "    else:\n",
    "        if action == label:\n",
    "            reward = 0.5  # set λ to 0.5\n",
    "        else:\n",
    "            reward = -0.5  # set λ to -0.5\n",
    "    return reward, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82377946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import keras\n",
    "# from keras import models, layers\n",
    "\n",
    "# # Initialize replay memory with M capacity\n",
    "# M = 10000\n",
    "# replay_memory = []\n",
    "\n",
    "# # Initialize simulation environment\n",
    "# env = None  # Replace with your own simulation environment\n",
    "\n",
    "# # Define the reward function\n",
    "# def reward_fn(action, label):\n",
    "#     # Replace with your own reward function\n",
    "#     if action == label:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "# # Define hyperparameters\n",
    "# K = 2  # Number of episodes\n",
    "# T = 2  # Number of timesteps per episode\n",
    "# gamma = 0.9  # Discount factor\n",
    "# batch_size = 32\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# # Initialize agent network with same architecture as mediator network\n",
    "# agent_network = keras.models.Sequential([\n",
    "#     keras.layers.Dense(20, activation='relu', input_shape=(10,)),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "# agent_network.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=learning_rate))\n",
    "\n",
    "# # Initialize mediator network\n",
    "# mediator_network = None  # Replace with your own mediator network\n",
    "\n",
    "# # Generate dataset D\n",
    "# hidden_layer_output = autoencoder.predict(X_train_resampled_final)\n",
    "# D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "# # Train agent\n",
    "# for k in range(K):\n",
    "#     # Shuffle dataset D\n",
    "#     np.random.shuffle(D)\n",
    "    \n",
    "#     # Initialize state\n",
    "#     state = D[0][0]\n",
    "    \n",
    "#     for t in range(T):\n",
    "#         # Choose action\n",
    "#         action = agent_network.predict(state.reshape(1, -1)).argmax()\n",
    "        \n",
    "#         # Calculate reward and terminal flag\n",
    "#         reward = reward_fn(action, D[t][1])\n",
    "#         terminal = 1 if t == T - 1 else 0\n",
    "#         print(\"Reward:\", reward) # Add this line to print the reward\n",
    "#         print(\"Terminal:\", terminal) # Add this line to print the terminal flag\n",
    "        \n",
    "#         # Update state\n",
    "#         state_next = D[t+1][0] if t < T - 1 else state\n",
    "        \n",
    "#         # Store transition in replay memory\n",
    "#         replay_memory.append((state, action, reward, state_next, terminal))\n",
    "#         if len(replay_memory) > M:\n",
    "#             replay_memory.pop(0)\n",
    "        \n",
    "#         # Sample minibatch from replay memory\n",
    "#         if len(replay_memory) >= batch_size:\n",
    "#             minibatch = random.sample(replay_memory, batch_size)\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#         X = np.zeros((batch_size, 10))\n",
    "#         y = np.zeros((batch_size, 10))\n",
    "#         for i in range(batch_size):\n",
    "#             state_i, action_i, reward_i, state_next_i, terminal_i = minibatch[i]\n",
    "#             X[i] = state_i\n",
    "#             y[i] = agent_network.predict(state_i.reshape(1, -1))\n",
    "#             if terminal_i:\n",
    "#                 y[i][action_i] = reward_i\n",
    "#             else:\n",
    "#                 y[i][action_i] = reward_i + gamma * np.max(agent_network.predict(state_next_i.reshape(1, -1)))\n",
    "        \n",
    "#         # Train agent network on minibatch\n",
    "#         agent_network.train_on_batch(X, y)\n",
    "        \n",
    "#         # Update state\n",
    "#         state = state_next\n",
    "        \n",
    "#         # Check if episode is over\n",
    "#         if terminal:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ee2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import keras\n",
    "# from keras import models, layers\n",
    "\n",
    "# # Initialize replay memory with M capacity\n",
    "# M = 10000\n",
    "# replay_memory = []\n",
    "\n",
    "# # Initialize simulation environment\n",
    "# env = None  # Replace with your own simulation environment\n",
    "\n",
    "# # Define the reward function\n",
    "# def reward_fn(action, label):\n",
    "#     # Replace with your own reward function\n",
    "#     if action == label:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "# # Define hyperparameters\n",
    "# K = 8  # Number of episodes\n",
    "# T = 8  # Number of timesteps per episode\n",
    "# gamma = 0.9  # Discount factor\n",
    "# batch_size = 32\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# # # Initialize agent network with same architecture as mediator network\n",
    "# # agent_network = keras.models.Sequential([\n",
    "# #     keras.layers.Dense(20, activation='relu', input_shape=(10,)),\n",
    "# #     keras.layers.Dense(2, activation='softmax')\n",
    "# # ])\n",
    "# # agent_network.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=learning_rate))\n",
    "\n",
    "# # #Initialize mediator network\n",
    "# # mediator_network = None  # Replace with your own mediator network\n",
    "\n",
    "# # Generate dataset D\n",
    "# hidden_layer_output = autoencoder.predict(X_train_resampled_final)\n",
    "# D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "# # Train agent\n",
    "# for k in range(K):\n",
    "#     # Shuffle dataset D\n",
    "#     np.random.shuffle(D)\n",
    "    \n",
    "#     # Initialize state\n",
    "#     state = D[0][0]\n",
    "    \n",
    "#     for t in range(T):\n",
    "#         # Choose action\n",
    "#         action = agent_network.predict(state.reshape(1, -1)).argmax()\n",
    "        \n",
    "#         # Calculate reward and terminal flag\n",
    "#         reward = reward_fn(action, D[t][1])\n",
    "#         terminal = 1 if t == T - 1 else 0\n",
    "#         print(\"Reward:\", reward) # Add this line to print the reward\n",
    "#         print(\"Terminal:\", terminal) # Add this line to print the terminal flag\n",
    "        \n",
    "#         # Update state\n",
    "#         state_next = D[t+1][0] if t < T - 1 else state\n",
    "        \n",
    "#         # Store transition in replay memory\n",
    "#         replay_memory.append((state, action, reward, state_next, terminal))\n",
    "#         if len(replay_memory) > M:\n",
    "#             replay_memory.pop(0)\n",
    "        \n",
    "#         # Sample minibatch from replay memory\n",
    "#         if len(replay_memory) >= batch_size:\n",
    "#             minibatch = random.sample(replay_memory, batch_size)\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#         X = np.zeros((batch_size, 10))\n",
    "#         y = np.zeros((batch_size, 10))\n",
    "#         for i in range(batch_size):\n",
    "#             state_i, action_i, reward_i, state_next_i, terminal_i = minibatch[i]\n",
    "#             X[i] = state_i\n",
    "#             y[i] = agent_network.predict(state_i.reshape(1, -1))\n",
    "#             if terminal_i:\n",
    "#                 y[i][action_i] = reward_i\n",
    "#             else:\n",
    "#                 y[i][action_i] = reward_i + gamma * np.max(agent_network.predict(state_next_i.reshape(1, -1)))\n",
    "        \n",
    "#         # Train agent network on minibatch\n",
    "#         agent_network.train_on_batch(X, y)\n",
    "        \n",
    "#         # Update state\n",
    "#         state = state_next\n",
    "        \n",
    "#         # Check if episode is over\n",
    "#         if terminal:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d5d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import models, layers\n",
    "import random\n",
    "\n",
    "# Initialize replay memory with M capacity\n",
    "M = 10000\n",
    "replay_memory = []\n",
    "\n",
    "# Initialize simulation environment\n",
    "env = None  # Replace with your own simulation environment\n",
    "\n",
    "# # Define the reward function\n",
    "# def reward_fn(action, label):\n",
    "#     # Replace with your own reward function\n",
    "#     if action == label:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "K = 2  # Number of episodes\n",
    "T = 2  # Number of timesteps per episode\n",
    "gamma = 0.9  # Discount factor\n",
    "batch_size = 32\n",
    "learning_rate_val = 0.001\n",
    "\n",
    "mediator_network = keras.models.Sequential([\n",
    "    keras.layers.Dense(20, activation='relu', input_shape=(10,)),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "mediator_network.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=learning_rate_val))\n",
    "\n",
    "\n",
    "# Generate dataset D\n",
    "# X_train_resampled_final_20 = np.hstack((X_train_resampled_final, np.zeros((X_train_resampled_final.shape[0], 10))))\n",
    "# hidden_layer_output = [mediator_network.predict(np.array([x]*2).reshape(2, -1))[0] for x in X_train_resampled_final]\n",
    "# D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "hidden_layer_output = mediator_network.predict(X_train_resampled_final)\n",
    "D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "# Train agent\n",
    "for k in range(K):\n",
    "    # Shuffle dataset D\n",
    "    np.random.shuffle(D)\n",
    "    \n",
    "    # Initialize state\n",
    "    state = D[0][0]\n",
    "    \n",
    "    for t in range(T):\n",
    "        # Choose action\n",
    "        action = agent_network.predict(state.reshape(1, -1)).argmax()\n",
    "        \n",
    "        # Calculate reward and terminal flag\n",
    "        reward = reward_fn(action, D[t][1])\n",
    "        terminal = 1 if t == T - 1 else 0\n",
    "        print(\"Reward:\", reward) # Add this line to print the reward\n",
    "        print(\"Terminal:\", terminal) # Add this line to print the terminal flag\n",
    "        \n",
    "        # Update state\n",
    "        state_next = D[t+1][0] if t < T - 1 else state\n",
    "        \n",
    "        # Store transition in replay memory\n",
    "        replay_memory.append((state, action, reward, state_next, terminal))\n",
    "        if len(replay_memory) > M:\n",
    "            replay_memory.pop(0)\n",
    "        \n",
    "        # Sample minibatch from replay memory\n",
    "        if len(replay_memory) >= batch_size:\n",
    "            minibatch = random.sample(replay_memory, batch_size)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        X = np.zeros((batch_size, 10))\n",
    "        y = np.zeros((batch_size, 10))\n",
    "        for i in range(batch_size):\n",
    "            state_i, action_i, reward_i, state_next_i, terminal_i = minibatch[i]\n",
    "            X[i] = state_i\n",
    "            y[i] = agent_network.predict(state_i.reshape(1, -1))\n",
    "            if terminal_i:\n",
    "                y[i][action_i] = reward_i\n",
    "            else:\n",
    "                y[i][action_i] = reward_i + gamma * np.max(agent_network.predict(state_next_i.reshape(1, -1)))\n",
    "        \n",
    "        # Train agent network on minibatch - CONCEPT OF GRADIENT DESCENT\n",
    "        agent_network.train_on_batch(X, y)\n",
    "        \n",
    "        # Update state\n",
    "        state = state_next\n",
    "        \n",
    "        # Check if episode is over\n",
    "        if terminal:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6610007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import models, layers\n",
    "import random\n",
    "\n",
    "# Initialize replay memory with M capacity\n",
    "M = 10000\n",
    "replay_memory = []\n",
    "\n",
    "# Initialize simulation environment\n",
    "env = None  # Replace with your own simulation environment\n",
    "\n",
    "# # Define the reward function\n",
    "# def reward_fn(action, label):\n",
    "#     # Replace with your own reward function\n",
    "#     if action == label:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "# Define policy\n",
    "def policy(state, model):\n",
    "    q_values = model.predict(state)\n",
    "    return np.argmax(q_values[0])\n",
    "\n",
    "# Define hyperparameters\n",
    "K = 2  # Number of episodes\n",
    "T = 2  # Number of timesteps per episode\n",
    "gamma = 0.9  # Discount factor\n",
    "batch_size = 32\n",
    "learning_rate_val = 0.001\n",
    "\n",
    "mediator_network = keras.models.Sequential([\n",
    "    keras.layers.Dense(20, activation='relu', input_shape=(10,)),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "mediator_network.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=learning_rate_val))\n",
    "\n",
    "\n",
    "# Generate dataset D\n",
    "# X_train_resampled_final_20 = np.hstack((X_train_resampled_final, np.zeros((X_train_resampled_final.shape[0], 10))))\n",
    "# hidden_layer_output = [mediator_network.predict(np.array([x]*2).reshape(2, -1))[0] for x in X_train_resampled_final]\n",
    "# D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "hidden_layer_output = mediator_network.predict(X_train_resampled_final)\n",
    "D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "# Train agent\n",
    "for k in range(K):\n",
    "    # Shuffle dataset D\n",
    "    np.random.shuffle(D)\n",
    "    \n",
    "    # Initialize state\n",
    "    state = D[0][0]\n",
    "    \n",
    "    for t in range(T):\n",
    "        # Choose action based on policy\n",
    "        action = policy(state.reshape(1, -1), agent_network)\n",
    "        \n",
    "        # Calculate reward and terminal flag\n",
    "        reward = reward_fn(action, D[t][1])\n",
    "        terminal = 1 if t == T - 1 else 0\n",
    "        print(\"Reward:\", reward) # Add this line to print the reward\n",
    "        print(\"Terminal:\", terminal) # Add this line to print the terminal flag\n",
    "        \n",
    "        # Update state\n",
    "        state_next = D[t+1][0] if t < T - 1 else state\n",
    "        \n",
    "        # Store transition in replay memory\n",
    "        replay_memory.append((state, action, reward, state_next, terminal))\n",
    "        if len(replay_memory) > M:\n",
    "            replay_memory.pop(0)\n",
    "        \n",
    "        # Sample minibatch from replay memory\n",
    "        if len(replay_memory) >= batch_size:\n",
    "            minibatch = random.sample(replay_memory, batch_size)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        X = np.zeros((batch_size, 10))\n",
    "        y = np.zeros((batch_size, 10))\n",
    "        for i in range(batch_size):\n",
    "            state_i, action_i, reward_i, state_next_i, terminal_i = minibatch[i]\n",
    "            X[i] = state_i\n",
    "            y[i] = agent_network.predict(state_i.reshape(1, -1))\n",
    "            if terminal_i:\n",
    "                y[i][action_i] = reward_i\n",
    "            else:\n",
    "                y[i][action_i] = reward_i + gamma * np.max(agent_network.predict(state_next_i.reshape(1, -1)))\n",
    "                    mediator_network.train_on_batch(X, y)\n",
    "    \n",
    "        # Update state\n",
    "        state = state_next\n",
    "\n",
    "        # Check if episode is over\n",
    "        if terminal:\n",
    "            break\n",
    "\n",
    "# Evaluate policy πθ\n",
    "rewards = []\n",
    "for i in range(len(D)):\n",
    "    state = D[i][0]\n",
    "    label = D[i][1]\n",
    "    action_probs = mediator_network.predict(np.array([state]*10).reshape(10, -1))\n",
    "    action = np.argmax(action_probs)\n",
    "    reward = reward_fn(action, label)\n",
    "    rewards.append(reward)\n",
    "print(\"Average reward:\", np.mean(rewards)) # Add this line to print the average reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d637de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediator_network.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
