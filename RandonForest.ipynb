{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc296ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "007b26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d8c9e",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the values in the isFraud column to Non-Fraud and Fraud\n",
    "df[\"isFraud\"] = df[\"isFraud\"].map({0: \"Non-Fraud\", 1: \"Fraud\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a72ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts of the isFraud column\n",
    "counts = df['isFraud'].value_counts().rename_axis('isFraud').reset_index(name='count')\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d87092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the count of Non-Fraud and Fraud using a barplot\n",
    "plt.figure(figsize=(5.5, 5.5))\n",
    "sns.barplot(x='isFraud', y='count', data=counts, color='pink', edgecolor =\"b\")\n",
    "plt.title('Count of Non-Fraudulent & Fraudulent Transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFraud\"] = df[\"isFraud\"].replace({\"Non-Fraud\": 0, \"Fraud\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd371e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"isFraud\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cdf4e8",
   "metadata": {},
   "source": [
    "## Feature Encoding on entire dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b9d8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of label Encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['type'])\n",
    "\n",
    "# printing label\n",
    "label\n",
    "\n",
    "# removing the column 'type' from df\n",
    "# as it is of no use now.\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "\n",
    "# Appending the array to our dataFrame\n",
    "# with column name 'type'\n",
    "df[\"type\"] = label\n",
    "\n",
    "\n",
    "# printing Dataframe\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4306aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of label Encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Using .fit_transform function to fit label and return encoded label\n",
    "label = le.fit_transform(df['type'])\n",
    "\n",
    "# removing the column 'type' from df as it is of no use now.\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "\n",
    "# Appending the array to our dataFrame with column name 'type'\n",
    "df[\"type\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5778b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameDest'])\n",
    "label\n",
    "df.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df[\"nameDest\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc78ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameOrig'])\n",
    "label\n",
    "df.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df[\"nameOrig\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f57a6d",
   "metadata": {},
   "source": [
    "# Split into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a04c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# Split the data into a 80%-20% train-test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=18)\n",
    "\n",
    "# Split the training set again into a 75%-25% train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ead6d7",
   "metadata": {},
   "source": [
    "The count of target variable without stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaecd560",
   "metadata": {},
   "source": [
    "## Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b38a972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.99871\n",
      "1    0.00129\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# Split the data into a 80%-20% train-test split with stratification\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=18, stratify=y)\n",
    "\n",
    "# Split the training set again into a 75%-25% train-validation split with stratification\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=18, stratify=y_train_full)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "668541a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3817572, 10)\n",
      "(1272524, 10)\n",
      "(1272524, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662a3ab",
   "metadata": {},
   "source": [
    "# Save train, test and validation sets to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23918644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from X_val and y_val\n",
    "val_df = pd.DataFrame(X_val, columns=X_train.columns)\n",
    "val_df['isFraud'] = y_val\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "val_df.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\train.csv\", index=False)\n",
    "X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e07573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3aed3",
   "metadata": {},
   "source": [
    "# Modified Z-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns you want to check for outliers\n",
    "columns_to_trim = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Calculate modified Z-score for each column\n",
    "for col in columns_to_trim:\n",
    "    # Extract column values\n",
    "    col_values = X_train[col].values\n",
    "\n",
    "    # Calculate median and MAD\n",
    "    med = np.median(col_values)\n",
    "    mad = np.median(np.abs(col_values - med))\n",
    "    if mad == 0:\n",
    "        mad = 1e-6  # Set MAD to a small non-zero value to avoid division by zero\n",
    "\n",
    "    # Calculate modified Z-score\n",
    "    z_score = 0.6745 * (col_values - med) / mad\n",
    "\n",
    "    # Count number of lower and upper outliers\n",
    "    lower_outliers = np.sum(z_score < -2.5)\n",
    "    upper_outliers = np.sum(z_score > 2.5)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Column {col}\")\n",
    "    print(f\"Number of lower outliers for column: {lower_outliers}\")\n",
    "    print(f\"Number of upper outliers: {upper_outliers}\")\n",
    "    print(f\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b5399",
   "metadata": {},
   "source": [
    "## Skewness before removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca60a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "skewness = skew(X_train.amount)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.oldbalanceOrg)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.newbalanceOrig)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.oldbalanceDest)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.newbalanceDest)\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8189555",
   "metadata": {},
   "source": [
    "## Trim proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125178f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Extract the columns of interest\n",
    "cols = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "data = X_train[cols]\n",
    "\n",
    "# Loop over each column and determine the direction of trimming\n",
    "for col in cols:\n",
    "    # Calculate the median and interquartile range of the column\n",
    "    median = np.median(data[col])\n",
    "    iqr = np.percentile(data[col], 75) - np.percentile(data[col], 25)\n",
    "\n",
    "    # Calculate the skewness of the column\n",
    "    skewness = data[col].skew()\n",
    "\n",
    "    # Determine whether to use symmetric or asymmetric trimming based on the skewness and IQR\n",
    "    if abs(skewness) > 1.5 or iqr > 2 * abs(median):\n",
    "        print(f\"For column {col}, the data is skewed and heavy-tailed, so asymmetric trimming may be appropriate.\")\n",
    "    else:\n",
    "        print(f\"For column {col}, the data is roughly symmetric, so symmetric trimming may be appropriate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84df595",
   "metadata": {},
   "source": [
    "## Asymmetric trimmed means and Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1a2f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 70105.81895973942, 'oldbalanceOrg': 20631.978172342868, 'newbalanceOrig': 5359.655760140145, 'oldbalanceDest': 137244.73693600064, 'newbalanceDest': 152687.2084515713}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed (11)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.2, 'oldbalanceOrg': 0.22, 'newbalanceOrig': 0.3,'oldbalanceDest': 0.27, 'newbalanceDest': 0.3}\n",
    "\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train.index, size=len(X_train), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train.loc[X_train[col_name] > np.percentile(X_train[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "\n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f51922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = (X_train['amount'] == 14793.948294785117).sum()\n",
    "# print(count)\n",
    "# count = (X_train['oldbalanceOrg'] == 6367.162451237726).sum()\n",
    "# print(count)\n",
    "# count = (X_train['newbalanceOrig'] == 990.4751087978151).sum()\n",
    "# print(count)\n",
    "# count = (X_train['oldbalanceDest'] ==  10188.054727652307).sum()\n",
    "# print(count)\n",
    "# count = (X_train['newbalanceDest'] == 19552.789367260193).sum()\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29728556",
   "metadata": {},
   "source": [
    "## Skewness after treating outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "999f62d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9882591226790532\n",
      "2.204696700365334\n",
      "3.6080154213914195\n",
      "1.7880044289835129\n",
      "1.633752276046139\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "skewness = skew(X_train.amount)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.oldbalanceOrg)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.newbalanceOrig)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.oldbalanceDest)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.newbalanceDest)\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48dc5d8",
   "metadata": {},
   "source": [
    "# Save train file after handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358784f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # save the trimmed train to new files\n",
    "X_train.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainAFTERHANDLINGOUTLIERS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbb386",
   "metadata": {},
   "source": [
    "# Check number of outliers after handling the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb6252",
   "metadata": {},
   "source": [
    "# Modified Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b05313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns you want to check for outliers\n",
    "columns_to_trim = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Calculate modified Z-score for each column\n",
    "for col in columns_to_trim:\n",
    "    # Extract column values\n",
    "    col_values = X_train[col].values\n",
    "\n",
    "    # Calculate median and MAD\n",
    "    med = np.median(col_values)\n",
    "    mad = np.median(np.abs(col_values - med))\n",
    "    if mad == 0:\n",
    "        mad = 1e-6  # Set MAD to a small non-zero value to avoid division by zero\n",
    "\n",
    "    # Calculate modified Z-score\n",
    "    z_score = 0.6745 * (col_values - med) / mad\n",
    "\n",
    "    # Count number of lower and upper outliers\n",
    "    lower_outliers = np.sum(z_score < -2.5)\n",
    "    upper_outliers = np.sum(z_score > 2.5)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Column {col}\")\n",
    "    print(f\"Number of lower outliers for column: {lower_outliers}\")\n",
    "    print(f\"Number of upper outliers: {upper_outliers}\")\n",
    "    print(f\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2b891",
   "metadata": {},
   "source": [
    "# Concept 1-Feature Selection using random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35692974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da18ac4",
   "metadata": {},
   "source": [
    "Add stratified K-fold Cross Validation (Good for imbalance set) to random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f7f47",
   "metadata": {},
   "source": [
    "## Run random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909fd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Define the parameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'min_samples_split': [2, 3, 4]\n",
    "# }\n",
    "\n",
    "# # Initialize StratifiedKFold with reduced number of samples\n",
    "# skfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# # Initialize Random Forest classifier\n",
    "# rfc = RandomForestClassifier(n_estimators=10, random_state=18, max_features='auto', min_samples_split=2, criterion='gini')\n",
    "\n",
    "# # Evaluate model using cross-validation\n",
    "# scores = cross_val_score(rfc, X_train, y_train, cv=skfold)\n",
    "\n",
    "# print(\"Cross-validation scores:\", scores)\n",
    "# print(\"Mean CV score:\", np.mean(scores))\n",
    "# print(\"Standard deviation of CV scores:\", np.std(scores))\n",
    "\n",
    "# # Initialize GridSearchCV with the parameter grid and StratifiedKFold\n",
    "# grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=skfold)\n",
    "\n",
    "# # Fit the grid search to the training data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and the corresponding mean test score\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "# print(\"Best mean test score:\", grid_search.best_score_)\n",
    "\n",
    "# # Predict on the test set using the best estimator from the grid search\n",
    "# best_estimator = grid_search.best_estimator_\n",
    "# y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# # Evaluate the accuracy of the best estimator on the test set\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d2d8b",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import cross_val_score, learning_curve\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Random Forest classifier\n",
    "# rfc = RandomForestClassifier(n_estimators=10, random_state=18, max_features='sqrt', min_samples_split=2,max_depth=4)\n",
    "\n",
    "# # Fit the model with cross-validation on the training set\n",
    "# cv_scores = cross_val_score(rfc, X_train, y_train, cv=5)\n",
    "\n",
    "# print(\"Cross-validation scores:\", cv_scores)\n",
    "# print(\"Mean CV score:\", np.mean(cv_scores))\n",
    "# print(\"Standard deviation of CV scores:\", np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bad13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute learning curves\n",
    "# train_sizes, train_scores, test_scores = learning_curve(rfc, X_train, y_train, cv=5, train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "# # Compute mean and standard deviation across folds\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "# test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d72ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot learning curves\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', label='Training score')\n",
    "# plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1)\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', label='Validation score')\n",
    "# plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1)\n",
    "# plt.xlabel('Training examples')\n",
    "# plt.ylabel('Score')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234dea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skfold=StratifiedKFold (n_splits=3)\n",
    "# # Initialize Random Forest classifier\n",
    "# rfc = RandomForestClassifier(n_estimators=10, random_state=18,max_features='auto',min_samples_split=2,criterion='gini')\n",
    "# scores=cross_val_score(rfc,X_train, y_train,cv=skfold)\n",
    "# print(np.mean(scores))\n",
    "# print(\"Cross-validation scores:\", scores)\n",
    "# print(\"Mean CV score:\", np.mean(scores))\n",
    "# print(\"Standard deviation of CV scores:\", np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab85654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float64 columns to float32\n",
    "float64_cols = df.select_dtypes(include=['float64']).columns\n",
    "df[float64_cols] = df[float64_cols].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25debabf",
   "metadata": {},
   "source": [
    "Task: 1. Adjust hyper-parameters\n",
    "2. Do stratiied cross-validation\n",
    "3.Plot OOB error rate vs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f98384",
   "metadata": {},
   "source": [
    "Graphs to plot for RF: https://www.researchgate.net/figure/ROC-graph-of-Random-Forest-Classifier-Method_fig4_336729141"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cba7f",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html#:~:text=The%20out%2Dof%2Dbag%20(,whilst%20being%20trained%20%5B1%5D. (TO PLOT)\n",
    "\n",
    "\n",
    "https://bookdown.org/mpfoley1973/data-sci/random-forests.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ccfe7c",
   "metadata": {},
   "source": [
    "## AUC/ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44fde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# Create lists to store evaluation metrics for each fold\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "accuracy_scores = []\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f'Fold: {fold+1}')\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Train a random forest model with 100 trees and a max depth of 4\n",
    "    rf_model = RandomForestClassifier(n_estimators=200, max_features='log2', min_samples_split=2,max_depth=4,class_weight=\"balanced\", oob_score=True, random_state=18,criterion=\"gini\")\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the class probabilities for the validation set\n",
    "    y_val_prob = rf_model.predict_proba(X_val)\n",
    "\n",
    "    # Compute the false positive rate (FPR) and true positive rate (TPR) for different probability thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_prob[:, 1])\n",
    "\n",
    "    # Compute the AUC score\n",
    "    auc_score = roc_auc_score(y_val, y_val_prob[:, 1])\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'Fold {fold+1}, AUC = {auc_score:.2f}')\n",
    "\n",
    "# Add labels and legend to the plot\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab49fa",
   "metadata": {},
   "source": [
    "How does this show there is no overfitting?\n",
    "\n",
    "The plot shows that as the number of trees (n_estimators) increases, the OOB error rate initially decreases and then stabilizes, with no further significant reduction in error rate as more trees are added. This pattern indicates that adding more trees does not lead to significant improvements in performance beyond a certain point, and the model is not overfitting to the training data.\n",
    "\n",
    "In other words, if the model were overfitting, we would expect to see the OOB error rate decrease as more trees are added, but eventually start to increase again as the model begins to overfit to the training data. However, since the error rate stabilizes and does not increase significantly as more trees are added, this suggests that the model is not overfitting and has reached an optimal level of complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b845b4c",
   "metadata": {},
   "source": [
    "# Perform Cost sensitive learning for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the weights for each class based on the cost of misclassification\n",
    "class_weights = {0:1, 1:10} # adjust the values based on your specific problem\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# Create lists to store evaluation metrics for each fold\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "accuracy_scores = []\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f'Fold: {fold+1}')\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "\n",
    "    # Train a random forest model with 200 trees and a max depth of 4\n",
    "    rf_model = RandomForestClassifier(n_estimators=200, max_features='log2', min_samples_split=2, max_depth=4, class_weight=class_weights, oob_score=True, random_state=18, criterion=\"gini\")\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the class probabilities for the validation set\n",
    "    y_val_prob = rf_model.predict_proba(X_val)\n",
    "\n",
    "    # Compute the false positive rate (FPR) and true positive rate (TPR) for different probability thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_prob[:, 1])\n",
    "\n",
    "    # Compute the AUC score\n",
    "    auc_score = roc_auc_score(y_val, y_val_prob[:, 1])\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'Fold {fold+1}, AUC = {auc_score:.2f}')\n",
    "\n",
    "# Add labels and legend to the plot\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef40ccf",
   "metadata": {},
   "source": [
    "## OOB error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the range of n_estimators values to test\n",
    "# n_estimators_range = range(10, 101, 10)\n",
    "\n",
    "# # Train a random forest model for each value of n_estimators and compute the OOB error\n",
    "# oob_error = []\n",
    "# for n_estimators in n_estimators_range:\n",
    "#     rf_model = RandomForestClassifier(n_estimators=200, max_features='log2', min_samples_split=2,max_depth=4,class_weight=\"balanced\", oob_score=True, random_state=18,criterion=\"gini\")\n",
    "#     rf_model.fit(X_train, y_train)\n",
    "#     oob_error.append(1 - rf_model.oob_score_)\n",
    "\n",
    "# # Plot the OOB error rate against n_estimators\n",
    "# plt.plot(n_estimators_range, oob_error)\n",
    "# plt.xlabel('Number of trees')\n",
    "# plt.ylabel('OOB error rate')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571715c",
   "metadata": {},
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
    "\n",
    "# Evaluate the classifier on the validation set\n",
    "y_pred_val = rfc.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "precision = precision_score(y_val, y_pred_val)\n",
    "recall = recall_score(y_val, y_pred_val)\n",
    "f1 = f1_score(y_val, y_pred_val)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1-Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec71809",
   "metadata": {},
   "source": [
    "4. Regularization\n",
    "If Overfitting occurs in a too complex model, it makes sense to reduce features. Regularization techniques such as Lasso and L1 are useful when you need to know which features to remove from your model. Regularization applies a “penalty” to input parameters with more significant coefficients and subsequently limits the variance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a130c65",
   "metadata": {},
   "source": [
    "Overfitting: If your model is overfitting, meaning that it is fitting too closely to the training data and not generalizing well to new data, increasing the min_samples_split value can help. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ba9eb",
   "metadata": {},
   "source": [
    "# Concept 1- Feature selection using Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# Select the top k features based on mutual information\n",
    "k = 5\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "\n",
    "# Print the names of the selected features\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd0605f",
   "metadata": {},
   "source": [
    "# Random Forest Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e6713",
   "metadata": {},
   "source": [
    "As we can see, there are hyperparameters which can be adjusted:\n",
    "The RandomForestClassifier in scikit-learn has a number of hyperparameters that can be tuned to optimize model performance. Here are some of the most commonly used ones:\n",
    "1. n_estimators\n",
    "2.max_depth\n",
    "3.min_samples_split\n",
    "4.bootstrap\n",
    "5.min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier with the desired hyperparameters\n",
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=10, min_samples_split=2, min_samples_leaf=1, max_features='auto', bootstrap=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7810042",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Mean Decrease in Gini Importance\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "#plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices])\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20049b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(rfc, X_train, y_train, n_repeats=10, random_state=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Mean Decrease in Accuracy Importance\")\n",
    "plt.bar(range(X_train.shape[1]), result.importances_mean[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4d13b",
   "metadata": {},
   "source": [
    "# Concept 1- Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad1292",
   "metadata": {},
   "source": [
    "For classification with small training samples and\n",
    "high dimensionality, feature selection plays an\n",
    "important role in avoiding overfitting problems and\n",
    "improving classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "sel=RFE(RandomForestClassifier(n_estimators=10,random_state=18,n_jobs=-1),n_features_to_select=5)\n",
    "sel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0037830",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294a594",
   "metadata": {},
   "source": [
    "# Concept 1 - Feature Selection by Gradient Boost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ca2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "605f1152",
   "metadata": {},
   "source": [
    "# Feature Selection using ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy, roc_auc_score\n",
    "from sklearn.feature_selection import Variancethreshold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c19a046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59347669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf84a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3001f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1abfdef4",
   "metadata": {},
   "source": [
    "# Concept 2- Feature Extraction -> PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b4c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "484591bf",
   "metadata": {},
   "source": [
    "# Handle class imbalance during training using threshold moving algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c31d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1218c17",
   "metadata": {},
   "source": [
    "# Cost Sensitive Learning to handle class imbalance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
