{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96fe4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f77aebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a4a9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88dbbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import random\n",
    "\n",
    "# def reservoir_sampling(iterable, k, header=True):\n",
    "#     reservoir = []\n",
    "#     for i, item in enumerate(iterable):\n",
    "#         if i < k:\n",
    "#             reservoir.append(item)\n",
    "#         else:\n",
    "#             j = random.randint(0, i)\n",
    "#             if j < k:\n",
    "#                 reservoir[j] = item\n",
    "#     return reservoir\n",
    "\n",
    "# # Open the input CSV file\n",
    "# with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\") as f:\n",
    "#     # Check if header line exists\n",
    "#     header = True\n",
    "#     first_line = f.readline()\n",
    "#     if not first_line.startswith('step,type,amount,nameOrig,oldbalanceOrg,newbalanceOrig,nameDest,oldbalanceDest,newbalanceDest,isFraud,isFlaggedFraud'):\n",
    "#         header = False\n",
    "#         f.seek(0)  # Rewind file pointer to beginning\n",
    "\n",
    "#     # Sample from remaining lines\n",
    "#     sampled_lines = reservoir_sampling(f, k=2300000, header=header)\n",
    "\n",
    "# # Open the output CSV file and write the subsample to it\n",
    "# with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample1300000.csv\", mode='w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     if header:\n",
    "#         writer.writerow(first_line.strip().split(','))\n",
    "#     for line in sampled_lines:\n",
    "#         writer.writerow(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c73182f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78004e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample1300000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a475b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0723ab28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef5a09b",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d941b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Calculate the correlation matrix\n",
    "# corr_matrix = df_sample.corr(method='pearson')\n",
    "# plt.figure(figsize=(7,5)) # Resize\n",
    "# # Plot the correlation matrix as a heatmap\n",
    "# sns.heatmap(corr_matrix, cmap='mako', center=0, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b32d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df_sample.corr(method='spearman')\n",
    "plt.figure(figsize=(7,5)) # Resize\n",
    "# Plot the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, cmap='mako', center=0, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e551a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10738b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_sample.corr()\n",
    "\n",
    "# Print correlation matrix\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009be1c",
   "metadata": {},
   "source": [
    "## Distribution shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['step','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for feature in features:\n",
    "    plt.subplot(2,3,features.index(feature)+1)\n",
    "    sns.distplot(df_sample[feature],hist=True,color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change the data type of column 'A' from float64 to float32\n",
    "# df_sample['amount'] = df_sample['amount'].astype('float32')\n",
    "# df_sample['oldbalanceOrg'] = df_sample['oldbalanceOrg'].astype('float32')\n",
    "# df_sample['oldbalanceDest'] = df_sample['oldbalanceDest'].astype('float32')\n",
    "# df_sample['newbalanceOrig'] = df_sample['newbalanceOrig'].astype('float32')\n",
    "# df_sample['newbalanceDest'] = df_sample['newbalanceDest'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3200a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample['step'] = df_sample['step'].astype('int32')\n",
    "# df_sample['isFlaggedFraud'] = df_sample['isFlaggedFraud'].astype('int32') \n",
    "# df_sample['isFraud'] = df_sample['isFraud'].astype('int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90be74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c850827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c998f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4726858",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c2c4bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80d76c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630000, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9678a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 629208\n",
      "Class 1 count: 792\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d2295ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f4d70",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9956a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8de52ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 314602\n",
      "Class 1 count: 125841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_resampled)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac687784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440443, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37071d3f",
   "metadata": {},
   "source": [
    "## Tomeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb7c5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8cbe4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629843, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c22208",
   "metadata": {},
   "source": [
    "## ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "884b8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c99782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 628366\n",
      "Class 1 count: 792\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train_resampled_new)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd513977",
   "metadata": {},
   "source": [
    "## OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "540e71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7344156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 576121\n",
      "Class 1 count: 792\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = np.bincount(y_train_resampled_final)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b69f5014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 69912\n",
      "Class 1 count: 88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_test)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8160d1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576913, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55a1be8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576913,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b64fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainPRIOR.csv\", index=False)\n",
    "#X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086706d5",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3996395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 155462.29142206896, 'oldbalanceOrg': 214154.78171020697, 'newbalanceOrig': 645125.903301646, 'oldbalanceDest': 919733.9532739912, 'newbalanceDest': 1089056.441068198}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random.seed(0)\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.01, 'oldbalanceOrg': 0.07, 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "    # Replace the outliers in the test set with the trimmed means obtained from the train set\n",
    "    test_outliers = X_test.loc[X_test[col_name] > np.percentile(X_test[col_name], 100*(1-trim_props[col_name])), col_name]\n",
    "    X_test.loc[test_outliers.index, col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf41283",
   "metadata": {},
   "source": [
    "## New trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6edbbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "# # Specify columns with outliers\n",
    "# cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# # Specify the number of bootstrapped samples to create per column\n",
    "# num_samples = 50\n",
    "\n",
    "# # Specify the trimming proportions for each column\n",
    "# trim_props = {'amount': 0.01, 'oldbalanceOrg': (0.07, 0.03), 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# # Initialize empty dictionaries to store the trimmed means for each column\n",
    "# train_trimmed_means = {}\n",
    "\n",
    "# # Loop over the specified columns\n",
    "# for col_name in cols_with_outliers:\n",
    "    \n",
    "#     # Check if the trimming proportion for this column is a tuple with two values\n",
    "#     if isinstance(trim_props[col_name], tuple):\n",
    "#         # If so, perform asymmetric trimming for the oldbalanceOrg column\n",
    "#         if col_name == 'oldbalanceOrg':\n",
    "#             # Calculate the median of the bootstrapped sample for the training set\n",
    "#             train_median = np.median(train_sample)\n",
    "#             train_trimmed_means[col_name] = train_median\n",
    "#             # Replace the outliers in the training set with the trimmed means\n",
    "#             X_train_resampled_final.loc[(X_train_resampled_final[col_name] < train_trimmed_means[col_name]) | (X_train_resampled_final[col_name] > train_trimmed_means[col_name]), col_name] = train_median\n",
    "\n",
    "#             continue\n",
    "#         else:\n",
    "#             continue\n",
    "    \n",
    "#     # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "#     train_bootstrapped_samples = []\n",
    "#     train_trimmed_means_list = []\n",
    "    \n",
    "#     # Loop over the number of desired samples\n",
    "#     for i in range(num_samples):\n",
    "#         # Randomly select indices from the column in the training set\n",
    "#         train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "#         # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "#         train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "#         # Calculate the right and left trimmed means of the bootstrapped sample for the training set\n",
    "#         train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "#         train_left_trimmed_mean = np.mean(train_sample[train_sample >= np.percentile(train_sample, 100*trim_props[col_name])])\n",
    "#         train_trimmed_means_list.append((train_left_trimmed_mean, train_right_trimmed_mean))\n",
    "        \n",
    "#     # Calculate the mean of the left and right trimmed means for the training set and add it to the dictionary\n",
    "#     train_left_mean = np.mean([x[0] for x in train_trimmed_means_list])\n",
    "#     train_right_mean = np.mean([x[1] for x in train_trimmed_means_list])\n",
    "#     train_trimmed_means[col_name] = (train_left_mean, train_right_mean)\n",
    "\n",
    "#     # Replace the outliers in the training set with the trimmed means\n",
    "#     X_train_resampled_final.loc[(X_train_resampled_final[col_name] < train_trimmed_means[col_name][0]) | (X_train_resampled_final[col_name] > train_trimmed_means[col_name][1]), col_name] = np.mean(train_sample)\n",
    "\n",
    "# # Print the trimmed means\n",
    "# print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fadbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_resampled_final.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainPOST29.csv\", index=False)\n",
    "# #X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ebc1cc",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48406ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# assuming X_train and X_test are your training and test data matrices\n",
    "# standardize the data using the mean and std from the training set\n",
    "X_train_mean = np.mean(X_train_resampled_final, axis=0)\n",
    "X_train_std = np.std(X_train_resampled_final, axis=0)\n",
    "X_train_std[X_train_std == 0] = 1 # avoid division by zero\n",
    "X_train_std_inv = 1 / X_train_std\n",
    "\n",
    "X_train_stdized = (X_train_resampled_final - X_train_mean) * X_train_std_inv\n",
    "X_test_stdized = (X_test - X_train_mean) * X_train_std_inv\n",
    "\n",
    "# compute the covariance matrix for the training data\n",
    "cov_matrix_train = np.cov(X_train_stdized.T)\n",
    "\n",
    "# compute the eigenvectors and eigenvalues for the training data\n",
    "eig_vals_train, eig_vecs_train = np.linalg.eig(cov_matrix_train)\n",
    "\n",
    "# select the top k eigenvectors for the training data\n",
    "pca_train = PCA(n_components=3)\n",
    "X_train_pca = pca_train.fit_transform(X_train_stdized)\n",
    "\n",
    "# project the test data onto the selected eigenvectors from the training data\n",
    "X_test_pca = pca_train.transform(X_test_stdized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e03563db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = list(df_sample.columns)\n",
    "\n",
    "# # print the selected features\n",
    "# print(\"Selected features:\")\n",
    "# for i in range(pca_train.n_components_):\n",
    "#     # find the index of the maximum absolute value in the ith row of the components array\n",
    "#     idx = np.argmax(np.abs(pca_train.components_[i]))\n",
    "#     # print the name of the feature with the maximum absolute value in the ith row of the components array\n",
    "#     print(f\"PC{i+1}: {feature_names[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e0525f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00327968,  0.29608955,  0.20122571,  0.24735604,  0.50350705,\n",
       "        0.49432113, -0.00097151, -0.34733487, -0.43825692, -0.00768835])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0dfa2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f8f47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "y_train_resampled_final = pd.Series(y_train_resampled_final)\n",
    "\n",
    "X_train_pca_df.reset_index(drop=True, inplace=True)\n",
    "y_train_resampled_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b023afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_df = X_test_pca_df.rename(columns={0: 'PC1', 1: 'PC2', 2: 'PC3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bcdfba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.588736</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.473023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.849198</td>\n",
       "      <td>0.397840</td>\n",
       "      <td>0.394076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.944718</td>\n",
       "      <td>0.128033</td>\n",
       "      <td>-1.082693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.682156</td>\n",
       "      <td>-2.494345</td>\n",
       "      <td>1.387687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.259653</td>\n",
       "      <td>2.047303</td>\n",
       "      <td>-0.369725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>-0.382149</td>\n",
       "      <td>-0.243386</td>\n",
       "      <td>-0.997956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>-2.107026</td>\n",
       "      <td>0.459816</td>\n",
       "      <td>1.383425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>1.749563</td>\n",
       "      <td>-2.567371</td>\n",
       "      <td>1.006318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>-2.165434</td>\n",
       "      <td>0.491134</td>\n",
       "      <td>1.024513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>-0.038363</td>\n",
       "      <td>0.160262</td>\n",
       "      <td>-0.780123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3\n",
       "0     -1.588736  0.351814  0.473023\n",
       "1     -1.849198  0.397840  0.394076\n",
       "2      0.944718  0.128033 -1.082693\n",
       "3      0.682156 -2.494345  1.387687\n",
       "4      0.259653  2.047303 -0.369725\n",
       "...         ...       ...       ...\n",
       "69995 -0.382149 -0.243386 -0.997956\n",
       "69996 -2.107026  0.459816  1.383425\n",
       "69997  1.749563 -2.567371  1.006318\n",
       "69998 -2.165434  0.491134  1.024513\n",
       "69999 -0.038363  0.160262 -0.780123\n",
       "\n",
       "[70000 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69a914c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df = X_train_pca_df.rename(columns={0: 'PC1', 1: 'PC2', 2: 'PC3', 3: 'PC4',4: 'PC5',5: 'PC6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd002ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PC1', 'PC2', 'PC3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17bb1639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.628784</td>\n",
       "      <td>0.331720</td>\n",
       "      <td>0.482672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.516070</td>\n",
       "      <td>0.127975</td>\n",
       "      <td>0.993578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.378926</td>\n",
       "      <td>-1.286529</td>\n",
       "      <td>0.525350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.699963</td>\n",
       "      <td>-0.325386</td>\n",
       "      <td>-0.562586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.655465</td>\n",
       "      <td>-0.805706</td>\n",
       "      <td>-1.651309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576908</th>\n",
       "      <td>0.466673</td>\n",
       "      <td>-0.168242</td>\n",
       "      <td>-0.275214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576909</th>\n",
       "      <td>-0.571104</td>\n",
       "      <td>-0.509340</td>\n",
       "      <td>0.098368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576910</th>\n",
       "      <td>-0.641263</td>\n",
       "      <td>0.485871</td>\n",
       "      <td>-0.889673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576911</th>\n",
       "      <td>1.777804</td>\n",
       "      <td>0.371750</td>\n",
       "      <td>-1.043303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576912</th>\n",
       "      <td>1.935681</td>\n",
       "      <td>1.555207</td>\n",
       "      <td>0.892766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576913 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0      -1.628784  0.331720  0.482672\n",
       "1      -1.516070  0.127975  0.993578\n",
       "2       1.378926 -1.286529  0.525350\n",
       "3      -0.699963 -0.325386 -0.562586\n",
       "4       0.655465 -0.805706 -1.651309\n",
       "...          ...       ...       ...\n",
       "576908  0.466673 -0.168242 -0.275214\n",
       "576909 -0.571104 -0.509340  0.098368\n",
       "576910 -0.641263  0.485871 -0.889673\n",
       "576911  1.777804  0.371750 -1.043303\n",
       "576912  1.935681  1.555207  0.892766\n",
       "\n",
       "[576913 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eedf6f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576913, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f395d",
   "metadata": {},
   "source": [
    "## Scree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "433dbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # get the explained variance ratios\n",
    "# variance_ratio = pca_train .explained_variance_ratio_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(variance_ratio)+1), variance_ratio, 'o-', color='gray', linewidth=2)\n",
    "# plt.title('Scree Plot: Variance Explained')\n",
    "# plt.xlabel('Principal Components')\n",
    "# plt.ylabel('Proportion of Variance Explained')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d66dcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.628784</td>\n",
       "      <td>0.331720</td>\n",
       "      <td>0.482672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.516070</td>\n",
       "      <td>0.127975</td>\n",
       "      <td>0.993578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.378926</td>\n",
       "      <td>-1.286529</td>\n",
       "      <td>0.525350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.699963</td>\n",
       "      <td>-0.325386</td>\n",
       "      <td>-0.562586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.655465</td>\n",
       "      <td>-0.805706</td>\n",
       "      <td>-1.651309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.636544</td>\n",
       "      <td>0.686139</td>\n",
       "      <td>-0.201950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3\n",
       "0 -1.628784  0.331720  0.482672\n",
       "1 -1.516070  0.127975  0.993578\n",
       "2  1.378926 -1.286529  0.525350\n",
       "3 -0.699963 -0.325386 -0.562586\n",
       "4  0.655465 -0.805706 -1.651309\n",
       "5  0.636544  0.686139 -0.201950"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84d36774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install adjustText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f483b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # create a PCA object\n",
    "# pca = PCA()\n",
    "\n",
    "# # fit the PCA object to your data\n",
    "# pca.fit(X)\n",
    "\n",
    "# # get the eigenvalues\n",
    "# eigenvalues = pca_train.explained_variance_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(eigenvalues)+1), eigenvalues, 'bo-', linewidth=2)\n",
    "# plt.title('Scree Plot')\n",
    "# plt.xlabel('Principal Component')\n",
    "# plt.ylabel('Eigenvalue')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df6ee46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # create a PCA object\n",
    "# pca = PCA()\n",
    "\n",
    "# # fit the PCA object to your data\n",
    "# pca.fit(X)\n",
    "\n",
    "# # get the eigenvalues\n",
    "# eigenvalues = pca_train.explained_variance_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(eigenvalues)+1), eigenvalues, 'o-', color='gray', linewidth=1, markersize=5)\n",
    "# plt.axhline(y=1, linestyle='--', color='black', linewidth=1)\n",
    "# plt.title('Scree Plot: PCA Eigenvalues')\n",
    "# plt.xlabel('Principal Components')\n",
    "# plt.ylabel('Eigenvalues')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a04a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    " \n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc2fec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot circle\n",
    "# #Create a list of 500 points with equal spacing between -1 and 1\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# columns=X_train_resampled_final.columns.values #Store the name of the columns for labeling\n",
    "\n",
    "# x=np.linspace(start=-1,stop=1,num=1000)\n",
    "# #Find y1 and y2 for these points\n",
    "# y_positive=lambda x: np.sqrt(1-x**2) \n",
    "# y_negative=lambda x: -np.sqrt(1-x**2)\n",
    "# plt.plot(x,list(map(y_positive, x)), color='maroon')\n",
    "# plt.plot(x,list(map(y_negative, x)),color='maroon')\n",
    "\n",
    "# #Plot smaller circle\n",
    "# x=np.linspace(start=-0.5,stop=0.5,num=500)\n",
    "# y_positive=lambda x: np.sqrt(0.5**2-x**2) \n",
    "# y_negative=lambda x: -np.sqrt(0.5**2-x**2)\n",
    "# plt.plot(x,list(map(y_positive, x)), color='maroon')\n",
    "# plt.plot(x,list(map(y_negative, x)),color='maroon')\n",
    "\n",
    "# #Create broken lines\n",
    "# x=np.linspace(start=-1,stop=1,num=30)\n",
    "# plt.scatter(x,[0]*len(x), marker='_',color='maroon')\n",
    "# plt.scatter([0]*len(x), x, marker='|',color='maroon')\n",
    "\n",
    "# pca_values=pca.components_\n",
    "# #Define color list\n",
    "# colors = ['pink', 'green','purple', 'blue','red','black']\n",
    "# if len(pca_values[0]) > 5:\n",
    "#     colors=colors*(int(len(pca_values[0])/5)+1)\n",
    "    \n",
    "#     add_string=\"\"\n",
    "#     for i in range(6):\n",
    "#         xi=pca_values[0][i]\n",
    "#         yi=pca_values[1][i]\n",
    "#         plt.arrow(0,0, \n",
    "#                   dx=xi, dy=yi, \n",
    "#                   head_width=0.03, head_length=0.03, \n",
    "#                   color=colors[i], length_includes_head=True)\n",
    "#         add_string=f\" ({round(xi,2)} {round(yi,2)})\"\n",
    "# #         plt.text(pca_values[0, i], \n",
    "# #                  pca_values[1, i] , \n",
    "# #                  s=columns[i] + add_string,\n",
    "# #                  fontsize=5)\n",
    "#         plt.text(pca_values[0, i] + 0.0, pca_values[1, i] + 0.07, s=columns[i] + add_string, fontsize=8)\n",
    "        \n",
    "# plt.xlabel(f\"Component 1 ({round(pca_train.explained_variance_ratio_[0]*100,2)}%)\")\n",
    "# plt.ylabel(f\"Component 2 ({round(pca_train.explained_variance_ratio_[1]*100,2)}%)\")\n",
    "# plt.title('Variable factor map (PCA)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f3ce5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs = X_train_pca[:,0]\n",
    "# ys = X_train_pca[:,1]\n",
    "# scalex = 1.0/(xs.max() - xs.min())\n",
    "# scaley = 1.0/(ys.max() - ys.min())\n",
    "# fig, ax = plt.subplots(figsize=(14, 9))\n",
    " \n",
    "# for i, feature in enumerate(columns):\n",
    "#     ax.arrow(0, 0, pca_train.components_[0, i], \n",
    "#              pca_train.components_[1, i])\n",
    "#     ax.text(pca_train.components_[0, i] * 1.15, \n",
    "#             pca_train.components_[1, i] * 1.15, \n",
    "#             feature, fontsize=10)\n",
    " \n",
    "#     ax.scatter(xs * scalex,ys * scaley)\n",
    " \n",
    "#     ax.set_xlabel('PC1', fontsize=10)\n",
    "#     ax.set_ylabel('PC2', fontsize=10)\n",
    "#     ax.set_title('Biplot', fontsize=15)\n",
    "#     plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca619079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the PCA components (loadings)\n",
    "# PCs = pca.components_\n",
    "\n",
    "# # Use quiver to generate the basic plot\n",
    "# fig = plt.figure(figsize=(5,5))\n",
    "# plt.quiver(np.zeros(PCs.shape[1]), np.zeros(PCs.shape[1]),\n",
    "#            PCs[0,:], PCs[1,:], \n",
    "#            angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "# # Add labels based on feature names (here just numbers)\n",
    "# feature_names = np.arange(PCs.shape[1])\n",
    "# for i,j,z in zip(PCs[1,:]+0.02, PCs[0,:]+0.02, feature_names):\n",
    "#     plt.text(j, i, z, ha='center', va='center')\n",
    "\n",
    "# # Add unit circle\n",
    "# circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "# plt.gca().add_artist(circle)\n",
    "\n",
    "# # Ensure correct aspect ratio and axis limits\n",
    "# plt.axis('equal')\n",
    "# plt.xlim([-1.0,1.0])\n",
    "# plt.ylim([-1.0,1.0])\n",
    "\n",
    "# # Label axes\n",
    "# plt.xlabel('PC 0')\n",
    "# plt.ylabel('PC 1')\n",
    "\n",
    "# # Done\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf9ba8",
   "metadata": {},
   "source": [
    "## Linear Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b085d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.linear_model import Perceptron\n",
    "\n",
    "# # Create a Perceptron object\n",
    "# clf = Perceptron(random_state=0)\n",
    "\n",
    "# # Train the Perceptron on the data\n",
    "# clf.fit(X_train_resampled_final, y_train_resampled_final)\n",
    "\n",
    "# # Predict the output classes for the data points\n",
    "# y_pred = clf.predict(X_train_resampled_final)\n",
    "\n",
    "# # Check if the Perceptron correctly classified all the data points\n",
    "# if np.all(y_pred == y_train_resampled_final):\n",
    "#     print(\"Data is linearly separable\")\n",
    "# else:\n",
    "#     print(\"Data is not linearly separable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c228282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your DataFrame is called df and the class column is called 'class'\n",
    "# class0 = df_sample[df_sample['isFraud'] == 0]\n",
    "# class1 = df_sample[df_sample['isFraud'] == 1]\n",
    "\n",
    "# s = 5\n",
    "# plt.scatter(class0['step'], class0['oldbalanceOrg'], color='blue', label='Class 0',marker='.', s=s)\n",
    "# plt.scatter(class1['step'], class1['oldbalanceOrg'], color='red', label='Class 1',marker='.', s=s)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('oldbalanceOrg')\n",
    "# plt.title('Scatter plot of two classes')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd4792f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your DataFrame is called df and the class column is called 'class'\n",
    "# class0 = df_sample[df_sample['isFraud'] == 0]\n",
    "# class1 = df_sample[df_sample['isFraud'] == 1]\n",
    "\n",
    "# s=4\n",
    "# plt.scatter(class0['step'], class0['oldbalanceOrg'], color='blue', label='Class 0',marker='.', s=s)\n",
    "# plt.scatter(class1['step'], class1['oldbalanceOrg'], color='red', label='Class',marker='.', s=s)\n",
    "\n",
    "# # Fit a linear SVM to the data\n",
    "# from sklearn.svm import SVC\n",
    "# X_new = df_sample[['step', 'oldbalanceOrg']]\n",
    "# y_new = df_sample['isFraud']\n",
    "# svm = SVC(kernel='linear')\n",
    "# svm.fit(X_new, y_new)\n",
    "\n",
    "# # Plot the decision boundary\n",
    "# w = svm.coef_[0]\n",
    "# a = -w[0] / w[1]\n",
    "# xx = np.linspace(np.min(X_new['step']), np.max(X_new['step']))\n",
    "# yy = a * xx - svm.intercept_[0] / w[1]\n",
    "# plt.plot(xx, yy, 'k-', label='Decision boundary')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('oldbalanceOrg')\n",
    "# plt.title('Scatter plot of two classes with decision boundary')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917bc01",
   "metadata": {},
   "source": [
    "## Choose 3 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b10bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.028142</td>\n",
       "      <td>0.371506</td>\n",
       "      <td>-1.348922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.357583</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>0.639693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.616451</td>\n",
       "      <td>-1.263329</td>\n",
       "      <td>-0.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.491998</td>\n",
       "      <td>-0.379992</td>\n",
       "      <td>-1.661583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.916355</td>\n",
       "      <td>-0.873515</td>\n",
       "      <td>-1.459530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621267</th>\n",
       "      <td>0.565284</td>\n",
       "      <td>-0.213893</td>\n",
       "      <td>0.274537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621268</th>\n",
       "      <td>-0.396072</td>\n",
       "      <td>-0.542564</td>\n",
       "      <td>0.617484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621269</th>\n",
       "      <td>-0.502319</td>\n",
       "      <td>0.371023</td>\n",
       "      <td>-1.415950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621270</th>\n",
       "      <td>2.166407</td>\n",
       "      <td>0.210716</td>\n",
       "      <td>0.670903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621271</th>\n",
       "      <td>2.091302</td>\n",
       "      <td>1.720442</td>\n",
       "      <td>-0.214477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       1.028142  0.371506 -1.348922\n",
       "1      -1.357583  0.030093  0.639693\n",
       "2       1.616451 -1.263329 -0.184453\n",
       "3      -0.491998 -0.379992 -1.661583\n",
       "4       0.916355 -0.873515 -1.459530\n",
       "...          ...       ...       ...\n",
       "621267  0.565284 -0.213893  0.274537\n",
       "621268 -0.396072 -0.542564  0.617484\n",
       "621269 -0.502319  0.371023 -1.415950\n",
       "621270  2.166407  0.210716  0.670903\n",
       "621271  2.091302  1.720442 -0.214477\n",
       "\n",
       "[621272 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "193e538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_df=X_test_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2dd82f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.449825</td>\n",
       "      <td>0.279358</td>\n",
       "      <td>0.234651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.700948</td>\n",
       "      <td>0.316871</td>\n",
       "      <td>-0.737768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.128978</td>\n",
       "      <td>0.154381</td>\n",
       "      <td>-0.736118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.017036</td>\n",
       "      <td>-2.751136</td>\n",
       "      <td>1.307427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467184</td>\n",
       "      <td>2.007929</td>\n",
       "      <td>-0.212149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>-0.187102</td>\n",
       "      <td>-0.290673</td>\n",
       "      <td>-0.836653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>-1.932913</td>\n",
       "      <td>0.364358</td>\n",
       "      <td>0.580938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>2.029871</td>\n",
       "      <td>-2.639866</td>\n",
       "      <td>2.003639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>-2.025831</td>\n",
       "      <td>0.417065</td>\n",
       "      <td>0.824832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.202684</td>\n",
       "      <td>0.122889</td>\n",
       "      <td>-1.739665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3\n",
       "0     -1.449825  0.279358  0.234651\n",
       "1     -1.700948  0.316871 -0.737768\n",
       "2      1.128978  0.154381 -0.736118\n",
       "3      1.017036 -2.751136  1.307427\n",
       "4      0.467184  2.007929 -0.212149\n",
       "...         ...       ...       ...\n",
       "69995 -0.187102 -0.290673 -0.836653\n",
       "69996 -1.932913  0.364358  0.580938\n",
       "69997  2.029871 -2.639866  2.003639\n",
       "69998 -2.025831  0.417065  0.824832\n",
       "69999  0.202684  0.122889 -1.739665\n",
       "\n",
       "[70000 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3b335c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df=X_train_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "89ff3ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.028142</td>\n",
       "      <td>0.371506</td>\n",
       "      <td>-1.348922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.357583</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>0.639693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.616451</td>\n",
       "      <td>-1.263329</td>\n",
       "      <td>-0.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.491998</td>\n",
       "      <td>-0.379992</td>\n",
       "      <td>-1.661583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.916355</td>\n",
       "      <td>-0.873515</td>\n",
       "      <td>-1.459530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621267</th>\n",
       "      <td>0.565284</td>\n",
       "      <td>-0.213893</td>\n",
       "      <td>0.274537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621268</th>\n",
       "      <td>-0.396072</td>\n",
       "      <td>-0.542564</td>\n",
       "      <td>0.617484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621269</th>\n",
       "      <td>-0.502319</td>\n",
       "      <td>0.371023</td>\n",
       "      <td>-1.415950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621270</th>\n",
       "      <td>2.166407</td>\n",
       "      <td>0.210716</td>\n",
       "      <td>0.670903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621271</th>\n",
       "      <td>2.091302</td>\n",
       "      <td>1.720442</td>\n",
       "      <td>-0.214477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       1.028142  0.371506 -1.348922\n",
       "1      -1.357583  0.030093  0.639693\n",
       "2       1.616451 -1.263329 -0.184453\n",
       "3      -0.491998 -0.379992 -1.661583\n",
       "4       0.916355 -0.873515 -1.459530\n",
       "...          ...       ...       ...\n",
       "621267  0.565284 -0.213893  0.274537\n",
       "621268 -0.396072 -0.542564  0.617484\n",
       "621269 -0.502319  0.371023 -1.415950\n",
       "621270  2.166407  0.210716  0.670903\n",
       "621271  2.091302  1.720442 -0.214477\n",
       "\n",
       "[621272 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8913f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# #class_weights={0:1,0:75}\n",
    "# #rf_model = RandomForestClassifier(criterion='entropy', max_depth= 8, max_features='log2',n_estimators=251,oob_score=True)\n",
    "# #rf_model = RandomForestClassifier(ccp_alpha=0.01,criterion='gini', max_depth= 3, max_features='log2',n_estimators=100,oob_score=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "    \n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print classification report\n",
    "#     print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17904f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print confusion matrix\n",
    "#     print(f\"Confusion matrix for fold {fold}:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f8c0f",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c967dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# # Define the parameter space to search over\n",
    "# param_dist = {\n",
    "#     'n_estimators': randint(100, 400),\n",
    "#     'max_features': ['sqrt', 'log2','none'],\n",
    "#     'max_depth': [None] + list(range(5, 20, 5)),\n",
    "#     'min_samples_split': randint(2, 15),\n",
    "#     'min_samples_leaf': randint(1, 15),\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# # Initialize the Random Forest model\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# # Initialize the RandomizedSearchCV object\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     rf_model, \n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=10,  # Number of iterations to sample from the parameter space\n",
    "#     cv=3,  # Number of cross-validation folds to use\n",
    "# )\n",
    "\n",
    "# # Fit the RandomizedSearchCV object to the data\n",
    "# random_search.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Print the best hyperparameters and corresponding score\n",
    "# print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "# print(\"Best score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410bd4c",
   "metadata": {},
   "source": [
    "## PCA-BASED MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369863b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "n_folds = 2\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "    X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "    y_pred = rf_model.predict(X_val)\n",
    "    score = rf_model.score(X_val, y_val)\n",
    "    #print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    print(f\"Confusion matrix:\")\n",
    "    # Print confusion matrix\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(f\"Classification report:\")\n",
    "    print('---------------------')\n",
    "    # Print classification report\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    # Print the OOB score\n",
    "    #print(f\"OOB score: {rf_model.oob_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685da952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(rf_model, X_test_pca_df, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888d6ec",
   "metadata": {},
   "source": [
    "## HalfRandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.experimental import enable_halving_search_cv  # Required to enable HalvingRandomSearchCV\n",
    "# from sklearn.model_selection import HalvingRandomSearchCV\n",
    "# import numpy as np\n",
    "\n",
    "# # Create the random forest model\n",
    "# rfc = RandomForestClassifier()\n",
    "\n",
    "# # Set the hyperparameters to tune and their possible values\n",
    "# param_dist = {\n",
    "#     'n_estimators': np.arange(100, 400),\n",
    "#     'max_features': ['sqrt', 'log2','auto']\n",
    "#     'max_depth': [5, 10, 15, 20, None],\n",
    "#     'min_samples_split': [2, 5, 15],\n",
    "#     'min_samples_leaf': [2, 5, 15],\n",
    "#     'bootstrap': [True, False],\n",
    "# }\n",
    "\n",
    "# # Set up the HalvingRandomSearchCV with aggressive early stopping\n",
    "# search = HalvingRandomSearchCV(rfc, param_dist, cv=5,verbose=1, \n",
    "#                                factor=2, resource='n_samples', max_resources=100, \n",
    "#                                aggressive_elimination=True, random_state=18, \n",
    "#                                scoring='accuracy', refit=True)\n",
    "\n",
    "# # Fit the HalvingRandomSearchCV object to the data\n",
    "# search.fit(X_train_pca_df, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27fb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and evaluate on the test set\n",
    "best_params = search.best_params_\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bad5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e86b11",
   "metadata": {},
   "source": [
    "## RF-PCA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec09298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "n_folds = 2\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "class_weights={0:15,1:70}\n",
    "rf_model = RandomForestClassifier(class_weight=class_weights)\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "start_time = time.time()\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "    X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "    \n",
    "#     # Print confusion matrix and classification report\n",
    "#     print(f\"Fold {fold+1}\")\n",
    "#     print(f\"Confusion matrix:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "#     print(f\"Classification report:\")\n",
    "#     print('---------------------')\n",
    "#     print(classification_report(y_val, y_pred))\n",
    "    \n",
    "#     # Get precision, recall, and f1 score for this fold\n",
    "#     report = classification_report(y_val, y_pred, output_dict=True)\n",
    "#     precision_list.append(report['weighted avg']['precision'])\n",
    "#     recall_list.append(report['weighted avg']['recall'])\n",
    "#     f1_list.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "\n",
    "# print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "# # Calculate average precision, recall, and f1 score across all folds\n",
    "# avg_precision = sum(precision_list) / n_folds\n",
    "# avg_recall = sum(recall_list) / n_folds\n",
    "# avg_f1 = sum(f1_list) / n_folds\n",
    "\n",
    "# print(f\"Average precision: {avg_precision}\")\n",
    "# print(f\"Average recall: {avg_recall}\")\n",
    "# print(f\"Average F1 score: {avg_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# # Load iris dataset\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# # Train a random forest classifier with 3 decision trees\n",
    "rf_model = RandomForestClassifier(n_estimators=2)\n",
    "rf_model.fit(X_train_pca_df, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# plot_tree(rf_model.estimators_[1], filled=True, ax=ax, max_depth=2, fontsize=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd19a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier('n_estimators': 130, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 20, 'bootstrap': False)\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     y_prob = rf_model.predict_proba(X_val)[:,1] # get probability estimates for positive class\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print confusion matrix\n",
    "#     print(f\"Confusion matrix for fold {fold}:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "    \n",
    "#     # Plot ROC curve\n",
    "#     fpr, tpr, thresholds = roc_curve(y_val, y_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     plt.plot(fpr, tpr, label=f\"Fold {fold} (AUC = {roc_auc:.2f})\")\n",
    "    \n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='Random guessing')\n",
    "# plt.xlabel('False positive rate')\n",
    "# plt.ylabel('True positive rate')\n",
    "# plt.title('ROC curve for Random Forest classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c1abe",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2023d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define the number of splits for stratified cross-validation\n",
    "# n_splits = 2\n",
    "\n",
    "# # Initialize StratifiedKFold\n",
    "# skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# # Create lists to store evaluation metrics for each fold\n",
    "# f1_scores = []\n",
    "# recall_scores = []\n",
    "# precision_scores = []\n",
    "# accuracy_scores = []\n",
    "\n",
    "# # Create lists to store ROC curve data for each fold\n",
    "# fprs = []\n",
    "# tprs = []\n",
    "# aucs = []\n",
    "\n",
    "# # Initialize the OOB error list\n",
    "# oob_error = []\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "#     print(f'Fold: {fold+1}')\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df[train_idx], y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df[val_idx], y_train_resampled_final[val_idx]\n",
    "\n",
    "#     #class_weights={0:1,0:75}\n",
    "#     rf_model = RandomForestClassifier(criterion='entropy', max_depth= 8, max_features='log2',n_estimators=251,oob_score=True)\n",
    "#     # Fit the model on the training data\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "#     # Predict the class labels for the validation set\n",
    "#     y_val_pred = rf_model.predict(X_val)\n",
    "    \n",
    "#     # Predict the class probabilities for the validation set\n",
    "#     y_val_pred_proba = rf_model.predict_proba(X_val)\n",
    "\n",
    "#     # Set the threshold\n",
    "#     threshold = 0.225\n",
    "#     # Convert the probabilities to binary predictions based on the threshold\n",
    "#     y_val_pred = (y_val_pred_proba[:,1] > threshold).astype(int)\n",
    "\n",
    "#     # Compute the evaluation metrics for the current fold\n",
    "#     conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "#     recall = recall_score(y_val, y_val_pred)\n",
    "#     accuracy = accuracy_score(y_val, y_val_pred)\n",
    "#     precision = precision_score(y_val, y_val_pred)\n",
    "#     f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "#     # Append the evaluation metrics for the current fold to the lists\n",
    "#     f1_scores.append(f1)\n",
    "#     recall_scores.append(recall)\n",
    "#     precision_scores.append(precision)\n",
    "#     accuracy_scores.append(accuracy)\n",
    "    \n",
    "#     # Compute the ROC curve and AUC for the current fold\n",
    "#     fpr, tpr, _ = roc_curve(y_val, rf_model.predict_proba(X_val)[:,1])\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "#     # Append the ROC curve data for the current fold to the lists\n",
    "#     fprs.append(fpr)\n",
    "#     tprs.append(tpr)\n",
    "#     aucs.append(roc_auc)\n",
    "\n",
    "#     # Compute the OOB error for the current fold and append to the list\n",
    "#     oob_error.append(1 - rf_model.oob_score_)\n",
    "\n",
    "#     # Print the evaluation metrics for the current fold\n",
    "#     print('Confusion matrix:\\n', conf_mat)\n",
    "#     print('Recall:', recall)\n",
    "#     #print('Accuracy:', accuracy)\n",
    "#     print('Precision:', precision)\n",
    "#     print('F1-score:', f1)\n",
    "#     print('OOB error:', 1 - rf_model.oob_score_)\n",
    "#     print('---------------------')\n",
    "    \n",
    "#     # Compute the classification report for the current fold\n",
    "#     report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "#     # Print the classification report\n",
    "#     print('Classification report:\\n', report)\n",
    "\n",
    "# # Create the ROC curve plot\n",
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# # Plot the ROC curve for each fold\n",
    "# for i in range(n_splits):\n",
    "#     ax.plot(fprs[i], tprs[i], lw=2, label='Fold %d (AUC = %0.2f)' % (i+1, aucs[i]))\n",
    "\n",
    "# # Add a dashed line representing the random guess classifier\n",
    "# ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Random guess')\n",
    "\n",
    "# # Add labels and legend to the plot\n",
    "# ax.set_xlabel('False Positive Rate')\n",
    "# ax.set_ylabel('True Positive Rate')\n",
    "# ax.set_title('Receiver Operating Characteristic')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c9809",
   "metadata": {},
   "source": [
    "## Contour plot for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4986a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "# X = X_train_pca_df.iloc[:, :2].values \n",
    "\n",
    "# # define the meshgrid\n",
    "# h = 0.02  # step size in the mesh\n",
    "# x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "# y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                      np.arange(y_min, y_max, h))\n",
    "\n",
    "# # predict the class probabilities for each meshgrid point\n",
    "# Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# # reshape the predicted probabilities into the meshgrid shape\n",
    "# Z = Z.reshape(xx.shape)\n",
    "\n",
    "# # plot the contour plot\n",
    "# plt.contourf(xx, yy, Z, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63250503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f938e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "y = y_train_resampled_final.values\n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.7, s=2)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add title and axis labels\n",
    "# add title and axis labels with smaller font size\n",
    "plt.title(\"Decision boundary with training points\", fontsize=14)\n",
    "plt.xlabel(\"PC1\", fontsize=12)\n",
    "plt.ylabel(\"PC2\", fontsize=12)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de573377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "y = y_train_resampled_final.values\n",
    "\n",
    "# shift the y-coordinate values of the positive class points\n",
    "X[y == 1, 1] += 1.8\n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.7, s=2)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add title and axis labels\n",
    "plt.title(\"Decision boundary with training points\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ce2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the plot_decision_boundary function first\n",
    "# def plot_decision_boundary(pred_func):\n",
    "#     # Set min and max values and give it some padding\n",
    "#     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "#     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "#     h = 0.01\n",
    "#     # Generate a grid of points with distance h between them\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "#     # Predict the function value for the whole gid\n",
    "#     Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     # Plot the contour and training examples\n",
    "#     plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "\n",
    "# # Train the RandomForestClassifier\n",
    "# rf_model = RandomForestClassifier()\n",
    "# rf_model.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Plot the decision boundary using the plot_decision_boundary function\n",
    "# plot_decision_boundary(lambda X_train_pca_df: rf_model.predict(X_train_pca_df))\n",
    "# plt.title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define plot_decision_boundary function here...\n",
    "# def plot_decision_boundary(pred_func):\n",
    "#     # Set min and max values and give it some padding\n",
    "#     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "#     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "#     h = 0.01\n",
    "#     # Generate a grid of points with distance h between them\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "#     # Predict the function value for the whole gid\n",
    "#     Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     # Plot the contour and training examples\n",
    "#     plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(X_train_pca_df[:, 0], X_train_pca_df[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "   \n",
    "# %matplotlib inline\n",
    "# matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "# # Train the logistic regression classifier\n",
    "# rf_model = RandomForestClassifier()\n",
    "# rf_model.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Plot decision boundary\n",
    "# #plot_decision_boundary(lambda x: rf_model.predict(x))\n",
    "# plot_decision_boundary(lambda x: rf_model.predict(x), X_train_pca_df.iloc[:, :2].values)\n",
    "# plt.title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68e29c",
   "metadata": {},
   "source": [
    "## Bubble Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e40639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample data frame\n",
    "df = pd.DataFrame({\n",
    "    'Model Name': ['Model 1', 'Model 1', 'Model 1', 'Model 2', 'Model 2', 'Model 2', 'Model 3', 'Model 3', 'Model 3'],\n",
    "    'Dataset Size': ['Small', 'Medium', 'Large', 'Small', 'Medium', 'Large', 'Small', 'Medium', 'Large'],\n",
    "    'Performance Value': [5, 0.9, 0.9, 0.7, 7, 9, 0.6, 1, 15]\n",
    "})\n",
    "\n",
    "# Define bubble sizes and colors\n",
    "bubble_sizes = df['Performance Value'] * 100\n",
    "bubble_colors = df['Performance Value']\n",
    "\n",
    "# Group the data by Model Name\n",
    "groups = df.groupby('Model Name')\n",
    "\n",
    "# Create a scatter plot for each group\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for name, group in groups:\n",
    "    ax.scatter(group['Dataset Size'], [name] * len(group), s=bubble_sizes.loc[group.index], c=bubble_colors.loc[group.index], alpha=0.5, label=name)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Dataset Size')\n",
    "ax.set_ylabel('Model Name')\n",
    "ax.set_title('Model Performance')\n",
    "\n",
    "# Add color bar and legend\n",
    "sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(vmin=bubble_colors.min(), vmax=bubble_colors.max()))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.ax.set_ylabel('Performance Value')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8157658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define the parameters for the learning curve\n",
    "# train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "# cv = 2  # number of cross-validation folds\n",
    "\n",
    "# # Generate the learning curve data\n",
    "# train_sizes, train_scores, val_scores = learning_curve(\n",
    "#     rf_model, X_train_pca_df, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    "# )\n",
    "\n",
    "# # Calculate the mean and standard deviation of the training and validation scores\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# val_scores_mean = np.mean(val_scores, axis=1)\n",
    "# val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Misclassification Error\")\n",
    "# plt.grid()\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (train_scores_mean + train_scores_std),\n",
    "#     1 - (train_scores_mean - train_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"r\",\n",
    "# )\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (val_scores_mean + val_scores_std),\n",
    "#     1 - (val_scores_mean - val_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"g\",\n",
    "# )\n",
    "# plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "# plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6532ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set up the data\n",
    "# training_samples = [23000, 73000, 124000, 162500, 220000]\n",
    "# cv_errors = [0.30, 0.30, 0.24, 0.075, 0.043]\n",
    "# training_errors = [0.27, 0.16, 0.05, 0.025,  0.025]\n",
    "\n",
    "# # Create the plot and set the grid\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.grid(True)\n",
    "\n",
    "# # Plot the data points as dots\n",
    "# # ax.plot(training_samples, cv_errors, 'o', color='green', label='Cross Validation Error')\n",
    "# # ax.plot(training_samples, training_errors, 'o', color='red', label='Training Error')\n",
    "\n",
    "# # Plot the lines connecting the dots with different colors and line styles\n",
    "# ax.plot(training_samples, cv_errors, color='green', linestyle='-', marker='o', label='Cross Validation Error')\n",
    "# ax.plot(training_samples, training_errors, color='red', linestyle='-', marker='o', label='Training Error')\n",
    "\n",
    "# # Set the axis labels and title\n",
    "# ax.set_xlabel('Training examples')\n",
    "# ax.set_ylabel('Miscalssification Error')\n",
    "# ax.set_title('Learning Curve')\n",
    "\n",
    "# # Add a legend\n",
    "# ax.legend()\n",
    "# plt.legend(loc=\"best\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a0029",
   "metadata": {},
   "source": [
    "## Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c39c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "# from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 6), sharey=True)\n",
    "\n",
    "# common_params = {\n",
    "#     \"X\": X_train_pca,\n",
    "#     \"y\": y_train_resampled_final,\n",
    "#     \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "#     \"cv\": KFold(n_splits=2, shuffle=True),\n",
    "#     \"score_type\": \"both\",\n",
    "#     \"line_kw\": {\"marker\": \"o\"},\n",
    "#     \"std_display_style\": \"fill_between\",\n",
    "#     \"score_name\": \"neg_log_loss\",\n",
    "# }\n",
    "\n",
    "# estimator = rf_model\n",
    "# LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax)\n",
    "# handles, label = ax.get_legend_handles_labels()\n",
    "# ax.legend(handles[:2], [\"Training Score\", \"Cross alidation Score\"])\n",
    "# ax.set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8008524",
   "metadata": {},
   "source": [
    "## Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d88ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#class_weights={0:1,0:75}\n",
    "    # Create a RandomForestClassifier object with the given hyperparameters\n",
    "#rf_model = RandomForestClassifier(max_features='sqrt',n_estimators=121,oob_score=True,class_weight=class_weights,random_state=1)\n",
    "clf = lgb.LGBMClassifier(objective='binary', metric='binary_logloss')\n",
    "\n",
    "train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "train_loss = []\n",
    "cv_loss = []\n",
    "    \n",
    "for size in train_sizes:\n",
    "    # Split the data into training and cross-validation sets\n",
    "    X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_pca_df, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    clf .fit(X_train_new, y_train_new)\n",
    "    \n",
    "    # Compute the cross-entropy loss on the training set\n",
    "    y_train_pred = clf .predict_proba(X_train_pca_df)\n",
    "    train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "    # Compute the cross-entropy loss on the cross-validation set\n",
    "    y_cv_pred = clf .predict_proba(X_cv)\n",
    "    cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.tree import export_graphviz\n",
    "# from IPython.display import Image\n",
    "# import pydotplus\n",
    "\n",
    "# # Visualize a decision tree from the random forest\n",
    "# tree = rf_model.estimators_[0]\n",
    "# export_graphviz(tree, out_file='tree.dot', feature_names=['newbalanceDest', 'step', 'nameDest', 'newbalanceOrig'], class_names=['class_0', 'class_1'], filled=True, rounded=True)\n",
    "\n",
    "# # Convert the .dot file to .png\n",
    "# graph = pydotplus.graph_from_dot_file('tree.dot')\n",
    "# graph.write_png('tree.png')\n",
    "\n",
    "# # Display the decision tree\n",
    "# Image(filename='tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve\n",
    "# # Get predicted probabilities for the test data\n",
    "# y_prob = rf_model.predict_proba(X_test_pca)[:,1]\n",
    "\n",
    "# # Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "# thresholds = np.arange(0.1,30,0.01)\n",
    "# precision_scores = []\n",
    "# recall_scores = []\n",
    "# f1_scores = []\n",
    "\n",
    "# for threshold in thresholds:\n",
    "#     y_pred = (y_prob >= threshold).astype(int)\n",
    "#     precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     precision_scores.append(precision[1])\n",
    "#     recall_scores.append(recall[1])\n",
    "#     f1_scores.append(f1[1])\n",
    "\n",
    "# # Find the optimal threshold that maximizes the F1-score\n",
    "# optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# # Assign the class labels based on the optimal threshold\n",
    "# y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# # Evaluate the performance of the classifier for the optimal threshold\n",
    "# confusion_matrix(y_test, y_pred)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64528a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Get predicted probabilities for the test data\n",
    "# y_prob = rf_model.predict_proba(X_test_pca)[:,1]\n",
    "\n",
    "# # Assign the class labels based on the optimal threshold\n",
    "# optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "# y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# # Print classification report on the test set\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ba105",
   "metadata": {},
   "source": [
    "## Partial dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_partial_dependence(rf_model, X_train_pca_df, features=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fab4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['newbalanceDest', 'oldbalanceOrg','nameDest']  # or ['feat1', 'feat2', 'feat3']\n",
    "# plot_partial_dependence(rf_model, X_train_pca, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef257a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [0, 1, 2] # Indices of the features in X_train_pca\n",
    "# feature_names = ['newbalanceDest', 'oldbalanceOrg', 'nameDest'] # Names of the features\n",
    "\n",
    "# plot_partial_dependence(rf_model, X_train_pca, features=features, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38890561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import partial_dependence\n",
    "# from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# # Compute partial dependence values for the feature 'feature_name'\n",
    "# pdp, axes = partial_dependence(rf_model,X_train_pca_df, feature_name='PC1')\n",
    "\n",
    "# # Create a partial dependence plot for the feature 'feature_name'\n",
    "# display = PartialDependenceDisplay.from_feature_values(feature_values=X[:, feature_index], \n",
    "#                                                        pdp_values=pdp, \n",
    "#                                                        feature_name='PC1')\n",
    "\n",
    "# # Plot the partial dependence plot\n",
    "# display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# Compute partial dependence values for the first principal component\n",
    "pdp, axes = partial_dependence(rf_model, X_train_pca_df, features=[0])\n",
    "\n",
    "# Create a partial dependence plot for the first principal component\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(axes[0], pdp[0])\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('Predicted Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937145c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "\n",
    "# X_train_pca_df = pd.DataFrame(X_train_pca, columns=[f\"PC{i+1}\" for i in range(pca_train.n_components_)])\n",
    "\n",
    "\n",
    "# # Generate PDPs for the principal components\n",
    "# fig, axs = plot_partial_dependence(clf, X_train_pca_df, features=range(pca_train.n_components_), grid_resolution=50)\n",
    "\n",
    "# # Compute the contribution of each original feature to each PC\n",
    "# pc_contributions = pca_train.components_\n",
    "\n",
    "# # Map the PDPs back to the original features\n",
    "# values = np.array(axs.pd_results_[0]['values'])\n",
    "# contributions = np.matmul(pc_contributions.T, values.T)\n",
    "# effects = np.sum(contributions.T, axis=1)\n",
    "# feature_effects = pd.DataFrame({'Feature': X_train_resampled_final.columns, 'Effect': effects})\n",
    "# for feature_name in X_train.columns:\n",
    "#     fig, ax = plt.subplots()\n",
    "#     pdp_values = axs.pd_results_[feature_name]['average']\n",
    "#     ax.plot(values[:, feature_name], pdp_values)\n",
    "#     ax.set_xlabel(feature_name)\n",
    "#     ax.set_ylabel('Predicted Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# # Choose the features to generate partial dependence plots for\n",
    "# features = [0,1,2]\n",
    "\n",
    "# # Generate partial dependence plots for the specified features\n",
    "# pdp_display = PartialDependenceDisplay.from_estimator(rf_model, X_train_pca_df, features)\n",
    "\n",
    "# # Display the PDP plots\n",
    "# pdp_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf59a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "# # Generate PDPs for the principal components\n",
    "# pdp_display = plot_partial_dependence(clf, X_train_pca_df, features=range(pca_train.n_components_), grid_resolution=50)\n",
    "\n",
    "# # Display the PDP plot\n",
    "# pdp_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b864889",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca15f9",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e885ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Define the hyperparameter space to search over\n",
    "param_dist = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "    'num_leaves': sp_randint(6, 50),\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': sp_randint(50, 200),\n",
    "    'max_depth': sp_randint(3, 15),\n",
    "    'min_child_samples': sp_randint(10, 50),\n",
    "    'min_split_gain': [0, 0.01, 0.1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c9d1f",
   "metadata": {},
   "source": [
    "### HalvingRandomSeacrhCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9326c217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HalvingRandomSearchCV(estimator=LGBMClassifier(), factor=2, max_resources=100,\n",
       "                      param_distributions={'boosting_type': ['gbdt', 'dart',\n",
       "                                                             'goss'],\n",
       "                                           'learning_rate': [0.05, 0.1, 0.2],\n",
       "                                           'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023B9002A9C8>,\n",
       "                                           'min_child_samples': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023B900897C8>,\n",
       "                                           'min_split_gain': [0, 0.01, 0.1, 1],\n",
       "                                           'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023B8C7D4108>,\n",
       "                                           'num_leaves': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023B9003E9C8>},\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Define the hyperparameter space to search over\n",
    "param_dist = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "    'num_leaves': sp_randint(6, 50),\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': sp_randint(50, 200),\n",
    "    'max_depth': sp_randint(3, 15),\n",
    "    'min_child_samples': sp_randint(10, 50),\n",
    "    'min_split_gain': [0, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "# Define the estimator object\n",
    "estimator = lgb.LGBMClassifier()\n",
    "\n",
    "# Instantiate a HalvingRandomSearchCV object\n",
    "halving_cv = HalvingRandomSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_distributions=param_dist,\n",
    "    factor=2,\n",
    "    resource='n_samples',\n",
    "    max_resources=100,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the HalvingRandomSearchCV object to the training data\n",
    "halving_cv.fit(X_train_pca, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d77b03b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'learning_rate': 0.05, 'max_depth': 14, 'min_child_samples': 31, 'min_split_gain': 0, 'n_estimators': 138, 'num_leaves': 32}\n"
     ]
    }
   ],
   "source": [
    "print(halving_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ad727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the LightGBM model\n",
    "# lgb_model = lgb.LGBMClassifier(objective='binary')\n",
    "\n",
    "# # Perform the hyperparameter search using RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(lgb_model, param_distributions=param_dist, cv=3, n_iter=15,\n",
    "#                                    scoring='roc_auc', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48099ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the random search to the training data\n",
    "# random_search.fit(X_train_pca, y_train_resampled_final)\n",
    "\n",
    "# # Print the best hyperparameters found\n",
    "# print('Best hyperparameters: ', random_search.best_params_)\n",
    "\n",
    "# # Get the best LightGBM model\n",
    "# best_lgb_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the best model on the test set\n",
    "# y_pred = best_lgb_model.predict(X_test_pca)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8539a96",
   "metadata": {},
   "source": [
    "## Model Training LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define the LightGBM classifier\n",
    "# clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate=0.2, max_depth= 11, min_child_samples= 33, min_split_gain= 0, n_estimators= 185, num_leaves= 29)\n",
    "\n",
    "# # Define the cross-validation method\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X_train_resampled_final, y_train_resampled_final)):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_fold_train, y_fold_train = X_train_resampled_final.iloc[train_index],  y_train_resampled_final.iloc[train_index]\n",
    "#     X_fold_test, y_fold_test = X_train_resampled_final.iloc[test_index],  y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "#     # Train the LightGBM classifier\n",
    "#     clf.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13bdb64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[287134    927]\n",
      " [   385     11]]\n",
      "Fold 0:\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    288061\n",
      "           1       0.01      0.03      0.02       396\n",
      "\n",
      "    accuracy                           1.00    288457\n",
      "   macro avg       0.51      0.51      0.51    288457\n",
      "weighted avg       1.00      1.00      1.00    288457\n",
      "\n",
      "Confusion matrix:\n",
      "[[287704    356]\n",
      " [   386     10]]\n",
      "Fold 1:\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    288060\n",
      "           1       0.03      0.03      0.03       396\n",
      "\n",
      "    accuracy                           1.00    288456\n",
      "   macro avg       0.51      0.51      0.51    288456\n",
      "weighted avg       1.00      1.00      1.00    288456\n",
      "\n",
      "Total runtime: 3.31 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Define the LightGBM classifier\n",
    "clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate= 0.5, max_depth= 18, min_child_samples= 20, min_split_gain= 0, n_estimators= 100, num_leaves= 33, objective='binary', metric='binary_logloss')\n",
    "\n",
    "# Define the cross-validation method\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "    X_fold_test, y_fold_test = X_train_pca_df.iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "    # Train the LightGBM classifier\n",
    "    clf.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Evaluate the performance of the model on the testing data\n",
    "    y_pred = clf.predict(X_fold_test)\n",
    "    report = classification_report(y_fold_test, y_pred)\n",
    "    cm = confusion_matrix(y_fold_test, y_pred)\n",
    "    print(f\"Confusion matrix:\\n{cm}\")\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"Classification report:\\n{report}\")\n",
    "\n",
    "    # Evaluate the performance of the model on the testing data\n",
    "    y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "    fpr, tpr, thresholds = roc_curve(y_fold_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'Fold {fold} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "\n",
    "# Plot the random classifier\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for LightGBM Classifier')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802ce91",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bd106eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[69830    82]\n",
      " [   84     4]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     69912\n",
      "           1       0.05      0.05      0.05        88\n",
      "\n",
      "    accuracy                           1.00     70000\n",
      "   macro avg       0.52      0.52      0.52     70000\n",
      "weighted avg       1.00      1.00      1.00     70000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = clf.predict(X_test_pca_df)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Compute the classification report, including recall, precision, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04dc9716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[69896    16]\n",
      " [   85     3]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     69912\n",
      "           1       0.16      0.03      0.06        88\n",
      "\n",
      "    accuracy                           1.00     70000\n",
      "   macro avg       0.58      0.52      0.53     70000\n",
      "weighted avg       1.00      1.00      1.00     70000\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ConfusionMatrixDisplay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19304\\2274229236.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Define the display object for the confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Negative\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Positive\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Plot the confusion matrix with colors and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ConfusionMatrixDisplay' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = clf.predict(X_test_pca_df)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Compute the classification report, including recall, precision, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\")\n",
    "print(report)\n",
    "\n",
    "# Define the display object for the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "\n",
    "# Plot the confusion matrix with colors and labels\n",
    "disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal', values_format=None)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ae1df45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_test_prob = clf.predict_proba(X_test_pca_df)[:, 1]\n",
    "\n",
    "# Calculate the false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "\n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label=f'Test Set (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for LightGBM Classifier')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21baab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [10,25,35],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedeef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(lgb_model, param_grid, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe977af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.fit(X_train_pca, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6125a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best params:\", grid_search.best_params_)\n",
    "# print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20869ac6",
   "metadata": {},
   "source": [
    "## Convert to PCA elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414eac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_pca_df = pd.DataFrame(X_train_pca, columns=['PC1', 'PC2', 'PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2217cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import warnings\n",
    "\n",
    "# # Ignore all warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# # Define the LightGBM classifier\n",
    "# #clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate= 0.2, max_depth= 11, min_child_samples= 13, min_split_gain= 0, n_estimators= 185, num_leaves= 10, objective='binary', metric='binary_logloss')\n",
    "# #clf = lgb.LGBMClassifier(max_depth=28,num_leaves=17,objective='binary', metric='binary_logloss',drop_rate=0.225)\n",
    "# class_weights={0:1,1:30}\n",
    "# clf = lgb.LGBMClassifier(learning_rate=0.05,max_depth=10,num_leaves=15,data_sample_strategy='goss',boosting_type='gbdt',objective='binary', metric='binary_logloss',class_weight=class_weights)\n",
    "\n",
    "# # Define the cross-validation method\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df , y_train_resampled_final)):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_fold_train, y_fold_train =X_train_pca_df .iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "#     X_fold_test, y_fold_test = X_train_pca_df .iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "#     # Train the LightGBM classifier with early stopping\n",
    "#     clf.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_test, y_fold_test)], early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     cm = confusion_matrix(y_fold_test, y_pred)\n",
    "#     print(f\"Confusion matrix:\\n{cm}\")\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "#     fpr, tpr, thresholds = roc_curve(y_fold_test, y_pred_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     # Plot the ROC curve\n",
    "#     plt.plot(fpr, tpr, label=f'Fold {fold} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# # Plot the random classifier\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')\n",
    "\n",
    "# # Add labels and legend\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve for LightGBM Classifier')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e12ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first tree\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ac36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Plot the first tree\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95173c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define graph and node attributes with desired color scheme\n",
    "graph_attr = {'size': '50,50', 'dpi': '100', 'bgcolor': 'white', 'rankdir': 'TB', 'splines': 'ortho'}\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '1.2', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Plot the first tree with color\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], graph_attr=graph_attr, node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1533d509",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19312\\3947523443.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Plot the first tree with colored leaf nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'split_gain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'internal_value'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'internal_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_attr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Show the plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 5000x5000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Define node attributes with desired color scheme\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '0.4', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Set leaf node color to green\n",
    "node_attr['fillcolor'] = 'green'\n",
    "\n",
    "# Plot the first tree with colored leaf nodes\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20277109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Define node attributes with desired color scheme\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '1.2', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Set leaf node color to green\n",
    "node_attr['fillcolor'] = 'green'\n",
    "\n",
    "# Plot the first tree with colored leaf nodes\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f3c8e",
   "metadata": {},
   "source": [
    "## Misclassification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e327599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define the parameters for the learning curve\n",
    "# train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "# cv = 2  # number of cross-validation folds\n",
    "\n",
    "# # Generate the learning curve data\n",
    "# train_sizes, train_scores, val_scores = learning_curve(\n",
    "#     clf, X_train_pca, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    "# )\n",
    "\n",
    "# # Calculate the mean and standard deviation of the training and validation scores\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# val_scores_mean = np.mean(val_scores, axis=1)\n",
    "# val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Misclassification Error\")\n",
    "# plt.grid()\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (train_scores_mean + train_scores_std),\n",
    "#     1 - (train_scores_mean - train_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"r\",\n",
    "# )\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (val_scores_mean + val_scores_std),\n",
    "#     1 - (val_scores_mean - val_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"g\",\n",
    "# )\n",
    "# plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "# plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7f5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# # Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "# train_loss = []\n",
    "# cv_loss = []\n",
    "    \n",
    "# for size in train_sizes:\n",
    "#     # Split the data into training and cross-validation sets\n",
    "#     X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_pca_df, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "#     # Train the model on the training set\n",
    "#     clf.fit(X_train_new, y_train_new)\n",
    "    \n",
    "#     # Compute the cross-entropy loss on the training set\n",
    "#     y_train_pred = clf.predict_proba(X_train_pca_df)\n",
    "#     train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "#     # Compute the cross-entropy loss on the cross-validation set\n",
    "#     y_cv_pred = clf.predict_proba(X_cv)\n",
    "#     cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "# plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "# plt.xlabel('Training Set Size')\n",
    "# plt.ylabel('Cross-Entropy Loss')\n",
    "# plt.title('Learning Curve')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(clf, X_train_pca, y_train_resampled_final, cv=5)\n",
    "\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b5fed",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df40499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "# Get predicted probabilities for the test data\n",
    "y_prob = clf.predict_proba(X_test_pca_df)[:,1]\n",
    "\n",
    "# Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "thresholds = np.arange(0.1,30,0.1)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    precision_scores.append(precision[1])\n",
    "    recall_scores.append(recall[1])\n",
    "    f1_scores.append(f1[1])\n",
    "\n",
    "# Find the optimal threshold that maximizes the F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Assign the class labels based on the optimal threshold\n",
    "y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the performance of the classifier for the optimal threshold\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the class labels and probabilities for the test set\n",
    "y_test_pred = clf.predict(X_test_pca_df)\n",
    "y_test_prob = clf.predict_proba(X_test_pca_df)[:, 1]\n",
    "# Compute the false positive rate, true positive rate, and AUC for the test set\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_prob)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "# Plot the ROC curve for the test set\n",
    "plt.plot(fpr_test, tpr_test, color='blue', lw=2, label='Test ROC curve (AUC =%0.2f)' % roc_auc_test)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Test Set')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the precision, recall, and F1-score for each threshold\n",
    "print(\"Threshold\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(len(thresholds)):\n",
    "    print(f\"{thresholds[i]:.1f}\\t\\t{precision_scores[i]:.3f}\\t\\t{recall_scores[i]:.3f}\\t\\t{f1_scores[i]:.3f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Print the optimal threshold and the corresponding F1-score\n",
    "print(f\"\\nOptimal Threshold: {optimal_threshold:.1f}\")\n",
    "print(f\"Optimal F1-Score: {max(f1_scores):.3f}\")\n",
    "print(f\"Optimal Recall: {max(recall_scores):.3f}\")\n",
    "print(f\"Optimal Precision: {max(precision_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061d019",
   "metadata": {},
   "source": [
    "## Performance Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d8946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.529, 0.404, 0.448]\n",
    "# recalls = [0.784, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['f1-score', 'recall', 'precision']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#635f83'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='Default', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='RandomizedSearchCV', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='HalvingRandomSearchCV', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.529, 0.404, 0.448]\n",
    "# recalls = [0.784, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['Default', 'RandomizedSearchCV', 'HalvingRandomSearchCV']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#c7e9b8'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='f1-score', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='recall', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='precision', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "default_scores = [0.529, 0.404, 0.448]\n",
    "randomized_scores = [0.610, 0.596, 0.565]\n",
    "metrics = ['f1-score', 'recall', 'precision']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "# Set the colors for the bars\n",
    "default_colors = ['#c5d3ff', '#c5d3ff', '#c5d3ff']\n",
    "randomized_colors = ['#e9c6b8', '#e9c6b8', '#e9c6b8']\n",
    "\n",
    "# Create the figure and axes objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars for each hyperparameter search method with the specified colors\n",
    "ax.bar(x - width/2, default_scores, width, label='Default', color=default_colors, edgecolor='black')\n",
    "ax.bar(x + width/2, randomized_scores, width, label='RandomizedSearchCV', color=randomized_colors, edgecolor='black')\n",
    "\n",
    "# Add some labels and a legend\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(title='Hyperparameters used',bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "default_scores = [0.529, 0.732, 1]\n",
    "randomized_scores = [0.610, 0.834, 1]\n",
    "metrics = ['f1-score', 'recall', 'precision']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "# Set the colors for the bars\n",
    "default_colors = ['#c5d3ff', '#c5d3ff', '#c5d3ff']\n",
    "randomized_colors = ['#e9c6b8', '#e9c6b8', '#e9c6b8']\n",
    "\n",
    "# Create the figure and axes objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars for each hyperparameter search method with the specified colors\n",
    "ax.bar(x - width/2, default_scores, width, label='Default', color=default_colors, edgecolor='black')\n",
    "ax.bar(x + width/2, randomized_scores, width, label='RandomizedSearchCV', color=randomized_colors, edgecolor='black')\n",
    "\n",
    "# Add the values on each bar\n",
    "for i, v in enumerate(default_scores):\n",
    "    ax.text(i - width/2, v + 0.02, str(v), color='black', ha='center')\n",
    "for i, v in enumerate(randomized_scores):\n",
    "    ax.text(i + width/2, v + 0.02, str(v), color='black', ha='center')\n",
    "\n",
    "# Add some labels and a legend\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(title='Hyperparameters used',bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.603, 0.404, 0.448]\n",
    "# recalls = [0.854, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['Default', 'RandomizedSearchCV', ' HalvingRandomSearchCV']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#635f83'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='f1-score', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='recall', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='precision', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add score values on top of each bar\n",
    "# for i, (score1, score2, score3) in enumerate(zip(f1_scores, recalls, precisions)):\n",
    "#     ax.text(x[i] - width, score1 + 0.01, str(score1), ha='center', va='bottom', fontweight='bold')\n",
    "#     ax.text(x[i], score2 + 0.01, str(score2), ha='center', va='bottom', fontweight='bold')\n",
    "#     ax.text(x[i] + width, score3 + 0.01, str(score3), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Hyperparameter and Metric')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87793743",
   "metadata": {},
   "source": [
    "## LightGBM New trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c015c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#class_weights={0:1,1:30}\n",
    "# Define the LightGBM classifier\n",
    "#clf = lgb.LGBMClassifier(max_depth=28,num_leaves=17,objective='binary', metric='binary_logloss',drop_rate=0.225,class_weight=class_weights)\n",
    "clf = lgb.LGBMClassifier(objective='binary', metric='binary_logloss')\n",
    "# Define the cross-validation method\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# Create an empty list to store the optimized thresholds for each fold\n",
    "optimized_thresholds = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df , y_train_resampled_final)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_fold_train, y_fold_train =X_train_pca_df .iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "    X_fold_test, y_fold_test = X_train_pca_df .iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "    # Train the LightGBM classifier with early stopping\n",
    "    clf.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_test, y_fold_test)], early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "    # Evaluate the performance of the model on the testing data\n",
    "    y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "    \n",
    "    # Create an empty dictionary to store the F1-scores for each threshold\n",
    "    f1_scores = {}\n",
    "    \n",
    "    # Iterate through a range of possible threshold values\n",
    "    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        # Convert the predicted probabilities to predicted labels based on the threshold\n",
    "        y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate the classification report and select the threshold that maximizes the F1-score\n",
    "        report = classification_report(y_fold_test, y_pred, output_dict=True)\n",
    "        f1_scores[threshold] = report['1']['f1-score']\n",
    "    \n",
    "    # Select the threshold that maximizes the F1-score\n",
    "    optimized_threshold = max(f1_scores, key=f1_scores.get)\n",
    "    optimized_thresholds.append(optimized_threshold)\n",
    "    \n",
    "    # Convert the predicted probabilities to predicted labels based on the optimized threshold\n",
    "    y_pred = (y_pred_prob >= optimized_threshold).astype(int)\n",
    "    \n",
    "    # Calculate the classification report and confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eec368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_set_size = [25000, 50000, 75000, 100000, 125000, 150000, 175000, 200000, 225000]\n",
    "training_loss = [0.253, 0.250, 0.247, 0.246, 0.2455, 0.245, 0.245, 0.245, 0.245]\n",
    "cv_loss = [0.255, 0.252, 0.249, 0.2475, 0.247, 0.2465, 0.246, 0.2458, 0.2458]\n",
    "\n",
    "plt.plot(training_set_size, training_loss, label='Training Loss')\n",
    "plt.plot(training_set_size, cv_loss, label='Cross-Validation Loss')\n",
    "\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Learing Curve')\n",
    "plt.ylim(0.244, 0.256) # Set the y-axis limits\n",
    "plt.yticks([0.244, 0.246, 0.248, 0.25, 0.252, 0.254, 0.256]) # Set the y-axis tick labels\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
