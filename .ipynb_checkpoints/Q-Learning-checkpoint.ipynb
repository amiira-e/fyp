{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6aee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fffedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7df038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>type</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>nameOrig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>246917.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3175848.97</td>\n",
       "      <td>3422766.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51184</td>\n",
       "      <td>181039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>165577.48</td>\n",
       "      <td>242080.31</td>\n",
       "      <td>407657.78</td>\n",
       "      <td>653770.69</td>\n",
       "      <td>488193.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34391</td>\n",
       "      <td>347697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331</td>\n",
       "      <td>11147.81</td>\n",
       "      <td>21271.00</td>\n",
       "      <td>10123.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>304528</td>\n",
       "      <td>587476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304</td>\n",
       "      <td>3758.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>369290</td>\n",
       "      <td>23581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "      <td>295770.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>429733.98</td>\n",
       "      <td>725504.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>121755</td>\n",
       "      <td>438334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699995</th>\n",
       "      <td>400</td>\n",
       "      <td>12484.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>292816</td>\n",
       "      <td>380945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699996</th>\n",
       "      <td>187</td>\n",
       "      <td>27274.11</td>\n",
       "      <td>10231.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>455832</td>\n",
       "      <td>483984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699997</th>\n",
       "      <td>225</td>\n",
       "      <td>29426.83</td>\n",
       "      <td>49601.00</td>\n",
       "      <td>20174.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>331919</td>\n",
       "      <td>127023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699998</th>\n",
       "      <td>354</td>\n",
       "      <td>21747.21</td>\n",
       "      <td>3309.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58996.31</td>\n",
       "      <td>80743.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>246709</td>\n",
       "      <td>104457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699999</th>\n",
       "      <td>254</td>\n",
       "      <td>157659.00</td>\n",
       "      <td>230708.00</td>\n",
       "      <td>73049.00</td>\n",
       "      <td>93659.92</td>\n",
       "      <td>251318.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148150</td>\n",
       "      <td>392062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        step     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "0        259  246917.44           0.00            0.00      3175848.97   \n",
       "1        161  165577.48      242080.31       407657.78       653770.69   \n",
       "2        331   11147.81       21271.00        10123.19            0.00   \n",
       "3        304    3758.44           0.00            0.00            0.00   \n",
       "4        355  295770.07           0.00            0.00       429733.98   \n",
       "...      ...        ...            ...             ...             ...   \n",
       "699995   400   12484.57           0.00            0.00            0.00   \n",
       "699996   187   27274.11       10231.00            0.00            0.00   \n",
       "699997   225   29426.83       49601.00        20174.17            0.00   \n",
       "699998   354   21747.21        3309.24            0.00        58996.31   \n",
       "699999   254  157659.00      230708.00        73049.00        93659.92   \n",
       "\n",
       "        newbalanceDest  isFraud  isFlaggedFraud  type  nameDest  nameOrig  \n",
       "0           3422766.41        0               0     1     51184    181039  \n",
       "1            488193.21        0               0     0     34391    347697  \n",
       "2                 0.00        0               0     3    304528    587476  \n",
       "3                 0.00        0               0     3    369290     23581  \n",
       "4            725504.05        0               0     1    121755    438334  \n",
       "...                ...      ...             ...   ...       ...       ...  \n",
       "699995            0.00        0               0     3    292816    380945  \n",
       "699996            0.00        0               0     3    455832    483984  \n",
       "699997            0.00        0               0     3    331919    127023  \n",
       "699998        80743.52        0               0     1    246709    104457  \n",
       "699999       251318.91        0               0     1    148150    392062  \n",
       "\n",
       "[700000 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917400ef",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ccfec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01831010",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4b163c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ffe88c",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9456e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acccb67",
   "metadata": {},
   "source": [
    "## Noisy samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7570d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb590ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96322164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9187674",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f140cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 598171.5264376234, 'oldbalanceOrg': 233057.91269653654, 'newbalanceOrig': 144030.63958698732, 'oldbalanceDest': 674633.4393627887, 'newbalanceDest': 1038934.0623143028}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random.seed(0)\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.01, 'oldbalanceOrg': 0.07, 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "    # Replace the outliers in the test set with the trimmed means obtained from the train set\n",
    "    test_outliers = X_test.loc[X_test[col_name] > np.percentile(X_test[col_name], 100*(1-trim_props[col_name])), col_name]\n",
    "    X_test.loc[test_outliers.index, col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c501e4e",
   "metadata": {},
   "source": [
    "## Scale train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e3938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73742329",
   "metadata": {},
   "source": [
    "## Scale test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "229fc7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efd450a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.64456917e+00, -1.90522237e-01, -3.90563892e-04, ...,\n",
       "        -1.44198759e+00, -1.41965405e+00, -6.87988149e-01],\n",
       "       [-8.86101418e-01, -3.44353884e-01, -3.90563892e-04, ...,\n",
       "        -1.44198759e+00, -7.76083661e-01, -8.36571262e-01],\n",
       "       [ 2.48566344e-01,  1.88267922e+00, -4.99719532e-01, ...,\n",
       "         1.41709201e+00, -8.71217903e-01,  6.88967858e-01],\n",
       "       ...,\n",
       "       [-1.35938530e+00,  1.40430900e-01,  1.29110515e+00, ...,\n",
       "         1.41709201e+00, -2.90024188e-01, -5.34184685e-01],\n",
       "       [ 1.00096636e+00, -3.44068453e-01, -4.11611613e-01, ...,\n",
       "        -7.27217691e-01, -5.43069501e-01, -1.29799175e+00],\n",
       "       [-3.88546570e-01, -3.47133556e-01, -4.46189747e-01, ...,\n",
       "        -7.27217691e-01, -7.70936605e-01, -1.08652209e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6e462",
   "metadata": {},
   "source": [
    "## Reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04713c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final = pd.DataFrame(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_resampled_final.reset_index(drop=True, inplace=True)\n",
    "# y_train_resampled_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe68a1",
   "metadata": {},
   "source": [
    "## Implement an auto-encoder to extract important characteristics from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f835f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Convert NumPy array to pandas DataFrame\n",
    "# X_train_resampled_final = pd.DataFrame(X_train_resampled_final, columns=X_train.columns)\n",
    "\n",
    "# # Define input layer\n",
    "# input_layer = Input(shape=(len(X_train_resampled_final.columns),))\n",
    "\n",
    "# # Define encoder layers\n",
    "# encoded = Dense(64, activation='relu')(input_layer)\n",
    "# encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "# # Define decoder layers\n",
    "# decoded = Dense(64, activation='relu')(encoded)\n",
    "# decoded = Dense(len(X_train_resampled_final.columns), activation='sigmoid')(decoded)\n",
    "\n",
    "# # Define autoencoder\n",
    "# autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "\n",
    "# # Compile autoencoder\n",
    "# autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# # Train autoencoder on preprocessed data\n",
    "# autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=50, batch_size=128, validation_split=0.2)\n",
    "\n",
    "# # Extract encoded features from data using encoder\n",
    "# encoded_features = autoencoder.predict(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4214e65c",
   "metadata": {},
   "source": [
    "## Create the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a47ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcf71006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "# Define model architecture\n",
    "model = Sequential()\n",
    "\n",
    "#Add one hidden layer with 64 neurons\n",
    "#Activation function in hidden layer is Relu\n",
    "model.add(Dense(64, activation='relu', input_shape=(input_dim,)))\n",
    "\n",
    "#Add an output layer with 2 neurons (binary classification:fraud or genuine)\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# Compile model with binary cross-entropy loss function and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46f33d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                704       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 834\n",
      "Trainable params: 834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dc943ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_resampled_final = to_categorical(y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c2ec60",
   "metadata": {},
   "source": [
    "## Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f44ee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019588396DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019588396DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000019588DE1DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000019588DE1DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019589BA1DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019589BA1DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000195895491F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000195895491F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019589C583A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019589C583A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000019589549E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000019589549E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Cross-validation scores: [0.9897447228431702, 0.990921676158905, 0.988976776599884]\n",
      "Mean recall: 0.9898810585339864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "# Define model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Define the number of folds\n",
    "n_folds = 3\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Train and evaluate the model using cross-validation\n",
    "cv_scores = []\n",
    "for train, val in kfold.split(X_train_resampled_final, y_train_resampled_final):\n",
    "    # Define model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(input_dim,)))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train_resampled_final[train], y_train_resampled_final[train], epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate the model on the validation data\n",
    "    loss, recall = model.evaluate(X_train_resampled_final[val], y_train_resampled_final[val], verbose=0)\n",
    "    cv_scores.append(recall)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean recall:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43cd63c",
   "metadata": {},
   "source": [
    "## AE & MN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2a93a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019589549288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019589549288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 19s 1ms/step - loss: -348.0738\n",
      "Epoch 2/2\n",
      "13064/13064 [==============================] - 18s 1ms/step - loss: -2092.0618\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000195888EFAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000195888EFAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 13s 1ms/step\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019588DEFDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019588DEFDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 18s 1ms/step - loss: 0.4547 - accuracy: 0.8036\n",
      "Epoch 2/2\n",
      "13064/13064 [==============================] - 18s 1ms/step - loss: 0.4441 - accuracy: 0.8076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19588dd7688>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "# Define input shape\n",
    "input_shape = X_train_resampled_final.shape[1]\n",
    "\n",
    "# Define autoencoder model\n",
    "autoencoder_input = Input(shape=input_shape)\n",
    "autoencoder_hidden = Dense(10, activation='relu')(autoencoder_input)\n",
    "autoencoder_output = Dense(10, activation='sigmoid')(autoencoder_hidden)\n",
    "autoencoder = Model(autoencoder_input, autoencoder_output)\n",
    "\n",
    "# Define mediator network model with a hidden layer\n",
    "mediator_input = autoencoder_hidden\n",
    "mediator_hidden = Dense(5, activation='relu')(mediator_input)\n",
    "mediator_output = Dense(2, activation='sigmoid')(mediator_hidden)\n",
    "mediator = Model(mediator_input, mediator_output)\n",
    "\n",
    "# Compile models\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "mediator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train autoencoder model\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=2, batch_size=32)\n",
    "\n",
    "# Get hidden layer output of autoencoder for training mediator network\n",
    "hidden_layer_output = autoencoder.predict(X_train_resampled_final)\n",
    "\n",
    "# Train mediator network using hidden layer output of autoencoder as input\n",
    "mediator.fit(hidden_layer_output, y_train_resampled_final, epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a13df472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_36 (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220\n",
      "Trainable params: 220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15abde5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mediator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f81f7c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000195888383A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000195888383A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 18s 1ms/step - loss: -730.5591\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001958B7ECDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001958B7ECDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 19s 1ms/step - loss: 0.0738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19589db7bc8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# # extract hidden layer output from autoencoder\n",
    "# hidden_layer_output = autoencoder.layers[1].output\n",
    "\n",
    "# # create the mediator network\n",
    "# mediator_encoding_dim = 11\n",
    "# mediator_output_dim = 2\n",
    "\n",
    "# mediator_input_layer = Input(shape=(encoding_dim,))\n",
    "# mediator_hidden_layer = Dense(mediator_encoding_dim, activation='relu')(mediator_input_layer)\n",
    "# mediator_output_layer = Dense(mediator_output_dim, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "# mediator_network = Model(inputs=hidden_layer_output, outputs=mediator_output_layer)\n",
    "# mediator_network.compile(optimizer='adam', loss='mse')\n",
    "# mediator_network.fit(autoencoder.predict(X_train_resampled_final), y_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "encoder_output = autoencoder.layers[1].output\n",
    "\n",
    "# Mediator network\n",
    "mediator_input_dim = 20\n",
    "mediator_output_dim = 2\n",
    "\n",
    "mediator_hidden_layer = Dense(11, activation='relu')(encoder_output)\n",
    "mediator_output_layer = Dense(mediator_output_dim, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "mediator_network = Model(inputs=autoencoder.input, outputs=mediator_output_layer)\n",
    "mediator_network.compile(optimizer='adam', loss='mse')\n",
    "mediator_network.fit(X_train_resampled_final, y_train_resampled_final, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89d81484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 430\n",
      "Trainable params: 430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd3fc25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 11)                231       \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 2)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 475\n",
      "Trainable params: 475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mediator_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5afaed6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019590D65E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019590D65E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 17s 1ms/step - loss: -707.1310\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000019590ECCCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000019590ECCCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "[[  0.         0.       117.2829    93.16803   84.73724  114.24515\n",
      "  126.07207    0.         0.         0.         0.        30.796825\n",
      "  119.49101  113.75199    0.        30.935465 132.06624    0.\n",
      "    0.         0.      ]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# create a new model that outputs the hidden layer\n",
    "hidden_layer_output = autoencoder.layers[1].output\n",
    "hidden_layer_model = Model(inputs=autoencoder.input, outputs=hidden_layer_output)\n",
    "\n",
    "# get the hidden layer output for a sample\n",
    "sample_hidden_output = hidden_layer_model.predict(X_train_resampled_final[0].reshape(1, -1))\n",
    "print(sample_hidden_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "89c6336d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_74 (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 20)                220       \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 430\n",
      "Trainable params: 430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5dfd4a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000195910FA678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000195910FA678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 18s 1ms/step - loss: -708.8043\n",
      "13064/13064 [==============================] - 12s 937us/step\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000195910FAA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000195910FAA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 16s 1ms/step - loss: 0.1382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1958bcac588>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# extract hidden layer output from autoencoder\n",
    "hidden_layer_output = autoencoder.layers[1].output\n",
    "\n",
    "# create the mediator network with the hidden layer output as input\n",
    "mediator_input_layer = Input(shape=hidden_layer_output.shape[1:])\n",
    "mediator_hidden_layer = Dense(11, activation='relu')(mediator_input_layer)\n",
    "mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "mediator_network.compile(optimizer='adam', loss='mse')\n",
    "mediator_network.fit(hidden_layer_model.predict(X_train_resampled_final), y_train_resampled_final, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "54e61721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_75 (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 20)                220       \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 430\n",
      "Trainable params: 430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0a9417ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_76 (InputLayer)       [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 11)                231       \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 2)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 255\n",
      "Trainable params: 255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mediator_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a24838db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019590C9D558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000019590C9D558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 20s 1ms/step - loss: -668.7812\n",
      "13064/13064 [==============================] - 14s 1ms/step\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001958B715AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001958B715AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13064/13064 [==============================] - 17s 1ms/step - loss: 0.0808\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# extract hidden layer output from autoencoder\n",
    "hidden_layer_output = autoencoder.layers[1].output\n",
    "\n",
    "# create the mediator network with the hidden layer output as input\n",
    "mediator_input_layer = Input(shape=hidden_layer_output.shape[1:])\n",
    "mediator_hidden_layer = Dense(11, activation='relu')(mediator_input_layer)\n",
    "mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "mediator_network.compile(optimizer='adam', loss='mse')\n",
    "mediator_network.fit(hidden_layer_model.predict(X_train_resampled_final), y_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "agent_hidden_layer_output = mediator_network.layers[1].output\n",
    "# extract hidden layer output from mediator network\n",
    "agent_input_layer = Input(shape=agent_hidden_layer_output.shape[1:])\n",
    "agent_hidden_layer = Dense(5, activation='relu')(agent_input_layer)\n",
    "agent_output_layer = Dense(2, activation='softmax')(agent_hidden_layer)\n",
    "\n",
    "agent_network = Model(inputs=agent_input_layer, outputs=agent_output_layer)\n",
    "agent_network.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eddd9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_78 (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 20)                220       \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 430\n",
      "Trainable params: 430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8dadf3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_79 (InputLayer)       [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 11)                231       \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 2)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 255\n",
      "Trainable params: 255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mediator_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5fc87d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_83 (InputLayer)       [(None, 11)]              0         \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 5)                 60        \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72\n",
      "Trainable params: 72\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agent_network.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
