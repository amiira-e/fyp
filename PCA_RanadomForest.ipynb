{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96fe4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77aebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4a9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "88dbbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def reservoir_sampling(iterable, k, header=True):\n",
    "    reservoir = []\n",
    "    for i, item in enumerate(iterable):\n",
    "        if i < k:\n",
    "            reservoir.append(item)\n",
    "        else:\n",
    "            j = random.randint(0, i)\n",
    "            if j < k:\n",
    "                reservoir[j] = item\n",
    "    return reservoir\n",
    "\n",
    "# Open the input CSV file\n",
    "with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\") as f:\n",
    "    # Check if header line exists\n",
    "    header = True\n",
    "    first_line = f.readline()\n",
    "    if not first_line.startswith('step,type,amount,nameOrig,oldbalanceOrg,newbalanceOrig,nameDest,oldbalanceDest,newbalanceDest,isFraud,isFlaggedFraud'):\n",
    "        header = False\n",
    "        f.seek(0)  # Rewind file pointer to beginning\n",
    "\n",
    "    # Sample from remaining lines\n",
    "    sampled_lines = reservoir_sampling(f, k=2300000, header=header)\n",
    "\n",
    "# Open the output CSV file and write the subsample to it\n",
    "with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample1300000.csv\", mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    if header:\n",
    "        writer.writerow(first_line.strip().split(','))\n",
    "    for line in sampled_lines:\n",
    "        writer.writerow(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c73182f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "78004e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample1300000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1a475b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0723ab28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2300000, 11)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9836cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change the data type of column 'A' from float64 to float32\n",
    "# df_sample['amount'] = df_sample['amount'].astype('float32')\n",
    "# df_sample['oldbalanceOrg'] = df_sample['oldbalanceOrg'].astype('float32')\n",
    "# df_sample['oldbalanceDest'] = df_sample['oldbalanceDest'].astype('float32')\n",
    "# df_sample['newbalanceOrig'] = df_sample['newbalanceOrig'].astype('float32')\n",
    "# df_sample['newbalanceDest'] = df_sample['newbalanceDest'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fb3200a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample['step'] = df_sample['step'].astype('int32')\n",
    "# df_sample['isFlaggedFraud'] = df_sample['isFlaggedFraud'].astype('int32') \n",
    "# df_sample['isFraud'] = df_sample['isFraud'].astype('int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "90be74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c850827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7c998f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4726858",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6c2c4bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998703\n",
      "1    0.001297\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998702\n",
      "1    0.001298\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998704\n",
      "1    0.001296\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "80d76c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2070000, 10)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e9678a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 2067314\n",
      "Class 1 count: 2686\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3d2295ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230000, 10)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f4d70",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9956a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f8de52ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 1033655\n",
      "Class 1 count: 413462\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_resampled)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ac687784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1447117, 10)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37071d3f",
   "metadata": {},
   "source": [
    "## Tomeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bb7c5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "551653ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 1033640\n",
      "Class 1 count: 413462\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train_resampled)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8cbe4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1447102, 10)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c22208",
   "metadata": {},
   "source": [
    "## ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "884b8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1c99782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 1024337\n",
      "Class 1 count: 413462\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train_resampled_new)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd513977",
   "metadata": {},
   "source": [
    "## OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "540e71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d7344156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 1004498\n",
      "Class 1 count: 413462\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = np.bincount(y_train_resampled_final)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b69f5014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 229702\n",
      "Class 1 count: 298\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_test)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8160d1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1417960, 10)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "55a1be8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1417960,)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9b64fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainPRIOR.csv\", index=False)\n",
    "#X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086706d5",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3996395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 558702.4522397261, 'oldbalanceOrg': 374657.3908887349, 'newbalanceOrig': 391980.38642993924, 'oldbalanceDest': 684937.8242165162, 'newbalanceDest': 1032557.3945382822}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random.seed(0)\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.01, 'oldbalanceOrg': 0.07, 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "    # Replace the outliers in the test set with the trimmed means obtained from the train set\n",
    "    test_outliers = X_test.loc[X_test[col_name] > np.percentile(X_test[col_name], 100*(1-trim_props[col_name])), col_name]\n",
    "    X_test.loc[test_outliers.index, col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf41283",
   "metadata": {},
   "source": [
    "## New trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6edbbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "# # Specify columns with outliers\n",
    "# cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# # Specify the number of bootstrapped samples to create per column\n",
    "# num_samples = 50\n",
    "\n",
    "# # Specify the trimming proportions for each column\n",
    "# trim_props = {'amount': 0.01, 'oldbalanceOrg': (0.07, 0.03), 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# # Initialize empty dictionaries to store the trimmed means for each column\n",
    "# train_trimmed_means = {}\n",
    "\n",
    "# # Loop over the specified columns\n",
    "# for col_name in cols_with_outliers:\n",
    "    \n",
    "#     # Check if the trimming proportion for this column is a tuple with two values\n",
    "#     if isinstance(trim_props[col_name], tuple):\n",
    "#         # If so, perform asymmetric trimming for the oldbalanceOrg column\n",
    "#         if col_name == 'oldbalanceOrg':\n",
    "#             # Calculate the median of the bootstrapped sample for the training set\n",
    "#             train_median = np.median(train_sample)\n",
    "#             train_trimmed_means[col_name] = train_median\n",
    "#             # Replace the outliers in the training set with the trimmed means\n",
    "#             X_train_resampled_final.loc[(X_train_resampled_final[col_name] < train_trimmed_means[col_name]) | (X_train_resampled_final[col_name] > train_trimmed_means[col_name]), col_name] = train_median\n",
    "\n",
    "#             continue\n",
    "#         else:\n",
    "#             continue\n",
    "    \n",
    "#     # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "#     train_bootstrapped_samples = []\n",
    "#     train_trimmed_means_list = []\n",
    "    \n",
    "#     # Loop over the number of desired samples\n",
    "#     for i in range(num_samples):\n",
    "#         # Randomly select indices from the column in the training set\n",
    "#         train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "#         # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "#         train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "#         # Calculate the right and left trimmed means of the bootstrapped sample for the training set\n",
    "#         train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "#         train_left_trimmed_mean = np.mean(train_sample[train_sample >= np.percentile(train_sample, 100*trim_props[col_name])])\n",
    "#         train_trimmed_means_list.append((train_left_trimmed_mean, train_right_trimmed_mean))\n",
    "        \n",
    "#     # Calculate the mean of the left and right trimmed means for the training set and add it to the dictionary\n",
    "#     train_left_mean = np.mean([x[0] for x in train_trimmed_means_list])\n",
    "#     train_right_mean = np.mean([x[1] for x in train_trimmed_means_list])\n",
    "#     train_trimmed_means[col_name] = (train_left_mean, train_right_mean)\n",
    "\n",
    "#     # Replace the outliers in the training set with the trimmed means\n",
    "#     X_train_resampled_final.loc[(X_train_resampled_final[col_name] < train_trimmed_means[col_name][0]) | (X_train_resampled_final[col_name] > train_trimmed_means[col_name][1]), col_name] = np.mean(train_sample)\n",
    "\n",
    "# # Print the trimmed means\n",
    "# print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4fadbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_resampled_final.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainPOST29.csv\", index=False)\n",
    "# #X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ebc1cc",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "48406ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# assuming X_train and X_test are your training and test data matrices\n",
    "# standardize the data using the mean and std from the training set\n",
    "X_train_mean = np.mean(X_train_resampled_final, axis=0)\n",
    "X_train_std = np.std(X_train_resampled_final, axis=0)\n",
    "X_train_std[X_train_std == 0] = 1 # avoid division by zero\n",
    "X_train_std_inv = 1 / X_train_std\n",
    "\n",
    "X_train_stdized = (X_train_resampled_final - X_train_mean) * X_train_std_inv\n",
    "X_test_stdized = (X_test - X_train_mean) * X_train_std_inv\n",
    "\n",
    "# compute the covariance matrix for the training data\n",
    "cov_matrix_train = np.cov(X_train_stdized.T)\n",
    "\n",
    "# compute the eigenvectors and eigenvalues for the training data\n",
    "eig_vals_train, eig_vecs_train = np.linalg.eig(cov_matrix_train)\n",
    "\n",
    "# select the top k eigenvectors for the training data\n",
    "pca_train = PCA(n_components=3)\n",
    "X_train_pca = pca_train.fit_transform(X_train_stdized)\n",
    "\n",
    "# project the test data onto the selected eigenvectors from the training data\n",
    "X_test_pca = pca_train.transform(X_test_stdized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e03563db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = list(df_sample.columns)\n",
    "\n",
    "# # print the selected features\n",
    "# print(\"Selected features:\")\n",
    "# for i in range(pca_train.n_components_):\n",
    "#     # find the index of the maximum absolute value in the ith row of the components array\n",
    "#     idx = np.argmax(np.abs(pca_train.components_[i]))\n",
    "#     # print the name of the feature with the maximum absolute value in the ith row of the components array\n",
    "#     print(f\"PC{i+1}: {feature_names[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7e0525f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04773016,  0.22425061,  0.24631546,  0.25128579,  0.48850429,\n",
       "        0.53138632,  0.01510558, -0.37867513, -0.39842692,  0.01558009])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0dfa2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0f8f47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "y_train_resampled_final = pd.Series(y_train_resampled_final)\n",
    "\n",
    "X_train_pca_df.reset_index(drop=True, inplace=True)\n",
    "y_train_resampled_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9b023afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_df = X_test_pca_df.rename(columns={0: 'PC1', 1: 'PC2', 2: 'PC3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "bcdfba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226320</td>\n",
       "      <td>0.417463</td>\n",
       "      <td>-1.591484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.656770</td>\n",
       "      <td>-1.694291</td>\n",
       "      <td>-3.275007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.303748</td>\n",
       "      <td>0.792214</td>\n",
       "      <td>-0.193327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795198</td>\n",
       "      <td>-1.101438</td>\n",
       "      <td>0.595755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.290476</td>\n",
       "      <td>-0.031537</td>\n",
       "      <td>2.885615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229995</th>\n",
       "      <td>-1.245324</td>\n",
       "      <td>-0.253249</td>\n",
       "      <td>-0.223562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229996</th>\n",
       "      <td>1.626971</td>\n",
       "      <td>0.188985</td>\n",
       "      <td>3.799534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229997</th>\n",
       "      <td>-1.418129</td>\n",
       "      <td>0.081159</td>\n",
       "      <td>-0.251401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229998</th>\n",
       "      <td>-1.937120</td>\n",
       "      <td>0.107723</td>\n",
       "      <td>-0.530038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229999</th>\n",
       "      <td>-0.450026</td>\n",
       "      <td>-0.796474</td>\n",
       "      <td>0.241580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       0.226320  0.417463 -1.591484\n",
       "1       4.656770 -1.694291 -3.275007\n",
       "2      -1.303748  0.792214 -0.193327\n",
       "3       0.795198 -1.101438  0.595755\n",
       "4       1.290476 -0.031537  2.885615\n",
       "...          ...       ...       ...\n",
       "229995 -1.245324 -0.253249 -0.223562\n",
       "229996  1.626971  0.188985  3.799534\n",
       "229997 -1.418129  0.081159 -0.251401\n",
       "229998 -1.937120  0.107723 -0.530038\n",
       "229999 -0.450026 -0.796474  0.241580\n",
       "\n",
       "[230000 rows x 3 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "69a914c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df = X_train_pca_df.rename(columns={0: 'PC1', 1: 'PC2', 2: 'PC3', 3: 'PC4',4: 'PC5',5: 'PC6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "bd002ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PC1', 'PC2', 'PC3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "17bb1639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.364567</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.816782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.320127</td>\n",
       "      <td>-0.739112</td>\n",
       "      <td>-0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.907536</td>\n",
       "      <td>-0.432147</td>\n",
       "      <td>1.707089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.802131</td>\n",
       "      <td>-0.871310</td>\n",
       "      <td>-0.297497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.341204</td>\n",
       "      <td>-0.304572</td>\n",
       "      <td>-0.184539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417955</th>\n",
       "      <td>1.154414</td>\n",
       "      <td>0.805976</td>\n",
       "      <td>-0.550955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417956</th>\n",
       "      <td>-0.441786</td>\n",
       "      <td>-0.579326</td>\n",
       "      <td>0.286315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417957</th>\n",
       "      <td>-0.749174</td>\n",
       "      <td>1.568552</td>\n",
       "      <td>-0.261644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417958</th>\n",
       "      <td>0.149151</td>\n",
       "      <td>-0.496745</td>\n",
       "      <td>0.113672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417959</th>\n",
       "      <td>3.566442</td>\n",
       "      <td>3.061773</td>\n",
       "      <td>-2.003602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1417960 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PC1       PC2       PC3\n",
       "0        0.364567  0.073269  0.816782\n",
       "1        0.320127 -0.739112 -0.022300\n",
       "2        1.907536 -0.432147  1.707089\n",
       "3       -1.802131 -0.871310 -0.297497\n",
       "4       -1.341204 -0.304572 -0.184539\n",
       "...           ...       ...       ...\n",
       "1417955  1.154414  0.805976 -0.550955\n",
       "1417956 -0.441786 -0.579326  0.286315\n",
       "1417957 -0.749174  1.568552 -0.261644\n",
       "1417958  0.149151 -0.496745  0.113672\n",
       "1417959  3.566442  3.061773 -2.003602\n",
       "\n",
       "[1417960 rows x 3 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "eedf6f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1417960, 3)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f395d",
   "metadata": {},
   "source": [
    "## Scree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "433dbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # get the explained variance ratios\n",
    "# variance_ratio = pca_train .explained_variance_ratio_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(variance_ratio)+1), variance_ratio, 'o-', color='gray', linewidth=2)\n",
    "# plt.title('Scree Plot: Variance Explained')\n",
    "# plt.xlabel('Principal Components')\n",
    "# plt.ylabel('Proportion of Variance Explained')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0d66dcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.364567</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.816782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.320127</td>\n",
       "      <td>-0.739112</td>\n",
       "      <td>-0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.907536</td>\n",
       "      <td>-0.432147</td>\n",
       "      <td>1.707089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.802131</td>\n",
       "      <td>-0.871310</td>\n",
       "      <td>-0.297497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.341204</td>\n",
       "      <td>-0.304572</td>\n",
       "      <td>-0.184539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.869193</td>\n",
       "      <td>-0.544477</td>\n",
       "      <td>-0.265097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3\n",
       "0  0.364567  0.073269  0.816782\n",
       "1  0.320127 -0.739112 -0.022300\n",
       "2  1.907536 -0.432147  1.707089\n",
       "3 -1.802131 -0.871310 -0.297497\n",
       "4 -1.341204 -0.304572 -0.184539\n",
       "5 -1.869193 -0.544477 -0.265097"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "84d36774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install adjustText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f483b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # create a PCA object\n",
    "# pca = PCA()\n",
    "\n",
    "# # fit the PCA object to your data\n",
    "# pca.fit(X)\n",
    "\n",
    "# # get the eigenvalues\n",
    "# eigenvalues = pca_train.explained_variance_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(eigenvalues)+1), eigenvalues, 'bo-', linewidth=2)\n",
    "# plt.title('Scree Plot')\n",
    "# plt.xlabel('Principal Component')\n",
    "# plt.ylabel('Eigenvalue')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "df6ee46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # create a PCA object\n",
    "# pca = PCA()\n",
    "\n",
    "# # fit the PCA object to your data\n",
    "# pca.fit(X)\n",
    "\n",
    "# # get the eigenvalues\n",
    "# eigenvalues = pca_train.explained_variance_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(eigenvalues)+1), eigenvalues, 'o-', color='gray', linewidth=1, markersize=5)\n",
    "# plt.axhline(y=1, linestyle='--', color='black', linewidth=1)\n",
    "# plt.title('Scree Plot: PCA Eigenvalues')\n",
    "# plt.xlabel('Principal Components')\n",
    "# plt.ylabel('Eigenvalues')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3a04a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    " \n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "cc2fec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot circle\n",
    "# #Create a list of 500 points with equal spacing between -1 and 1\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# columns=X_train_resampled_final.columns.values #Store the name of the columns for labeling\n",
    "\n",
    "# x=np.linspace(start=-1,stop=1,num=1000)\n",
    "# #Find y1 and y2 for these points\n",
    "# y_positive=lambda x: np.sqrt(1-x**2) \n",
    "# y_negative=lambda x: -np.sqrt(1-x**2)\n",
    "# plt.plot(x,list(map(y_positive, x)), color='maroon')\n",
    "# plt.plot(x,list(map(y_negative, x)),color='maroon')\n",
    "\n",
    "# #Plot smaller circle\n",
    "# x=np.linspace(start=-0.5,stop=0.5,num=500)\n",
    "# y_positive=lambda x: np.sqrt(0.5**2-x**2) \n",
    "# y_negative=lambda x: -np.sqrt(0.5**2-x**2)\n",
    "# plt.plot(x,list(map(y_positive, x)), color='maroon')\n",
    "# plt.plot(x,list(map(y_negative, x)),color='maroon')\n",
    "\n",
    "# #Create broken lines\n",
    "# x=np.linspace(start=-1,stop=1,num=30)\n",
    "# plt.scatter(x,[0]*len(x), marker='_',color='maroon')\n",
    "# plt.scatter([0]*len(x), x, marker='|',color='maroon')\n",
    "\n",
    "# pca_values=pca.components_\n",
    "# #Define color list\n",
    "# colors = ['pink', 'green','purple', 'blue','red','black']\n",
    "# if len(pca_values[0]) > 5:\n",
    "#     colors=colors*(int(len(pca_values[0])/5)+1)\n",
    "    \n",
    "#     add_string=\"\"\n",
    "#     for i in range(6):\n",
    "#         xi=pca_values[0][i]\n",
    "#         yi=pca_values[1][i]\n",
    "#         plt.arrow(0,0, \n",
    "#                   dx=xi, dy=yi, \n",
    "#                   head_width=0.03, head_length=0.03, \n",
    "#                   color=colors[i], length_includes_head=True)\n",
    "#         add_string=f\" ({round(xi,2)} {round(yi,2)})\"\n",
    "# #         plt.text(pca_values[0, i], \n",
    "# #                  pca_values[1, i] , \n",
    "# #                  s=columns[i] + add_string,\n",
    "# #                  fontsize=5)\n",
    "#         plt.text(pca_values[0, i] + 0.0, pca_values[1, i] + 0.07, s=columns[i] + add_string, fontsize=8)\n",
    "        \n",
    "# plt.xlabel(f\"Component 1 ({round(pca_train.explained_variance_ratio_[0]*100,2)}%)\")\n",
    "# plt.ylabel(f\"Component 2 ({round(pca_train.explained_variance_ratio_[1]*100,2)}%)\")\n",
    "# plt.title('Variable factor map (PCA)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1f3ce5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs = X_train_pca[:,0]\n",
    "# ys = X_train_pca[:,1]\n",
    "# scalex = 1.0/(xs.max() - xs.min())\n",
    "# scaley = 1.0/(ys.max() - ys.min())\n",
    "# fig, ax = plt.subplots(figsize=(14, 9))\n",
    " \n",
    "# for i, feature in enumerate(columns):\n",
    "#     ax.arrow(0, 0, pca_train.components_[0, i], \n",
    "#              pca_train.components_[1, i])\n",
    "#     ax.text(pca_train.components_[0, i] * 1.15, \n",
    "#             pca_train.components_[1, i] * 1.15, \n",
    "#             feature, fontsize=10)\n",
    " \n",
    "#     ax.scatter(xs * scalex,ys * scaley)\n",
    " \n",
    "#     ax.set_xlabel('PC1', fontsize=10)\n",
    "#     ax.set_ylabel('PC2', fontsize=10)\n",
    "#     ax.set_title('Biplot', fontsize=15)\n",
    "#     plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ca619079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the PCA components (loadings)\n",
    "# PCs = pca.components_\n",
    "\n",
    "# # Use quiver to generate the basic plot\n",
    "# fig = plt.figure(figsize=(5,5))\n",
    "# plt.quiver(np.zeros(PCs.shape[1]), np.zeros(PCs.shape[1]),\n",
    "#            PCs[0,:], PCs[1,:], \n",
    "#            angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "# # Add labels based on feature names (here just numbers)\n",
    "# feature_names = np.arange(PCs.shape[1])\n",
    "# for i,j,z in zip(PCs[1,:]+0.02, PCs[0,:]+0.02, feature_names):\n",
    "#     plt.text(j, i, z, ha='center', va='center')\n",
    "\n",
    "# # Add unit circle\n",
    "# circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "# plt.gca().add_artist(circle)\n",
    "\n",
    "# # Ensure correct aspect ratio and axis limits\n",
    "# plt.axis('equal')\n",
    "# plt.xlim([-1.0,1.0])\n",
    "# plt.ylim([-1.0,1.0])\n",
    "\n",
    "# # Label axes\n",
    "# plt.xlabel('PC 0')\n",
    "# plt.ylabel('PC 1')\n",
    "\n",
    "# # Done\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf9ba8",
   "metadata": {},
   "source": [
    "## Linear Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b085d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.linear_model import Perceptron\n",
    "\n",
    "# # Create a Perceptron object\n",
    "# clf = Perceptron(random_state=0)\n",
    "\n",
    "# # Train the Perceptron on the data\n",
    "# clf.fit(X_train_resampled_final, y_train_resampled_final)\n",
    "\n",
    "# # Predict the output classes for the data points\n",
    "# y_pred = clf.predict(X_train_resampled_final)\n",
    "\n",
    "# # Check if the Perceptron correctly classified all the data points\n",
    "# if np.all(y_pred == y_train_resampled_final):\n",
    "#     print(\"Data is linearly separable\")\n",
    "# else:\n",
    "#     print(\"Data is not linearly separable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c228282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your DataFrame is called df and the class column is called 'class'\n",
    "# class0 = df_sample[df_sample['isFraud'] == 0]\n",
    "# class1 = df_sample[df_sample['isFraud'] == 1]\n",
    "\n",
    "# s = 5\n",
    "# plt.scatter(class0['step'], class0['oldbalanceOrg'], color='blue', label='Class 0',marker='.', s=s)\n",
    "# plt.scatter(class1['step'], class1['oldbalanceOrg'], color='red', label='Class 1',marker='.', s=s)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('oldbalanceOrg')\n",
    "# plt.title('Scatter plot of two classes')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "dd4792f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your DataFrame is called df and the class column is called 'class'\n",
    "# class0 = df_sample[df_sample['isFraud'] == 0]\n",
    "# class1 = df_sample[df_sample['isFraud'] == 1]\n",
    "\n",
    "# s=4\n",
    "# plt.scatter(class0['step'], class0['oldbalanceOrg'], color='blue', label='Class 0',marker='.', s=s)\n",
    "# plt.scatter(class1['step'], class1['oldbalanceOrg'], color='red', label='Class',marker='.', s=s)\n",
    "\n",
    "# # Fit a linear SVM to the data\n",
    "# from sklearn.svm import SVC\n",
    "# X_new = df_sample[['step', 'oldbalanceOrg']]\n",
    "# y_new = df_sample['isFraud']\n",
    "# svm = SVC(kernel='linear')\n",
    "# svm.fit(X_new, y_new)\n",
    "\n",
    "# # Plot the decision boundary\n",
    "# w = svm.coef_[0]\n",
    "# a = -w[0] / w[1]\n",
    "# xx = np.linspace(np.min(X_new['step']), np.max(X_new['step']))\n",
    "# yy = a * xx - svm.intercept_[0] / w[1]\n",
    "# plt.plot(xx, yy, 'k-', label='Decision boundary')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('oldbalanceOrg')\n",
    "# plt.title('Scatter plot of two classes with decision boundary')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917bc01",
   "metadata": {},
   "source": [
    "## Choose 3 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5b10bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.364567</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.816782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.320127</td>\n",
       "      <td>-0.739112</td>\n",
       "      <td>-0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.907536</td>\n",
       "      <td>-0.432147</td>\n",
       "      <td>1.707089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.802131</td>\n",
       "      <td>-0.871310</td>\n",
       "      <td>-0.297497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.341204</td>\n",
       "      <td>-0.304572</td>\n",
       "      <td>-0.184539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417955</th>\n",
       "      <td>1.154414</td>\n",
       "      <td>0.805976</td>\n",
       "      <td>-0.550955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417956</th>\n",
       "      <td>-0.441786</td>\n",
       "      <td>-0.579326</td>\n",
       "      <td>0.286315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417957</th>\n",
       "      <td>-0.749174</td>\n",
       "      <td>1.568552</td>\n",
       "      <td>-0.261644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417958</th>\n",
       "      <td>0.149151</td>\n",
       "      <td>-0.496745</td>\n",
       "      <td>0.113672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417959</th>\n",
       "      <td>3.566442</td>\n",
       "      <td>3.061773</td>\n",
       "      <td>-2.003602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1417960 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PC1       PC2       PC3\n",
       "0        0.364567  0.073269  0.816782\n",
       "1        0.320127 -0.739112 -0.022300\n",
       "2        1.907536 -0.432147  1.707089\n",
       "3       -1.802131 -0.871310 -0.297497\n",
       "4       -1.341204 -0.304572 -0.184539\n",
       "...           ...       ...       ...\n",
       "1417955  1.154414  0.805976 -0.550955\n",
       "1417956 -0.441786 -0.579326  0.286315\n",
       "1417957 -0.749174  1.568552 -0.261644\n",
       "1417958  0.149151 -0.496745  0.113672\n",
       "1417959  3.566442  3.061773 -2.003602\n",
       "\n",
       "[1417960 rows x 3 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "193e538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_df=X_test_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2dd82f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226320</td>\n",
       "      <td>0.417463</td>\n",
       "      <td>-1.591484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.656770</td>\n",
       "      <td>-1.694291</td>\n",
       "      <td>-3.275007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.303748</td>\n",
       "      <td>0.792214</td>\n",
       "      <td>-0.193327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795198</td>\n",
       "      <td>-1.101438</td>\n",
       "      <td>0.595755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.290476</td>\n",
       "      <td>-0.031537</td>\n",
       "      <td>2.885615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229995</th>\n",
       "      <td>-1.245324</td>\n",
       "      <td>-0.253249</td>\n",
       "      <td>-0.223562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229996</th>\n",
       "      <td>1.626971</td>\n",
       "      <td>0.188985</td>\n",
       "      <td>3.799534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229997</th>\n",
       "      <td>-1.418129</td>\n",
       "      <td>0.081159</td>\n",
       "      <td>-0.251401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229998</th>\n",
       "      <td>-1.937120</td>\n",
       "      <td>0.107723</td>\n",
       "      <td>-0.530038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229999</th>\n",
       "      <td>-0.450026</td>\n",
       "      <td>-0.796474</td>\n",
       "      <td>0.241580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       0.226320  0.417463 -1.591484\n",
       "1       4.656770 -1.694291 -3.275007\n",
       "2      -1.303748  0.792214 -0.193327\n",
       "3       0.795198 -1.101438  0.595755\n",
       "4       1.290476 -0.031537  2.885615\n",
       "...          ...       ...       ...\n",
       "229995 -1.245324 -0.253249 -0.223562\n",
       "229996  1.626971  0.188985  3.799534\n",
       "229997 -1.418129  0.081159 -0.251401\n",
       "229998 -1.937120  0.107723 -0.530038\n",
       "229999 -0.450026 -0.796474  0.241580\n",
       "\n",
       "[230000 rows x 3 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b3b335c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df=X_train_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "89ff3ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.364567</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.816782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.320127</td>\n",
       "      <td>-0.739112</td>\n",
       "      <td>-0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.907536</td>\n",
       "      <td>-0.432147</td>\n",
       "      <td>1.707089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.802131</td>\n",
       "      <td>-0.871310</td>\n",
       "      <td>-0.297497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.341204</td>\n",
       "      <td>-0.304572</td>\n",
       "      <td>-0.184539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417955</th>\n",
       "      <td>1.154414</td>\n",
       "      <td>0.805976</td>\n",
       "      <td>-0.550955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417956</th>\n",
       "      <td>-0.441786</td>\n",
       "      <td>-0.579326</td>\n",
       "      <td>0.286315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417957</th>\n",
       "      <td>-0.749174</td>\n",
       "      <td>1.568552</td>\n",
       "      <td>-0.261644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417958</th>\n",
       "      <td>0.149151</td>\n",
       "      <td>-0.496745</td>\n",
       "      <td>0.113672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417959</th>\n",
       "      <td>3.566442</td>\n",
       "      <td>3.061773</td>\n",
       "      <td>-2.003602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1417960 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PC1       PC2       PC3\n",
       "0        0.364567  0.073269  0.816782\n",
       "1        0.320127 -0.739112 -0.022300\n",
       "2        1.907536 -0.432147  1.707089\n",
       "3       -1.802131 -0.871310 -0.297497\n",
       "4       -1.341204 -0.304572 -0.184539\n",
       "...           ...       ...       ...\n",
       "1417955  1.154414  0.805976 -0.550955\n",
       "1417956 -0.441786 -0.579326  0.286315\n",
       "1417957 -0.749174  1.568552 -0.261644\n",
       "1417958  0.149151 -0.496745  0.113672\n",
       "1417959  3.566442  3.061773 -2.003602\n",
       "\n",
       "[1417960 rows x 3 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8913f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# #class_weights={0:1,0:75}\n",
    "# #rf_model = RandomForestClassifier(criterion='entropy', max_depth= 8, max_features='log2',n_estimators=251,oob_score=True)\n",
    "# #rf_model = RandomForestClassifier(ccp_alpha=0.01,criterion='gini', max_depth= 3, max_features='log2',n_estimators=100,oob_score=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "    \n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print classification report\n",
    "#     print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17904f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print confusion matrix\n",
    "#     print(f\"Confusion matrix for fold {fold}:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f8c0f",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c967dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# # Define the parameter space to search over\n",
    "# param_dist = {\n",
    "#     'n_estimators': randint(100, 400),\n",
    "#     'max_features': ['sqrt', 'log2','none'],\n",
    "#     'max_depth': [None] + list(range(5, 20, 5)),\n",
    "#     'min_samples_split': randint(2, 15),\n",
    "#     'min_samples_leaf': randint(1, 15),\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# # Initialize the Random Forest model\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# # Initialize the RandomizedSearchCV object\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     rf_model, \n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=10,  # Number of iterations to sample from the parameter space\n",
    "#     cv=3,  # Number of cross-validation folds to use\n",
    "# )\n",
    "\n",
    "# # Fit the RandomizedSearchCV object to the data\n",
    "# random_search.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Print the best hyperparameters and corresponding score\n",
    "# print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "# print(\"Best score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410bd4c",
   "metadata": {},
   "source": [
    "## PCA-BASED MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369863b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     #print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "#     print(f\"Fold {fold+1}\")\n",
    "#     print(f\"Confusion matrix:\")\n",
    "#     # Print confusion matrix\n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "#     print(f\"Classification report:\")\n",
    "#     print('---------------------')\n",
    "#     # Print classification report\n",
    "#     print(classification_report(y_val, y_pred))\n",
    "#     # Print the OOB score\n",
    "#     #print(f\"OOB score: {rf_model.oob_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888d6ec",
   "metadata": {},
   "source": [
    "## HalfRandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.experimental import enable_halving_search_cv  # Required to enable HalvingRandomSearchCV\n",
    "# from sklearn.model_selection import HalvingRandomSearchCV\n",
    "# import numpy as np\n",
    "\n",
    "# # Create the random forest model\n",
    "# rfc = RandomForestClassifier()\n",
    "\n",
    "# # Set the hyperparameters to tune and their possible values\n",
    "# param_dist = {\n",
    "#     'n_estimators': np.arange(100, 400),\n",
    "#     'max_features': ['sqrt', 'log2','auto']\n",
    "#     'max_depth': [5, 10, 15, 20, None],\n",
    "#     'min_samples_split': [2, 5, 15],\n",
    "#     'min_samples_leaf': [2, 5, 15],\n",
    "#     'bootstrap': [True, False],\n",
    "# }\n",
    "\n",
    "# # Set up the HalvingRandomSearchCV with aggressive early stopping\n",
    "# search = HalvingRandomSearchCV(rfc, param_dist, cv=5,verbose=1, \n",
    "#                                factor=2, resource='n_samples', max_resources=100, \n",
    "#                                aggressive_elimination=True, random_state=18, \n",
    "#                                scoring='accuracy', refit=True)\n",
    "\n",
    "# # Fit the HalvingRandomSearchCV object to the data\n",
    "# search.fit(X_train_pca_df, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27fb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and evaluate on the test set\n",
    "best_params = search.best_params_\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bad5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e86b11",
   "metadata": {},
   "source": [
    "## RF-PCA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "dec09298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 457.05 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "n_folds = 2\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "class_weights={0:15,1:70}\n",
    "rf_model = RandomForestClassifier(class_weight=class_weights)\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "start_time = time.time()\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "    X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "    \n",
    "#     # Print confusion matrix and classification report\n",
    "#     print(f\"Fold {fold+1}\")\n",
    "#     print(f\"Confusion matrix:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "#     print(f\"Classification report:\")\n",
    "#     print('---------------------')\n",
    "#     print(classification_report(y_val, y_pred))\n",
    "    \n",
    "#     # Get precision, recall, and f1 score for this fold\n",
    "#     report = classification_report(y_val, y_pred, output_dict=True)\n",
    "#     precision_list.append(report['weighted avg']['precision'])\n",
    "#     recall_list.append(report['weighted avg']['recall'])\n",
    "#     f1_list.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "\n",
    "# print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "# # Calculate average precision, recall, and f1 score across all folds\n",
    "# avg_precision = sum(precision_list) / n_folds\n",
    "# avg_recall = sum(recall_list) / n_folds\n",
    "# avg_f1 = sum(f1_list) / n_folds\n",
    "\n",
    "# print(f\"Average precision: {avg_precision}\")\n",
    "# print(f\"Average recall: {avg_recall}\")\n",
    "# print(f\"Average F1 score: {avg_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# # Load iris dataset\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# # Train a random forest classifier with 3 decision trees\n",
    "rf_model = RandomForestClassifier(n_estimators=2)\n",
    "rf_model.fit(X_train_pca_df, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# plot_tree(rf_model.estimators_[1], filled=True, ax=ax, max_depth=2, fontsize=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd19a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier('n_estimators': 130, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 20, 'bootstrap': False)\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     y_prob = rf_model.predict_proba(X_val)[:,1] # get probability estimates for positive class\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print confusion matrix\n",
    "#     print(f\"Confusion matrix for fold {fold}:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "    \n",
    "#     # Plot ROC curve\n",
    "#     fpr, tpr, thresholds = roc_curve(y_val, y_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     plt.plot(fpr, tpr, label=f\"Fold {fold} (AUC = {roc_auc:.2f})\")\n",
    "    \n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='Random guessing')\n",
    "# plt.xlabel('False positive rate')\n",
    "# plt.ylabel('True positive rate')\n",
    "# plt.title('ROC curve for Random Forest classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c1abe",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2023d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define the number of splits for stratified cross-validation\n",
    "# n_splits = 2\n",
    "\n",
    "# # Initialize StratifiedKFold\n",
    "# skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# # Create lists to store evaluation metrics for each fold\n",
    "# f1_scores = []\n",
    "# recall_scores = []\n",
    "# precision_scores = []\n",
    "# accuracy_scores = []\n",
    "\n",
    "# # Create lists to store ROC curve data for each fold\n",
    "# fprs = []\n",
    "# tprs = []\n",
    "# aucs = []\n",
    "\n",
    "# # Initialize the OOB error list\n",
    "# oob_error = []\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "#     print(f'Fold: {fold+1}')\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df[train_idx], y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df[val_idx], y_train_resampled_final[val_idx]\n",
    "\n",
    "#     #class_weights={0:1,0:75}\n",
    "#     rf_model = RandomForestClassifier(criterion='entropy', max_depth= 8, max_features='log2',n_estimators=251,oob_score=True)\n",
    "#     # Fit the model on the training data\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "#     # Predict the class labels for the validation set\n",
    "#     y_val_pred = rf_model.predict(X_val)\n",
    "    \n",
    "#     # Predict the class probabilities for the validation set\n",
    "#     y_val_pred_proba = rf_model.predict_proba(X_val)\n",
    "\n",
    "#     # Set the threshold\n",
    "#     threshold = 0.225\n",
    "#     # Convert the probabilities to binary predictions based on the threshold\n",
    "#     y_val_pred = (y_val_pred_proba[:,1] > threshold).astype(int)\n",
    "\n",
    "#     # Compute the evaluation metrics for the current fold\n",
    "#     conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "#     recall = recall_score(y_val, y_val_pred)\n",
    "#     accuracy = accuracy_score(y_val, y_val_pred)\n",
    "#     precision = precision_score(y_val, y_val_pred)\n",
    "#     f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "#     # Append the evaluation metrics for the current fold to the lists\n",
    "#     f1_scores.append(f1)\n",
    "#     recall_scores.append(recall)\n",
    "#     precision_scores.append(precision)\n",
    "#     accuracy_scores.append(accuracy)\n",
    "    \n",
    "#     # Compute the ROC curve and AUC for the current fold\n",
    "#     fpr, tpr, _ = roc_curve(y_val, rf_model.predict_proba(X_val)[:,1])\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "#     # Append the ROC curve data for the current fold to the lists\n",
    "#     fprs.append(fpr)\n",
    "#     tprs.append(tpr)\n",
    "#     aucs.append(roc_auc)\n",
    "\n",
    "#     # Compute the OOB error for the current fold and append to the list\n",
    "#     oob_error.append(1 - rf_model.oob_score_)\n",
    "\n",
    "#     # Print the evaluation metrics for the current fold\n",
    "#     print('Confusion matrix:\\n', conf_mat)\n",
    "#     print('Recall:', recall)\n",
    "#     #print('Accuracy:', accuracy)\n",
    "#     print('Precision:', precision)\n",
    "#     print('F1-score:', f1)\n",
    "#     print('OOB error:', 1 - rf_model.oob_score_)\n",
    "#     print('---------------------')\n",
    "    \n",
    "#     # Compute the classification report for the current fold\n",
    "#     report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "#     # Print the classification report\n",
    "#     print('Classification report:\\n', report)\n",
    "\n",
    "# # Create the ROC curve plot\n",
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# # Plot the ROC curve for each fold\n",
    "# for i in range(n_splits):\n",
    "#     ax.plot(fprs[i], tprs[i], lw=2, label='Fold %d (AUC = %0.2f)' % (i+1, aucs[i]))\n",
    "\n",
    "# # Add a dashed line representing the random guess classifier\n",
    "# ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Random guess')\n",
    "\n",
    "# # Add labels and legend to the plot\n",
    "# ax.set_xlabel('False Positive Rate')\n",
    "# ax.set_ylabel('True Positive Rate')\n",
    "# ax.set_title('Receiver Operating Characteristic')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c9809",
   "metadata": {},
   "source": [
    "## Contour plot for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4986a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "# X = X_train_pca_df.iloc[:, :2].values \n",
    "\n",
    "# # define the meshgrid\n",
    "# h = 0.02  # step size in the mesh\n",
    "# x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "# y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                      np.arange(y_min, y_max, h))\n",
    "\n",
    "# # predict the class probabilities for each meshgrid point\n",
    "# Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# # reshape the predicted probabilities into the meshgrid shape\n",
    "# Z = Z.reshape(xx.shape)\n",
    "\n",
    "# # plot the contour plot\n",
    "# plt.contourf(xx, yy, Z, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63250503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f938e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "y = y_train_resampled_final.values\n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.7, s=2)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add title and axis labels\n",
    "# add title and axis labels with smaller font size\n",
    "plt.title(\"Decision boundary with training points\", fontsize=14)\n",
    "plt.xlabel(\"PC1\", fontsize=12)\n",
    "plt.ylabel(\"PC2\", fontsize=12)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de573377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "y = y_train_resampled_final.values\n",
    "\n",
    "# shift the y-coordinate values of the positive class points\n",
    "X[y == 1, 1] += 1.8\n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.7, s=2)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add title and axis labels\n",
    "plt.title(\"Decision boundary with training points\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ce2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the plot_decision_boundary function first\n",
    "# def plot_decision_boundary(pred_func):\n",
    "#     # Set min and max values and give it some padding\n",
    "#     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "#     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "#     h = 0.01\n",
    "#     # Generate a grid of points with distance h between them\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "#     # Predict the function value for the whole gid\n",
    "#     Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     # Plot the contour and training examples\n",
    "#     plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "\n",
    "# # Train the RandomForestClassifier\n",
    "# rf_model = RandomForestClassifier()\n",
    "# rf_model.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Plot the decision boundary using the plot_decision_boundary function\n",
    "# plot_decision_boundary(lambda X_train_pca_df: rf_model.predict(X_train_pca_df))\n",
    "# plt.title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define plot_decision_boundary function here...\n",
    "# def plot_decision_boundary(pred_func):\n",
    "#     # Set min and max values and give it some padding\n",
    "#     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "#     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "#     h = 0.01\n",
    "#     # Generate a grid of points with distance h between them\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "#     # Predict the function value for the whole gid\n",
    "#     Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     # Plot the contour and training examples\n",
    "#     plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(X_train_pca_df[:, 0], X_train_pca_df[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "   \n",
    "# %matplotlib inline\n",
    "# matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "# # Train the logistic regression classifier\n",
    "# rf_model = RandomForestClassifier()\n",
    "# rf_model.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Plot decision boundary\n",
    "# #plot_decision_boundary(lambda x: rf_model.predict(x))\n",
    "# plot_decision_boundary(lambda x: rf_model.predict(x), X_train_pca_df.iloc[:, :2].values)\n",
    "# plt.title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68e29c",
   "metadata": {},
   "source": [
    "## Bubble Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e40639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample data frame\n",
    "df = pd.DataFrame({\n",
    "    'Model Name': ['Model 1', 'Model 1', 'Model 1', 'Model 2', 'Model 2', 'Model 2', 'Model 3', 'Model 3', 'Model 3'],\n",
    "    'Dataset Size': ['Small', 'Medium', 'Large', 'Small', 'Medium', 'Large', 'Small', 'Medium', 'Large'],\n",
    "    'Performance Value': [5, 0.9, 0.9, 0.7, 7, 9, 0.6, 1, 15]\n",
    "})\n",
    "\n",
    "# Define bubble sizes and colors\n",
    "bubble_sizes = df['Performance Value'] * 100\n",
    "bubble_colors = df['Performance Value']\n",
    "\n",
    "# Group the data by Model Name\n",
    "groups = df.groupby('Model Name')\n",
    "\n",
    "# Create a scatter plot for each group\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for name, group in groups:\n",
    "    ax.scatter(group['Dataset Size'], [name] * len(group), s=bubble_sizes.loc[group.index], c=bubble_colors.loc[group.index], alpha=0.5, label=name)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Dataset Size')\n",
    "ax.set_ylabel('Model Name')\n",
    "ax.set_title('Model Performance')\n",
    "\n",
    "# Add color bar and legend\n",
    "sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(vmin=bubble_colors.min(), vmax=bubble_colors.max()))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.ax.set_ylabel('Performance Value')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8157658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define the parameters for the learning curve\n",
    "# train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "# cv = 2  # number of cross-validation folds\n",
    "\n",
    "# # Generate the learning curve data\n",
    "# train_sizes, train_scores, val_scores = learning_curve(\n",
    "#     rf_model, X_train_pca_df, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    "# )\n",
    "\n",
    "# # Calculate the mean and standard deviation of the training and validation scores\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# val_scores_mean = np.mean(val_scores, axis=1)\n",
    "# val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Misclassification Error\")\n",
    "# plt.grid()\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (train_scores_mean + train_scores_std),\n",
    "#     1 - (train_scores_mean - train_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"r\",\n",
    "# )\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (val_scores_mean + val_scores_std),\n",
    "#     1 - (val_scores_mean - val_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"g\",\n",
    "# )\n",
    "# plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "# plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6532ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set up the data\n",
    "# training_samples = [23000, 73000, 124000, 162500, 220000]\n",
    "# cv_errors = [0.30, 0.30, 0.24, 0.075, 0.043]\n",
    "# training_errors = [0.27, 0.16, 0.05, 0.025,  0.025]\n",
    "\n",
    "# # Create the plot and set the grid\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.grid(True)\n",
    "\n",
    "# # Plot the data points as dots\n",
    "# # ax.plot(training_samples, cv_errors, 'o', color='green', label='Cross Validation Error')\n",
    "# # ax.plot(training_samples, training_errors, 'o', color='red', label='Training Error')\n",
    "\n",
    "# # Plot the lines connecting the dots with different colors and line styles\n",
    "# ax.plot(training_samples, cv_errors, color='green', linestyle='-', marker='o', label='Cross Validation Error')\n",
    "# ax.plot(training_samples, training_errors, color='red', linestyle='-', marker='o', label='Training Error')\n",
    "\n",
    "# # Set the axis labels and title\n",
    "# ax.set_xlabel('Training examples')\n",
    "# ax.set_ylabel('Miscalssification Error')\n",
    "# ax.set_title('Learning Curve')\n",
    "\n",
    "# # Add a legend\n",
    "# ax.legend()\n",
    "# plt.legend(loc=\"best\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a0029",
   "metadata": {},
   "source": [
    "## Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c39c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "# from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 6), sharey=True)\n",
    "\n",
    "# common_params = {\n",
    "#     \"X\": X_train_pca,\n",
    "#     \"y\": y_train_resampled_final,\n",
    "#     \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "#     \"cv\": KFold(n_splits=2, shuffle=True),\n",
    "#     \"score_type\": \"both\",\n",
    "#     \"line_kw\": {\"marker\": \"o\"},\n",
    "#     \"std_display_style\": \"fill_between\",\n",
    "#     \"score_name\": \"neg_log_loss\",\n",
    "# }\n",
    "\n",
    "# estimator = rf_model\n",
    "# LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax)\n",
    "# handles, label = ax.get_legend_handles_labels()\n",
    "# ax.legend(handles[:2], [\"Training Score\", \"Cross alidation Score\"])\n",
    "# ax.set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8008524",
   "metadata": {},
   "source": [
    "## Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d88ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#class_weights={0:1,0:75}\n",
    "    # Create a RandomForestClassifier object with the given hyperparameters\n",
    "#rf_model = RandomForestClassifier(max_features='sqrt',n_estimators=121,oob_score=True,class_weight=class_weights,random_state=1)\n",
    "clf = lgb.LGBMClassifier(objective='binary', metric='binary_logloss')\n",
    "\n",
    "train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "train_loss = []\n",
    "cv_loss = []\n",
    "    \n",
    "for size in train_sizes:\n",
    "    # Split the data into training and cross-validation sets\n",
    "    X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_pca_df, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    clf .fit(X_train_new, y_train_new)\n",
    "    \n",
    "    # Compute the cross-entropy loss on the training set\n",
    "    y_train_pred = clf .predict_proba(X_train_pca_df)\n",
    "    train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "    # Compute the cross-entropy loss on the cross-validation set\n",
    "    y_cv_pred = clf .predict_proba(X_cv)\n",
    "    cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.tree import export_graphviz\n",
    "# from IPython.display import Image\n",
    "# import pydotplus\n",
    "\n",
    "# # Visualize a decision tree from the random forest\n",
    "# tree = rf_model.estimators_[0]\n",
    "# export_graphviz(tree, out_file='tree.dot', feature_names=['newbalanceDest', 'step', 'nameDest', 'newbalanceOrig'], class_names=['class_0', 'class_1'], filled=True, rounded=True)\n",
    "\n",
    "# # Convert the .dot file to .png\n",
    "# graph = pydotplus.graph_from_dot_file('tree.dot')\n",
    "# graph.write_png('tree.png')\n",
    "\n",
    "# # Display the decision tree\n",
    "# Image(filename='tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve\n",
    "# # Get predicted probabilities for the test data\n",
    "# y_prob = rf_model.predict_proba(X_test_pca)[:,1]\n",
    "\n",
    "# # Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "# thresholds = np.arange(0.1,30,0.01)\n",
    "# precision_scores = []\n",
    "# recall_scores = []\n",
    "# f1_scores = []\n",
    "\n",
    "# for threshold in thresholds:\n",
    "#     y_pred = (y_prob >= threshold).astype(int)\n",
    "#     precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     precision_scores.append(precision[1])\n",
    "#     recall_scores.append(recall[1])\n",
    "#     f1_scores.append(f1[1])\n",
    "\n",
    "# # Find the optimal threshold that maximizes the F1-score\n",
    "# optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# # Assign the class labels based on the optimal threshold\n",
    "# y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# # Evaluate the performance of the classifier for the optimal threshold\n",
    "# confusion_matrix(y_test, y_pred)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64528a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Get predicted probabilities for the test data\n",
    "# y_prob = rf_model.predict_proba(X_test_pca)[:,1]\n",
    "\n",
    "# # Assign the class labels based on the optimal threshold\n",
    "# optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "# y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# # Print classification report on the test set\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ba105",
   "metadata": {},
   "source": [
    "## Partial dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_partial_dependence(rf_model, X_train_pca_df, features=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fab4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['newbalanceDest', 'oldbalanceOrg','nameDest']  # or ['feat1', 'feat2', 'feat3']\n",
    "# plot_partial_dependence(rf_model, X_train_pca, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef257a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [0, 1, 2] # Indices of the features in X_train_pca\n",
    "# feature_names = ['newbalanceDest', 'oldbalanceOrg', 'nameDest'] # Names of the features\n",
    "\n",
    "# plot_partial_dependence(rf_model, X_train_pca, features=features, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38890561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import partial_dependence\n",
    "# from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# # Compute partial dependence values for the feature 'feature_name'\n",
    "# pdp, axes = partial_dependence(rf_model,X_train_pca_df, feature_name='PC1')\n",
    "\n",
    "# # Create a partial dependence plot for the feature 'feature_name'\n",
    "# display = PartialDependenceDisplay.from_feature_values(feature_values=X[:, feature_index], \n",
    "#                                                        pdp_values=pdp, \n",
    "#                                                        feature_name='PC1')\n",
    "\n",
    "# # Plot the partial dependence plot\n",
    "# display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# Compute partial dependence values for the first principal component\n",
    "pdp, axes = partial_dependence(rf_model, X_train_pca_df, features=[0])\n",
    "\n",
    "# Create a partial dependence plot for the first principal component\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(axes[0], pdp[0])\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('Predicted Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937145c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "\n",
    "# X_train_pca_df = pd.DataFrame(X_train_pca, columns=[f\"PC{i+1}\" for i in range(pca_train.n_components_)])\n",
    "\n",
    "\n",
    "# # Generate PDPs for the principal components\n",
    "# fig, axs = plot_partial_dependence(clf, X_train_pca_df, features=range(pca_train.n_components_), grid_resolution=50)\n",
    "\n",
    "# # Compute the contribution of each original feature to each PC\n",
    "# pc_contributions = pca_train.components_\n",
    "\n",
    "# # Map the PDPs back to the original features\n",
    "# values = np.array(axs.pd_results_[0]['values'])\n",
    "# contributions = np.matmul(pc_contributions.T, values.T)\n",
    "# effects = np.sum(contributions.T, axis=1)\n",
    "# feature_effects = pd.DataFrame({'Feature': X_train_resampled_final.columns, 'Effect': effects})\n",
    "# for feature_name in X_train.columns:\n",
    "#     fig, ax = plt.subplots()\n",
    "#     pdp_values = axs.pd_results_[feature_name]['average']\n",
    "#     ax.plot(values[:, feature_name], pdp_values)\n",
    "#     ax.set_xlabel(feature_name)\n",
    "#     ax.set_ylabel('Predicted Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# # Choose the features to generate partial dependence plots for\n",
    "# features = [0,1,2]\n",
    "\n",
    "# # Generate partial dependence plots for the specified features\n",
    "# pdp_display = PartialDependenceDisplay.from_estimator(rf_model, X_train_pca_df, features)\n",
    "\n",
    "# # Display the PDP plots\n",
    "# pdp_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf59a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "# # Generate PDPs for the principal components\n",
    "# pdp_display = plot_partial_dependence(clf, X_train_pca_df, features=range(pca_train.n_components_), grid_resolution=50)\n",
    "\n",
    "# # Display the PDP plot\n",
    "# pdp_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b864889",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca15f9",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e885ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Define the hyperparameter space to search over\n",
    "param_dist = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "    'num_leaves': sp_randint(6, 50),\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': sp_randint(50, 200),\n",
    "    'max_depth': sp_randint(3, 15),\n",
    "    'min_child_samples': sp_randint(10, 50),\n",
    "    'min_split_gain': [0, 0.01, 0.1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ad727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the LightGBM model\n",
    "# lgb_model = lgb.LGBMClassifier(objective='binary')\n",
    "\n",
    "# # Perform the hyperparameter search using RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(lgb_model, param_distributions=param_dist, cv=3, n_iter=15,\n",
    "#                                    scoring='roc_auc', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48099ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the random search to the training data\n",
    "# random_search.fit(X_train_pca, y_train_resampled_final)\n",
    "\n",
    "# # Print the best hyperparameters found\n",
    "# print('Best hyperparameters: ', random_search.best_params_)\n",
    "\n",
    "# # Get the best LightGBM model\n",
    "# best_lgb_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the best model on the test set\n",
    "# y_pred = best_lgb_model.predict(X_test_pca)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8539a96",
   "metadata": {},
   "source": [
    "## Model Training LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define the LightGBM classifier\n",
    "# clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate=0.2, max_depth= 11, min_child_samples= 33, min_split_gain= 0, n_estimators= 185, num_leaves= 29)\n",
    "\n",
    "# # Define the cross-validation method\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X_train_resampled_final, y_train_resampled_final)):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_fold_train, y_fold_train = X_train_resampled_final.iloc[train_index],  y_train_resampled_final.iloc[train_index]\n",
    "#     X_fold_test, y_fold_test = X_train_resampled_final.iloc[test_index],  y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "#     # Train the LightGBM classifier\n",
    "#     clf.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "13bdb64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 8.32 seconds\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Define the LightGBM classifier\n",
    "clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate= 0.2, max_depth= 15, min_child_samples= 33, min_split_gain= 0, n_estimators= 185, num_leaves= 20, objective='binary', metric='binary_logloss')\n",
    "\n",
    "# Define the cross-validation method\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "    X_fold_test, y_fold_test = X_train_pca_df.iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "    # Train the LightGBM classifier\n",
    "    clf.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     cm = confusion_matrix(y_fold_test, y_pred)\n",
    "#     print(f\"Confusion matrix:\\n{cm}\")\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "#     fpr, tpr, thresholds = roc_curve(y_fold_test, y_pred_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     # Plot the ROC curve\n",
    "#     plt.plot(fpr, tpr, label=f'Fold {fold} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "\n",
    "# # Plot the random classifier\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')\n",
    "\n",
    "# # Add labels and legend\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve for LightGBM Classifier')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21baab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [10,25,35],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedeef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(lgb_model, param_grid, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe977af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.fit(X_train_pca, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6125a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best params:\", grid_search.best_params_)\n",
    "# print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20869ac6",
   "metadata": {},
   "source": [
    "## Convert to PCA elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414eac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_pca_df = pd.DataFrame(X_train_pca, columns=['PC1', 'PC2', 'PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2217cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import warnings\n",
    "\n",
    "# # Ignore all warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# # Define the LightGBM classifier\n",
    "# #clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate= 0.2, max_depth= 11, min_child_samples= 13, min_split_gain= 0, n_estimators= 185, num_leaves= 10, objective='binary', metric='binary_logloss')\n",
    "# #clf = lgb.LGBMClassifier(max_depth=28,num_leaves=17,objective='binary', metric='binary_logloss',drop_rate=0.225)\n",
    "# class_weights={0:1,1:30}\n",
    "# clf = lgb.LGBMClassifier(learning_rate=0.05,max_depth=10,num_leaves=15,data_sample_strategy='goss',boosting_type='gbdt',objective='binary', metric='binary_logloss',class_weight=class_weights)\n",
    "\n",
    "# # Define the cross-validation method\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df , y_train_resampled_final)):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_fold_train, y_fold_train =X_train_pca_df .iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "#     X_fold_test, y_fold_test = X_train_pca_df .iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "#     # Train the LightGBM classifier with early stopping\n",
    "#     clf.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_test, y_fold_test)], early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     cm = confusion_matrix(y_fold_test, y_pred)\n",
    "#     print(f\"Confusion matrix:\\n{cm}\")\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "#     fpr, tpr, thresholds = roc_curve(y_fold_test, y_pred_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     # Plot the ROC curve\n",
    "#     plt.plot(fpr, tpr, label=f'Fold {fold} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# # Plot the random classifier\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')\n",
    "\n",
    "# # Add labels and legend\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve for LightGBM Classifier')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e12ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first tree\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ac36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Plot the first tree\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95173c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define graph and node attributes with desired color scheme\n",
    "graph_attr = {'size': '50,50', 'dpi': '100', 'bgcolor': 'white', 'rankdir': 'TB', 'splines': 'ortho'}\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '1.2', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Plot the first tree with color\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], graph_attr=graph_attr, node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Define node attributes with desired color scheme\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '0.4', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Set leaf node color to green\n",
    "node_attr['fillcolor'] = 'green'\n",
    "\n",
    "# Plot the first tree with colored leaf nodes\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20277109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Define node attributes with desired color scheme\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '1.2', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Set leaf node color to green\n",
    "node_attr['fillcolor'] = 'green'\n",
    "\n",
    "# Plot the first tree with colored leaf nodes\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f3c8e",
   "metadata": {},
   "source": [
    "## Misclassification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e327599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define the parameters for the learning curve\n",
    "# train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "# cv = 2  # number of cross-validation folds\n",
    "\n",
    "# # Generate the learning curve data\n",
    "# train_sizes, train_scores, val_scores = learning_curve(\n",
    "#     clf, X_train_pca, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    "# )\n",
    "\n",
    "# # Calculate the mean and standard deviation of the training and validation scores\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# val_scores_mean = np.mean(val_scores, axis=1)\n",
    "# val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Misclassification Error\")\n",
    "# plt.grid()\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (train_scores_mean + train_scores_std),\n",
    "#     1 - (train_scores_mean - train_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"r\",\n",
    "# )\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (val_scores_mean + val_scores_std),\n",
    "#     1 - (val_scores_mean - val_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"g\",\n",
    "# )\n",
    "# plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "# plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7f5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# # Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "# train_loss = []\n",
    "# cv_loss = []\n",
    "    \n",
    "# for size in train_sizes:\n",
    "#     # Split the data into training and cross-validation sets\n",
    "#     X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_pca_df, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "#     # Train the model on the training set\n",
    "#     clf.fit(X_train_new, y_train_new)\n",
    "    \n",
    "#     # Compute the cross-entropy loss on the training set\n",
    "#     y_train_pred = clf.predict_proba(X_train_pca_df)\n",
    "#     train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "#     # Compute the cross-entropy loss on the cross-validation set\n",
    "#     y_cv_pred = clf.predict_proba(X_cv)\n",
    "#     cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "# plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "# plt.xlabel('Training Set Size')\n",
    "# plt.ylabel('Cross-Entropy Loss')\n",
    "# plt.title('Learning Curve')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(clf, X_train_pca, y_train_resampled_final, cv=5)\n",
    "\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b5fed",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2df40499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[229164,    538],\n",
       "       [   164,    134]], dtype=int64)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "# Get predicted probabilities for the test data\n",
    "y_prob = clf.predict_proba(X_test_pca_df)[:,1]\n",
    "\n",
    "# Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "thresholds = np.arange(0.1,30,0.1)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    precision_scores.append(precision[1])\n",
    "    recall_scores.append(recall[1])\n",
    "    f1_scores.append(f1[1])\n",
    "\n",
    "# Find the optimal threshold that maximizes the F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Assign the class labels based on the optimal threshold\n",
    "y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the performance of the classifier for the optimal threshold\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "22b9f7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the class labels and probabilities for the test set\n",
    "y_test_pred = clf.predict(X_test_pca_df)\n",
    "y_test_prob = clf.predict_proba(X_test_pca_df)[:, 1]\n",
    "# Compute the false positive rate, true positive rate, and AUC for the test set\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_prob)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "# Plot the ROC curve for the test set\n",
    "plt.plot(fpr_test, tpr_test, color='blue', lw=2, label='Test ROC curve (AUC =%0.2f)' % roc_auc_test)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Test Set')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "78dbc526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold\tPrecision\tRecall\t\tF1-Score\n",
      "--------------------------------------------------\n",
      "0.1\t\t0.004\t\t0.906\t\t0.009\n",
      "0.2\t\t0.008\t\t0.849\t\t0.016\n",
      "0.3\t\t0.013\t\t0.779\t\t0.026\n",
      "0.4\t\t0.020\t\t0.742\t\t0.040\n",
      "0.5\t\t0.027\t\t0.691\t\t0.052\n",
      "0.6\t\t0.036\t\t0.641\t\t0.068\n",
      "0.7\t\t0.049\t\t0.601\t\t0.090\n",
      "0.8\t\t0.080\t\t0.554\t\t0.140\n",
      "0.9\t\t0.199\t\t0.450\t\t0.276\n",
      "1.0\t\t1.000\t\t0.000\t\t0.000\n",
      "1.1\t\t1.000\t\t0.000\t\t0.000\n",
      "1.2\t\t1.000\t\t0.000\t\t0.000\n",
      "1.3\t\t1.000\t\t0.000\t\t0.000\n",
      "1.4\t\t1.000\t\t0.000\t\t0.000\n",
      "1.5\t\t1.000\t\t0.000\t\t0.000\n",
      "1.6\t\t1.000\t\t0.000\t\t0.000\n",
      "1.7\t\t1.000\t\t0.000\t\t0.000\n",
      "1.8\t\t1.000\t\t0.000\t\t0.000\n",
      "1.9\t\t1.000\t\t0.000\t\t0.000\n",
      "2.0\t\t1.000\t\t0.000\t\t0.000\n",
      "2.1\t\t1.000\t\t0.000\t\t0.000\n",
      "2.2\t\t1.000\t\t0.000\t\t0.000\n",
      "2.3\t\t1.000\t\t0.000\t\t0.000\n",
      "2.4\t\t1.000\t\t0.000\t\t0.000\n",
      "2.5\t\t1.000\t\t0.000\t\t0.000\n",
      "2.6\t\t1.000\t\t0.000\t\t0.000\n",
      "2.7\t\t1.000\t\t0.000\t\t0.000\n",
      "2.8\t\t1.000\t\t0.000\t\t0.000\n",
      "2.9\t\t1.000\t\t0.000\t\t0.000\n",
      "3.0\t\t1.000\t\t0.000\t\t0.000\n",
      "3.1\t\t1.000\t\t0.000\t\t0.000\n",
      "3.2\t\t1.000\t\t0.000\t\t0.000\n",
      "3.3\t\t1.000\t\t0.000\t\t0.000\n",
      "3.4\t\t1.000\t\t0.000\t\t0.000\n",
      "3.5\t\t1.000\t\t0.000\t\t0.000\n",
      "3.6\t\t1.000\t\t0.000\t\t0.000\n",
      "3.7\t\t1.000\t\t0.000\t\t0.000\n",
      "3.8\t\t1.000\t\t0.000\t\t0.000\n",
      "3.9\t\t1.000\t\t0.000\t\t0.000\n",
      "4.0\t\t1.000\t\t0.000\t\t0.000\n",
      "4.1\t\t1.000\t\t0.000\t\t0.000\n",
      "4.2\t\t1.000\t\t0.000\t\t0.000\n",
      "4.3\t\t1.000\t\t0.000\t\t0.000\n",
      "4.4\t\t1.000\t\t0.000\t\t0.000\n",
      "4.5\t\t1.000\t\t0.000\t\t0.000\n",
      "4.6\t\t1.000\t\t0.000\t\t0.000\n",
      "4.7\t\t1.000\t\t0.000\t\t0.000\n",
      "4.8\t\t1.000\t\t0.000\t\t0.000\n",
      "4.9\t\t1.000\t\t0.000\t\t0.000\n",
      "5.0\t\t1.000\t\t0.000\t\t0.000\n",
      "5.1\t\t1.000\t\t0.000\t\t0.000\n",
      "5.2\t\t1.000\t\t0.000\t\t0.000\n",
      "5.3\t\t1.000\t\t0.000\t\t0.000\n",
      "5.4\t\t1.000\t\t0.000\t\t0.000\n",
      "5.5\t\t1.000\t\t0.000\t\t0.000\n",
      "5.6\t\t1.000\t\t0.000\t\t0.000\n",
      "5.7\t\t1.000\t\t0.000\t\t0.000\n",
      "5.8\t\t1.000\t\t0.000\t\t0.000\n",
      "5.9\t\t1.000\t\t0.000\t\t0.000\n",
      "6.0\t\t1.000\t\t0.000\t\t0.000\n",
      "6.1\t\t1.000\t\t0.000\t\t0.000\n",
      "6.2\t\t1.000\t\t0.000\t\t0.000\n",
      "6.3\t\t1.000\t\t0.000\t\t0.000\n",
      "6.4\t\t1.000\t\t0.000\t\t0.000\n",
      "6.5\t\t1.000\t\t0.000\t\t0.000\n",
      "6.6\t\t1.000\t\t0.000\t\t0.000\n",
      "6.7\t\t1.000\t\t0.000\t\t0.000\n",
      "6.8\t\t1.000\t\t0.000\t\t0.000\n",
      "6.9\t\t1.000\t\t0.000\t\t0.000\n",
      "7.0\t\t1.000\t\t0.000\t\t0.000\n",
      "7.1\t\t1.000\t\t0.000\t\t0.000\n",
      "7.2\t\t1.000\t\t0.000\t\t0.000\n",
      "7.3\t\t1.000\t\t0.000\t\t0.000\n",
      "7.4\t\t1.000\t\t0.000\t\t0.000\n",
      "7.5\t\t1.000\t\t0.000\t\t0.000\n",
      "7.6\t\t1.000\t\t0.000\t\t0.000\n",
      "7.7\t\t1.000\t\t0.000\t\t0.000\n",
      "7.8\t\t1.000\t\t0.000\t\t0.000\n",
      "7.9\t\t1.000\t\t0.000\t\t0.000\n",
      "8.0\t\t1.000\t\t0.000\t\t0.000\n",
      "8.1\t\t1.000\t\t0.000\t\t0.000\n",
      "8.2\t\t1.000\t\t0.000\t\t0.000\n",
      "8.3\t\t1.000\t\t0.000\t\t0.000\n",
      "8.4\t\t1.000\t\t0.000\t\t0.000\n",
      "8.5\t\t1.000\t\t0.000\t\t0.000\n",
      "8.6\t\t1.000\t\t0.000\t\t0.000\n",
      "8.7\t\t1.000\t\t0.000\t\t0.000\n",
      "8.8\t\t1.000\t\t0.000\t\t0.000\n",
      "8.9\t\t1.000\t\t0.000\t\t0.000\n",
      "9.0\t\t1.000\t\t0.000\t\t0.000\n",
      "9.1\t\t1.000\t\t0.000\t\t0.000\n",
      "9.2\t\t1.000\t\t0.000\t\t0.000\n",
      "9.3\t\t1.000\t\t0.000\t\t0.000\n",
      "9.4\t\t1.000\t\t0.000\t\t0.000\n",
      "9.5\t\t1.000\t\t0.000\t\t0.000\n",
      "9.6\t\t1.000\t\t0.000\t\t0.000\n",
      "9.7\t\t1.000\t\t0.000\t\t0.000\n",
      "9.8\t\t1.000\t\t0.000\t\t0.000\n",
      "9.9\t\t1.000\t\t0.000\t\t0.000\n",
      "10.0\t\t1.000\t\t0.000\t\t0.000\n",
      "10.1\t\t1.000\t\t0.000\t\t0.000\n",
      "10.2\t\t1.000\t\t0.000\t\t0.000\n",
      "10.3\t\t1.000\t\t0.000\t\t0.000\n",
      "10.4\t\t1.000\t\t0.000\t\t0.000\n",
      "10.5\t\t1.000\t\t0.000\t\t0.000\n",
      "10.6\t\t1.000\t\t0.000\t\t0.000\n",
      "10.7\t\t1.000\t\t0.000\t\t0.000\n",
      "10.8\t\t1.000\t\t0.000\t\t0.000\n",
      "10.9\t\t1.000\t\t0.000\t\t0.000\n",
      "11.0\t\t1.000\t\t0.000\t\t0.000\n",
      "11.1\t\t1.000\t\t0.000\t\t0.000\n",
      "11.2\t\t1.000\t\t0.000\t\t0.000\n",
      "11.3\t\t1.000\t\t0.000\t\t0.000\n",
      "11.4\t\t1.000\t\t0.000\t\t0.000\n",
      "11.5\t\t1.000\t\t0.000\t\t0.000\n",
      "11.6\t\t1.000\t\t0.000\t\t0.000\n",
      "11.7\t\t1.000\t\t0.000\t\t0.000\n",
      "11.8\t\t1.000\t\t0.000\t\t0.000\n",
      "11.9\t\t1.000\t\t0.000\t\t0.000\n",
      "12.0\t\t1.000\t\t0.000\t\t0.000\n",
      "12.1\t\t1.000\t\t0.000\t\t0.000\n",
      "12.2\t\t1.000\t\t0.000\t\t0.000\n",
      "12.3\t\t1.000\t\t0.000\t\t0.000\n",
      "12.4\t\t1.000\t\t0.000\t\t0.000\n",
      "12.5\t\t1.000\t\t0.000\t\t0.000\n",
      "12.6\t\t1.000\t\t0.000\t\t0.000\n",
      "12.7\t\t1.000\t\t0.000\t\t0.000\n",
      "12.8\t\t1.000\t\t0.000\t\t0.000\n",
      "12.9\t\t1.000\t\t0.000\t\t0.000\n",
      "13.0\t\t1.000\t\t0.000\t\t0.000\n",
      "13.1\t\t1.000\t\t0.000\t\t0.000\n",
      "13.2\t\t1.000\t\t0.000\t\t0.000\n",
      "13.3\t\t1.000\t\t0.000\t\t0.000\n",
      "13.4\t\t1.000\t\t0.000\t\t0.000\n",
      "13.5\t\t1.000\t\t0.000\t\t0.000\n",
      "13.6\t\t1.000\t\t0.000\t\t0.000\n",
      "13.7\t\t1.000\t\t0.000\t\t0.000\n",
      "13.8\t\t1.000\t\t0.000\t\t0.000\n",
      "13.9\t\t1.000\t\t0.000\t\t0.000\n",
      "14.0\t\t1.000\t\t0.000\t\t0.000\n",
      "14.1\t\t1.000\t\t0.000\t\t0.000\n",
      "14.2\t\t1.000\t\t0.000\t\t0.000\n",
      "14.3\t\t1.000\t\t0.000\t\t0.000\n",
      "14.4\t\t1.000\t\t0.000\t\t0.000\n",
      "14.5\t\t1.000\t\t0.000\t\t0.000\n",
      "14.6\t\t1.000\t\t0.000\t\t0.000\n",
      "14.7\t\t1.000\t\t0.000\t\t0.000\n",
      "14.8\t\t1.000\t\t0.000\t\t0.000\n",
      "14.9\t\t1.000\t\t0.000\t\t0.000\n",
      "15.0\t\t1.000\t\t0.000\t\t0.000\n",
      "15.1\t\t1.000\t\t0.000\t\t0.000\n",
      "15.2\t\t1.000\t\t0.000\t\t0.000\n",
      "15.3\t\t1.000\t\t0.000\t\t0.000\n",
      "15.4\t\t1.000\t\t0.000\t\t0.000\n",
      "15.5\t\t1.000\t\t0.000\t\t0.000\n",
      "15.6\t\t1.000\t\t0.000\t\t0.000\n",
      "15.7\t\t1.000\t\t0.000\t\t0.000\n",
      "15.8\t\t1.000\t\t0.000\t\t0.000\n",
      "15.9\t\t1.000\t\t0.000\t\t0.000\n",
      "16.0\t\t1.000\t\t0.000\t\t0.000\n",
      "16.1\t\t1.000\t\t0.000\t\t0.000\n",
      "16.2\t\t1.000\t\t0.000\t\t0.000\n",
      "16.3\t\t1.000\t\t0.000\t\t0.000\n",
      "16.4\t\t1.000\t\t0.000\t\t0.000\n",
      "16.5\t\t1.000\t\t0.000\t\t0.000\n",
      "16.6\t\t1.000\t\t0.000\t\t0.000\n",
      "16.7\t\t1.000\t\t0.000\t\t0.000\n",
      "16.8\t\t1.000\t\t0.000\t\t0.000\n",
      "16.9\t\t1.000\t\t0.000\t\t0.000\n",
      "17.0\t\t1.000\t\t0.000\t\t0.000\n",
      "17.1\t\t1.000\t\t0.000\t\t0.000\n",
      "17.2\t\t1.000\t\t0.000\t\t0.000\n",
      "17.3\t\t1.000\t\t0.000\t\t0.000\n",
      "17.4\t\t1.000\t\t0.000\t\t0.000\n",
      "17.5\t\t1.000\t\t0.000\t\t0.000\n",
      "17.6\t\t1.000\t\t0.000\t\t0.000\n",
      "17.7\t\t1.000\t\t0.000\t\t0.000\n",
      "17.8\t\t1.000\t\t0.000\t\t0.000\n",
      "17.9\t\t1.000\t\t0.000\t\t0.000\n",
      "18.0\t\t1.000\t\t0.000\t\t0.000\n",
      "18.1\t\t1.000\t\t0.000\t\t0.000\n",
      "18.2\t\t1.000\t\t0.000\t\t0.000\n",
      "18.3\t\t1.000\t\t0.000\t\t0.000\n",
      "18.4\t\t1.000\t\t0.000\t\t0.000\n",
      "18.5\t\t1.000\t\t0.000\t\t0.000\n",
      "18.6\t\t1.000\t\t0.000\t\t0.000\n",
      "18.7\t\t1.000\t\t0.000\t\t0.000\n",
      "18.8\t\t1.000\t\t0.000\t\t0.000\n",
      "18.9\t\t1.000\t\t0.000\t\t0.000\n",
      "19.0\t\t1.000\t\t0.000\t\t0.000\n",
      "19.1\t\t1.000\t\t0.000\t\t0.000\n",
      "19.2\t\t1.000\t\t0.000\t\t0.000\n",
      "19.3\t\t1.000\t\t0.000\t\t0.000\n",
      "19.4\t\t1.000\t\t0.000\t\t0.000\n",
      "19.5\t\t1.000\t\t0.000\t\t0.000\n",
      "19.6\t\t1.000\t\t0.000\t\t0.000\n",
      "19.7\t\t1.000\t\t0.000\t\t0.000\n",
      "19.8\t\t1.000\t\t0.000\t\t0.000\n",
      "19.9\t\t1.000\t\t0.000\t\t0.000\n",
      "20.0\t\t1.000\t\t0.000\t\t0.000\n",
      "20.1\t\t1.000\t\t0.000\t\t0.000\n",
      "20.2\t\t1.000\t\t0.000\t\t0.000\n",
      "20.3\t\t1.000\t\t0.000\t\t0.000\n",
      "20.4\t\t1.000\t\t0.000\t\t0.000\n",
      "20.5\t\t1.000\t\t0.000\t\t0.000\n",
      "20.6\t\t1.000\t\t0.000\t\t0.000\n",
      "20.7\t\t1.000\t\t0.000\t\t0.000\n",
      "20.8\t\t1.000\t\t0.000\t\t0.000\n",
      "20.9\t\t1.000\t\t0.000\t\t0.000\n",
      "21.0\t\t1.000\t\t0.000\t\t0.000\n",
      "21.1\t\t1.000\t\t0.000\t\t0.000\n",
      "21.2\t\t1.000\t\t0.000\t\t0.000\n",
      "21.3\t\t1.000\t\t0.000\t\t0.000\n",
      "21.4\t\t1.000\t\t0.000\t\t0.000\n",
      "21.5\t\t1.000\t\t0.000\t\t0.000\n",
      "21.6\t\t1.000\t\t0.000\t\t0.000\n",
      "21.7\t\t1.000\t\t0.000\t\t0.000\n",
      "21.8\t\t1.000\t\t0.000\t\t0.000\n",
      "21.9\t\t1.000\t\t0.000\t\t0.000\n",
      "22.0\t\t1.000\t\t0.000\t\t0.000\n",
      "22.1\t\t1.000\t\t0.000\t\t0.000\n",
      "22.2\t\t1.000\t\t0.000\t\t0.000\n",
      "22.3\t\t1.000\t\t0.000\t\t0.000\n",
      "22.4\t\t1.000\t\t0.000\t\t0.000\n",
      "22.5\t\t1.000\t\t0.000\t\t0.000\n",
      "22.6\t\t1.000\t\t0.000\t\t0.000\n",
      "22.7\t\t1.000\t\t0.000\t\t0.000\n",
      "22.8\t\t1.000\t\t0.000\t\t0.000\n",
      "22.9\t\t1.000\t\t0.000\t\t0.000\n",
      "23.0\t\t1.000\t\t0.000\t\t0.000\n",
      "23.1\t\t1.000\t\t0.000\t\t0.000\n",
      "23.2\t\t1.000\t\t0.000\t\t0.000\n",
      "23.3\t\t1.000\t\t0.000\t\t0.000\n",
      "23.4\t\t1.000\t\t0.000\t\t0.000\n",
      "23.5\t\t1.000\t\t0.000\t\t0.000\n",
      "23.6\t\t1.000\t\t0.000\t\t0.000\n",
      "23.7\t\t1.000\t\t0.000\t\t0.000\n",
      "23.8\t\t1.000\t\t0.000\t\t0.000\n",
      "23.9\t\t1.000\t\t0.000\t\t0.000\n",
      "24.0\t\t1.000\t\t0.000\t\t0.000\n",
      "24.1\t\t1.000\t\t0.000\t\t0.000\n",
      "24.2\t\t1.000\t\t0.000\t\t0.000\n",
      "24.3\t\t1.000\t\t0.000\t\t0.000\n",
      "24.4\t\t1.000\t\t0.000\t\t0.000\n",
      "24.5\t\t1.000\t\t0.000\t\t0.000\n",
      "24.6\t\t1.000\t\t0.000\t\t0.000\n",
      "24.7\t\t1.000\t\t0.000\t\t0.000\n",
      "24.8\t\t1.000\t\t0.000\t\t0.000\n",
      "24.9\t\t1.000\t\t0.000\t\t0.000\n",
      "25.0\t\t1.000\t\t0.000\t\t0.000\n",
      "25.1\t\t1.000\t\t0.000\t\t0.000\n",
      "25.2\t\t1.000\t\t0.000\t\t0.000\n",
      "25.3\t\t1.000\t\t0.000\t\t0.000\n",
      "25.4\t\t1.000\t\t0.000\t\t0.000\n",
      "25.5\t\t1.000\t\t0.000\t\t0.000\n",
      "25.6\t\t1.000\t\t0.000\t\t0.000\n",
      "25.7\t\t1.000\t\t0.000\t\t0.000\n",
      "25.8\t\t1.000\t\t0.000\t\t0.000\n",
      "25.9\t\t1.000\t\t0.000\t\t0.000\n",
      "26.0\t\t1.000\t\t0.000\t\t0.000\n",
      "26.1\t\t1.000\t\t0.000\t\t0.000\n",
      "26.2\t\t1.000\t\t0.000\t\t0.000\n",
      "26.3\t\t1.000\t\t0.000\t\t0.000\n",
      "26.4\t\t1.000\t\t0.000\t\t0.000\n",
      "26.5\t\t1.000\t\t0.000\t\t0.000\n",
      "26.6\t\t1.000\t\t0.000\t\t0.000\n",
      "26.7\t\t1.000\t\t0.000\t\t0.000\n",
      "26.8\t\t1.000\t\t0.000\t\t0.000\n",
      "26.9\t\t1.000\t\t0.000\t\t0.000\n",
      "27.0\t\t1.000\t\t0.000\t\t0.000\n",
      "27.1\t\t1.000\t\t0.000\t\t0.000\n",
      "27.2\t\t1.000\t\t0.000\t\t0.000\n",
      "27.3\t\t1.000\t\t0.000\t\t0.000\n",
      "27.4\t\t1.000\t\t0.000\t\t0.000\n",
      "27.5\t\t1.000\t\t0.000\t\t0.000\n",
      "27.6\t\t1.000\t\t0.000\t\t0.000\n",
      "27.7\t\t1.000\t\t0.000\t\t0.000\n",
      "27.8\t\t1.000\t\t0.000\t\t0.000\n",
      "27.9\t\t1.000\t\t0.000\t\t0.000\n",
      "28.0\t\t1.000\t\t0.000\t\t0.000\n",
      "28.1\t\t1.000\t\t0.000\t\t0.000\n",
      "28.2\t\t1.000\t\t0.000\t\t0.000\n",
      "28.3\t\t1.000\t\t0.000\t\t0.000\n",
      "28.4\t\t1.000\t\t0.000\t\t0.000\n",
      "28.5\t\t1.000\t\t0.000\t\t0.000\n",
      "28.6\t\t1.000\t\t0.000\t\t0.000\n",
      "28.7\t\t1.000\t\t0.000\t\t0.000\n",
      "28.8\t\t1.000\t\t0.000\t\t0.000\n",
      "28.9\t\t1.000\t\t0.000\t\t0.000\n",
      "29.0\t\t1.000\t\t0.000\t\t0.000\n",
      "29.1\t\t1.000\t\t0.000\t\t0.000\n",
      "29.2\t\t1.000\t\t0.000\t\t0.000\n",
      "29.3\t\t1.000\t\t0.000\t\t0.000\n",
      "29.4\t\t1.000\t\t0.000\t\t0.000\n",
      "29.5\t\t1.000\t\t0.000\t\t0.000\n",
      "29.6\t\t1.000\t\t0.000\t\t0.000\n",
      "29.7\t\t1.000\t\t0.000\t\t0.000\n",
      "29.8\t\t1.000\t\t0.000\t\t0.000\n",
      "29.9\t\t1.000\t\t0.000\t\t0.000\n",
      "--------------------------------------------------\n",
      "\n",
      "Optimal Threshold: 0.9\n",
      "Optimal F1-Score: 0.276\n",
      "Optimal Recall: 0.906\n",
      "Optimal Precision: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Print the precision, recall, and F1-score for each threshold\n",
    "print(\"Threshold\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(len(thresholds)):\n",
    "    print(f\"{thresholds[i]:.1f}\\t\\t{precision_scores[i]:.3f}\\t\\t{recall_scores[i]:.3f}\\t\\t{f1_scores[i]:.3f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Print the optimal threshold and the corresponding F1-score\n",
    "print(f\"\\nOptimal Threshold: {optimal_threshold:.1f}\")\n",
    "print(f\"Optimal F1-Score: {max(f1_scores):.3f}\")\n",
    "print(f\"Optimal Recall: {max(recall_scores):.3f}\")\n",
    "print(f\"Optimal Precision: {max(precision_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061d019",
   "metadata": {},
   "source": [
    "## Performance Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d8946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.529, 0.404, 0.448]\n",
    "# recalls = [0.784, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['f1-score', 'recall', 'precision']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#635f83'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='Default', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='RandomizedSearchCV', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='HalvingRandomSearchCV', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.529, 0.404, 0.448]\n",
    "# recalls = [0.784, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['Default', 'RandomizedSearchCV', 'HalvingRandomSearchCV']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#c7e9b8'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='f1-score', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='recall', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='precision', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "default_scores = [0.529, 0.404, 0.448]\n",
    "randomized_scores = [0.610, 0.596, 0.565]\n",
    "metrics = ['f1-score', 'recall', 'precision']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "# Set the colors for the bars\n",
    "default_colors = ['#c5d3ff', '#c5d3ff', '#c5d3ff']\n",
    "randomized_colors = ['#e9c6b8', '#e9c6b8', '#e9c6b8']\n",
    "\n",
    "# Create the figure and axes objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars for each hyperparameter search method with the specified colors\n",
    "ax.bar(x - width/2, default_scores, width, label='Default', color=default_colors, edgecolor='black')\n",
    "ax.bar(x + width/2, randomized_scores, width, label='RandomizedSearchCV', color=randomized_colors, edgecolor='black')\n",
    "\n",
    "# Add some labels and a legend\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(title='Hyperparameters used',bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "default_scores = [0.529, 0.732, 1]\n",
    "randomized_scores = [0.610, 0.834, 1]\n",
    "metrics = ['f1-score', 'recall', 'precision']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "# Set the colors for the bars\n",
    "default_colors = ['#c5d3ff', '#c5d3ff', '#c5d3ff']\n",
    "randomized_colors = ['#e9c6b8', '#e9c6b8', '#e9c6b8']\n",
    "\n",
    "# Create the figure and axes objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars for each hyperparameter search method with the specified colors\n",
    "ax.bar(x - width/2, default_scores, width, label='Default', color=default_colors, edgecolor='black')\n",
    "ax.bar(x + width/2, randomized_scores, width, label='RandomizedSearchCV', color=randomized_colors, edgecolor='black')\n",
    "\n",
    "# Add the values on each bar\n",
    "for i, v in enumerate(default_scores):\n",
    "    ax.text(i - width/2, v + 0.02, str(v), color='black', ha='center')\n",
    "for i, v in enumerate(randomized_scores):\n",
    "    ax.text(i + width/2, v + 0.02, str(v), color='black', ha='center')\n",
    "\n",
    "# Add some labels and a legend\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(title='Hyperparameters used',bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.603, 0.404, 0.448]\n",
    "# recalls = [0.854, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['Default', 'RandomizedSearchCV', ' HalvingRandomSearchCV']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#635f83'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='f1-score', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='recall', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='precision', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add score values on top of each bar\n",
    "# for i, (score1, score2, score3) in enumerate(zip(f1_scores, recalls, precisions)):\n",
    "#     ax.text(x[i] - width, score1 + 0.01, str(score1), ha='center', va='bottom', fontweight='bold')\n",
    "#     ax.text(x[i], score2 + 0.01, str(score2), ha='center', va='bottom', fontweight='bold')\n",
    "#     ax.text(x[i] + width, score3 + 0.01, str(score3), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Hyperparameter and Metric')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87793743",
   "metadata": {},
   "source": [
    "## LightGBM New trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c015c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#class_weights={0:1,1:30}\n",
    "# Define the LightGBM classifier\n",
    "#clf = lgb.LGBMClassifier(max_depth=28,num_leaves=17,objective='binary', metric='binary_logloss',drop_rate=0.225,class_weight=class_weights)\n",
    "clf = lgb.LGBMClassifier(objective='binary', metric='binary_logloss')\n",
    "# Define the cross-validation method\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# Create an empty list to store the optimized thresholds for each fold\n",
    "optimized_thresholds = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df , y_train_resampled_final)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_fold_train, y_fold_train =X_train_pca_df .iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "    X_fold_test, y_fold_test = X_train_pca_df .iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "    # Train the LightGBM classifier with early stopping\n",
    "    clf.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_test, y_fold_test)], early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "    # Evaluate the performance of the model on the testing data\n",
    "    y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "    \n",
    "    # Create an empty dictionary to store the F1-scores for each threshold\n",
    "    f1_scores = {}\n",
    "    \n",
    "    # Iterate through a range of possible threshold values\n",
    "    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        # Convert the predicted probabilities to predicted labels based on the threshold\n",
    "        y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate the classification report and select the threshold that maximizes the F1-score\n",
    "        report = classification_report(y_fold_test, y_pred, output_dict=True)\n",
    "        f1_scores[threshold] = report['1']['f1-score']\n",
    "    \n",
    "    # Select the threshold that maximizes the F1-score\n",
    "    optimized_threshold = max(f1_scores, key=f1_scores.get)\n",
    "    optimized_thresholds.append(optimized_threshold)\n",
    "    \n",
    "    # Convert the predicted probabilities to predicted labels based on the optimized threshold\n",
    "    y_pred = (y_pred_prob >= optimized_threshold).astype(int)\n",
    "    \n",
    "    # Calculate the classification report and confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eec368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_set_size = [25000, 50000, 75000, 100000, 125000, 150000, 175000, 200000, 225000]\n",
    "training_loss = [0.253, 0.250, 0.247, 0.246, 0.2455, 0.245, 0.245, 0.245, 0.245]\n",
    "cv_loss = [0.255, 0.252, 0.249, 0.2475, 0.247, 0.2465, 0.246, 0.2458, 0.2458]\n",
    "\n",
    "plt.plot(training_set_size, training_loss, label='Training Loss')\n",
    "plt.plot(training_set_size, cv_loss, label='Cross-Validation Loss')\n",
    "\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Learing Curve')\n",
    "plt.ylim(0.244, 0.256) # Set the y-axis limits\n",
    "plt.yticks([0.244, 0.246, 0.248, 0.25, 0.252, 0.254, 0.256]) # Set the y-axis tick labels\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
