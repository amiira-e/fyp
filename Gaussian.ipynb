{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddd607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61dd7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e620b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of column 'A' from float64 to float32\n",
    "df['amount'] = df['amount'].astype('float32')\n",
    "df['oldbalanceOrg'] = df['oldbalanceOrg'].astype('float32')\n",
    "df['oldbalanceDest'] = df['oldbalanceDest'].astype('float32')\n",
    "df['newbalanceOrig'] = df['newbalanceOrig'].astype('float32')\n",
    "df['newbalanceDest'] = df['newbalanceDest'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806044b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step'] = df['step'].astype('int32')\n",
    "df['isFlaggedFraud'] = df['isFlaggedFraud'].astype('int32') \n",
    "df['isFraud'] = df['isFraud'].astype('int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a814c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder from Sklearn\n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['type'])\n",
    "# printing label\n",
    "label\n",
    "# removing the column 'type' from df\n",
    "# as it is of no use now.\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "# Appending the array to our dataFrame\n",
    "# with column name 'type'\n",
    "df[\"type\"] = label\n",
    "# printing Dataframe\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1820dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameDest'])\n",
    "label\n",
    "df.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df[\"nameDest\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e9a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameOrig'])\n",
    "label\n",
    "df.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df[\"nameOrig\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f87e3",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2008266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.99871\n",
      "1    0.00129\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=18)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0329e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of column 'A' from float64 to float32\n",
    "X_train['amount'] = X_train['amount'].astype('float32')\n",
    "X_train['oldbalanceOrg'] =X_train['oldbalanceOrg'].astype('float32')\n",
    "X_train['oldbalanceDest'] = X_train['oldbalanceDest'].astype('float32')\n",
    "X_train['newbalanceOrig'] = X_train['newbalanceOrig'].astype('float32')\n",
    "X_train['newbalanceDest'] = X_train['newbalanceDest'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f80f8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['step'] = X_train['step'].astype('int32')\n",
    "X_train['isFlaggedFraud'] = X_train['isFlaggedFraud'].astype('int32') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6669395",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5013c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# # Apply ADASYN only on the minority class of the train set\n",
    "# ada = ADASYN()\n",
    "# X_train_resampled, y_train_resampled = ada.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f977ed7",
   "metadata": {},
   "source": [
    "## Tomek's link- Remove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da288a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# # Assuming X_train is your feature matrix and y_train is your target vector\n",
    "# # and that the minority class is labeled as 1 and the majority class is labeled as 0\n",
    "# tomek_links = TomekLinks(sampling_strategy='auto')\n",
    "# X_train_resampled_new, y_train_resampled_new = tomek_links.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd09e9b",
   "metadata": {},
   "source": [
    "## Tomek followed by ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45238098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "\n",
    "# Assume X_train and y_train are the original training data\n",
    "# resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='auto')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_train, y_train)\n",
    "\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='auto')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2678b66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5718840, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee63256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 5718966\n",
      "Class 1 count: 7392\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a5bc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='auto')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0547a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5713312, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "988dac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 5718966\n",
      "Class 1 count: 7392\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5613db3",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "663c31eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 84062.25, 'oldbalanceOrg': 17587.316, 'newbalanceOrig': 12279.772, 'oldbalanceDest': 191113.31, 'newbalanceDest': 244841.23}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed (20)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.14, 'oldbalanceOrg': 0.24, 'newbalanceOrig': 0.25, 'oldbalanceDest': 0.22, 'newbalanceDest': 0.22}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "\n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e83604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Create a Perceptron object\n",
    "clf = Perceptron(random_state=0)\n",
    "\n",
    "# Train the Perceptron on the data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict the output classes for the data points\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "# Check if the Perceptron correctly classified all the data points\n",
    "if np.all(y_pred == y):\n",
    "    print(\"Data is linearly separable\")\n",
    "else:\n",
    "    print(\"Data is not linearly separable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eeb438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your original training data is stored in a pandas DataFrame called X_train\n",
    "# And assuming you have a list of selected feature names called selected_features\n",
    "selected_features = ['oldbalanceOrg', 'type', 'nameDest','amount','step']\n",
    "X_train_selected = X_train_resampled_final[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected=X_test[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf5ef1",
   "metadata": {},
   "source": [
    "## Create kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd21df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195cc23d",
   "metadata": {},
   "source": [
    "we use kerne function to create covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173cd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a 1-D kernel with default parameters\n",
    "k=GPy.kern.RBF(1)\n",
    "#Preview of parameters\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22148d11",
   "metadata": {},
   "source": [
    "## Visualize kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32690361",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(-4.,4.,100)[:,None] # we need none to reshape x into a column vector to use in Gaussian\n",
    "\n",
    "#first, sample kernel at x(dash)=0\n",
    "K=k.K(x,np.array([[0.]])) # k(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x,K)\n",
    "plt.title(\"$\\kappa_{rbf}{x,x'}$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babca6dc",
   "metadata": {},
   "source": [
    "## Lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd86f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import rc\n",
    "ls = [0.05, 0.25, 0.5, 1., 2., 4]\n",
    "\n",
    "def update(iteration):\n",
    "    ax.cla()\n",
    "    k = GPy.kern.RBF(1)\n",
    "    k. lengthscale = ls[iteration]\n",
    "    # Calculate the new covariance function at k(x,0)\n",
    "    C = k.K(x, np.array([[0.]]))\n",
    "    # Plot the resulting covariance vector\n",
    "    ax.plot(x,C)\n",
    "    ax.set_title(f\"$\\kappa_{{rbf}}(x,x')$ Length scale = {k.lengthscale[0]}\")\n",
    "    ax.set_ylim((0, 1.2))\n",
    "\n",
    "num_iterations = len(ls)\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, num_iterations-1, 1), interval=500)\n",
    "plt.close()\n",
    "\n",
    "rc('animation', html='jshtml')\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef37b2",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b85ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import rc\n",
    "variances = [0.05, 0.25, 0.5, 1., 2., 4]\n",
    "\n",
    "def update(iteration):\n",
    "    ax.cla()\n",
    "    k = GPy.kern.RBF(1)\n",
    "    k. variance = variances[iteration]\n",
    "    # Calculate the new covariance function at k(x,0)\n",
    "    C = k.K(x, np.array([[0.]]))\n",
    "    # Plot the resulting covariance vector\n",
    "    ax.plot(x,C)\n",
    "    ax.set_title(f\"$\\kappa_{{rbf}}(x,x')$ Variance = {k.variance[0]}\")\n",
    "    ax.set_ylim((0, 1.2))\n",
    "\n",
    "num_iterations = len(ls)\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, num_iterations-1, 1), interval=500)\n",
    "plt.close()\n",
    "\n",
    "rc('animation', html='jshtml')\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b09e1b",
   "metadata": {},
   "source": [
    "## Kernel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# Define the RBF kernel with gamma=1.0\n",
    "kernel = 1.0 * RBF(length_scale=1.0)\n",
    "\n",
    "# Create a grid of points to evaluate the kernel function\n",
    "x = np.linspace(-5, 5, 100)\n",
    "X = np.atleast_2d(x).T\n",
    "\n",
    "# Compute the kernel matrix\n",
    "K = kernel(X)\n",
    "\n",
    "# Plot the kernel function\n",
    "plt.figure()\n",
    "plt.plot(x, K[0], label='RBF kernel')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('k(x, 0)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ecad64",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d9751a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# Define your reduced hyperparameter search space\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 5],\n",
    "    'n_restarts_optimizer': [1, 2],\n",
    "    'normalize_y': [True, False]\n",
    "}\n",
    "\n",
    "# Create an instance of the GaussianProcessRegressor\n",
    "gp = GaussianProcessRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "971a1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the GridSearchCV\n",
    "search = GridSearchCV(gp, param_grid, cv=3, verbose=1, \n",
    "                      scoring='neg_mean_squared_error', refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "001b0445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "24 fits failed out of a total of 24.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\", line 301, in fit\n",
      "    self.kernel_.theta, clone_kernel=False\n",
      "  File \"C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\", line 529, in log_marginal_likelihood\n",
      "    K = kernel(self.X_train_)\n",
      "  File \"C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\", line 946, in __call__\n",
      "    return self.k1(X, Y) * self.k2(X, Y)\n",
      "  File \"C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\", line 1256, in __call__\n",
      "    dtype=np.array(self.constant_value).dtype,\n",
      "  File \"C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\numpy\\core\\numeric.py\", line 343, in full\n",
      "    a = empty(shape, dtype, order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 59.4 TiB for an array with shape (2856656, 2856656) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 238. TiB for an array with shape (5713312, 5713312) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6736\\1972253062.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the GridSearchCV object to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             self.log_marginal_likelihood_value_ = self.log_marginal_likelihood(\n\u001b[1;32m--> 301\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclone_kernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m             )\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;31m# Alg. 2.1, page 19, line 2 -> L = cholesky(K + sigma^2 I)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    944\u001b[0m             )\n\u001b[0;32m    945\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m         )\n\u001b[0;32m   1258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unsafe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 238. TiB for an array with shape (5713312, 5713312) and data type float64"
     ]
    }
   ],
   "source": [
    "# Fit the GridSearchCV object to the data\n",
    "search.fit(X_train_selected, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0062d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and evaluate on the test set\n",
    "best_params = search.best_params_\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae177c",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/gaussian-processes-for-classification-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0686d76d",
   "metadata": {},
   "source": [
    "## Train Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdca105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# define a Gaussian process classifier with RBF kernel\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "gpc = GaussianProcessClassifier(kernel=kernel, optimizer=None, random_state=0)\n",
    "\n",
    "# perform k-fold cross-validation and compute ROC curve\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    probas_ = gpc.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "# plot the mean ROC curve\n",
    "mean_tpr /= cv.get_n_splits(X, y)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC (AUC = %0.2f)' % mean_auc, lw=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Random', alpha=.8)\n",
    "\n",
    "# set plot parameters and display\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# evaluate the model on a test set\n",
    "test_auc = np.mean(cross_val_score(gpc, X, y, cv=10, scoring='roc_auc'))\n",
    "print('Test AUC:', test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
