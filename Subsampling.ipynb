{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fbc4c87",
   "metadata": {},
   "source": [
    "## Base Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f8de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5f7dc",
   "metadata": {},
   "source": [
    "## Sub-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ceb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import random\n",
    "\n",
    "# def reservoir_sampling(iterable, k, header=True):\n",
    "#     reservoir = []\n",
    "#     for i, item in enumerate(iterable):\n",
    "#         if i < k:\n",
    "#             reservoir.append(item)\n",
    "#         else:\n",
    "#             j = random.randint(0, i)\n",
    "#             if j < k:\n",
    "#                 reservoir[j] = item\n",
    "#     return reservoir\n",
    "\n",
    "# # Open the input CSV file\n",
    "# with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\") as f:\n",
    "#     # Check if header line exists\n",
    "#     header = True\n",
    "#     first_line = f.readline()\n",
    "#     if not first_line.startswith('step,type,amount,nameOrig,oldbalanceOrg,newbalanceOrig,nameDest,oldbalanceDest,newbalanceDest,isFraud,isFlaggedFraud'):\n",
    "#         header = False\n",
    "#         f.seek(0)  # Rewind file pointer to beginning\n",
    "\n",
    "#     # Sample from remaining lines\n",
    "#     sampled_lines = reservoir_sampling(f, k=800000, header=header)\n",
    "\n",
    "# # Open the output CSV file and write the subsample to it\n",
    "# with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample8000000.csv\", mode='w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     if header:\n",
    "#         writer.writerow(first_line.strip().split(','))\n",
    "#     for line in sampled_lines:\n",
    "#         writer.writerow(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057871db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4226977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4495f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>246917.44</td>\n",
       "      <td>C1498821826</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1385924981</td>\n",
       "      <td>3175848.97</td>\n",
       "      <td>3422766.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>165577.48</td>\n",
       "      <td>C1959842869</td>\n",
       "      <td>242080.31</td>\n",
       "      <td>407657.78</td>\n",
       "      <td>C125997794</td>\n",
       "      <td>653770.69</td>\n",
       "      <td>488193.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11147.81</td>\n",
       "      <td>C690176304</td>\n",
       "      <td>21271.00</td>\n",
       "      <td>10123.19</td>\n",
       "      <td>M1395131038</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>3758.44</td>\n",
       "      <td>C1065078045</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1924230681</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>295770.07</td>\n",
       "      <td>C278303549</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1920150261</td>\n",
       "      <td>429733.98</td>\n",
       "      <td>725504.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type     amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0   259  CASH_OUT  246917.44  C1498821826           0.00            0.00   \n",
       "1   161   CASH_IN  165577.48  C1959842869      242080.31       407657.78   \n",
       "2   331   PAYMENT   11147.81   C690176304       21271.00        10123.19   \n",
       "3   304   PAYMENT    3758.44  C1065078045           0.00            0.00   \n",
       "4   355  CASH_OUT  295770.07   C278303549           0.00            0.00   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  C1385924981      3175848.97      3422766.41        0               0  \n",
       "1   C125997794       653770.69       488193.21        0               0  \n",
       "2  M1395131038            0.00            0.00        0               0  \n",
       "3  M1924230681            0.00            0.00        0               0  \n",
       "4  C1920150261       429733.98       725504.05        0               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3c997",
   "metadata": {},
   "source": [
    "## Data type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5adc2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of column 'A' from float64 to float32\n",
    "df_sample['amount'] = df_sample['amount'].astype('float32')\n",
    "df_sample['oldbalanceOrg'] = df_sample['oldbalanceOrg'].astype('float32')\n",
    "df_sample['oldbalanceDest'] = df_sample['oldbalanceDest'].astype('float32')\n",
    "df_sample['newbalanceOrig'] = df_sample['newbalanceOrig'].astype('float32')\n",
    "df_sample['newbalanceDest'] = df_sample['newbalanceDest'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04aa4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['step'] = df_sample['step'].astype('int32')\n",
    "df_sample['isFlaggedFraud'] = df_sample['isFlaggedFraud'].astype('int32') \n",
    "df_sample['isFraud'] = df_sample['isFraud'].astype('int32') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8f053",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c0fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4479c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a23f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e4f40",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50f8965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76ff7f",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7828129",
   "metadata": {},
   "source": [
    "## SMOTE & UnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5b8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Set up the resampling methods\n",
    "smote = SMOTE(sampling_strategy=0.2,random_state=0)\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "# Apply the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b24db7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 314602\n",
      "Class 1 count: 125841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_resampled)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1ceed",
   "metadata": {},
   "source": [
    "## Tomeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46029c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "\n",
    "# Assume X_train and y_train are the original training data\n",
    "# resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af72e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 314594\n",
      "Class 1 count: 125841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train_resampled)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9565c3ee",
   "metadata": {},
   "source": [
    "## ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fc80bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b88691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 311729\n",
      "Class 1 count: 125841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train_resampled_new)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85caa12",
   "metadata": {},
   "source": [
    "## OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df9b9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d70884b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 284708\n",
      "Class 1 count: 125841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = np.bincount(y_train_resampled_final)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eb58bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 69912\n",
      "Class 1 count: 88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_test)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "996351dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410549,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4284376e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410549, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720ba93",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f465ea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 157892.92, 'oldbalanceOrg': 70943.41, 'newbalanceOrig': 2700.3584, 'oldbalanceDest': 171853.73, 'newbalanceDest': 269596.8}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.14, 'oldbalanceOrg': 0.24, 'newbalanceOrig': 0.21, 'oldbalanceDest': 0.2, 'newbalanceDest': 0.22}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "\n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca463ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ca9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4835705d",
   "metadata": {},
   "source": [
    "## Feature selection- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4256bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Select top features using Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_resampled_final, y_train_resampled_final)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_features = X_train_resampled_final.columns[indices][:4]  # select top 6 features\n",
    "print(top_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e15bc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410549, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e83ad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>type</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>nameOrig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>9943.059570</td>\n",
       "      <td>114475.039062</td>\n",
       "      <td>2700.358398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>411302</td>\n",
       "      <td>221620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138</td>\n",
       "      <td>44423.328125</td>\n",
       "      <td>70943.406250</td>\n",
       "      <td>2700.358398</td>\n",
       "      <td>171853.734375</td>\n",
       "      <td>2.695968e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92881</td>\n",
       "      <td>180374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325</td>\n",
       "      <td>157892.921875</td>\n",
       "      <td>4564.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>171853.734375</td>\n",
       "      <td>2.695968e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>80756</td>\n",
       "      <td>482539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308</td>\n",
       "      <td>300712.343750</td>\n",
       "      <td>51474.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>353504.687500</td>\n",
       "      <td>6.542170e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>175711</td>\n",
       "      <td>597630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>349</td>\n",
       "      <td>47243.761719</td>\n",
       "      <td>11262.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>444683</td>\n",
       "      <td>26253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410544</th>\n",
       "      <td>547</td>\n",
       "      <td>111168.882812</td>\n",
       "      <td>111168.882812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>810537.875000</td>\n",
       "      <td>9.217068e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90379</td>\n",
       "      <td>472585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410545</th>\n",
       "      <td>274</td>\n",
       "      <td>157892.921875</td>\n",
       "      <td>70943.406250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>171853.734375</td>\n",
       "      <td>2.695968e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112071</td>\n",
       "      <td>494845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410546</th>\n",
       "      <td>60</td>\n",
       "      <td>157892.921875</td>\n",
       "      <td>70943.406250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>154830</td>\n",
       "      <td>240268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410547</th>\n",
       "      <td>449</td>\n",
       "      <td>44882.355469</td>\n",
       "      <td>44882.355469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.623762e+04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>122579</td>\n",
       "      <td>88980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410548</th>\n",
       "      <td>220</td>\n",
       "      <td>39953.089844</td>\n",
       "      <td>29059.333984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>171853.734375</td>\n",
       "      <td>1.451221e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93537</td>\n",
       "      <td>130866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410549 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        step         amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "0         37    9943.059570  114475.039062     2700.358398        0.000000   \n",
       "1        138   44423.328125   70943.406250     2700.358398   171853.734375   \n",
       "2        325  157892.921875    4564.000000        0.000000   171853.734375   \n",
       "3        308  300712.343750   51474.000000        0.000000   353504.687500   \n",
       "4        349   47243.761719   11262.000000        0.000000        0.000000   \n",
       "...      ...            ...            ...             ...             ...   \n",
       "410544   547  111168.882812  111168.882812        0.000000   810537.875000   \n",
       "410545   274  157892.921875   70943.406250        0.000000   171853.734375   \n",
       "410546    60  157892.921875   70943.406250        0.000000        0.000000   \n",
       "410547   449   44882.355469   44882.355469        0.000000        0.000000   \n",
       "410548   220   39953.089844   29059.333984        0.000000   171853.734375   \n",
       "\n",
       "        newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
       "0         0.000000e+00               0     3    411302    221620  \n",
       "1         2.695968e+05               0     0     92881    180374  \n",
       "2         2.695968e+05               0     4     80756    482539  \n",
       "3         6.542170e+05               0     1    175711    597630  \n",
       "4         0.000000e+00               0     3    444683     26253  \n",
       "...                ...             ...   ...       ...       ...  \n",
       "410544    9.217068e+05               0     1     90379    472585  \n",
       "410545    2.695968e+05               0     1    112071    494845  \n",
       "410546    0.000000e+00               0     4    154830    240268  \n",
       "410547    3.623762e+04               0     1    122579     88980  \n",
       "410548    1.451221e+06               0     1     93537    130866  \n",
       "\n",
       "[410549 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices])\n",
    "plt.xticks(range(len(indices)), X_train_resampled_final.columns[indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5455b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset X_train to include only selected features\n",
    "X_train_selected = X_train_resampled_final[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c97012",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_b = df_sample.columns.get_loc('oldbalanceOrg')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e166ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract same features in test set,select the columns by index\n",
    "selected_indices = [2,3,7,1]\n",
    "X_test_selected = X_test.iloc[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ac039c",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634eb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "# Define your hyperparameter search space\n",
    "param_dist = { \n",
    "    'n_estimators': sp_randint(100, 500),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : sp_randint(3,4,5),\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # Required to enable HalvingRandomSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "# Set up the HalvingRandomSearchCV with aggressive early stopping\n",
    "search = HalvingRandomSearchCV(rf, param_dist, cv=3,verbose=1, \n",
    "                               factor=2, resource='n_samples', max_resources=100, \n",
    "                               aggressive_elimination=True, \n",
    "                               scoring='accuracy', refit=True)\n",
    "\n",
    "# Fit the HalvingRandomSearchCV object to the data\n",
    "search.fit(X_train_selected, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and evaluate on the test set\n",
    "best_params = search.best_params_\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d098c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d21856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d31a950",
   "metadata": {},
   "source": [
    "## GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ac447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Initialize the random forest classifier\n",
    "# rfc = RandomForestClassifier()\n",
    "\n",
    "# # Define the hyperparameter grid to search\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 150],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'min_samples_split': [2, 4, 6],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "# }\n",
    "\n",
    "# # Initialize the GridSearchCV object\n",
    "# grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=3, scoring='f1')\n",
    "\n",
    "# # Fit the GridSearchCV object to the training data\n",
    "# grid_search.fit(X_train_selected, y_train_resampled_final)\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding F1 score\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "# print(\"Best F1 score:\", grid_search.best_score_)\n",
    "\n",
    "# # Evaluate the performance of the best model on the testing set\n",
    "# y_pred = grid_search.predict(X_test)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# print(\"F1 score on testing set:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c188ff7",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94898a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_dist = {\n",
    "    \"n_estimators\": randint(100, 250),\n",
    "    \"max_features\": randint(1, X_train.shape[1]),\n",
    "    #\"max_depth\": [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "    \"min_samples_split\": randint(2,5),\n",
    "    \"min_samples_leaf\": randint(1,5),\n",
    "    \"bootstrap\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e69fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier object\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a randomized search object\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_model, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=50, \n",
    "    cv=2, \n",
    "    verbose=1, \n",
    "    random_state=42, \n",
    "    scoring='precision'\n",
    ")\n",
    "\n",
    "# Fit the random search object to the data\n",
    "random_search.fit(X_train_selected, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be370fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters and corresponding score\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5082cf",
   "metadata": {},
   "source": [
    "## OOB error search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 7],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# create the random forest classifier object\n",
    "rfc = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "\n",
    "# create the RandomizedSearchCV object\n",
    "rscv = RandomizedSearchCV(\n",
    "    rfc,\n",
    "    param_grid,\n",
    "    n_iter=10,\n",
    "    scoring='precision',\n",
    "    cv=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# fit the RandomizedSearchCV object to the data\n",
    "rscv.fit(X_train, y_train)\n",
    "\n",
    "# get the best estimator\n",
    "best_rfc = rscv.best_estimator_\n",
    "\n",
    "# print the OOB score of the best estimator\n",
    "print(f\"OOB score: {best_rfc.oob_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c31aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712a040",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1af582f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# assuming X_train and X_test are your training and test data matrices\n",
    "# standardize the data using the mean and std from the training set\n",
    "X_train_mean = np.mean(X_train_resampled_final, axis=0)\n",
    "X_train_std = np.std(X_train_resampled_final, axis=0)\n",
    "X_train_std[X_train_std == 0] = 1 # avoid division by zero\n",
    "X_train_std_inv = 1 / X_train_std\n",
    "\n",
    "X_train_stdized = (X_train_resampled_final - X_train_mean) * X_train_std_inv\n",
    "X_test_stdized = (X_test - X_train_mean) * X_train_std_inv\n",
    "\n",
    "# compute the covariance matrix for the training data\n",
    "cov_matrix_train = np.cov(X_train_stdized.T)\n",
    "\n",
    "# compute the eigenvectors and eigenvalues for the training data\n",
    "eig_vals_train, eig_vecs_train = np.linalg.eig(cov_matrix_train)\n",
    "\n",
    "# select the top k eigenvectors for the training data\n",
    "pca_train = PCA(n_components=3)\n",
    "X_train_pca = pca_train.fit_transform(X_train_stdized)\n",
    "\n",
    "# project the test data onto the selected eigenvectors from the training data\n",
    "X_test_pca = pca_train.transform(X_test_stdized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "006bce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "PC1: newbalanceDest\n",
      "PC2: oldbalanceOrg\n",
      "PC3: isFraud\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(df_sample.columns)\n",
    "\n",
    "# print the selected features\n",
    "print(\"Selected features:\")\n",
    "for i in range(pca_train.n_components_):\n",
    "    # find the index of the maximum absolute value in the ith row of the components array\n",
    "    idx = np.argmax(np.abs(pca_train.components_[i]))\n",
    "    # print the name of the feature with the maximum absolute value in the ith row of the components array\n",
    "    print(f\"PC{i+1}: {feature_names[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 2\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# Create lists to store evaluation metrics for each fold\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create lists to store ROC curve data for each fold\n",
    "fprs = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "# Initialize the OOB error list\n",
    "oob_error = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_pca, y_train_resampled_final)):\n",
    "    print(f'Fold: {fold+1}')\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_pca[train_idx], y_train_resampled_final[train_idx]\n",
    "    X_val, y_val = X_train_pca[val_idx], y_train_resampled_final[val_idx]\n",
    "\n",
    "    class_weights={0:1,0:40}\n",
    "    # Create a RandomForestClassifier object with the given hyperparameters\n",
    "    rf_model = RandomForestClassifier(max_features='sqrt',n_estimators=121,oob_score=True,class_weight=class_weights,random_state=1)\n",
    "   \n",
    "    # Fit the model on the training data\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "    # Predict the class labels for the validation set\n",
    "    y_val_pred = rf_model.predict(X_val)\n",
    "    \n",
    "    # Predict the class probabilities for the validation set\n",
    "    y_val_pred_proba = rf_model.predict_proba(X_val)\n",
    "\n",
    "    # Set the threshold\n",
    "    threshold = 0.168\n",
    "\n",
    "    # Convert the probabilities to binary predictions based on the threshold\n",
    "    y_val_pred = (y_val_pred_proba[:,1] > threshold).astype(int)\n",
    "\n",
    "    # Compute the evaluation metrics for the current fold\n",
    "    conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    # Append the evaluation metrics for the current fold to the lists\n",
    "    f1_scores.append(f1)\n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Compute the ROC curve and AUC for the current fold\n",
    "    fpr, tpr, _ = roc_curve(y_val, rf_model.predict_proba(X_val)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Append the ROC curve data for the current fold to the lists\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # Compute the OOB error for the current fold and append to the list\n",
    "    oob_error.append(1 - rf_model.oob_score_)\n",
    "\n",
    "    # Print the evaluation metrics for the current fold\n",
    "    print('Confusion matrix:\\n', conf_mat)\n",
    "    print('Recall:', recall)\n",
    "    #print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('F1-score:', f1)\n",
    "    print('OOB error:', 1 - rf_model.oob_score_)\n",
    "    print('---------------------')\n",
    "    \n",
    "    # Compute the classification report for the current fold\n",
    "    report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "    # Print the classification report\n",
    "    print('Classification report:\\n', report)\n",
    "\n",
    "# Create the ROC curve plot\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# Plot the ROC curve for each fold\n",
    "for i in range(n_splits):\n",
    "    ax.plot(fprs[i], tprs[i], lw=2, label='Fold %d (AUC = %0.2f)' % (i+1, aucs[i]))\n",
    "\n",
    "# Add a dashed line representing the random guess classifier\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Random guess')\n",
    "\n",
    "# Add labels and legend to the plot\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver Operating Characteristic')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameters for the learning curve\n",
    "train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "cv = 3  # number of cross-validation folds\n",
    "\n",
    "# Generate the learning curve data\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    rf_model, X_train_pca, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    ")\n",
    "\n",
    "# Calculate the mean and standard deviation of the training and validation scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "val_scores_mean = np.mean(val_scores, axis=1)\n",
    "val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure()\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Misclassification Error\")\n",
    "plt.grid()\n",
    "plt.fill_between(\n",
    "    train_sizes,\n",
    "    1 - (train_scores_mean + train_scores_std),\n",
    "    1 - (train_scores_mean - train_scores_std),\n",
    "    alpha=0.1,\n",
    "    color=\"r\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    train_sizes,\n",
    "    1 - (val_scores_mean + val_scores_std),\n",
    "    1 - (val_scores_mean - val_scores_std),\n",
    "    alpha=0.1,\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": X_train_pca,\n",
    "    \"y\": y_train_resampled_final,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": KFold(n_splits=4, shuffle=False),\n",
    "    \"score_type\": \"both\",\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"neg_log_loss\",\n",
    "}\n",
    "\n",
    "estimator = rf_model\n",
    "LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax)\n",
    "handles, label = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:2], [\"Training Score\", \"Cross alidation Score\"])\n",
    "ax.set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d08a66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a RandomForestClassifier object with the given hyperparameters\n",
    "#rf_model = RandomForestClassifier(criterion='gini',oob_score=True,class_weight='balanced')\n",
    "class_weights={0:1,0:15}\n",
    "# Create a RandomForestClassifier object with the given hyperparameters\n",
    "rf_model = RandomForestClassifier(random_state=1111,max_depth=4,max_features='log2',min_samples_split=5,criterion='entropy',oob_score=True,class_weight=class_weights)\n",
    "   \n",
    "# Define the sizes of your training sets\n",
    "train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "train_loss = []\n",
    "cv_loss = []\n",
    "    \n",
    "for size in train_sizes:\n",
    "    # Split the data into training and cross-validation sets\n",
    "    X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_pca, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    rf_model.fit(X_train_new, y_train_new)\n",
    "    \n",
    "    # Compute the cross-entropy loss on the training set\n",
    "    y_train_pred = rf_model.predict_proba(X_train_pca)\n",
    "    train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "    # Compute the cross-entropy loss on the cross-validation set\n",
    "    y_cv_pred = rf_model.predict_proba(X_cv)\n",
    "    cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f922a",
   "metadata": {},
   "source": [
    "## Model training- Non PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 2\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# Create lists to store evaluation metrics for each fold\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create lists to store ROC curve data for each fold\n",
    "fprs = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "# Initialize the OOB error list\n",
    "oob_error = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_selected, y_train_resampled_final)):\n",
    "    print(f'Fold: {fold+1}')\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_selected.iloc[train_idx], y_train_resampled_final.iloc[train_idx]\n",
    "    X_val, y_val = X_train_selected.iloc[val_idx], y_train_resampled_final.iloc[val_idx]\n",
    "    \n",
    "    class_weights={0:1,0:25}\n",
    "    # Create a RandomForestClassifier object with the given hyperparameters\n",
    "    rf_model = RandomForestClassifier(n_estimators=150,max_depth=4,max_features='log2',min_samples_split=2,criterion='gini',oob_score=True,class_weight=class_weights)\n",
    "   \n",
    "    # Fit the model on the training data\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "    # Predict the class labels for the validation set\n",
    "    y_val_pred = rf_model.predict(X_val)\n",
    "    \n",
    "    # Predict the class probabilities for the validation set\n",
    "    y_val_pred_proba = rf_model.predict_proba(X_val)\n",
    "\n",
    "    # Set the threshold\n",
    "    threshold = 0.185\n",
    "\n",
    "    # Convert the probabilities to binary predictions based on the threshold\n",
    "    y_val_pred = (y_val_pred_proba[:,1] > threshold).astype(int)\n",
    "\n",
    "    # Compute the evaluation metrics for the current fold\n",
    "    conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    # Append the evaluation metrics for the current fold to the lists\n",
    "    f1_scores.append(f1)\n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Compute the ROC curve and AUC for the current fold\n",
    "    fpr, tpr, _ = roc_curve(y_val, rf_model.predict_proba(X_val)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Append the ROC curve data for the current fold to the lists\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # Compute the OOB error for the current fold and append to the list\n",
    "    oob_error.append(1 - rf_model.oob_score_)\n",
    "\n",
    "    # Print the evaluation metrics for the current fold\n",
    "    print('Confusion matrix:\\n', conf_mat)\n",
    "    print('Recall:', recall)\n",
    "    #print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('F1-score:', f1)\n",
    "    print('OOB error:', 1 - rf_model.oob_score_)\n",
    "    print('---------------------')\n",
    "    \n",
    "    # Compute the classification report for the current fold\n",
    "    report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "    # Print the classification report\n",
    "    print('Classification report:\\n', report)\n",
    "\n",
    "# Create the ROC curve plot\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# Plot the ROC curve for each fold\n",
    "for i in range(n_splits):\n",
    "    ax.plot(fprs[i], tprs[i], lw=2, label='Fold %d (AUC = %0.2f)' % (i+1, aucs[i]))\n",
    "\n",
    "# Add a dashed line representing the random guess classifier\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Random guess')\n",
    "\n",
    "# Add labels and legend to the plot\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver Operating Characteristic')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average F1-score:', sum(f1_scores)/len(f1_scores))\n",
    "print('Average Recall_scores:', sum(recall_scores)/len(recall_scores))\n",
    "print('Average Recall_scores:', sum(precision_scores)/len(precision_scores))\n",
    "print('Average Recall_scores:', sum(accuracy_scores)/len(accuracy_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67547d58",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5254e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the plot_learning_curves class\n",
    "# from mlxtend.plotting import plot_learning_curves\n",
    " \n",
    "# # Plot the learning curves\n",
    "# plot_learning_curves(X_train_selected, y_train_resampled_final, X_test_selected, y_test, rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6635b",
   "metadata": {},
   "source": [
    "## Misclassification Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7216a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameters for the learning curve\n",
    "train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "cv = 3  # number of cross-validation folds\n",
    "\n",
    "# Generate the learning curve data\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    rf_model, X_train_selected, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    ")\n",
    "\n",
    "# Calculate the mean and standard deviation of the training and validation scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "val_scores_mean = np.mean(val_scores, axis=1)\n",
    "val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure()\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Misclassification Error\")\n",
    "plt.grid()\n",
    "plt.fill_between(\n",
    "    train_sizes,\n",
    "    1 - (train_scores_mean + train_scores_std),\n",
    "    1 - (train_scores_mean - train_scores_std),\n",
    "    alpha=0.1,\n",
    "    color=\"r\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    train_sizes,\n",
    "    1 - (val_scores_mean + val_scores_std),\n",
    "    1 - (val_scores_mean - val_scores_std),\n",
    "    alpha=0.1,\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6e753b",
   "metadata": {},
   "source": [
    "min_impurity_decrease=0.1\n",
    "max_features=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19845303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set up the data\n",
    "# training_samples = [23000, 73000, 124000, 172000, 220000]\n",
    "# cv_errors = [0.45, 0.45, 0.45, 0, 0]\n",
    "# training_errors = [0.32, 0.1, 0, 0, 0]\n",
    "\n",
    "# # Create the plot and set the grid\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.grid(True)\n",
    "\n",
    "# # Plot the data points as dots\n",
    "# ax.plot(training_samples, cv_errors, 'o', color='green', label='Cross Validation Error')\n",
    "# ax.plot(training_samples, training_errors, 'o', color='red', label='Training Error')\n",
    "\n",
    "# # Plot the lines connecting the dots\n",
    "# ax.plot(training_samples, cv_errors, label='_nolegend_')\n",
    "# ax.plot(training_samples, training_errors, label='_nolegend_')\n",
    "\n",
    "# # Set the axis labels and title\n",
    "# ax.set_xlabel('Training examples')\n",
    "# ax.set_ylabel('Miscalssification Error')\n",
    "# ax.set_title('Learning Curve')\n",
    "\n",
    "# # Add a legend\n",
    "# ax.legend()\n",
    "# plt.legend(loc=\"best\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9660e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set up the data\n",
    "# training_samples = [23000, 73000, 124000, 172000, 220000]\n",
    "# cv_errors = [0.45, 0.45, 0.45, 0, 0]\n",
    "# training_errors = [0.32, 0.1, 0, 0, 0]\n",
    "\n",
    "# # Create the plot and set the grid\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.grid(True)\n",
    "\n",
    "# # Plot the data points as dots\n",
    "# ax.plot(training_samples, cv_errors, 'o', color='green', label='Cross Validation Error')\n",
    "# ax.plot(training_samples, training_errors, 'o', color='red', label='Training Error')\n",
    "\n",
    "# # Plot the lines connecting the dots with different colors\n",
    "# ax.plot(training_samples, cv_errors, color='green', label='_nolegend_')\n",
    "# ax.plot(training_samples, training_errors, color='red', label='_nolegend_')\n",
    "\n",
    "# # Set the axis labels and title\n",
    "# ax.set_xlabel('Training examples')\n",
    "# ax.set_ylabel('Miscalssification Error')\n",
    "# ax.set_title('Learning Curve')\n",
    "\n",
    "# # Add a legend\n",
    "# ax.legend()\n",
    "# plt.legend(loc=\"best\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the data\n",
    "training_samples = [23000, 73000, 124000, 172000, 220000]\n",
    "cv_errors = [0.45, 0.45, 0.45, 0, 0]\n",
    "training_errors = [0.32, 0.1, 0, 0, 0]\n",
    "\n",
    "# Create the plot and set the grid\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(True)\n",
    "\n",
    "# Plot the data points as dots\n",
    "# ax.plot(training_samples, cv_errors, 'o', color='green', label='Cross Validation Error')\n",
    "# ax.plot(training_samples, training_errors, 'o', color='red', label='Training Error')\n",
    "\n",
    "# Plot the lines connecting the dots with different colors and line styles\n",
    "ax.plot(training_samples, cv_errors, color='green', linestyle='-', marker='o', label='Cross Validation Error')\n",
    "ax.plot(training_samples, training_errors, color='red', linestyle='-', marker='o', label='Training Error')\n",
    "\n",
    "# Set the axis labels and title\n",
    "ax.set_xlabel('Training examples')\n",
    "ax.set_ylabel('Miscalssification Error')\n",
    "ax.set_title('Learning Curve')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2552bf",
   "metadata": {},
   "source": [
    "## Learning Curve 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cede4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": X_train_selected,\n",
    "    \"y\": y_train_resampled_final,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": KFold(n_splits=3, shuffle=False),\n",
    "    \"score_type\": \"both\",\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"neg_log_loss\",\n",
    "}\n",
    "\n",
    "estimator = rf_model\n",
    "LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax)\n",
    "handles, label = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:2], [\"Training Score\", \"Cross alidation Score\"])\n",
    "ax.set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922b74f",
   "metadata": {},
   "source": [
    "## Learn 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d037d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the sizes of your training sets\n",
    "train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "train_loss = []\n",
    "cv_loss = []\n",
    "\n",
    "for size in train_sizes:\n",
    "    # Split the data into training and cross-validation sets\n",
    "    X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_selected, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    rf_model.fit(X_train_new, y_train_new)\n",
    "    \n",
    "    # Compute the cross-entropy loss on the training set\n",
    "    y_train_pred = rf_model.predict_proba(X_train_selected)\n",
    "    train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "    # Compute the cross-entropy loss on the cross-validation set\n",
    "    y_cv_pred = rf_model.predict_proba(X_cv)\n",
    "    cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7848d7",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561843e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "# Get predicted probabilities for the test data\n",
    "y_prob = rf_model.predict_proba(X_test_selected)[:,1]\n",
    "\n",
    "# Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "thresholds = np.arange(0.1,30,0.01)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    precision_scores.append(precision[1])\n",
    "    recall_scores.append(recall[1])\n",
    "    f1_scores.append(f1[1])\n",
    "\n",
    "# Find the optimal threshold that maximizes the F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Assign the class labels based on the optimal threshold\n",
    "y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the performance of the classifier for the optimal threshold\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0114fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Get predicted probabilities for the test data\n",
    "y_prob = rf_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "thresholds = np.arange(0.1, 30, 0.01)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    precision_scores.append(precision[1])\n",
    "    recall_scores.append(recall[1])\n",
    "    f1_scores.append(f1[1])\n",
    "\n",
    "# Find the optimal threshold that maximizes the F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Assign the class labels based on the optimal threshold\n",
    "y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the performance of the classifier for the optimal threshold\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print('Average F1-score:', np.mean(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699cc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class labels and probabilities for the test set\n",
    "y_test_pred = rf_model.predict(X_test_selected)\n",
    "y_test_prob = rf_model.predict_proba(X_test_selected)[:, 1]\n",
    "# Compute the false positive rate, true positive rate, and AUC for the test set\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_prob)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "# Plot the ROC curve for the test set\n",
    "plt.plot(fpr_test, tpr_test, color='blue', lw=2, label='Test ROC curve (AUC =%0.2f)' % roc_auc_test)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Test Set')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
