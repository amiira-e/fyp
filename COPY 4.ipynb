{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36751d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bd0f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6224bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder from Sklearn\n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['type'])\n",
    "# printing label\n",
    "label\n",
    "# removing the column 'type' from df\n",
    "# as it is of no use now.\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "# Appending the array to our dataFrame\n",
    "# with column name 'type'\n",
    "df[\"type\"] = label\n",
    "# printing Dataframe\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a48f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameDest'])\n",
    "label\n",
    "df.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df[\"nameDest\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ad34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameOrig'])\n",
    "label\n",
    "df.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df[\"nameOrig\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee6b35d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.99871\n",
      "1    0.00129\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=18)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffcc877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in X_train: 5726358\n",
      "Number of rows in X_test: 636262\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in X_train:\", X_train.shape[0])\n",
    "print(\"Number of rows in X_test:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9df157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5726358,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed (20)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.14, 'oldbalanceOrg': 0.24, 'newbalanceOrig': 0.25, 'oldbalanceDest': 0.22, 'newbalanceDest': 0.22}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train.index, size=len(X_train), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train.loc[X_train[col_name] > np.percentile(X_train[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "\n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float64 columns to float32\n",
    "float64_cols = df.select_dtypes(include=['float64']).columns\n",
    "df[float64_cols] = df[float64_cols].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff831ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e69302",
   "metadata": {},
   "source": [
    "## FS Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Select top features using Random Forest\n",
    "rf = RandomForestClassifier(random_state=18)\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_features = X_train.columns[indices][:5]  # select top 5 features\n",
    "print(top_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12468a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d7ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # Plot feature importances\n",
    "# plt.figure(figsize=(7, 5))\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(len(indices)), importances[indices])\n",
    "# plt.xticks(range(len(indices)), X_train.columns[indices], rotation=90)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset X_train to include only selected features\n",
    "X_train_selected = X_train[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7145fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_b = df.columns.get_loc('newbalanceDest')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b44f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_b = df.columns.get_loc('step')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178bee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_b = df.columns.get_loc('oldbalanceOrg')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be97b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_b = df.columns.get_loc('amount')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_b = df.columns.get_loc('oldbalanceDest')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "caa1accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract same features in test set,select the columns by index\n",
    "selected_indices = [5,0,2,4,1]\n",
    "X_test_selected = X_test.iloc[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d37cf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(636262, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e267705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5726358,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40b288",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33b47e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "# Define your hyperparameter search space\n",
    "param_dist = { \n",
    "    'n_estimators': sp_randint(100, 300),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : sp_randint(3,5),\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "252479cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5726358,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bdb45fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 20\n",
      "max_resources_: 100\n",
      "aggressive_elimination: True\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 5\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 3\n",
      "n_resources: 40\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 2\n",
      "n_resources: 80\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingRandomSearchCV(aggressive_elimination=True,\n",
       "                      estimator=RandomForestClassifier(random_state=18),\n",
       "                      factor=2, max_resources=100,\n",
       "                      param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                           'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002AD567A4948>,\n",
       "                                           'max_features': ['sqrt', 'log2'],\n",
       "                                           'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002AD567A4DC8>},\n",
       "                      random_state=18, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # Required to enable HalvingRandomSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "# Set up the HalvingRandomSearchCV with aggressive early stopping\n",
    "search = HalvingRandomSearchCV(rf, param_dist, cv=5,verbose=1, \n",
    "                               factor=2, resource='n_samples', max_resources=100, \n",
    "                               aggressive_elimination=True, random_state=18, \n",
    "                               scoring='accuracy', refit=True)\n",
    "\n",
    "# Fit the HalvingRandomSearchCV object to the data\n",
    "search.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "095785e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and evaluate on the test set\n",
    "best_params = search.best_params_\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "400f7970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>step</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402687</th>\n",
       "      <td>323930.00</td>\n",
       "      <td>139</td>\n",
       "      <td>2080.00</td>\n",
       "      <td>500046.97</td>\n",
       "      <td>176116.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760752</th>\n",
       "      <td>97668.37</td>\n",
       "      <td>213</td>\n",
       "      <td>5854688.09</td>\n",
       "      <td>657536.54</td>\n",
       "      <td>559868.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594236</th>\n",
       "      <td>0.00</td>\n",
       "      <td>262</td>\n",
       "      <td>274516.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8622.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933631</th>\n",
       "      <td>0.00</td>\n",
       "      <td>177</td>\n",
       "      <td>70800.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30724.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227203</th>\n",
       "      <td>4123295.63</td>\n",
       "      <td>186</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3308021.94</td>\n",
       "      <td>815273.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753638</th>\n",
       "      <td>0.00</td>\n",
       "      <td>279</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1305.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532557</th>\n",
       "      <td>0.00</td>\n",
       "      <td>154</td>\n",
       "      <td>1235072.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26853.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800777</th>\n",
       "      <td>0.00</td>\n",
       "      <td>217</td>\n",
       "      <td>12915.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28641.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444235</th>\n",
       "      <td>0.00</td>\n",
       "      <td>203</td>\n",
       "      <td>271067.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10589.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935763</th>\n",
       "      <td>4673794.76</td>\n",
       "      <td>177</td>\n",
       "      <td>1263913.98</td>\n",
       "      <td>4739241.21</td>\n",
       "      <td>65446.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636262 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         newbalanceDest  step  oldbalanceOrg  oldbalanceDest     amount\n",
       "1402687       323930.00   139        2080.00       500046.97  176116.97\n",
       "2760752        97668.37   213     5854688.09       657536.54  559868.17\n",
       "3594236            0.00   262      274516.76            0.00    8622.10\n",
       "1933631            0.00   177       70800.94            0.00   30724.62\n",
       "2227203      4123295.63   186           0.00      3308021.94  815273.69\n",
       "...                 ...   ...            ...             ...        ...\n",
       "3753638            0.00   279           0.00            0.00    1305.97\n",
       "1532557            0.00   154     1235072.75            0.00   26853.36\n",
       "2800777            0.00   217       12915.80            0.00   28641.92\n",
       "2444235            0.00   203      271067.00            0.00   10589.28\n",
       "1935763      4673794.76   177     1263913.98      4739241.21   65446.45\n",
       "\n",
       "[636262 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb01d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5726358,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0752d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7833f8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5726358,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6b699f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 290}\n",
      "Test set accuracy: 0.9987112227352883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "453f09fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5726358,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853b65f",
   "metadata": {},
   "source": [
    "## Use cost sensitive learning random forest with the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Confusion matrix:\n",
      " [[1594161  312733]\n",
      " [     22    1870]]\n",
      "Recall: 0.9883720930232558\n",
      "Accuracy: 0.8361497831606057\n",
      "Precision: 0.005943999262562658\n",
      "F1-score: 0.011816932337003745\n",
      "---------------------\n",
      "Fold: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 3\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# Create lists to store evaluation metrics for each fold\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create lists to store ROC curve data for each fold\n",
    "fprs = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_selected, y_train)):\n",
    "    print(f'Fold: {fold+1}')\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "\n",
    "    # Train a random forest model with 100 trees and a max depth of 4\n",
    "    class_weight = {0: 1, 1: 5500}\n",
    "    rf_model = RandomForestClassifier(n_estimators=290, max_features='log2', max_depth=4,\n",
    "                                   class_weight=class_weight, oob_score=True, random_state=18, criterion=\"entropy\")\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    rf_model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Predict the class labels for the validation set\n",
    "    y_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "    # Compute the evaluation metrics for the current fold\n",
    "    conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    # Append the evaluation metrics for the current fold to the lists\n",
    "    f1_scores.append(f1)\n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Compute the ROC curve and AUC for the current fold\n",
    "    fpr, tpr, _ = roc_curve(y_val, rf_model.predict_proba(X_val)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Append the ROC curve data for the current fold to the lists\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # Print the evaluation metrics for the current fold\n",
    "    print('Confusion matrix:\\n', conf_mat)\n",
    "    print('Recall:', recall)\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('F1-score:', f1)\n",
    "    print('---------------------')\n",
    "\n",
    "# Create the ROC curve plot\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# Plot the ROC curve for each fold\n",
    "for i in range(n_splits):\n",
    "    plt.plot(fprs[i], tprs[i], lw=2, label='Fold %d (AUC = %0.2f)' % (i+1, aucs[i]))\n",
    "\n",
    "# Add labels and legend to the plot\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Random guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83218870",
   "metadata": {},
   "source": [
    "Cost sensitive learning\n",
    "Use correct hyperparameter\n",
    "plot OOB error for every fold\n",
    "plot f1 score for train & test : https://www.bing.com/images/search?view=detailV2&ccid=7RhAWIsn&id=EFDAEB69AA4818AB3C9475F012C996C507736D0B&thid=OIP.7RhAWIsn6RONqcOdAR6t6gHaHJ&mediaurl=https%3A%2F%2Fcdn.analyticsvidhya.com%2Fwp-content%2Fuploads%2F2020%2F03%2FScreenshot-2020-03-04-at-15.08.50-850x820.png&cdnurl=https%3A%2F%2Fth.bing.com%2Fth%2Fid%2FR.ed1840588b27e9138da9c39d011eadea%3Frik%3DC21zB8WWyRLwdQ%26pid%3DImgRaw%26r%3D0&exph=820&expw=850&q=graphs+for+random+forest&simid=608001867482224477&form=IRPRST&ck=ACE74CE8E33F1BDCD8DFF63221C79789&selectedindex=9&ajaxhist=0&ajaxserp=0&vt=0&sim=11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8163f5",
   "metadata": {},
   "source": [
    "out-of-sample testing\" or \"model validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c87c2",
   "metadata": {},
   "source": [
    "https://www.bing.com/images/search?view=detailV2&ccid=HiBreHJ1&id=4AE90CD5515EF4A6E50E9C0688ACB5FE7C375F42&thid=OIP.HiBreHJ1b7h-1uQEgXJDfQHaFB&mediaurl=https%3A%2F%2Fmiro.medium.com%2Fmax%2F552%2F1*80OL6-Nn2oYwQPcS3aO3jg.png&exph=374&expw=552&q=graphs+for+random+forest&simid=608008151010657800&form=IRPRST&ck=18435DC859CC9886473DD5FB88D029A8&selectedindex=29&ajaxhist=0&ajaxserp=0&vt=0&sim=11&cdnurl=https%3A%2F%2Fth.bing.com%2Fth%2Fid%2FR.1e206b7872756fb87ed6e4048172437d%3Frik%3DQl83fP61rIgGnA%26pid%3DImgRaw%26r%3D0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
