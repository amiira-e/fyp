{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f374f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90396195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17bda14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41793035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f83c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5f220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a3c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ced06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5184944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        step         amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0        352   27467.510000   40908.500000             0.0           0.000   \n",
      "1        138   44423.330000   40908.500000             0.0       42211.705   \n",
      "2        325  129966.345000    4564.000000             0.0       42211.705   \n",
      "3        308  300712.340000   51474.000000             0.0       42211.705   \n",
      "4        349   47243.760000   11262.000000             0.0           0.000   \n",
      "...      ...            ...            ...             ...             ...   \n",
      "422195   277  111168.880136  111168.880136             0.0       42211.705   \n",
      "422196   274  129966.345000   40908.500000             0.0       42211.705   \n",
      "422197    60  129966.345000   40908.500000             0.0           0.000   \n",
      "422198   449   44882.356239   44882.356239             0.0           0.000   \n",
      "422199   220   39953.091459   29059.334627             0.0       42211.705   \n",
      "\n",
      "        newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "0             0.000000               0     3    334319    153257  \n",
      "1        212049.580000               0     0     92881    180374  \n",
      "2        212049.580000               0     1     80756    482539  \n",
      "3        654217.020000               0     1    175711    597630  \n",
      "4             0.000000               0     3    163709     26253  \n",
      "...                ...             ...   ...       ...       ...  \n",
      "422195   212049.580000               0     1     90379    472585  \n",
      "422196   212049.580000               0     1    112071    494845  \n",
      "422197        0.000000               0     1    154830    240268  \n",
      "422198    36237.626509               0     1    122579     88980  \n",
      "422199   212049.580000               0     1     93537    130866  \n",
      "\n",
      "[422200 rows x 10 columns]\n",
      "         step     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "485376  278.0   22928.58            0.0             0.0           0.000   \n",
      "642214   45.0    8606.90         5764.0             0.0           0.000   \n",
      "192982  237.0  220046.83            0.0             0.0      130797.505   \n",
      "99091   328.0   83938.53        13653.5             0.0      130797.505   \n",
      "203398  307.0   74636.86            0.0             0.0      130797.505   \n",
      "...       ...        ...            ...             ...             ...   \n",
      "230877  154.0  195805.05        31725.0             0.0           0.000   \n",
      "315026  301.0   36352.03        13653.5             0.0           0.000   \n",
      "661254  238.5  163969.90        13653.5             0.0      130797.505   \n",
      "688112  280.0    3092.79            0.0             0.0           0.000   \n",
      "642560   35.0   74636.86        30807.0             0.0      130797.505   \n",
      "\n",
      "        newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "485376           0.000               0     3    291184    424837  \n",
      "642214           0.000               0     3    363649    442961  \n",
      "192982      214326.245               0     1      1853    410946  \n",
      "99091       537297.070               0     0    252825    347652  \n",
      "203398      214326.245               0     1    201182    417173  \n",
      "...                ...             ...   ...       ...       ...  \n",
      "230877      195805.050               0     1    181881    192704  \n",
      "315026           0.000               0     3    458861    630843  \n",
      "661254      706564.020               0     0     37270    676511  \n",
      "688112           0.000               0     3    455345    152073  \n",
      "642560      214326.245               0     1    214954    689599  \n",
      "\n",
      "[70000 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# convert X_test to a pandas dataframe\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "# define a function to replace outliers with MAD for a single column\n",
    "def replace_outliers_with_mad(column):\n",
    "    median = np.median(column)\n",
    "    mad = np.median(np.abs(column - median))\n",
    "    threshold = 2.5 * mad\n",
    "    column[np.abs(column - median) > threshold] = median\n",
    "    return column\n",
    "\n",
    "# apply the function to all columns of X_train_resampled_final\n",
    "for i in range(X_train_resampled_final.shape[1]):\n",
    "    X_train_resampled_final.iloc[:, i] = replace_outliers_with_mad(X_train_resampled_final.iloc[:, i])\n",
    "\n",
    "# apply the function to all columns of X_test\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test.iloc[:, i] = replace_outliers_with_mad(X_test.iloc[:, i])\n",
    "\n",
    "# convert the numpy arrays back to pandas dataframes\n",
    "X_train_resampled_final = pd.DataFrame(X_train_resampled_final, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "\n",
    "# print the modified dataframes\n",
    "print(X_train_resampled_final)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0385cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc22192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba3d6140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022E64B55F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022E64B55F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6576/6597 [============================>.] - ETA: 0s - loss: 0.4640WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000022E65AC14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000022E65AC14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6597/6597 [==============================] - 17s 2ms/step - loss: 0.4638 - val_loss: 0.4871\n",
      "Epoch 2/10\n",
      "6597/6597 [==============================] - 16s 2ms/step - loss: 0.4111 - val_loss: 0.4785\n",
      "Epoch 3/10\n",
      "6597/6597 [==============================] - 15s 2ms/step - loss: 0.4071 - val_loss: 0.4765\n",
      "Epoch 4/10\n",
      "6597/6597 [==============================] - 16s 2ms/step - loss: 0.4060 - val_loss: 0.4759\n",
      "Epoch 5/10\n",
      "6597/6597 [==============================] - 15s 2ms/step - loss: 0.4056 - val_loss: 0.4757\n",
      "Epoch 6/10\n",
      "6597/6597 [==============================] - 15s 2ms/step - loss: 0.4054 - val_loss: 0.4755\n",
      "Epoch 7/10\n",
      "6597/6597 [==============================] - 16s 2ms/step - loss: 0.4052 - val_loss: 0.4754\n",
      "Epoch 8/10\n",
      "6597/6597 [==============================] - 17s 3ms/step - loss: 0.4051 - val_loss: 0.4753\n",
      "Epoch 9/10\n",
      "6597/6597 [==============================] - 17s 3ms/step - loss: 0.4051 - val_loss: 0.4752\n",
      "Epoch 10/10\n",
      "6597/6597 [==============================] - 24s 4ms/step - loss: 0.4050 - val_loss: 0.4751\n",
      "Test MSE: 0.43057\n",
      "Epoch 1/10\n",
      "6597/6597 [==============================] - 21s 3ms/step - loss: 0.4751 - val_loss: 0.4050\n",
      "Epoch 2/10\n",
      "6597/6597 [==============================] - 17s 3ms/step - loss: 0.4751 - val_loss: 0.4050\n",
      "Epoch 3/10\n",
      "6597/6597 [==============================] - 21s 3ms/step - loss: 0.4750 - val_loss: 0.4050\n",
      "Epoch 4/10\n",
      "6597/6597 [==============================] - 18s 3ms/step - loss: 0.4750 - val_loss: 0.4049\n",
      "Epoch 5/10\n",
      "6597/6597 [==============================] - 16s 3ms/step - loss: 0.4750 - val_loss: 0.4049\n",
      "Epoch 6/10\n",
      "6597/6597 [==============================] - 16s 2ms/step - loss: 0.4750 - val_loss: 0.4049\n",
      "Epoch 7/10\n",
      "6597/6597 [==============================] - 16s 2ms/step - loss: 0.4749 - val_loss: 0.4048\n",
      "Epoch 8/10\n",
      "6597/6597 [==============================] - 16s 2ms/step - loss: 0.4749 - val_loss: 0.4050\n",
      "Epoch 9/10\n",
      "6597/6597 [==============================] - 16s 2ms/step - loss: 0.4749 - val_loss: 0.4049\n",
      "Epoch 10/10\n",
      "6597/6597 [==============================] - 16s 2ms/step - loss: 0.4749 - val_loss: 0.4048\n",
      "Test MSE: 0.43033\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeXgT1foH8O8kadI2adO9pQtFZLcsCgiyqnBBL1ARUWQryuYuy8UFLz+94IKIgKIiiiK4UkVFFERQAcsuS6vIvrTQjdLSfU8yvz+mSZs2LUmbdrp8P88zTzNnzpx5E6p5e+bMOYIoiiKIiIiIWhCF3AEQERERNTQmQERERNTiMAEiIiKiFocJEBEREbU4TICIiIioxWECRERERC0OEyAiIiJqcVRyB9AYmUwmJCcnw8PDA4IgyB0OERER2UEUReTm5iI4OBgKRc19PEyAbEhOTkZYWJjcYRAREVEtXL58GaGhoTXWYQJkg4eHBwDpA/T09JQ5GiIiIrJHTk4OwsLCLN/jNWECZIP5tpenpycTICIioibGnuErHARNRERELQ4TICIiImpxmAARERFRi8MxQERE5HRGoxGlpaVyh0HNjIuLC5RKpVPaYgJEREROI4oiUlNTkZWVJXco1Ex5eXkhKCiozvP0MQEiIiKnMSc/AQEBcHd352Sy5DSiKKKgoABpaWkAgFatWtWpPSZARETkFEaj0ZL8+Pr6yh0ONUNubm4AgLS0NAQEBNTpdhgHQRMRkVOYx/y4u7vLHAk1Z+bfr7qOMWMCRERETsXbXlSfnPX7xQSIiIiIWhwmQERERNTiMAEiIiKqR3379sXzzz9vd/1Tp05BEAScOnWqHqMiJkBERNSiCYJQ4/bQQw/Vqf2tW7diwYIFdtdv3749UlJS0L59+zpd93rMiZZarcbVq1etjiUkJEChUEAQBKSmplrKN2zYgN69e1sWC4+IiLBK7lavXm3zM/Ty8qrX91IbfAy+gRmNgMkEuLjIHQkREQFASkqK5XV0dDRefPFFnD592lJmfvS6stLSUrjY8T9zHx8fh+JRKpUICgpy6Jy6CAoKwueff445c+ZYyj755BOEhYXh0qVLlrItW7YgKioKS5YswYgRIyCKIv755x/ExMRYtefv74+//vrLqkyhaHz9LY0vomYuKQn4+28pCSIiau5EEcjPl2cTRftiDAoKsmx6vR6CIFQpM/eWfPfddxg4cCA0Gg02btyIK1eu4IEHHkBISAjc3d3RvXt3fPvtt1btV74FFhQUhDfffBNRUVHQ6XRo06YN1q1bZzle+RbYtm3bIAgCdu/ejZtvvhlarRaDBg3C+fPnK3zOIl588UX4+flBr9fj0Ucfxdy5c9G3b9/rvv8pU6Zg7dq1Vm2tX78eU6ZMsar3448/YsiQIZgzZw46dOiAjh07YsyYMVixYoVVPYVCYfX5BQUFISAg4Pr/EA2MCVADM5mA5GSgbCJLIqJmraAA0Onk2QoKnP9+nnvuOcybNw+nTp3CHXfcgcLCQvTr1w9btmzB33//jSlTpmDcuHGIjY2tsZ0lS5Zg4MCBiI2NxdSpUzFjxgxcvHixxnMWLFiAd955B4cOHUJJSQlmzpxpObZ27VosW7YMK1aswJ9//gk/Pz98/PHHdr2n++67D4mJiTh8+DAA4LfffkNJSQmGDx9uVS8oKAhxcXHNZmwSEyAZ5OYC588DXCeQiKhpmTdvHu655x7ccMMNCAoKQps2bTB79mz06NEDN954I+bOnYvBgwdj48aNNbYzevRozJgxA+3atcOCBQug1Wqxe/fuGs95/fXXMWDAANx000149tlnsXv3bhiNRgDAO++8g8ceewyTJ09Ghw4d8Morr9g9hsjV1RUPPvigpRdo7dq1mDJlSpVZlufOnYuIiAh07twZbdu2xYQJE/Dpp59WmZAwLS0NOp3Oahs1apRdsTQkjgGSgVot9QAlJwPh4XJHQ0RUf9zdgbw8+a7tbL169bLaNxgMeO211/DNN98gKSkJJSUlKC4uRkhISI3tdOvWzfJaoVAgMDDQssaVPee0atUKRqMRGRkZCAgIwJkzZ/DCCy9Y1b/11ltx9OhRu97X1KlTMWzYMLz44ovYtGkT4uLikJGRYVXH09MT27dvx9mzZ7Fr1y7s378fTz31FFauXIk9e/bA1dUVAODr64v9+/dbndsYZwdnAiQDlUr6D/PcOSAgAKhmfB0RUZMnCIBWK3cUzqOt9GZee+01vPfee3jrrbfQpUsXaLVaPPbYYygpKamxncqDpwVBgOk6g0MrnmOeDdlkMkEsG+xUeYZk0d5BUAB69+6NsLAwjB8/Hr169UL79u2rJEBm7du3R/v27TFjxgw8//zz6NSpE77//nuMHz8egDSIu127dnZfWy68BSYTb28gJweoMMCeiIiamJiYGIwdOxbjx49H9+7d0aZNG5w9e7ZBYxAEAR06dMChQ4esys1jeuz18MMPY9euXZg6dard57Rt2xaurq7Iz8936FqNAXuAZCIIUhIUHw8EBQF6vdwRERGRo9q1a4dt27bh4MGD8PDwwJIlS5CZmdngcTz11FOYNWsWevTogd69e+Pzzz/HmTNn0KVLF4famDx5Mry9vW0ef+GFFyCKIu666y6Eh4cjIyMDy5cvh1KpxJAhQyz1TCaT1dxBZoGBgY1qnTjZe4BWrVqFG264Aa6urujZs2eV+QQqWrdunc0JloqKimrdppw8PIDCQuDiRfsf1yQiosZj0aJF6Ny5M4YMGYIhQ4agXbt2uPvuuxs8jqlTp2LOnDl4+umn0atXL6SlpWHChAmWcTn2UKlU8PPzqzL42ez222/HqVOnMGnSJHTs2BEjR45EVlYWduzYgRtuuMFS7+rVq2jVqlWVLTs7u87v05kE0ZGbhE4WHR2NyZMnY9WqVejfvz8++OADfPTRRzhx4gRat25dpf66deswa9YsqwmqAFhNGOVom7bk5ORAr9cjOzsbnp6edXuTlcTHA3FxQGiotF9UBGRmAn36AP7+Tr0UEVGDKioqwsWLFy1/gJK8Bg4ciE6dOmHNmjVyh+JUNf2eOfL9LWsP0PLlyzFt2jRMnz4dnTt3xltvvYWwsDC8//771Z5TeYKqyrNl1qZNObm6Sr0/Fy5Is0QTERE5Kjs7GytXrsTJkydx8uRJzJ8/H3v27EFUVJTcoTVasiVAJSUlOHLkCIYNG2ZVPmzYMOzbt6/a8/Ly8hAeHo7Q0FCMHDkSx44dq3ObxcXFyMnJsdoaUkAAkJIC2LhlSkREdF2CIGDTpk3o378/evfujR07dmDz5s0YOHCg3KE1WrINgk5PT4fRaERgYKBVeWBgoM3BUwDQqVMnrFu3Dl27dkVOTg7efvtt9O/fH3FxcWjfvn2t2gSAxYsXY+HChXV/U7WkUkmPwp87B/j5ARqNbKEQEVET5Onpid9//13uMJoU2QdB25q3oLpR4n379sWkSZPQvXt3DBw4EF9//TU6dOiAd955p9ZtAsD8+fORnZ1t2S5fvlzLd1N7Pj5ARgaQmNjglyYiImpxZOsBMo80r9wzk5aWVqUHpzoKhQK9e/e2zLlQ2zY1Gg00Mne7KBTSo/AXLgCBgdI6NkRERFQ/ZOsBUqvV6NmzJ3bs2GFVvmPHDvTr18+uNkRRRGxsLFq1auW0NuXk5SVNGZ+QIHckREREzZusEyHOnTsXkydPRq9evXDbbbfhww8/xKVLl/Doo48CAKKiohASEoLFixcDABYuXIi+ffuiffv2yMnJwcqVKxEbG4v33nvP7jYbO19fKQFq1Uq6LUZERETOJ2sCNG7cOGRkZGDRokVISUlBREQEtm7divCyFUIvXboEhaK8kyorKwszZ85Eamoq9Ho9br75Zvzxxx+49dZb7W6zsdNqpXmBLl6UeoQUso/SIiIian5knQixsWrIiRBtKSmRVovv00daJoOIqCngRIjApEmTUFRUhI0bNwIABgwYgL59++LNN9+s9pzQ0FA8//zzePLJJ+t0bWe109g1i4kQyTa1Wno0/vx5oLRU7miIiJq3UaNGYejQoTaP7d+/H4Ig4OjRo7Vqe/PmzXjppZfqEl4VH330Efz8/KqUHzt2zKGFTGvj119/hSAI8PX1RXFxsdWxffv2QRAEqFTWN5dWrVqFbt26QavVwsvLC7fccotVQrhgwQKby1xFRETU63vhYqiNlJ8fkJQEJCcDTeTuHRFRkzRt2jSMGTMGCQkJVYZLrF27Fj169MAtt9xSq7Z9GnAwp38Drqek1WqxefNm3H///ZaytWvXonXr1khKSrKUffDBB3j22WfxzjvvYNCgQSgqKkJcXFyVJa26d++Obdu2WZW5uLjU63tgD1AjpVJJi6WeOyctmEpERPVj5MiRCAgIwLp166zKCwoKEB0djWnTpgEASktLMXXqVLRp0wZubm7o2LFjlXnoKhswYADmzZtn2U9NTcXIkSPh5uaGtm3bYsOGDVXOWbp0KSIiIuDu7o6wsDA8+eSTyM/PByD1wMyYMQMZGRmWnpJXXnkFgHQL7N1337W0Ex8fj8jISGi1Wuj1ejz44IO4evWq5fiCBQvQq1cvrF+/HuHh4fDy8sLEiRORl5d33c9sypQpWLt2rWU/Pz8fX3/9NaZMmWJV78cff8T48ePx8MMP48Ybb8RNN92ECRMmVJl8WKVSVVnmytfX97px1AUToEbM2xvIzgYuXZI7EiKiWhJFID9fns3OIa4qlQpRUVFYt24dKg6L/eabb1BSUoKJEycCAIxGI1q3bo2NGzfixIkTWLBgAZ577jl89913dn8cUVFRSExMxK5duxAdHY23334bGRkZVeJ59913ceLECaxbtw7bt2/H/PnzAQCDBg3CsmXL4OPjg5SUFKSkpGDOnDlVrmMymRAZGYmcnBzExMTgl19+wenTpzF+/HireqdPn8aWLVuwZcsW/PDDD/j111+xdOnS676PKVOm4Pfff7f09nzzzTfo0KEDunXrZlUvKCgI+/fvx6VG+EXGW2CNmCBIj8LHx0uDofV6uSMiInJQQYF8M7vm5UmP1tph6tSpWLp0KXbt2oU77rgDgHRLZ8yYMfD29gYAuLq64n//+5/lnBtuuAF79uzB119/jTFjxlz3GidOnMCOHTtw+PBh9OzZEwCwZs0adO3a1apexYSmTZs2WLhwIebMmYOVK1dCrVbD09PTsjB4dX755RecPHkS8fHxCAkJAQCsX78e3bt3x7Fjx3DzzTdb6n7yySfQln1OEydOxG+//Xbd5aGCgoIwbNgwrF+/Hi+88ALWrl1rc/zRwoULMWbMGISHh6Njx4647bbbMGLECNx3331WKzQcO3YMukq/J5MmTcLq1atrjKMu2APUyHl4SLfALl60+48ZIiJyUKdOndCvXz/LbZ3z588jJiamypf6qlWr0KtXL/j7+0On0+GTTz6xu3fj5MmTUKvVVuOJIiIi4OHhYVXv119/xZAhQxASEgKdToepU6fiypUrVQYdX+9abdq0sSQ/ANCtWzfodDqcPHnSUta2bVtL8gMArVq1Qlpaml3XmDp1KtatW4ezZ8/i8OHDmDBhQpU6ISEhOHjwIP766y889dRTKC4uxqRJkzBixAir3rYuXbogNjbWalu0aJHd77c2mAA1Af7+0hph6elyR0JE5CB3d6knRo7N3d2hUKdNm4Zvv/0WOTk5+OSTTxAeHo4hQ4ZYjn/55ZeYN28epk+fju3btyM2NhZRUVEoKSmxq/3q1qWsmAhcvHgRI0eORI8ePfDdd9/h6NGjWLlyJQBpDJK9aloDs2J55YHGgiDAZDLZdY2RI0ciOzsbM2fOxOjRo+Hl5VVt3a5du+KJJ57Al19+iW3btuHnn3/Gnj17LMc1Gg3atWtntQUEBNgVR23xFlgT4Ooq9f5cuCDdElMq5Y6IiMhOgmD3bSi5PfDAA5g1axa+/PJLrF+/HjNmzLBKFmJiYjBw4ECrlQXOnTtnd/tdunRBcXExjh07ZukF+ueff6wGHR86dAgAsGzZMkvZl19+adWOWq2G0Wi87rUuXryI5ORkBAcHAwD++usv5OXloXPnznbHXBMXFxdMmjQJy5cvr7IE1fViA2AZ2C0X9gA1EQEBQEoKUGmdVyIichKdTodx48bhhRdeQHJyMh566CGr4+3atcPBgwexY8cOnDlzBi+88AKOHTtmd/tdunTB0KFDMX36dBw6dAiHDx/GzJkzrSbza9euHYqLi/Huu+/iwoULWL9+PT788EOrdtq0aYPs7Gzs2rUL6enpKLTxqPDw4cPRuXNnTJw4EceOHcOBAwfw0EMPYciQIejRo4djH0wNFi9ejKtXr1r1lFX0yCOP4JVXXsHevXuRkJCA/fv346GHHkJgYCD69OljqWcwGJCammq12XsrrraYADURKhXg5iY9Fu/AbWAiInLAtGnTkJmZiaFDh6J169ZWx5544glERkbi/vvvR9++fZGTk4NHHnnEofY//fRTBAUFYdCgQRg7diyeeOIJq8e9e/bsiaVLl+LVV19FREQEoqOjLethmg0cOBDTp0/H2LFj4e/vb9VbZKZQKLB582bodDoMGDAAw4cPR4cOHfDVV185FO/1qNVq+Pn5VXu7bejQodi3bx/Gjh2LDh064P7774dOp8Nvv/1mGVwOAHFxcWjVqpXV1rZtW6fGWhmXwrBB7qUwqmMyAZcvA927Azfe6NSwiIjqjEthUEPgUhgtkEIhPQp/4YI0xQURERHVDhOgJsbLS3q4IT5e7kiIiIiaLiZATZCvL5CQAFy7JnckRERETRMToCZIq5VWib94URoXRERERI5hAtREBQRIq8XX81OCREQO47M1VJ+c9fvFBKiJUqulCREvXJB6g4iI5GaeVbigoEDmSKg5M/9+VZ7F2lGcCboJ8/MDkpOlCRIrTVdBRNTglEolvLy8LBPYubu7Vzs/DJGjRFFEQUEB0tLS4OXlBWUdl0VgAtSEqVTSIsvnzknrhbm5yR0REbV05hXK63sWX2q5vLy8LL9ndcEEqInz9gYuXZK2jh3ljoaIWjpBENCqVSsEBAQ4tHgnkT1cXFzq3PNjxgSoiRMEaYHU+HigVSvAyRNXExHVilKpdNoXFVF94CDoZsDDAygslAZE8+ELIiKi62MC1Ez4+wOJiUB6utyREBERNX5MgJoJV1ep9+fCBcBolDsaIiKixo0JUDMSECA9Ep+aKnckREREjRsToGZEpZJ6gs6dA4qL5Y6GiIio8WIC1Mz4+gIZGdJ4ICIiIrKNCVAzo1AAer00Fig/X+5oiIiIGicmQM2QlxeQlyfNDURERERVMQFqpnx9gYQEIDNT7kiIiIgaHyZAzZRWK60Sf+ECYDLJHQ0REVHjwgSoGfP3B5KSAK5JSEREZI0JUDOm0QBKpdQLZDDIHQ0REVHjwQSomfPzA65cAZKT5Y6EiIio8WAC1MypVIBOJ02OWFgodzRERESNAxOgFsDbG8jKAi5dkjsSIiKixoEJUAsgCICPjzQvUE6O3NEQERHJjwlQC+HhId0Cu3hRWjWeiIioJWMC1IL4+wOXLwPp6XJHQkREJC8mQC2Iq6vU+3PhAmA0yh0NERGRfJgAtTABAUBqqrQRERG1VEyAWhiVSpog8dw5oKRE7miIiIjkwQSoBfL1BTIygMREuSMhIiKSBxOgFkihAPR6aSxQfr7c0RARETU8JkAtlF4P5OZKcwMRERG1NEyAWihBkG6FJSQAmZlyR0NERNSwmAC1YFotUFoq3QozmeSOhoiIqOEwAWrh/P2BpCQgLU3uSIiIiBoOE6AWTqMBlEqpF8hgkDsaIiKihsEEiODnB1y5AiQnyx0JERFRw2ACRFCppPFA585JC6YSERE1d0yACADg4wNkZUmLpRIRETV3TIAIgPRYvI8PcPEikJMjdzRERET1iwlQA1NeTYX+7J9QJ8dDmZPZqJZl9/AACgqkJEgU5Y6GiIio/qjkDqClEYqL4H7lItyQCFHlApO7B0p9AmH09IZRp4eocZU1voAA6TZYSIg0OJqIiKg5YgIkA5OLBqVBoYChFMqCPGgSTkMAYHJ1g8HTBwafABh1epjcPaSFuxqQq6vU+3P+PODtLT0iT0RE1NwwAZKTygVGT2/A0xswmaAoLoDLtStQX7kM0UUNo9YTBt8gGD28pN4hF3WDhOXvD6SmSltISINckoiIqEHJPgZo1apVuOGGG+Dq6oqePXsiJibGrvM2bNgAQRAwevRoq/K8vDw8+eSTCA0NhZubGzp37oz333+/PkJ3LoUCJjcdDL5BKA1qDaOHNxTFhXA9/w+0cfugO/oH3E7HwuVKIhT5ufU6SMfFRZog8dw5oKSk3i5DREQkG1l7gKKjozF79mysWrUK/fv3xwcffIC7774bJ06cQOvWras9LyEhAfPmzcPAgQOrHJszZw527tyJzz//HG3atMH27dvx+OOPIzg4GPfcc099vh2nEtUaGNUaGPW+gMkIRWEBXNISoU6+CFHtCqNOL40d8tDDqNMDKhenXt/XVxoLlJgItG3r1KaJiIhkJ2sP0PLlyzFt2jRMnz4dnTt3xltvvYWwsLAae2yMRiMmTpyIhQsXoq2Nb+b9+/djypQpuP3229GmTRvMnDkT3bt3x+HDh+vzrdQvhRImrQcMfq2k3iGtJ5QFuXA79xe0sXuhO/oHXM/+DZeryVAU5juld0ihAPR6aYmM/HwnvAciIqJGRLYEqKSkBEeOHMGwYcOsyocNG4Z9+/ZVe96iRYvg7++PadOm2Tw+YMAAbN68GUlJSRBFETt37sSZM2cwfPjwatssLi5GTk6O1daYiRpXGLz8UBrUGga/IEAQoEm+CPd/DkEbuwfuxw9CnXQRyuxrdVrgS68HcnOB+HjnxU5ERNQYOHQLLDs7G99//z1iYmIQHx+PgoIC+Pv74+abb8bw4cPRr18/u9tKT0+H0WhEYGCgVXlgYCBSU1NtnrN37158/PHHiI2NrbbdlStXYsaMGQgNDYVKpYJCocBHH32EAQMGVHvO4sWLsXDhQrtjb1SUKph0eph0ekAUIRQXQpWTCZeMVIgKJUzuurLH7H2kgdSubnY3LQjSrbCEBCA4WHoqjIiIqDmwqwcoJSUFM2bMQKtWrbBo0SLk5+ejR48eGDJkCEJDQ7Fz507861//QpcuXRAdHe1QAIIgWO2LolilDAByc3MxadIkrFmzBn41TFCzcuVKHDhwAJs3b8aRI0ewbNkyPP744/j111+rPWf+/PnIzs62bJeb6noQggDR1R0GnwCUBobB4B0AwWSC5vJZaP8+AF1sDNyPH4I6JQHK3CzAZLpuk1otUFoq3QqzozoREVGTYFcPUPfu3REVFYVDhw4hIiLCZp3CwkJs2rQJy5cvx+XLlzFv3rwa2/Tz84NSqazS25OWllalVwgAzp8/j/j4eIwaNcpSZir7RlapVDh9+jSCg4Pxwgsv4Pvvv8eIESMAAN26dUNsbCzefPNNDB061GYsGo0GGo2mxnibJJUKRg8vwMMLEEUoivKhyk6Hy9Uk6TF7dx0MPkHlkzCqbX8G/v5AUpL0SHxQUAO/ByIionpgVwL0zz//wN/fv8Y6bm5uGD9+PMaPH4+rV69et021Wo2ePXtix44duPfeey3lO3bssPm0VqdOnfD3339blS1YsAC5ubl4++23ERYWhqKiIpSWlkJRafJApVJpSZZaLEGAyU0Hk5tO2i0tgaIgD67xpwBRhMlNC4PeFwZvf2kSRq2HdA8M0iPxSqXUC+TnJ60eT0RE1JTZ9VV2veSntvXnzp2LyZMno1evXrjtttvw4Ycf4tKlS3j00UcBAFFRUQgJCcHixYvh6upapffJy8sLACzlarUagwcPxjPPPAM3NzeEh4dj9+7d+PTTT7F8+XKH3kNzJ7qoYdT7wKj3kSZhLCqAS3oK1KkJEF00MGo9UeoXBJNOeszez0+N5GQgORmoYYYCIiKiJsHuv+Uff/xxvPHGG9DppB6Ezz77DPfee69lPysrCxMmTMDWrVvtvvi4ceOQkZGBRYsWISUlBREREdi6dSvCw8MBAJcuXarSm3M9GzZswPz58zFx4kRcu3YN4eHhePXVVy1JFdmgUMDkroPJvax3qKQIioI8uJ07DlEh9RwZvP3gY/LDxb/18PfTws296jgtIiKipkIQRfsmjVEqlUhJSUFAQAAAwNPTE7GxsZa5eK5cuYLg4GAYG9Hq5rWVk5MDvV6P7OxseHp6OrXtxD3xSNwaB32XUKe2W29MRigK86EsyAMMBqTmuCEsQo/w3oGATifdD1OppHtk5p9KpeX2GRERUUNx5Pvb7h6gynmSnXkTNXUKJUxaT5i00i+Su6YQV89lw8+QCq1WkGZMNCc9FV+7uABqtbRpNNJ+xQTJVtJkfs3kiYiI6hmHs5JD3HzckFrqhiQF0D4UEEQTYDSWb6ay/ZISaRbFiuWAlNyYk+fqkieVSkqamDwREVE9YQJEDvP2Aq5ckZ4I8/ZWQHBRSEmKo0w1JE95eeXloihtjiZP5u16SZO5DUEo34iIqFlzKAF68cUX4e7uDkBayuLVV1+FXq8HABQUFDg/OmqUNBqpc+f0aSnvcXMD3LWAq6b8zpeLGlC7SLlFtRQKaWsMyRNQnvyYkyHzMXOc5n1BqJp4VUyeKidTlfedWYeIiGrF7gRo0KBBOH36tGW/X79+uHDhQpU61DL4+gJFRdJSY1lZwNWrgHlUmFJRftdKrQbc3aUkqWJipFZLx2v9He6s5MlkkjZRLH9dcd+cNNnaN5eZ9ysmWUDV/cpllZMZ84dRMdG53n7lxKxiPVvtV/zAbV3X1nm26lZux9ZPe8vsre+Mus44ry5tOLrv6LlEZDe7E6Bdu3bVYxjU1AiClNTYYjACRgNQagAKCoCcHKkMAARIiY+Li7RZkiNNeWJk7kVycAYE+9UleXImcxJVm82cjFXczG1W/FldWU3Hrle/psSucoJX1/oVy2xdv/JrWxxJVurrPHv2Halrb9JUXdJb3bHKbV4vwaruYZi6PCTjyLk1/U5Xx5H3XdPnd722HP3sHfl3qct+YzrH07P6L5IGUOcxQAaDAR9ubpUAACAASURBVEVFRZb5gIhUSmmztbqIKEprixkM0s/0dOm1WPFcFaByAVxdAa279NOcMJl7kVyaw+g1e75gyDG2ErmaXst1XnXHqtuvKSl1tK3axFVbjeH3u2IM13tfNf271eXzc6Td6o7ZSvZr6nGuXMfec2pqw95zaur5Nu+bTED37kDZVDpysPtrZOvWrcjIyMDkyZMtZa+++ipefvllGAwG3HnnnYiOjoY3lwynGghC+dhkWwxGwFAqJUe5OcC1DMBk/u8X5YmQi1pKjtzcK9xScyl/3Rj+v0sysKeHhojkl5jovES7luxOgN58803cd999lv19+/bhxRdfxKJFi9C5c2f897//xcsvv8wlJ6hOzL1Hrq5Vj5lM5b1HRUXSWGeDocK5ZXMyuqiqH5jtouJaZkRE5EACdPz4cSxbtsyyv3HjRvzrX//Cf//7XwCAq6srZs2axQSI6o1CId1Wq+7WmtFYniDZGphtTpA0mkoDs12kzgKFAhAUgEKwfhCschkRETV9didAubm58PX1tezv2bMHY8eOtezfdNNNSE5Odm50RHYShPIExxajsWzcUTUDs81tKBRSgaLSa0GokAiV9VJVfAre8lS98voJFBMtIiL52Z0ABQcH4+TJk2jdujXy8vIQFxeHFStWWI5nZGRY5ggiamzMCYqt3iOgwoNVAEST9WtRlMYhiSbAIAKmUgDmp+bF8tf23s6uz0RLgI2HScz7FcosCZZQ/TkVE8Oa2kKl10RETYHdCdDYsWMxe/ZsvPDCC9i6dSuCgoLQt29fy/HDhw+jY8eO9RIkUX0ThAqTNtY0eWMdOSvRMudaFXOOyvmXANv1bCU05jo2E5pqkh5zPZvJksI6oQOs9wVU6OmykfxZxVDh+lbXtfGzcryVj1Wp3wBtw/auQ08619SWQ08nOxCTXXFVU0bUFNidAL300ktITk7G008/jaCgIHz++edQVpjm96uvvsKoUaPqJUii5qKhEi1brKYNsjpQzVRC1Ry3tGWuJJY/qWfVToVGKs8fac/1Kxy2SubMhBqOVa5T0zFH27b1fW9P0lRdDLbasXe/psYcSZKqNHWd+Ks73e6pYGzEaquezTiriceu820kvJXjrOmzqfZYLdutLlmuWHS9z/R6MVXnenmrPYmtQ79HlSjTALdcwOP6l6k3didA7u7u+Oyzz6o9vnPnTqcERET1g7epnKfGeSdtnmD7fHv3a2jKqsCRdiofr7Zde9/jda5rs8zmyddpvDbXceTztPviNRxy4HN39Nwa263hmGBnnfpuw1xHlQqE3dhEEiAiIpLY01tARNXLyZA7AgcSoDvvvNOuer///nutgyEiIiJqCA6tBRYeHo4RI0bARe41lIiIiIjqwO4E6PXXX8e6devwzTffYOLEiZg6dSoiIiLqMzYiIiKiemH3etvPPvssTpw4gU2bNiE3Nxf9+/fHrbfeitWrVyMnJ6c+YyQiIiJyKrsTILPbbrsNa9asQUpKCp544gmsXbsWwcHBTIKIiIioyXA4ATI7evQodu/ejZMnTyIiIoLjgoiIiKjJcCgBSk5OxmuvvYYOHTpg7Nix8PHxwcGDB3HgwAG4ubnVV4xERERETmX3IOh///vf2LlzJ4YNG4alS5dixIgRUFW38iQRERFRI2Z3BrNt2za0atUKly5dwsKFC7Fw4UKb9Y4ePeq04IiIiIjqg0NrgRERERE1B0yAGlh+gWBZOJKIiIjkUeunwMhxX3wBDBofgm3Hw+QOhYiIqEWzKwG66667sG/fvuvWy83NxZIlS/Dee+/VObDmKDkZSLumwurdnVFQxNyTiIhILnbdArv//vvxwAMPwMPDA5GRkejVqxeCg4Ph6uqKzMxMnDhxAnv27MHWrVsxcuRILF26tL7jbpKeegp4d0UpLqW4Yd3PgXj83hS5QyIiImqR7EqApk2bhsmTJ2Pjxo2Ijo7GmjVrkJWVBQAQBAFdunTB8OHDceTIEXTs2LFeA27KXF2B+Y9l4rEXA/DxT4EYe3s6ArxL5Q6LiIioxbF7ELRarcaECRMwYcIEAEB2djYKCwvh6+vLWaAdMOL2AnQNycDfSb54e2MwXp2RIHdIRERELU6tB6Lo9XoEBQUx+XGQIACzhvwDANgU44sT8ZxBm4iIqKFxJK4MbgrJxIjbMiCKApZ+GQqRj8UTERE1KCZAMpnzQBI0LiYcPOmJncf0codDRETUojABkkmwXymm3H0FALD0q1CUGASZIyIiImo5HEqAjEYjdu/ejczMzPqKp0WZMTIVvp6lSEh1RfRvfnKHQ0RE1GI4lAAplUoMHz7c8gg81Y3WzYSnxyYDAN77PhhZeUqZIyIiImoZHL4F1rVrV1y4cKE+YmmRxgxOR/vQQuTkq/DBD63kDoeIiKhFcDgBevXVVzFv3jz89NNPSElJQU5OjtVGjlEqgGcnXAYAfLHDHwlXNDJHRERE1PzZPRGi2V133QUAiIyMhCCUD9wVRRGCIMBoNDovuhaif9dcDOyWjZi/9Fi+IQRvz2IPGxERUX1yOAHauXNnfcTR4j0zIRH7jntix2FvHD6lQ69OeXKHRERE1Gw5nAANHjy4PuJo8dqFFOH+O65iw28BWPJlKKL/dwoKTlJARERULxxOgAAgKysLH3/8MU6ePGlZDHXq1KnQ6zmhX108cW8Kftrni38uavHTPh9EDrgmd0hERETNksN9DIcPH8aNN96IFStW4Nq1a0hPT8fy5ctx44034ujRo/URY4vhqzfgkcgUAMCKr0NQWMzJEYmIiOqDwwnQnDlzEBkZifj4eHz33Xf4/vvvcfHiRYwcORKzZ8+ujxhblEnD0hDiV4wrmWqs+zlQ7nCIiIiapVr1AD333HNQqcrvnqlUKjz77LM4fPiwU4NriTRqEXMfTAIAfPRjENIyXWSOiIiIqPlxOAHy9PTEpUuXqpRfvnwZHh4eTgmqpbvr1kz0aJeHwhIlVm4MljscIiKiZsfhBGjcuHGYNm0aoqOjcfnyZSQmJmLDhg2YPn06xo8fXx8xtjiCADw3MREA8H2ML04muMkcERERUfPi8FNgb775JgRBQFRUFAwGAwDAxcUFjz32GF5//XWnB9hSdW+XjxG3XcOW/T5448tQrH3+LASOiSYiInIKh3uA1Go13n77bWRmZiI2NhbHjh3DtWvXsGLFCmg0XMbBmWY/kAS1iwkHT3hi1zFOMUBEROQsDiVABoMBKpUKx48fh7u7O7p27Ypu3brB3d29vuJr0UL8SjDlrisAgKVfhaLUIHNAREREzYRDCZBKpUJ4eDjX+2pAM0alwtezFPGproj+3V/ucIiIiJoFh2+BLViwAPPnz8e1a5yluCHo3Ex46r5kAMB73wcjO18pc0RERERNn8ODoFeuXIlz584hODgY4eHh0Gq1Vsc5G7TzjRmcji92BOBsohtW/9AKz01IlDskIiKiJs3hBGj06NH1EQfVQKUEnp1wGTPe6IAvtvvjwSFXER5YLHdYRERETZZDCZDRaMTtt9+Obt26wdvbu75iIhv6d83FwG7ZiPlLj+UbQvD2rAtyh0RERNRkOTQGSKlUYvjw4cjKynJaAKtWrcINN9wAV1dX9OzZEzExMXadt2HDBgiCYLNH6uTJk4iMjIRer4eHhwf69u1rc/bqpuaZCYlQKkTsOOyNw6d0codDRETUZDk8CLpr1664cME5vQ/R0dGYPXs2/vvf/+LYsWMYOHAg7r777usmKwkJCZg3bx4GDhxY5dj58+cxYMAAdOrUCbt27UJcXBz+7//+D66urk6JWU7tQoow9vZ0AMCSL0NhMskcEBERURMliKIoOnLC9u3b8dxzz+Hll19Gz549qwyC9vT0tLutPn364JZbbsH7779vKevcuTNGjx6NxYsX2zzHaDRi8ODBePjhhxETE4OsrCxs2rTJcvzBBx+Ei4sLPvvsM7vjKC4uRnFx+ZianJwchIWFITs726H3Y4/EPfFI3BoHfZfQWp2fka3CXfMikF+kxOuPXETkAD6NR0RETUvOiUQEDY1A+J03OrfdnBzo9Xq7vr8d7gG66667EBcXh8jISISGhsLb2xve3t7w8vJyaFxQSUkJjhw5gmHDhlmVDxs2DPv27av2vEWLFsHf3x/Tpk2rcsxkMmHLli3o0KEDhg8fjoCAAPTp08cqQbJl8eLF0Ov1li0sLMzu99HQfPUGPHJPCgBgxdchKCzm+hhERESOcvgpsJ07dzrlwunp6TAajQgMDLQqDwwMRGpqqs1z9u7di48//hixsbE2j6elpSEvLw+vv/46XnnlFSxZsgTbtm3DmDFjsHPnTgwePNjmefPnz8fcuXMt++YeoMZq8rA0bPjNH8npGqz7ORCPjbb9eREREZFtDidA1SURtSVUWuFTFMUqZQCQm5uLSZMmYc2aNfDz87PZlqlsUMw999yDOXPmAAB69OiBffv2YfXq1dXGrtFomtQ6Zhq1iP+MS8J/3muLj34Mwn2DMxDgXSp3WERERE2G3bfA3njjDRQWFlr2//jjD6txM7m5uXj88cftvrCfnx+USmWV3p60tLQqvUKANLg5Pj4eo0aNgkqlgkqlwqefforNmzdDpVLh/Pnz8PPzg0qlQpcuXazO7dy5c7N4Cqyiu/pkonu7PBSWKLFyY7Dc4RARETUpdidA8+fPR25urmV/5MiRSEpKsuwXFBTggw8+sPvCarUaPXv2xI4dO6zKd+zYgX79+lWp36lTJ/z999+IjY21bJGRkbjjjjsQGxuLsLAwqNVq9O7dG6dPn7Y698yZMwgPD7c7tqZAEIDnJ0ozQn8f44uTCW4yR0RERNR02H0LrPLDYg4+PGbT3LlzMXnyZPTq1Qu33XYbPvzwQ1y6dAmPPvooACAqKgohISFYvHgxXF1dERERYXW+l5cXAFiVP/PMMxg3bhwGDRqEO+64A9u2bcOPP/6IXbt21TnexqZ7u3z8u+81bD3ggze+DMXa58/Cxt1DIiIiqsThMUDONG7cOGRkZGDRokVISUlBREQEtm7daumtuXTpEhQKxx5Uu/fee7F69WosXrwYTz/9NDp27Ihvv/0WAwYMqI+3ILs5DyTh1yNeOHjCE7uO6XHHLdlyh0RERNTo2T0PkEKhQGpqKgICAgAAHh4eiIuLQ9u2bQEAV65cQXBwMIxGY/1F20AcmUfAUXWdB8iW5dHB+OinVmgTVIQfFv8DF1nTWiIiopo1hnmAHPqq/Oijj6DTSUswGAwGrFu3zvJEVsXxQdSwZkam4rvdfohPdUX07/6YNOyq3CERERE1anYnQK1bt8aaNWss+0FBQVVmW27durXzIiO76dxMeGpsMhZ+Eo73vg/GqP7XoNc2/Z44IiKi+mJ3AhQfH1+PYVBd3Tc4HV9sD8C5JDes/qEVnpuQKHdIREREjZbDS2FQ46RSAs+WJT1fbPdHwpWmM7EjERFRQ2MC1IwM6JaDAd2yYTAqsCI6RO5wiIiIGi0mQM3MM+MToRBEbP/TG4dP6+QOh4iIqFFiAtTMtA8twv13pAMA3vgiFGXLoxEREVEFTICaoSfHJEPrasTxi1r8tN9H7nCIiIgaHbueAsvJybG7QWdPHEiO89Ub8Mg9KVgeHYq3vg7Bv3plwk1T96VLiIiImgu7EiAvLy8Idi4y1Rxmgm4OJg9Lw4bf/JGcrsH6nwPx6OhUuUMiIiJqNOxKgHbu3Gl5HR8fj+effx4PPfQQbrvtNgDA/v37sX79eixevLh+oiSHadQi5j6QhHmr2mLNT0G47/Z0+HsZ5A6LiIioUbArARo8eLDl9aJFi7B8+XKMHz/eUhYZGYmuXbviww8/xJQpU5wfJdXK3X0z8dn2PMSd02HlxhC8PD1B7pCIiIgaBYcHQe/fvx+9evWqUt6rVy8cOnTIKUGRcwgCLDNCf/eHL04luMkcERERUePgcAIUFhaG1atXVyn/4IMPEBYW5pSgyHl6tM/H3X2uQRQFLPkyFCLHQhMRETm2GjwArFixAvfddx9++eUX9O3bFwBw4MABnD9/Ht9++63TA6S6mzsuCb8d9cLBE57YHavH7Tdnyx0SERGRrBzuAfr3v/+NM2fOIDIyEteuXUNGRgbuuecenDlzBv/+97/rI0aqoxD/EkQNTwMALP0qFKUcC01ERC2cwz1AgHQb7LXXXnN2LFSPZoxKwXe7fXExxRVf7/THxH9dlTskIiIi2dRqJuiYmBhMmjQJ/fr1Q1JSEgDgs88+w549e5waHDmPh7sJT96XDAB477tgZOcrZY6IiIhIPg4nQN9++y2GDx8ONzc3HD16FMXFxQCA3Nxc9go1cmNvT8eNIYXIylPhgx+C5A6HiIhINg4nQK+88gpWr16NNWvWwMXFxVLer18/HD161KnBkXOplMCzZY/Ff749AJeuqGWOiIiISB4OJ0CnT5/GoEGDqpR7enoiKyvLKUFR/RnYLQcDumbDYFRgeXSo3OEQERHJwuEEqFWrVjh37lyV8j179qBt27ZOCYrq1zPjE6EQRGz/0xuHT+vkDoeIiKjBOZwAPfLII5g1axYOHjwIQRCQnJyML774AvPmzcPjjz9eHzGSk7UPK8LYO9IBAG98EQqTSeaAiIiIGpjDj8E/++yzyM7Oxh133IGioiIMGjQIGo0G8+bNw5NPPlkfMVI9eHJMMrbs88Hxi1r8tN8Hkf2vyR0SERFRg6nVY/Cvvvoq0tPTcejQIRw4cABXr17Fyy+/7OzYqB756Q2YGZkCAHjr6xAUFgsyR0RERNRwHEqADAYDVCoVjh8/Dnd3d/Tq1Qu33nordDqOI2mKooanIdivGKnX1Fj/c6Dc4RARETUYhxIglUqF8PBwGI3G+oqHGpBGLWLuA9JElmt+CsLVrFpNDE5ERNTkOHwLbMGCBZg/fz6uXeOYkebg7r6Z6N4uD4XFSqzcGCJ3OERERA3C4T/5V65ciXPnziE4OBjh4eHQarVWxzkZYtMiCMBzExIxYVEnfPeHLyb+Kw2dwgvlDouIiKheOZwAjR49uj7iIBn1aJ+Pu/tcw88HfbDky1Csff4sBI6JJiKiZszhBOill16qjzhIZnMeSMKvR7xw8IQndsfqcfvN2XKHREREVG9q9Rg8NT+hASWIGp4GAFj6VShKDTIHREREVI8cToCMRiPefPNN3HrrrQgKCoKPj4/VRk3XzMgUeHuU4mKKK77e6S93OERERPXG4QRo4cKFWL58OR544AFkZ2dj7ty5GDNmDBQKBf73v//VQ4jUUDzcTXhqTDIA4L3vgpGdr5Q5IiIiovrhcAL0xRdfYM2aNZg3bx5UKhXGjx+Pjz76CC+++CIOHDhQHzFSAxp7RzraBhciK0+FD34IkjscIiKieuFwApSamoquXbsCAHQ6HbKzpcGyI0eOxJYtW5wbHTU4lRJ4dkIiAODz7QG4dEUtc0RERETO53ACFBoaipQUaQ2pdu3aYfv27QCAP//8ExqNxrnRkSwGdstB/67ZMBgVWB4dKnc4RERETudwAnTvvffit99+AwDMmjUL//d//4f27dsjKioKU6dOdXqAzYooyh2BXQQBeGZ8IhSCiO1/euPIae31TyIiImpCHJ4H6PXXX7e8Hjt2LEJDQ7Fv3z60a9cOkZGRTg2u2fn5ZwQ+MRuKwJtQKtyFgvY9AFXjXH+rQ1gR7rs9Hd/s9McbX4bhq5dOQcFJE4iIqJmo87dv37590bdvX2fE0vxt3QqX+LMIjj8LHNwEo5sW+RF9kdejP/K69YPRy0/uCK08dV8ytuz3wd8XtNiy3wej+nP9NyIiah4cToA+/fTTGo9HRUXVOphm7+WXkeHfCaaN38E7IRaq3Ex4/vkbPP+UbikW3tAZed0HIK97fxS17Qwo5H0M3U9vwMxRqXjrmxCs+DoEQ3tlwk3TNG7jERER1UQQRccGpnh7e1vtl5aWoqCgAGq1Gu7u7s1ilficnBzo9XpkZ2fD09PTqW0n7olH4tY46DsFw/XiCeji9kIXuxduF09Y1TN4eCGvWz/kd++PvG63waR1bhz2KioRMOLZm5CSocHTY5Pw6D2pssRBRETNR86JRAQNjUD4nTc6t10Hvr8d7gHKzMysUnb27Fk89thjeOaZZxxtruVSKFB0YwSKboxA+phHoMzOgC5uH3Rxe6H9ez9UuVnw2rsVXnu3QhQUKGzfDXk9pN6h4rB2aKjVSl3VIuaOS8Izq9pizY9BuG9wOvy9uE4GERE1bQ73AFXn8OHDmDRpEk6dOuWM5mTVID1AXWp4vNxggPvZOOhi90AbtxeuSResDpf6BCKvez/k9RiA/C69Ibq6OzXGykQRGL+wI/46r8PY269i0bRL9Xo9IiJq3ppkD1B1lEolkpOTndVcy6ZSoaBzTxR07gmMnwWXq8nQxu2DLm4PtCf+hMu1K/De+T28d34Pk8oFBZ17Iq97f+R174/SoNZOD0cQgOcmJGLiy53w7W4/TBh6FZ3CC51+HSIioobicAK0efNmq31RFJGSkoJ3330X/fv3d1pgVK7UPxhZQ8cia+hYCCVFcD91FLrYPdDF7oX6ahJ0fx+A7u8DwOfLUBzUWho31L0/CjrdAtHFOTM539whH3f1uYZtB33wxleh+Pi5sw11F46IiMjpHE6ARo8ebbUvCAL8/f1x5513YtmyZU4LjGwT1a7I79YP+d364cpkEeqUBOjipGTI/fRRaFIvQZN6CT6/fAWTxg35N90q9Q716A+DT2Cdrj33gST8dsQLB/7xxB9xnhjcI8dJ74qIiKhhOZwAmUym+oiDakMQUBLcBteC2+Da3ZOgKMyD9vghaSB13F64ZKXD4+hueBzdDQAoCmtvGUhd2C4CUDr2zx8aUIKo4Wn4eEsQln4Vin4RJ+DSOOdxJCIiqhG/vpoRk5sOub3vRG7vOwFRhCbhdPlj9uf/huvls3C9fBZ+P34Co9YTeV37Iq97f+R36wejp/f1LwBgZmQKvvvDFxeS3fDEinbo2jYfof4lCAssRph/Mfy9SjljNBERNXoOJ0Bz5861u+7y5csdbZ6cRRBQ3KYTitt0QsY906DMzYL2r/3lj9nnZUN/YDv0B7ZDFAQUtb3J0jtUFN4R1WUxHu4mzL4/GS+tDceev/TY85fe6rjGxYTQACkZCgssRqh/MVoHFiPUvwSh/sXQqDmRIhERyc/hBOjYsWM4evQoDAYDOnbsCAA4c+YMlEolbrnlFks9gSNkGxWjhxdy+t+NnP53AyYj3M4dl8YOxe2Fa8IZuJ0/Drfzx+H/7WoY9L7lj9nf1Acmd51VW/ffkY7WgUU4fkGLS2kaJKZpcDlNg5QMNYpLFTif5IbzSW5VYhAEEYHepQgtS44qJ0leOiMHVhMRUYNwOAEaNWoUPDw8sH79esus0JmZmXj44YcxcOBA/Oc//3F6kORkCiUKO3RHYYfuuHr/E1BdS4Pur33SvEPHD0KVnQGvP36E1x8/QlQqUdDh5rKB1ANQEtwGEAT06ZKHPl3yrJotNQApGWokpmlwqSwpqvi6oEiJ1GtqpF5T4/Bpjyph6dyMCA0oRuuA4ipJUivfEqjkXRmEiIiaEYcnQgwJCcH27dtx0003WZUfP34cw4YNaxZzAck+EaKMhNISuJ0+Jo0ditsLTUqC1fESv2Bp3FCP/igOag2T1hNGd911B1SLIpCZq8LlNHWVxCgxTYMrmTU/rq9UiAj2K0FYQLF0i63SpnPj4HwioqaiSU6EmJOTgytXrlRJgNLS0pCbm+toc9TIiC5qFET0QUFEH6RNnAuXK5ctA6ndTx2BOj0ZPr99A5/fvrE6z+iqhUnrAaPWE8aynyb38n2T1hN6rQfCtJ4wBnjCdIMHjDq9JXkqKhGQdFVKiConSYlXNSgpVZQd09iM29ujFKH+JWgdWGxJklqX/QzgwGwiIqrE4QTo3nvvxcMPP4xly5ahb9++AIADBw7gmWeewZgxY5weIMmrNDAMmcMeROawByEUFUJ74k/o4vbC/cSfUGVlQFmUDwBQFuVDWZQPlwzHF0s1J0+dKydPrTxhbOcBg7snsuCNlBJfXC70xcU8f5zN9sfpawGIv6rDtVwXZJZtf1/QVmlf7WKSbqkFFFdJkkL9i+HKgdlERC2OwwnQ6tWrMW/ePEyaNAmlpaVSIyoVpk2bhqVLlzo9QGo8RFc35N0yCHm3DCovNBqgLMiDIj8HyvwcKPNzy37mlJVJ+4qCXKvjivxch5KnYABdbJQbXd1h8PZEkcYTuUovZMIb6SYfpJb4IrHIF5cL/JBe6oPMZG9kJnvjT3hjO7yRiSAY4AIAcNMY4aY2QaM2wU1jgqta2iq+dlWLVcqsj5vgqjHBrcJrSz21CWoXkQO8iYgaEYcTIHd3d6xatQpLly7F+fPnIYoi2rVrB6226l/e9jK3l5KSgptuuglvvfUWBg4ceN3zNmzYgPHjx+Oee+7Bpk2bbNZ55JFH8OGHH2LFihWYPXt2rWOkaihVMHp4wejhhVJHz60meVLk50JZUHG/7HVB2bH8HCgLzclTAZRFBdAgFXoAjoysyoMWmfBGfrEWJcVqlKDqVgyNzXLzVgANsmo4bj6/FC6AiwoKFxcIapW0ubhAoVFBpVFBqVFCqVHBxVUFtVqwnWhpTHB1qZpomZM3tUqESilCqRShEMCEi4ioBrWeCFGr1aJbt25ISEhAQkICOnXqBEUtBlpER0dj9uzZWLVqFfr3748PPvgAd999N06cOIHWratf2DMhIQHz5s2rMVHatGkTDh48iODgYIfjogYgc/KkQz50yHf626pWadlWUHM1A5R2JV/m4zll+waoYILCsolQQBQEQFDApFAAUEBUKABBgChIP6FQAIJUT1QoK5RJPwWFdD4UZeWVjgkK82uF5TWUAhTmcstrAQpzHaUCCqUAQSlAUEivFUqpLancfA2hrF1AEBRl9c3lWcGnBwAAIABJREFU0jEI0jkKAYCyPCZBKUAhCGVlkK6tLP8pKBQQBAEKpXSeUmluE1BY2imLg5kkUbNkdwK0fv16ZGZmWvWizJw5Ex9//DEAoGPHjvjll18QFhbmUADLly/HtGnTMH36dADAW2+9hV9++QXvv/8+Fi9ebPMco9GIiRMnYuHChYiJiUFWVlaVOklJSXjyySfxyy+/YMSIEQ7FRE2AM5KnsttyQmkJBENp2U8DBGOptG/ZDBAMJRVel1rXKa20X6EOSkoBQ6k0R0DF48ZSKAwlUBpLoRCNVuGpYIQKhXBHYd0/J7Fs40NydWK0SiwF6yTTvC9I++Y6oiBIPyFYklHLa8txRXmdsuOAUNaW9FoUbNexlJvLhPLrmNsABECA1fVhbrtCuflcqUywJMUSqa70SjSXSK8r5IbmyABpzi9b5aj4WgAEUSxrXrQ+VvE8wfo8cwyWQyi/vWx1TBQrxF1+gogKfwBYXqPC67JorOoI5X84mD/rsmOW11btVS4TLMm0rXYhSNcTULEOKlwPZZPTSucIlY5VvBbM76di8l7xupZ6KGtLqNCudUzm91cee1l9cxuK8s9NMLdXqS1BYd2O+b0VJl2DW5tAwMlPgTnC7gRo9erVmDlzpmV/27Zt+OSTT/Dpp5+ic+fOePLJJ7Fw4UJ89NFHdl+8pKQER44cwfPPP29VPmzYMOzbt6/a8xYtWgR/f39MmzYNMTExVY6bTCZMnjwZzzzzTJWn1WwpLi5GcXGxZT8nh4t8Nmt1SZ7qg8lYIfEylCdjFfer28rqmIpLYDKYIJpEmIwiRKNY9loqE80/TSbLMZhEmEwiYC4TRcBoBEwiRNEEmMtMJqnMZJLmMyg7B6JUVzDXEc3HTVKZaIIgmiCUHRNEEYJo/dq8AdK+QjRCgAmCCChQdrws3YBYIb0QpTLBnH5Y9k1lKUZ5X5j1fu0GvCthgvJ6WWTlpjm2nqhGv5yZg24z+8p2fbsToDNnzqBXr16W/R9++AGRkZGYOHEiAOC1117Dww8/7NDF09PTYTQaERhovUp5YGAgUlNtD4jdu3cvPv74Y8TGxlbb7pIlS6BSqfD000/bFcfixYuxcOFC+wMnciaFEqJaCRG2H/GvD+a/iOWeW9LcQWVmrK6i0y5YlhiKIkwGKZkzGk1S7maSEkeT5aeU+JmMkBJHc3IpAjCaYDJJ58FkstQxty8ay5JKiICIskRSlBJEcx1RSh5Fk/RJiCaxLIlEWRJaob6IsiRTLPvQTOXlYoXyCu1CNJUdr9CuuU3zotaVjgkVrllxEwUBMF8aAsyzx4lSF0B50wDKullgMvfPiLCcb65ssrRX1s9Toe3y1wDE8j4nkyiUX6tC20DZtSrEJJqvU6meOYkGUJZ8l7VW9j6FsuTaElnFcpQl7mXJuFDWRnldKdkub8e6PUXF81Dx2uZEvvwcQIRCLE/wK8ZW3qNWXscq3rJrWcVSqf2K5ygqvgfzMdGqb9KqfUvblc6x1Y7C/C8gVi0HTCh1rzohbkOyOwEqLCy0mlRo3759mDp1qmW/bdu21SYt11N52QxRFG0upZGbm4tJkyZhzZo18PPzs9nWkSNH8Pbbb+Po0aN2L8cxf/58qzXOcnJyHL6VR0RNgCCND1KifO5OF1kDImoexEo/ryfnRCK6Do2or3DsYncCFB4ejiNHjiA8PBzp6en4559/MGDAAMvx1NRU6PX6Glqoys/PD0qlskrilJaWVqVXCADOnz+P+Ph4jBo1ylJmKvtLRqVS4fTp04iJiUFaWprVAGqj0Yj//Oc/+P/27j4qqjr/A/j7zjAMw4ggA8wwBoTlhkqlQXm0fOhBylqLjq1mimadU6SW5Lppq23+qGRtd93a5UgHj9U5PVFu5tqDW5Qd8+G0uSrFUbMHFShFEnEAiQFm7u+Pr4wMMwMzwHAH7vt1zo2Z+zSfYap5873f7/e+8MILOHHihMd59Xo99Pr+++ubiIiIlOV3AJo/fz4WL16MQ4cOYceOHUhLS0NGRoZr+969e5GeHliaCw8PR0ZGBkpLS3H33Xe71peWluKuu+7y2D8tLQ3l5eVu61avXo2Ghga8+OKLSEpKQk5ODm655Ra3fW699Vbk5OQEfImOiIiIBie/A9CKFSvQ1NSELVu2wGKxYPNm91sh7NmzB3PmzAm4gGXLliEnJweZmZmYMGECiouLUVlZidzcXAAieA0fPhwFBQWIiIjwCFkxMTEA4FpvMplgMpnc9tHpdLBYLK671xMREZG6+R2ANBoNnnnmGTzzzDNet3cORP6aPXs2amtrkZ+fj1OnTiE9PR0fffQRUlJSAACVlZU9ml+IiIiIyJeA7wavBmq+GzwREVGwhcLd4Nm0QkRERKrDAERERESqwwBEREREqsMARERERKoT8N3gHQ4HXn31VXz22WeoqalxTUTYbseOHX1WHBEREVEwBByAli5dildffRV33HEH0tPT/b7dBBEREVGoCDgAlZSU4J133sHtt98ejHqIiIiIgi7gPkDh4eG4/PLLg1GLenDmJSIiIkUFHIB+//vf48UXXwTnT+yZiAhAkgC7XelKiIiI1CvgS2C7d+/G559/ju3bt2PMmDHQ6XRu27ds2dJnxQ1GJhNQHw9UngO83PCeiIiI+kHAASgmJsbtzu0UGEkCEhKA6rNAUxMQGal0RUREROoTcAB65ZVXglGHqgwZAiRGAMePAQaDCEVERETUfzgRokIsFhGEGhqUroSIiEh9Am4BAoB//etfeOedd1BZWYmWlha3bQcOHOiTwgY7QwRwySXAt98CRiOg1SpdERERkXoE3AL0j3/8AwsXLkRCQgIOHjyI6667DiaTCceOHcP06dODUeOgFR8PDIsFbDalKyEiIlKXgAPQhg0bUFxcjMLCQoSHh+OJJ55AaWkpHnvsMdj4TR4QnQ64ZDjQ2ioWIiIi6h8BB6DKykpMnDgRAGAwGNBwoRNLTk4O3nrrrb6tTgVMJtESVFendCVERETqEXAAslgsqK2tBQCkpKTgyy+/BAAcP36ckyP2gEYDDB8OaLRAMydHJCIi6hcBB6CbbroJ77//PgDgwQcfxOOPP45p06Zh9uzZnB+oh6Kjxaiwc2wFIiIi6hcBjwIrLi6G0+kEAOTm5iI2Nha7d+/GjBkzkJub2+cFqoEkAdZE4MwZoLFRDI8nIiKi4Ak4AGk0Gmg0FxuOZs2ahVmzZvVpUWpkNIoO0d9/L2aH1nCGJiIioqDp0dfsrl27MG/ePEyYMAE///wzAOC1117D7t27+7Q4tUlIAIYOBerrla6EiIhocAs4AL377ru49dZbYTAYcPDgQdgv3Na8oaEBa9eu7fMC1USvF5MjNtuBNofS1RAREQ1eAQegZ599Fi+99BI2btzodif4iRMnchboPhAXB5higXPnlK6EiIho8Ao4AB09ehSTJ0/2WD906FCc47d2r4WFiWHxTgdg57B4IiKioAg4ACUmJuKHH37wWL97926MGDGiT4pSu9hYwGxmKxAREVGwBByAHn74YSxduhT//e9/IUkSTp48iTfeeAPLly/HokWLglGj6kiSaAXS6YCmJqWrISIiGnwCHgb/xBNPwGaz4cYbb0RzczMmT54MvV6P5cuXY8mSJcGoUZWiogCrFThxAjAYRCgiIiKivhFwAAKA5557DqtWrcLhw4fhdDoxevRoDOHsfX3Okgj88gvQ0CCGxxMREVHf6FEAAoDIyEhkZmb2ZS3UiSFCDIv/9lsxUaJWq3RFREREg4PfAeiBBx7wa7+XX365x8WQp/h44PRpwGYTnaOJiIio9/wOQK+++ipSUlIwbtw43vW9H+l0ohXo0CGgrU0MkyciIqLe8fvrNDc3FyUlJTh27BgeeOABzJs3D7FskugXJpNoCaqtFT+JiIiod/weBr9hwwacOnUKK1aswPvvv4+kpCTMmjULH3/8MVuEgkyjEcPiJY24TQYRERH1TkDzAOn1esyZMwelpaU4fPgwxowZg0WLFiElJQWNjY3BqpEAREcDFgtwrk7pSoiIiAa+Ht0NHgAkSYIkSZBlGU6nsy9rIi8kCbAmAhEGoPG80tUQERENbAEFILvdjrfeegvTpk3DFVdcgfLychQWFqKyspLzAPUDoxG4ZDjQUA8wcxIREfWc352gFy1ahJKSEiQnJ2PhwoUoKSmByWQKZm3kRUKCGBZfXw/ExChdDRER0cDkdwB66aWXkJycjNTUVOzcuRM7d+70ut+WLVv6rDjypNeLYfFHvgXaHEAYJ0ckIiIKmN8BaP78+ZB4Q6qQEBcHmGLF3eLj2AhHREQUsIAmQqTQEBYmhsXX1QF2u2gVIiIiIv/1eBQYKSs2FjCbRSsQERERBYYBaICSJNEKpNMBTU1KV0NERDSwMAANYFFRgNUqRoRxMm4iIiL/MQANcJZEMT8QJ+ImIiLyHwPQAGeIEMPiGxsBh0PpaoiIiAYGBqBBID4eGDYMsNmUroSIiGhgYAAaBHQ60QrU2gq0tSldDRERUehjABokTCbRElTHu8UTERF1iwFokNBoAOtwQNIAzXalqyEiIgptDECDSEw0YDED59gKRERE1CUGoEFEksS8QBERQON5pashIiIKXQxAg4zRKGaIbqgHnE6lqyEiIgpNDECDkNkMDB0qZogmIiIiTwxAg5BeL4bFN9uBNk6OSERE5IEBaJCKiwNMsbxbPBERkTcMQINUWJjoC+R0AHYOiyciInITEgFow4YNSE1NRUREBDIyMrBr1y6/jispKYEkScjOznata21txYoVK3DllVfCaDTCarVi/vz5OHnyZLDKD1mxsaI/EFuBiIiI3CkegN5++23k5eVh1apVOHjwICZNmoTp06ejsrKyy+MqKiqwfPlyTJo0yW19U1MTDhw4gKeeegoHDhzAli1b8N133+HOO+8M5tsISZIkWoF0OqCpSelqiIiIQocky7KsZAHjx4/HNddcg6KiIte6UaNGITs7GwUFBV6PcTgcmDJlChYuXIhdu3bh3Llz2Lp1q8/X2LdvH6677jpUVFQgOTnZY7vdboe9w3Wi+vp6JCUlwWazYejQob14d16cOAF8/bXopdxPjh0DKipEa5Ak9dvLEhEReVV/+CdYbklHyk2X9e156+sRHR3t1/e3oi1ALS0t2L9/P7KystzWZ2VlYe/evT6Py8/PR3x8PB588EG/Xsdms0GSJMTExHjdXlBQgOjoaNeSlJTk/5sYABKtYn6gxkalKyEiIgoNigagM2fOwOFwwGw2u603m82orq72esyePXuwadMmbNy40a/XaG5uxsqVK3Hffff5TINPPvkkbDaba6mqqgrsjYQ4Q4S4FNbYCDg4LJ6IiAhhShcAAFKn6zKyLHusA4CGhgbMmzcPGzduRFxcXLfnbW1txb333gun04kNGzb43E+v10Ov1wde+ACSkADU1AA2m+gcTUREpGaKBqC4uDhotVqP1p6amhqPViEA+PHHH3HixAnMmDHDtc554X4PYWFhOHr0KC67TFxPbG1txaxZs3D8+HHs2LGj7/vyDDA6neh2dOgQ0NYmhskTERGplaKXwMLDw5GRkYHS0lK39aWlpZg4caLH/mlpaSgvL0dZWZlrufPOO3HjjTeirKzM1XenPfx8//33+PTTT2Eymfrl/YQ6kwmIjwfqeLd4IiJSOcXbAZYtW4acnBxkZmZiwoQJKC4uRmVlJXJzcwEA8+fPx/Dhw1FQUICIiAikp6e7Hd/esbl9fVtbG+655x4cOHAAH3zwARwOh6uFKTY2FuHh4f347kKLRgNYhwNn68RtMiIG91U/IiIinxQPQLNnz0ZtbS3y8/Nx6tQppKen46OPPkJKSgoAoLKyEhqN/w1VP/30E7Zt2wYAGDt2rNu2zz//HFOnTu2z2geimGjAYgZ++ln8JCIiUiPF5wEKRYHMIxAwBeYB6qyxESgvB8J0wBCjYmUQEZFKqX4eIFLGkCEXhsU3ABf6kBMREakKA5BKmc1AVBRQ36B0JURERP2PAUil9HpxFa65GWjj5IhERKQyDEAqFhcHmGJ5t3giIlIfBiAVCwsTfYFkJ9DSonQ1RERE/YcBSOViY8VtMjg5IhERqQkDkMpJEmC1iltlNDUpXQ0REVH/YAAiDB0KJCYC9fUAZ4UiIiI1YAAiACIAGY1ikkQiIqLBjgGIAAAGg7gU1tgIODgsnoiIBjkGIHIxm4FhwwCbTelKiIiIgosBiFx0OjE5Yksr0NamdDVERETBwwBEbkwmICGew+KJiGhwYwAiNxoNYB0OSBqg2a50NURERMHBAEQeYqIBi5m3yCAiosGLAYg8SJIYFh+hBxrPK10NERFR32MAIq+GDBH3CWvg5IhERDQIMQCRT2azmCXaVq90JURERH2LAYh80uvFsPjmX4E2To5IRESDCAMQdSkuTgyNZ4doIiIaTBiAqEthYaIvkOwEWlqUroaIiKhvMABRt2JjgYQETo5IRESDBwMQdUuSxI1SdTqgqUnpaoiIiHqPAYj8MnSomBvIZuOweCIiGvgYgMhviYmA0Qg0NipdCRERUe8wAJHfDAbRIfr8ecDBYfFERDSAMQApoaUFqK0F7APvbqNmMxATA9RzckQiIhrAGID6W3w8MHasaE6pqwMqKoDqanFdyelUurpu6XRicsSWFqCtTelqiIiIeiZM6QJUx2gERo4ELrsMaGgQvYp/+QU4e/bibINGo7gZl06nbK0+xMaKHHf6NGCIBHRhYr4gnQ7QMFITEdEAwACkFI0GiI4WS3Iy0NwswlBdnUgWZ84Ara3ifhRDhgCRkWI8egjQaoHkFBF4zjcBrS2iX1BrK9A+QEyrEdu1WvEzTAeEaRUtm4iIyIUBKFRERIjFbBYtRO2tQ6dPi1B09qwITe2tQ2HKfnRRQ4Co34jHrW0iBLW0iBDU0iLyXFMT0GwXj9saL95PTMLFFqOwDq1HIZLviIhIBRiAQpFWK3oax8QAKSkiSdhsIgSdPg3U1IgOOAaDCEMREYqmB12YWCIjPbc5ne7BqKUVaLGLt9TUJN7Gr7+Kn+2tR2HaC8FId/HympatR0RE1IcYgAaCyEixJCYCV1whhmDZbKLzdHsfIq1WhCGjUfHWoY40mouNW53Jsgg+7cGovRXp119FOLLbL4Ykx4X+4RJEa1F761H7ZTa2HhERUSBC55uS/BMWJnohx8YCl14qOt/YbKLP0JkzIhTJsnvrUIiSpIthxuhlu8PhHoxaW8UltabzIiTZW0QfpLY2iOYjqcMlNXbMJiKiLjAADWSSJELOkCFihsKWFtE6dO7cxdah06eB8PCLrUMDKA1otYBBCxh8tB61h6KOl9d+bfLRMVsWb71jyxE7ZhMRqRcD0GASHg7ExYml4zD72lrROnTypNgvMlIEovBwZevtBUkSA+T0eu/b3TpmX3jc3CzCUXNzp47ZF1qPXOe+cH6NRjzRdHosdVo0GvfHbscQEVFIYgAarCRJ3MF06FAgKUl0qGkfZl9dLTpUt7S4tw4Noo40gXTMbmsDnDIgO8U2WRbByNEmnjsc4rnTIR637+PssH/7cxkdztNNjX4FLY37Y5/HEBFRQBiA1EKvBxISxDJypLhUVl8vRpSdPSuCkSSF/CSMfaGrjtn+cAs87UGoU4Dyd50/QcvhZ9DqGF87hi/Jy3Nv+7ged2jd6rhR8rX9wsb2cIbOPzsc3/EY1zkkz9f39tNtp06rOp+38zoios4YgNRIo7k4zD45WfQobh9mX1NzcRLGiAgRhgwGfpt04Ha5K4g6hiy/QxXgSjbtx8ntzy/8w22dfHG967Xgfj75wgg8byEMXkKZ63Vdb8T9udv2Dimsc12dNnus8NjXS5Obr1a4zqEw0G3+Ht/dfl3p/J+ct5Dnz8k8du3ivF7P3d0Ju1jt7Vz+/q/E535dBOGevI6/+3e5PYDfv7+6ej1/3ltPP0d/+XN4VzV4+++1vzEAkQg4BgNgsXgfZn/mjPi2b+9wHULD7AczSRrY8x95BLBOoafj9s5hqX2720+3k3vfx+v+Xe3TD+f2OH+nFR1/R67nHfbz2Nb5vD4CYFf7dt7u9pp+1OjzGC81e6vN5zof5/P2vMvfbzev09X67s7X7bXtHtTSm21Ar0ry+wTd1hDgdkPnVmQF8JuM3Gm1wLBhYuk4zL62Vsw3dPq0+HO/PTRptRcXdkahDjwukxF54W84CmRfv4KUH6/nz/ZgBKnehCG/9+n1Dr2rRXMSCDd3f3wwMQBR14xGsVit4rJY+zD706cv3sHe0aHTCiC+9dr/rddo3ANSV4+JSHV6c5mMBrAGAD5G8fYXBiDyn04HmExiGTHi4hAqh8PzZ/vj1lYxAq2lw2yGDod43DE8eWtjbw9GHcMSwxMREfUBBiDqme4m4vFFlt0DEsMTEREpgAGI+pfU4X4VfRmeOq/rTXhqr7Pjem/jt9v7PPl63lcLERH1OQYgGjiCGZ46T+7Tcem4rmN/p46L28Q9Xs7Z3j+q4zp/n7e/956MG+2qg4W/k+f4nJjHy/7dnbO3+3e1PVjH+VMbgyrRgMMAROrQm/DUG12FKX+eB7pP+2v6en23cc+d1nUOXb62dT7O39fpuK+vn90N8+luvHl/HOfrWH/CqreWxa6eB3JsMF+no94G8Z4c31fn6Hy+nv4OfNXV3fNAJhvq9YRNPThHMM7pa11bW/evFWQMQETBxMtY3vkKa4GsC/SxkscF+ry/jg30dTrr7b/bSh3fk9+RPz+9/VHQ1TG+9vV1HuDiHyNd1dvVc1/7+Dpfd/t09weFr3NERys+pxwDEBH1P96vgij0BRKEenKMwrdcYgAiIiIiT4N8kiZO3UtERESqwwBEREREqsMARERERKrDAERERESqwwBEREREqsMARERERKoTEgFow4YNSE1NRUREBDIyMrBr1y6/jispKYEkScjOznZbL8sy1qxZA6vVCoPBgKlTp+LQoUPBKJ2IiIgGIMUD0Ntvv428vDysWrUKBw8exKRJkzB9+nRUVlZ2eVxFRQWWL1+OSZMmeWx7/vnnsX79ehQWFmLfvn2wWCyYNm0aGhoagvU2iIiIaACRZLkvbqrSc+PHj8c111yDoqIi17pRo0YhOzsbBQUFXo9xOByYMmUKFi5ciF27duHcuXPYunUrANH6Y7VakZeXhxUrVgAA7HY7zGYz1q1bh4cffrjbmurr6xEdHQ2bzYahQ4f2wbskIiKiYAvk+1vRFqCWlhbs378fWVlZbuuzsrKwd+9en8fl5+cjPj4eDz74oMe248ePo7q62u2cer0eU6ZM8XlOu92O+vp6t4WIiIgGL0UD0JkzZ+BwOGA2m93Wm81mVFdXez1mz5492LRpEzZu3Oh1e/txgZyzoKAA0dHRriUpKSnQt0JEREQDiOJ9gABA6nRvEVmWPdYBQENDA+bNm4eNGzciLi6uT84JAE8++SRsNptrqaqqCvAdEBER0UCi6M1Q4+LioNVqPVpmampqPFpwAODHH3/EiRMnMGPGDNc6p9MJAAgLC8PRo0dhsVgAiJagxMTEbs8JiEtker2+1++HiIiIBgZFA1B4eDgyMjJQWlqKu+++27W+tLQUd911l8f+aWlpKC8vd1u3evVqNDQ04MUXX0RSUhJ0Oh0sFgtKS0sxbtw4AKKv0c6dO7Fu3Tq/6mrvF86+QERERANH+/e2X+O7ZIWVlJTIOp1O3rRpk3z48GE5Ly9PNhqN8okTJ2RZluWcnBx55cqVPo9fsGCBfNddd7mt+/Of/yxHR0fLW7ZskcvLy+U5c+bIiYmJcn19vV81VVVVyQC4cOHChQsXLgNwqaqq6va7XtEWIACYPXs2amtrkZ+fj1OnTiE9PR0fffQRUlJSAACVlZXQaALrqvTEE0/g119/xaJFi1BXV4fx48fjk08+QVRUlF/HW61WVFVVISoqyme/IbWrr69HUlISqqqqOFVACODnEVr4eYQWfh6hJZifhyzLaGhogNVq7XZfxecBooGJcyWFFn4eoYWfR2jh5xFaQuXzCIlRYERERET9iQGIiIiIVEe7Zs2aNUoXQQOTVqvF1KlTERameFcyAj+PUMPPI7Tw8wgtofB5sA8QERERqQ4vgREREZHqMAARERGR6jAAERERkeowABEREZHqMACR3woKCnDttdciKioKCQkJyM7OxtGjR5Uuiy4oKCiAJEnIy8tTuhRV+/nnnzFv3jyYTCZERkZi7Nix2L9/v9JlqVJbWxtWr16N1NRUGAwGjBgxAvn5+a6baFNwffHFF5gxYwasViskScLWrVvdtsuyjDVr1sBqtcJgMGDq1Kk4dOhQv9XHAER+27lzJxYvXowvv/wSpaWlaGtrQ1ZWFs6fP690aaq3b98+FBcX46qrrlK6FFWrq6vD9ddfD51Oh+3bt+Pw4cP429/+hpiYGKVLU6V169bhpZdeQmFhIY4cOYLnn38ef/nLX/DPf/5T6dJU4fz587j66qtRWFjodfvzzz+P9evXo7CwEPv27YPFYsG0adPQ0NDQL/VxGDz12C+//IKEhATs3LkTkydPVroc1WpsbMQ111yDDRs24Nlnn8XYsWPxwgsvKF2WKq1cuRJ79uzBrl27lC6FAPz2t7+F2WzGpk2bXOtmzpyJyMhIvPbaawpWpj6SJOG9995DdnY2ANH6Y7VakZeXhxUrVgAA7HY7zGYz1q1bh4cffjjoNbEFiHrMZrMBAGJjYxWuRN0WL16MO+64A7fccovSpajetm3bkJmZid/97ndISEjAuHHjsHHjRqXLUq0bbrgBn332Gb777jsAwNdff43du3fj9ttvV7gyOn78OKqrq5GVleVap9frMWXKFOzdu7dfauCUmNQjsixj2bJluOGGG5Cenq50OapVUlKC/fv343//+5/SpRCAY8eOoaioCMuWLcMf//hHfPXVV3jssceg1+t11hwpAAAHCklEQVQxf/58pctTnRUrVsBmsyEtLQ1arRYOhwPPPfcc5syZo3RpqlddXQ0AMJvNbuvNZjMqKir6pQYGIOqRJUuW4JtvvsHu3buVLkW1qqqqsHTpUnzyySeIiIhQuhwC4HQ6kZmZibVr1wIAxo0bh0OHDqGoqIgBSAFvv/02Xn/9dbz55psYM2YMysrKkJeXB6vVigULFihdHkFcGutIlmWPdcHCAEQBe/TRR7Ft2zZ88cUXuOSSS5QuR7X279+PmpoaZGRkuNY5HA588cUXKCwshN1uh1arVbBC9UlMTMTo0aPd1o0aNQrvvvuuQhWp2x/+8AesXLkS9957LwDgyiuvREVFBQoKChiAFGaxWACIlqDExETX+pqaGo9WoWBhHyDymyzLWLJkCbZs2YIdO3YgNTVV6ZJU7eabb0Z5eTnKyspcS2ZmJubOnYuysjKGHwVcf/31HlNDfPfdd0hJSVGoInVramqCRuP+NafVajkMPgSkpqbCYrGgtLTUta6lpQU7d+7ExIkT+6UGtgCR3xYvXow333wT//73vxEVFeW6hhsdHQ2DwaBwdeoTFRXl0f/KaDTCZDKxX5ZCHn/8cUycOBFr167FrFmz8NVXX6G4uBjFxcVKl6ZKM2bMwHPPPYfk5GSMGTMGBw8exPr16/HAAw8oXZoqNDY24ocffnA9P378OMrKyhAbG4vk5GTk5eVh7dq1GDlyJEaOHIm1a9ciMjIS9913X/8UKBP5CYDX5ZVXXlG6NLpgypQp8tKlS5UuQ9Xef/99OT09Xdbr9XJaWppcXFysdEmqVV9fLy9dulROTk6WIyIi5BEjRsirVq2S7Xa70qWpwueff+71O2PBggWyLMuy0+mUn376adlisch6vV6ePHmyXF5e3m/1cR4gIiIiUh32ASIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiIiItVhACIiIiLVYQAiIiIi1WEAIiLyQZIkbN26VekyiCgIGICIKCTdf//9kCTJY7ntttuULo2IBgHeDJWIQtZtt92GV155xW2dXq9XqBoiGkzYAkREIUuv18Nisbgtw4YNAyAuTxUVFWH69OkwGAxITU3F5s2b3Y4vLy/HTTfdBIPBAJPJhIceegiNjY1u+7z88ssYM2YM9Ho9EhMTsWTJErftZ86cwd13343IyEiMHDkS27Ztc22rq6vD3LlzER8fD4PBgJEjR3oENiIKTQxARDRgPfXUU5g5cya+/vprzJs3D3PmzMGRI0cAAE1NTbjtttswbNgw7Nu3D5s3b8ann37qFnCKioqwePFiPPTQQygvL8e2bdtw+eWXu73G//3f/2HWrFn45ptvcPvtt2Pu3Lk4e/as6/UPHz6M7du348iRIygqKkJcXFz//QKIqOf67b7zREQBWLBggazVamWj0ei25Ofny7IsywDk3Nxct2PGjx8vP/LII7Isy3JxcbE8bNgwubGx0bX9ww8/lDUajVxdXS3LsixbrVZ51apVPmsAIK9evdr1vLGxUZYkSd6+fbssy7I8Y8YMeeHChX3zhomoX7EPEBGFrBtvvBFFRUVu62JjY12PJ0yY4LZtwoQJKCsrAwAcOXIEV199NYxGo2v79ddfD6fTiaNHj0KSJJw8eRI333xzlzVcddVVrsdGoxFRUVGoqakBADzyyCOYOXMmDhw4gKysLGRnZ2PixIk9e7NE1K8YgIgoZBmNRo9LUt2RJAkAIMuy67G3fQwGg1/n0+l0Hsc6nU4AwPTp01FRUYEPP/wQn376KW6++WYsXrwYf/3rXwOqmYj6H/sAEdGA9eWXX3o8T0tLAwCMHj0aZWVlOH/+vGv7nj17oNFo8Jvf/AZRUVG49NJL8dlnn/Wqhvj4eNx///14/fXX8cILL6C4uLhX5yOi/sEWICIKWXa7HdXV1W7rwsLCXB2NN2/ejMzMTNxwww1444038NVXX2HTpk0AgLlz5+Lpp5/GggULsGbNGvzyyy949NFHkZOTA7PZDABYs2YNcnNzkZCQgOnTp6OhoQF79uzBo48+6ld9f/rTn5CRkYExY8bAbrfjgw8+wKhRo/rwN0BEwcIAREQh6z//+Q8SExPd1l1xxRX49ttvAYgRWiUlJVi0aBEsFgveeOMNjB49GgAQGRmJjz/+GEuXLsW1116LyMhIzJw5E+vXr3eda8GCBWhubsbf//53LF++HHFxcbjnnnv8ri88PBxPPvkkTpw4AYPBgEmTJqGkpKQP3jkRBZsky7KsdBFERIGSJAnvvfcesrOzlS6FiAYg9gEiIiIi1WEAIiIiItVhHyAiGpB49Z6IeoMtQERERKQ6DEBERESkOgxAREREpDoMQERERKQ6DEBERESkOgxAREREpDoMQERERKQ6DEBERESkOv8PPmPOZyLkzgoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 15\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='tanh', kernel_regularizer=regularizers.l1(0.000391))(input_layer)\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# Define the optimizer with the desired learning rate\n",
    "opt = Adam(lr= 0.00087)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the autoencoder model with the specified optimizer and loss function\n",
    "autoencoder.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 2\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Define lists to store the MSE of training and validation sets for each fold\n",
    "train_mse = []\n",
    "val_mse = []\n",
    "test_mse = []\n",
    "recon_errors = []\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, val_index in kf.split(X_train_resampled_final):\n",
    "    \n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    X_train_fold, X_val_fold = X_train_resampled_final[train_index], X_train_resampled_final[val_index]\n",
    "    \n",
    "    # Define early stopping to prevent overfitting and improve efficiency\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    # Fit the autoencoder on the training set for the current fold\n",
    "    history = autoencoder.fit(X_train_fold, X_train_fold, epochs=10,batch_size=32, verbose=1, validation_data=(X_val_fold, X_val_fold),callbacks=[early_stopping])\n",
    "    \n",
    "    # Append the MSE of training and validation sets for the current fold to the lists\n",
    "    train_mse.append(history.history['loss'])\n",
    "    val_mse.append(history.history['val_loss'])\n",
    "    \n",
    "    # compute the reconstruction error for the test data\n",
    "    recon_error = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "    recon_errors.append(recon_error)\n",
    "    \n",
    "    # Calculate the MSE for the test set\n",
    "    test_error = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "    test_mse.append(test_error)\n",
    "    print(f\"Test MSE: {test_error:.5f}\")\n",
    "\n",
    "# Calculate the mean and standard deviation of MSE for training and validation sets across all folds\n",
    "mean_train_mse = np.mean(train_mse, axis=0)\n",
    "std_train_mse = np.std(np.concatenate(train_mse), axis=0)\n",
    "mean_val_mse = np.mean(val_mse, axis=0)\n",
    "std_val_mse = np.std(np.concatenate(val_mse), axis=0)\n",
    "\n",
    "# Plot the MSE of training and validation sets against the number of epochs\n",
    "epochs = range(1, len(mean_train_mse)+1)\n",
    "plt.plot(epochs, mean_train_mse, 'b', label='Training MSE')\n",
    "plt.fill_between(epochs, mean_train_mse - std_train_mse, mean_train_mse + std_train_mse, alpha=0.2, color='b')\n",
    "plt.plot(epochs, mean_val_mse, 'r', label='Validation MSE')\n",
    "plt.fill_between(epochs, mean_val_mse - std_val_mse, mean_val_mse + std_val_mse, alpha=0.2, color='r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50466ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E65D4D288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E65D4D288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13194/13194 [==============================] - 13s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define the hidden layer model\n",
    "hidden_layer_model = Model(inputs=autoencoder.input, outputs=autoencoder.layers[1].output)\n",
    "\n",
    "# Get the activations of the hidden layer for the training data\n",
    "hidden_layer_output_train = hidden_layer_model.predict(X_train_resampled_final)\n",
    "\n",
    "# Define a new model that takes the output of the hidden layer as input\n",
    "new_model_input = Input(shape=(hidden_layer_output_train.shape[1],))\n",
    "x = Dense(10, activation='tanh',kernel_regularizer=regularizers.l1(0.000111))(new_model_input)\n",
    "# x = Dense(32, activation='relu')(x)\n",
    "output = Dense(2, activation='sigmoid')(x)\n",
    "#output = Dense(1, activation='softmax')(x)\n",
    "mediator_network = Model(inputs=new_model_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db0c2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert target labels to one-hot encoded format\n",
    "y_train_resampled_final_onehot = to_categorical(y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f0dcd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "opt_new = Adam(lr= 0.000992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b3c124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022E65D69558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022E65D69558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "11853/11875 [============================>.] - ETA: 0s - loss: 0.3620WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000022E071B3E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000022E071B3E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "11875/11875 [==============================] - 19s 2ms/step - loss: 0.3619 - val_loss: 0.7033\n",
      "Epoch 2/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.2310 - val_loss: 0.4532\n",
      "Epoch 3/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1898 - val_loss: 0.4018\n",
      "Epoch 4/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1766 - val_loss: 0.3677\n",
      "Epoch 5/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1707 - val_loss: 0.3361\n",
      "Epoch 6/15\n",
      "11875/11875 [==============================] - 19s 2ms/step - loss: 0.1665 - val_loss: 0.3616\n",
      "Epoch 7/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1635 - val_loss: 0.3351\n",
      "Epoch 8/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1612 - val_loss: 0.3436\n",
      "Epoch 9/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1595 - val_loss: 0.3432\n",
      "Epoch 10/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1581 - val_loss: 0.3863\n",
      "Epoch 11/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1566 - val_loss: 0.3363\n",
      "Epoch 12/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1548 - val_loss: 0.3745\n",
      "Epoch 13/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1526 - val_loss: 0.3284\n",
      "Epoch 14/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1500 - val_loss: 0.3124\n",
      "Epoch 15/15\n",
      "11875/11875 [==============================] - 18s 2ms/step - loss: 0.1473 - val_loss: 0.3085\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "#Compile the new model\n",
    "mediator_network.compile(optimizer=opt_new, loss='binary_crossentropy')\n",
    "\n",
    "# Train the new model on the activations of the hidden layer\n",
    "history = mediator_network.fit(hidden_layer_output_train, y_train_resampled_final_onehot,\n",
    "                               epochs=15, batch_size=32, validation_split=0.1,\n",
    "                               callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a333b984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E07C26EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E07C26EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13194/13194 [==============================] - 13s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define the hidden layer model\n",
    "hidden_layer_model_med = Model(inputs=mediator_network .input, outputs=mediator_network .layers[1].output)\n",
    "\n",
    "# Get the activations of the hidden layer for the training data\n",
    "hidden_layer_output_train_med = hidden_layer_model_med.predict(hidden_layer_output_train)\n",
    "\n",
    "# Define a new model that takes the output of the hidden layer as input\n",
    "new_model_input_med = Input(shape=(hidden_layer_output_train_med.shape[1],))\n",
    "\n",
    "x = Dense(10, activation='tanh',kernel_regularizer=regularizers.l1(0.0000611))(new_model_input_med)\n",
    "\n",
    "output_med = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "agent_network = Model(inputs=new_model_input_med, outputs=output_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc42333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022E07C4E438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022E07C4E438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000022E65D4D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000022E65D4D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "agent_network.compile(optimizer=opt_new, loss='binary_crossentropy')\n",
    "\n",
    "# Train the new model on the activations of the hidden layer\n",
    "history = agent_network.fit(hidden_layer_output_train_med, y_train_resampled_final_onehot,\n",
    "                               epochs=10, batch_size=32, validation_split=0.2,\n",
    "                               callbacks=[early_stopping],verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d192342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "agent_network.save(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\RLagent_network.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb525670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Load the agent_network variable as a Keras model object\n",
    "agent_network = load_model(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\RLagent_network.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84373d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -0.1\n",
      "\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E0814E678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E0814E678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13194/13194 [==============================] - 14s 1ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"model_384\" with a weight list of length 10, but the layer was expecting 4 weights. Provided weights: [[0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. ...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4444\\394118823.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# Start episode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon_greedy_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[0mtrue_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mpredicted_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4444\\394118823.py\u001b[0m in \u001b[0;36mepsilon_greedy_policy\u001b[1;34m(state, epsilon, theta)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# Choose the action with the highest Q-value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mQ_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4444\\394118823.py\u001b[0m in \u001b[0;36mQ\u001b[1;34m(state, theta)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m# Set the weights of the model to theta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;31m# Compute Q-values for all actions in the state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mQ_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1790\u001b[0m                     \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m                     \u001b[0mexpected_num_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1792\u001b[1;33m                     \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1793\u001b[0m                 )\n\u001b[0;32m   1794\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"model_384\" with a weight list of length 10, but the layer was expecting 4 weights. Provided weights: [[0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. ..."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Define hyperparameters\n",
    "gamma = 0.85\n",
    "epsilon = 0.1\n",
    "batch_size = 32\n",
    "num_episodes = 15\n",
    "max_steps = 7\n",
    "learning_rate=0.5\n",
    "\n",
    "# Initialize counters for true positives, true negatives, false positives, and false negatives\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "D = list(zip(hidden_layer_output_train_med, y_train_resampled_final))\n",
    "\n",
    "# Initialize experience replay memory\n",
    "M = 20000\n",
    "replay_memory = []\n",
    "\n",
    "def epsilon_greedy_policy(state, epsilon, theta):\n",
    "    if np.random.uniform() < epsilon:\n",
    "        # Choose a random action\n",
    "        action = np.random.randint(num_actions)\n",
    "    else:\n",
    "        # Choose the action with the highest Q-value\n",
    "        Q_values = Q(state, theta)\n",
    "        action = np.argmax(Q_values)\n",
    "    return action\n",
    "\n",
    "# Define function for computing loss\n",
    "def compute_loss(y, Q_values):\n",
    "    return np.sum(np.square(y - Q_values))\n",
    "\n",
    "def reward_fn(action, true_label, predicted_label, lambda_val=0.1):\n",
    "    # Initialize terminal flag\n",
    "    terminal = 0\n",
    "    # Fraud class\n",
    "    if true_label == 1:\n",
    "        if action == true_label:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "            terminal = 1\n",
    "    # Not fraud class\n",
    "    else:\n",
    "        if action == true_label:\n",
    "            reward = lambda_val\n",
    "        else:\n",
    "            reward = -lambda_val\n",
    "    return reward, terminal\n",
    "\n",
    "# Define function for computing Q-values\n",
    "# def Q(states, theta):\n",
    "#     # Compute Q-values for all states and actions in the batch\n",
    "#     Q_values = np.dot(states, theta)\n",
    "#     return Q_values\n",
    "# Define function for computing Q-values using neural network\n",
    "# def Q(state, model):\n",
    "#     # Compute Q-values for all actions in the state\n",
    "#     Q_values = model.predict(state)\n",
    "#     return Q_values[0]\n",
    "def Q(state, theta):\n",
    "    # Define state_shape\n",
    "    state_shape = state.shape\n",
    "    # Create a new instance of the agent_network\n",
    "    model = agent_network(state_shape, num_actions)\n",
    "    # Set the weights of the model to theta\n",
    "    model.set_weights(theta)\n",
    "    # Compute Q-values for all actions in the state\n",
    "    Q_values = model.predict(state)\n",
    "    return Q_values[0]\n",
    "\n",
    "\n",
    "# Initialize simulation environments\n",
    "environments = [epsilon for i in range(num_episodes)]\n",
    "\n",
    "# Initialize Q-network parameters\n",
    "num_features = D[0][0].shape[0]\n",
    "num_actions = 2\n",
    "theta = np.zeros((num_features, num_actions))\n",
    "\n",
    "# Initialize index counter for hidden_layer_output_train_med\n",
    "idx = 0\n",
    "\n",
    "# Start training\n",
    "for episode in range(num_episodes):\n",
    "    \n",
    "    # Shuffle training data\n",
    "    random.shuffle(D)\n",
    "    print(\"Episode \", episode)\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    # Initialize state\n",
    "    state= hidden_layer_output_train_med[0, 0]\n",
    "    \n",
    "    # Start episode\n",
    "    for step in range(max_steps):\n",
    "        action = epsilon_greedy_policy(state, epsilon, theta)\n",
    "        true_label = D[step][1]\n",
    "        predicted_label = action\n",
    "\n",
    "        # Get next state from hidden_layer_output_train_med\n",
    "        next_state = hidden_layer_output_train_med[idx, 0]\n",
    "        idx += 1\n",
    "\n",
    "        reward, terminal = reward_fn(action, true_label, predicted_label, lambda_val=0.1)\n",
    "        print(\"Step:\", step)\n",
    "        print(\"True label is\", true_label, \". Agent has predicted:\", predicted_label)\n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"\")\n",
    "        \n",
    "        # Update counters for precision and accuracy\n",
    "        if true_label == 1:\n",
    "            if predicted_label == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if predicted_label == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        \n",
    "\n",
    "        # Store experience in memory\n",
    "        replay_memory.append((state, action, reward, next_state, terminal))\n",
    "\n",
    "        # Sample a batch of experiences from memory\n",
    "        if len(replay_memory) >= batch_size:\n",
    "            batch = random.sample(replay_memory, batch_size)\n",
    "            states, actions, rewards, next_states, terminals = zip(*batch)\n",
    "\n",
    "            # Convert actions tuple into numpy array\n",
    "            actions = np.array(actions)\n",
    "\n",
    "            # Compute target Q-values\n",
    "            target_Q_values = []\n",
    "            for i in range(batch_size):\n",
    "                if terminals[i]:\n",
    "                    target_Q_values.append(rewards[i])\n",
    "                else:\n",
    "                    next_Q_values = Q(next_states[i], theta)\n",
    "                    target_Q_values.append(rewards[i] + gamma * np.max(next_Q_values))\n",
    "\n",
    "            # Compute predicted Q-values and loss\n",
    "            predicted_Q_values = Q(states, theta)[np.arange(batch_size), actions.astype(int)]\n",
    "            loss = compute_loss(target_Q_values, predicted_Q_values)\n",
    "\n",
    "            # Compute gradients\n",
    "            grad = np.gradient(loss, np.ravel(theta.T), axis=0)\n",
    "\n",
    "            # Reshape gradients to match the shape of theta\n",
    "            grad = grad.reshape(theta.shape)\n",
    "\n",
    "            # Update parameters using gradient descent\n",
    "            theta -= grad * learning_rate\n",
    "        \n",
    "      \n",
    "        # Update state\n",
    "        state = next_state\n",
    "        \n",
    "        # Check if episode is finished\n",
    "        if terminal==1:\n",
    "            break\n",
    "            \n",
    "# Calculate precision and accuracy\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b494e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -1.1\n",
      "\n",
      "Step: 1\n",
      "True label is 1 . Agent has predicted: 1\n",
      "Reward: 0.9\n",
      "\n",
      "Episode  1\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Episode  2\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -1.1\n",
      "\n",
      "Step: 1\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -1.1\n",
      "\n",
      "Step: 2\n",
      "True label is 1 . Agent has predicted: 1\n",
      "Reward: 0.9\n",
      "\n",
      "Episode  3\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 1 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Step: 1\n",
      "True label is 1 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Step: 2\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -1.1\n",
      "\n",
      "Step: 3\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -1.1\n",
      "\n",
      "Step: 4\n",
      "True label is 0 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Episode  4\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Episode  5\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Episode  6\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 1 . Agent has predicted: 1\n",
      "Reward: 0.9\n",
      "\n",
      "Episode  7\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Episode  8\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -1.1\n",
      "\n",
      "Step: 1\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -1.1\n",
      "\n",
      "Step: 2\n",
      "True label is 1 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Step: 3\n",
      "True label is 0 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Episode  9\n",
      "--------------------------------------------\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -1.1\n",
      "\n",
      "Step: 1\n",
      "True label is 0 . Agent has predicted: 0\n",
      "Reward: -0.1\n",
      "\n",
      "Precision: 0.2727272727272727\n",
      "Accuracy: 0.47619047619047616\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow import keras\n",
    "\n",
    "# Import necessary libraries\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Define hyperparameters\n",
    "gamma = 0.85\n",
    "epsilon = 0.1\n",
    "batch_size = 32\n",
    "num_episodes = 15\n",
    "max_steps = 7\n",
    "learning_rate=0.5\n",
    "\n",
    "# Initialize counters for true positives, true negatives, false positives, and false negatives\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "D = list(zip(hidden_layer_output_train_med, y_train_resampled_final))\n",
    "\n",
    "# Initialize experience replay memory\n",
    "M = 20000\n",
    "replay_memory = []\n",
    "\n",
    "# Define epsilon-greedy policy\n",
    "def epsilon_greedy_policy(state, epsilon, theta):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.randint(0, 1)\n",
    "    else:\n",
    "        Q_values = Q(state, theta)\n",
    "        return np.argmax(Q_values)\n",
    "\n",
    "# Define Q-network\n",
    "# def agent_network(state_shape, num_actions):\n",
    "#     inputs = keras.layers.Input(shape=state_shape)\n",
    "#     x = keras.layers.Dense(32, activation='relu')(inputs)\n",
    "#     x = keras.layers.Dense(32, activation='relu')(x)\n",
    "#     outputs = keras.layers.Dense(num_actions)(x)\n",
    "#     model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "#     return model\n",
    "\n",
    "def agent_network(state_shape, num_actions):\n",
    "    inputs = keras.layers.Input(shape=(1,))\n",
    "    x = keras.layers.Dense(10, activation='tanh')(inputs)\n",
    "    outputs = keras.layers.Dense(num_actions)(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "# Define Q function\n",
    "def Q(state, theta):\n",
    "    return agent_network(state.shape, 2)(state.reshape(1, -1)).numpy()[0]\n",
    "\n",
    "\n",
    "# Define loss function\n",
    "def compute_loss(target_Q_values, predicted_Q_values):\n",
    "    return np.mean(np.square(target_Q_values - predicted_Q_values))\n",
    "\n",
    "# Define reward function\n",
    "def reward_fn(action, true_label, predicted_label, lambda_val=0.1):\n",
    "    if action == 1:\n",
    "        reward = true_label * (predicted_label - lambda_val) - (1 - true_label) * (predicted_label + lambda_val)\n",
    "    else:\n",
    "        reward = (1 - true_label) * (predicted_label - lambda_val) - true_label * (predicted_label + lambda_val)\n",
    "    return reward, int(predicted_label == true_label)\n",
    "\n",
    "# Define hyperparameters\n",
    "num_episodes = 10\n",
    "max_steps = 20\n",
    "epsilon = 0.1\n",
    "gamma = 0.99\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize simulation environments\n",
    "environments = [epsilon for i in range(num_episodes)]\n",
    "\n",
    "# Initialize Q-network parameters\n",
    "num_features = D[0][0].shape[0]\n",
    "num_actions = 2\n",
    "model = agent_network(num_features, num_actions)\n",
    "theta = model.get_weights()\n",
    "\n",
    "# Initialize index counter for hidden_layer_output_train_med\n",
    "idx = 0\n",
    "\n",
    "# Start training\n",
    "for episode in range(num_episodes):\n",
    "    \n",
    "    # Shuffle training data\n",
    "    random.shuffle(D)\n",
    "    print(\"Episode \", episode)\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    # Initialize state\n",
    "    state= hidden_layer_output_train_med[0, 0]\n",
    "    \n",
    "    # Start episode\n",
    "    for step in range(max_steps):\n",
    "        action = epsilon_greedy_policy(state, epsilon, theta)\n",
    "        true_label = D[step][1]\n",
    "        predicted_label = action\n",
    "\n",
    "        # Get next state from hidden_layer_output_train_med\n",
    "        next_state = hidden_layer_output_train_med[idx, 0]\n",
    "        idx += 1\n",
    "\n",
    "        reward, terminal = reward_fn(action, true_label, predicted_label, lambda_val=0.1)\n",
    "        print(\"Step:\", step)\n",
    "        print(\"True label is\", true_label, \". Agent has predicted:\", predicted_label)\n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"\")\n",
    "        \n",
    "        # Update counters for precision and accuracy\n",
    "        if true_label == 1:\n",
    "            if predicted_label == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if predicted_label == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        \n",
    "\n",
    "        # Store experience in memory\n",
    "        replay_memory.append((state, action, reward, next_state, terminal))\n",
    "\n",
    "        # Sample a batch of experiences from memory\n",
    "        if len(replay_memory) >= batch_size:\n",
    "            batch = random.sample(replay_memory, batch_size)\n",
    "            states, actions, rewards, next_states, terminals = zip(*batch)\n",
    "\n",
    "            # Convert actions tuple into numpy array\n",
    "            actions = np.array(actions)\n",
    "\n",
    "            # Compute target Q-values\n",
    "            target_Q_values = []\n",
    "            for i in range(batch_size):\n",
    "                if terminals[i]:\n",
    "                    target_Q_values.append(rewards[i])\n",
    "                else:\n",
    "                    next_Q_values = Q(next_states[i], model)\n",
    "                    target_Q_values.append(rewards[i] + gamma * np.max(next_Q_values))\n",
    "\n",
    "            # Convert states and next_states tuples into numpy arrays\n",
    "            states = np.array(states)\n",
    "            next_states = np.array(next_states)\n",
    "\n",
    "            # Compute predicted Q-values and loss\n",
    "            predicted_Q_values = Q(states, model)[np.arange(batch_size), actions.astype(int)]\n",
    "            target_Q_values = np.array(target_Q_values)\n",
    "            loss = compute_loss(target_Q_values, predicted_Q_values)\n",
    "\n",
    "            # Backpropagation\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(model.trainable_variables)\n",
    "                predictions = Q(states, model)\n",
    "                loss = compute_loss(target_Q_values, predictions[np.arange(batch_size), actions.astype(int)])\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Check if episode is finished\n",
    "        if terminal==1:\n",
    "            break\n",
    "        \n",
    "# Calculate precision and accuracy\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "db532ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E12833DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E12833DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13194/13194 [==============================] - 14s 1ms/step\n",
      "Episode  0\n",
      "--------------------------------------------\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E0A2D30D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000022E0A2D30D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Step: 0\n",
      "True label is 0 . Agent has predicted: 1\n",
      "Reward: -0.1\n",
      "\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4444\\2303572844.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;31m# Compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[1;31m# Reshape gradients to match the shape of theta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(f, axis, edge_order, *varargs)\u001b[0m\n\u001b[0;32m    993\u001b[0m         \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 995\u001b[1;33m         \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_axis_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[0mlen_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mnormalize_axis_tuple\u001b[1;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[0;32m   1383\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m     \u001b[1;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1385\u001b[1;33m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1383\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m     \u001b[1;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1385\u001b[1;33m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define hyperparameters\n",
    "gamma = 0.85\n",
    "epsilon = 0.1\n",
    "batch_size = 1\n",
    "num_episodes = 15\n",
    "max_steps = 7\n",
    "learning_rate = 0.5\n",
    "\n",
    "replay_memory_size = 20000\n",
    "num_features = D[0][0].shape[0]\n",
    "\n",
    "D = list(zip(hidden_layer_output_train_med, y_train_resampled_final))\n",
    "\n",
    "# Initialize counters for true positives, true negatives, false positives, and false negatives\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "# Initialize simulation environment\n",
    "environment = epsilon\n",
    "\n",
    "theta = np.zeros((num_features, num_actions))\n",
    "\n",
    "# Define Q-network\n",
    "input_shape = hidden_layer_output_train_med[0].shape\n",
    "num_actions = 2\n",
    "\n",
    "# Define Q-network\n",
    "\n",
    "# Define the hidden layer model\n",
    "hidden_layer_model_med = keras.models.Model(inputs=mediator_network.input,\n",
    "                                            outputs=mediator_network.layers[1].output)\n",
    "\n",
    "# Get the activations of the hidden layer for the training data\n",
    "hidden_layer_output_train_med = hidden_layer_model_med.predict(hidden_layer_output_train)\n",
    "\n",
    "# Define a new model that takes the output of the hidden layer as input\n",
    "new_model_input_med = keras.layers.Input(shape=(hidden_layer_output_train_med.shape[1],))\n",
    "reshaped_input_med = keras.layers.Reshape((1, -1))(new_model_input_med)\n",
    "\n",
    "x = keras.layers.Dense(10, activation='tanh',kernel_regularizer=keras.regularizers.l1(0.0000611))(reshaped_input_med)\n",
    "\n",
    "output_med = keras.layers.Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "model= keras.Model(inputs=new_model_input_med, outputs=output_med)\n",
    "\n",
    "# Compile your Keras model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Initialize replay memory\n",
    "replay_memory = []\n",
    "\n",
    "# def Q(state, theta):\n",
    "    \n",
    "#     # Convert state to numpy array\n",
    "#     #state = np.array(state)\n",
    "\n",
    "#     # Compute Q-values using the network\n",
    "#     Q_values = model(state).numpy()[0]\n",
    "\n",
    "#     return Q_values\n",
    "\n",
    "def Q(state, theta):\n",
    "    # Convert state to numpy array\n",
    "    state = np.array(state)\n",
    "    # Reshape state to (1, num_features)\n",
    "    state = np.reshape(state, (1, -1))\n",
    "    # Compute Q-values using the network\n",
    "    Q_values = model(state).numpy()[0]\n",
    "    return Q_values\n",
    "\n",
    "\n",
    "def epsilon_greedy_policy(state, epsilon, model):\n",
    "    if np.random.uniform() < epsilon:\n",
    "        # Choose a random action\n",
    "        action = np.random.randint(num_actions)\n",
    "    else:\n",
    "        # Choose the action with the highest Q-value\n",
    "        Q_values = model.predict(state[np.newaxis])[0]\n",
    "        action = np.argmax(Q_values)\n",
    "    return action\n",
    "\n",
    "def reward_fn(action, true_label, predicted_label, lambda_val=0.1):\n",
    "    # Initialize terminal flag\n",
    "    terminal = 0\n",
    "    # Fraud class\n",
    "    if true_label == 1:\n",
    "        if action == true_label:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "            terminal = 1\n",
    "    # Not fraud class\n",
    "    else:\n",
    "        if action == true_label:\n",
    "            reward = lambda_val\n",
    "        else:\n",
    "            reward = -lambda_val\n",
    "    return reward, terminal\n",
    "\n",
    "# Define function for computing loss\n",
    "def compute_loss(y, Q_values):\n",
    "    return tf.reduce_mean(tf.square(y - Q_values))\n",
    "\n",
    "# Start training\n",
    "for episode in range(num_episodes):\n",
    "    # Shuffle training data\n",
    "    np.random.shuffle(D)\n",
    "    print(\"Episode \", episode)\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    # Initialize state\n",
    "    state = hidden_layer_output_train_med[0]\n",
    "    \n",
    "    # Reshape the state array to match the expected size\n",
    "    #state = np.reshape(state, (batch_size, num_features))\n",
    "    \n",
    "    #state = np.stack(states, axis=0)\n",
    "    #state = np.array(state)\n",
    "    #state = np.reshape(state, (batch_size, num_features))\n",
    "    \n",
    "    # Start episode\n",
    "    for step in range(max_steps):\n",
    "        # Choose action\n",
    "        action = epsilon_greedy_policy(state, epsilon, model)\n",
    "        \n",
    "        # Get true label\n",
    "        true_label = D[step][1]\n",
    "        \n",
    "        # Predict label\n",
    "        predicted_label = action\n",
    "        \n",
    "        # Get next state\n",
    "        next_state = hidden_layer_output_train_med[step+1] if step < max_steps - 1 else state\n",
    "        \n",
    "        # Calculate reward and terminal flag\n",
    "        reward, terminal = reward_fn(action, true_label, predicted_label)\n",
    "        \n",
    "        print(\"Step:\", step)\n",
    "        print(\"True label is\", true_label, \". Agent has predicted:\", predicted_label)\n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"\")\n",
    "        \n",
    "        # Update counters for precision and accuracy\n",
    "        if true_label == 1:\n",
    "            if predicted_label == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if predicted_label == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        \n",
    "\n",
    "        # Store experience in memory\n",
    "        replay_memory.append((state, action, reward, next_state, terminal))\n",
    "\n",
    "        # Sample a batch of experiences from memory\n",
    "        if len(replay_memory) >= batch_size:\n",
    "            batch = random.sample(replay_memory, batch_size)\n",
    "            states, actions, rewards, next_states, terminals = zip(*batch)\n",
    "\n",
    "            # Convert actions tuple into numpy array\n",
    "            actions = np.array(actions)\n",
    "\n",
    "            # Compute target Q-values\n",
    "            target_Q_values = []\n",
    "            for i in range(batch_size):\n",
    "                if terminals[i]:\n",
    "                    target_Q_values.append(rewards[i])\n",
    "                else:\n",
    "                    next_Q_values = Q(next_states[i], theta)\n",
    "                    target_Q_values.append(rewards[i] + gamma * np.max(next_Q_values))\n",
    "\n",
    "            # Compute predicted Q-values and loss\n",
    "            predicted_Q_values = Q(states, theta)[np.arange(batch_size), actions.astype(int)]\n",
    "            loss = compute_loss(target_Q_values, predicted_Q_values)\n",
    "\n",
    "            # Compute gradients\n",
    "            grad = np.gradient(loss, theta.T, axis=1)\n",
    "\n",
    "            # Reshape gradients to match the shape of theta\n",
    "            grad = grad.reshape(theta.shape)\n",
    "\n",
    "            # Update parameters using gradient descent\n",
    "            theta -= grad * learning_rate\n",
    "        \n",
    "      \n",
    "        # Update state\n",
    "        state = next_state\n",
    "        \n",
    "        # Check if episode is finished\n",
    "        if terminal==1:\n",
    "            break\n",
    "            \n",
    "# Calculate precision and accuracy\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
