{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36751d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bd0f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6224bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder from Sklearn\n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['type'])\n",
    "# printing label\n",
    "label\n",
    "# removing the column 'type' from df\n",
    "# as it is of no use now.\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "# Appending the array to our dataFrame\n",
    "# with column name 'type'\n",
    "df[\"type\"] = label\n",
    "# printing Dataframe\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a48f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameDest'])\n",
    "label\n",
    "df.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df[\"nameDest\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ad34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameOrig'])\n",
    "label\n",
    "df.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df[\"nameOrig\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee6b35d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.99871\n",
      "1    0.00129\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=18)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffcc877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in X_train: 5726358\n",
      "Number of rows in X_test: 636262\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in X_train:\", X_train.shape[0])\n",
    "print(\"Number of rows in X_test:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6393636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5726358,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed (20)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.14, 'oldbalanceOrg': 0.24, 'newbalanceOrig': 0.25, 'oldbalanceDest': 0.22, 'newbalanceDest': 0.22}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train.index, size=len(X_train), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train.loc[X_train[col_name] > np.percentile(X_train[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "\n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float64 columns to float32\n",
    "float64_cols = df.select_dtypes(include=['float64']).columns\n",
    "df[float64_cols] = df[float64_cols].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f76bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e69302",
   "metadata": {},
   "source": [
    "## FS Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Select top features using Random Forest\n",
    "rf = RandomForestClassifier(random_state=18)\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_features = X_train.columns[indices][:5]  # select top 5 features\n",
    "print(top_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e48f0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>step</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402687</th>\n",
       "      <td>323930.00</td>\n",
       "      <td>139</td>\n",
       "      <td>500046.97</td>\n",
       "      <td>2080.00</td>\n",
       "      <td>176116.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760752</th>\n",
       "      <td>97668.37</td>\n",
       "      <td>213</td>\n",
       "      <td>657536.54</td>\n",
       "      <td>5854688.09</td>\n",
       "      <td>559868.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594236</th>\n",
       "      <td>0.00</td>\n",
       "      <td>262</td>\n",
       "      <td>0.00</td>\n",
       "      <td>274516.76</td>\n",
       "      <td>8622.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933631</th>\n",
       "      <td>0.00</td>\n",
       "      <td>177</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70800.94</td>\n",
       "      <td>30724.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227203</th>\n",
       "      <td>4123295.63</td>\n",
       "      <td>186</td>\n",
       "      <td>3308021.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>815273.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753638</th>\n",
       "      <td>0.00</td>\n",
       "      <td>279</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1305.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532557</th>\n",
       "      <td>0.00</td>\n",
       "      <td>154</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1235072.75</td>\n",
       "      <td>26853.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800777</th>\n",
       "      <td>0.00</td>\n",
       "      <td>217</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12915.80</td>\n",
       "      <td>28641.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444235</th>\n",
       "      <td>0.00</td>\n",
       "      <td>203</td>\n",
       "      <td>0.00</td>\n",
       "      <td>271067.00</td>\n",
       "      <td>10589.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935763</th>\n",
       "      <td>4673794.76</td>\n",
       "      <td>177</td>\n",
       "      <td>4739241.21</td>\n",
       "      <td>1263913.98</td>\n",
       "      <td>65446.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636262 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         newbalanceDest  step  oldbalanceDest  oldbalanceOrg     amount\n",
       "1402687       323930.00   139       500046.97        2080.00  176116.97\n",
       "2760752        97668.37   213       657536.54     5854688.09  559868.17\n",
       "3594236            0.00   262            0.00      274516.76    8622.10\n",
       "1933631            0.00   177            0.00       70800.94   30724.62\n",
       "2227203      4123295.63   186      3308021.94           0.00  815273.69\n",
       "...                 ...   ...             ...            ...        ...\n",
       "3753638            0.00   279            0.00           0.00    1305.97\n",
       "1532557            0.00   154            0.00     1235072.75   26853.36\n",
       "2800777            0.00   217            0.00       12915.80   28641.92\n",
       "2444235            0.00   203            0.00      271067.00   10589.28\n",
       "1935763      4673794.76   177      4739241.21     1263913.98   65446.45\n",
       "\n",
       "[636262 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d7ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # Plot feature importances\n",
    "# plt.figure(figsize=(7, 5))\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(len(indices)), importances[indices])\n",
    "# plt.xticks(range(len(indices)), X_train.columns[indices], rotation=90)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset X_train to include only selected features\n",
    "X_train_selected = X_train[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7145fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "index_of_b = df.columns.get_loc('newbalanceDest')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58b44f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "index_of_b = df.columns.get_loc('step')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "178bee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "index_of_b = df.columns.get_loc('oldbalanceOrg')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1be97b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "index_of_b = df.columns.get_loc('amount')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c46f487c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "index_of_b = df.columns.get_loc('oldbalanceDest')\n",
    "print(index_of_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract same features in test set,select the columns by index\n",
    "selected_indices = [5,0,2,4,1]\n",
    "X_test_selected = X_test.iloc[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebeaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40b288",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b47e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "# Define your hyperparameter search space\n",
    "param_dist = { \n",
    "    'n_estimators': sp_randint(100, 300),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : sp_randint(3,5),\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bdb45fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 20\n",
      "max_resources_: 100\n",
      "aggressive_elimination: True\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 5\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 3\n",
      "n_resources: 40\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 2\n",
      "n_resources: 80\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingRandomSearchCV(aggressive_elimination=True,\n",
       "                      estimator=RandomForestClassifier(random_state=18),\n",
       "                      factor=2, max_resources=100,\n",
       "                      param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                           'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001DFC7F2A3C8>,\n",
       "                                           'max_features': ['sqrt', 'log2'],\n",
       "                                           'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001DF9A64D788>},\n",
       "                      random_state=18, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # Required to enable HalvingRandomSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "# Set up the HalvingRandomSearchCV with aggressive early stopping\n",
    "search = HalvingRandomSearchCV(rf, param_dist, cv=5,verbose=1, \n",
    "                               factor=2, resource='n_samples', max_resources=100, \n",
    "                               aggressive_elimination=True, random_state=18, \n",
    "                               scoring='accuracy', refit=True)\n",
    "\n",
    "# Fit the HalvingRandomSearchCV object to the data\n",
    "search.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "095785e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and evaluate on the test set\n",
    "best_params = search.best_params_\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0752d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6b699f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 290}\n",
      "Test set accuracy: 0.9987112227352883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853b65f",
   "metadata": {},
   "source": [
    "## Use cost sensitive learning random forest with the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd46bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# Create lists to store evaluation metrics for each fold\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Initialize lists to store OOB error rates and number of trees\n",
    "oob_error_rates = []\n",
    "n_trees = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63048398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over each fold\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "#     print(f'Fold: {fold+1}')\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "#     X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "#     # Train a random forest model with different number of trees\n",
    "#     for n in range(10, 301, 10):\n",
    "#         class_weight = {0: 1, 1: 7714}\n",
    "#         rf_model = RandomForestClassifier(n_estimators=n, max_features='log2', max_depth=4,\n",
    "#                                        class_weight=class_weight, oob_score=True, random_state=18, criterion=\"entropy\")\n",
    "\n",
    "#         # Fit the model on the training data\n",
    "#         rf_model.fit(X_train, y_train)\n",
    "\n",
    "#         # Predict the class labels for the validation set\n",
    "#         y_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "#         # Compute the evaluation metrics for the current fold\n",
    "#         conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "#         recall = recall_score(y_val, y_val_pred)\n",
    "#         accuracy = accuracy_score(y_val, y_val_pred)\n",
    "#         precision = precision_score(y_val, y_val_pred)\n",
    "#         f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "#         # Compute the probabilities of each class for the validation set\n",
    "#         y_val_prob = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#         # Compute the false positive rate, true positive rate, and area under the ROC curve\n",
    "#         fpr, tpr, _ = roc_curve(y_val, y_val_prob)\n",
    "#         roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#         # Append the evaluation metrics for the current fold to the lists\n",
    "#         f1_scores.append(f1)\n",
    "#         recall_scores.append(recall)\n",
    "#         precision_scores.append(precision)\n",
    "#         accuracy_scores.append(accuracy)\n",
    "#         roc_auc_scores.append(roc_auc)\n",
    "\n",
    "#         # Print the evaluation metrics for the current fold\n",
    "#         print(f'Number of trees: {n}')\n",
    "#         print('Confusion matrix:\\n', conf_mat)\n",
    "#         print('Recall:', recall)\n",
    "#         print('Accuracy:', accuracy)\n",
    "#         print('Precision:', precision)\n",
    "#         print('F1-score:', f1)\n",
    "#         print('AUC-ROC:', roc_auc)\n",
    "#         print('OOB error rate:', 1 - rf_model.oob_score_)\n",
    "#         print('---------------------')\n",
    "\n",
    "#         # Append the OOB error rate and number of trees to the lists\n",
    "#         oob_error_rates.append(1 - rf_model.oob_score_)\n",
    "#         n_trees.append(n)\n",
    "    \n",
    "# # Compute the mean and standard deviation of the evaluation metrics over all the folds\n",
    "# mean_f1 = np.mean(f1_scores)\n",
    "# std_f1 = np.std(f1_scores)\n",
    "# mean_recall = np.mean(recall_scores)\n",
    "# std_recall = np.std(recall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9103d635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5726358, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6bde7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5090096,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43ac24a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5726358, 5090096]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10944\\382643182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Iterate over each fold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Fold: {fold+1}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \"\"\"\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    332\u001b[0m         raise ValueError(\n\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         )\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5726358, 5090096]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# Create lists to store evaluation metrics for each fold\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_selected, y_train)):\n",
    "    print(f'Fold: {fold+1}')\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "#     X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "#     X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    X_train, y_train = X_train_selected.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train_selected.iloc[val_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    # Train a random forest model with 100 trees and a max depth of 4\n",
    "    #6355400/8213\n",
    "    class_weight = {0: 1, 1: 7714}\n",
    "    rf_model = RandomForestClassifier(n_estimators=290, max_features='log2', max_depth=4,\n",
    "                                   class_weight=class_weight, oob_score=True, random_state=18, criterion=\"entropy\")\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the class labels for the validation set\n",
    "    y_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "    # Compute the evaluation metrics for the current fold\n",
    "    conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    # Compute the probabilities of each class for the validation set\n",
    "    y_val_prob = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Compute the false positive rate, true positive rate, and area under the ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_val_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Append the evaluation metrics for the current fold to the lists\n",
    "    f1_scores.append(f1)\n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    # Print the evaluation metrics for the current fold\n",
    "    print('Confusion matrix:\\n', conf_mat)\n",
    "    print('Recall:', recall)\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('F1-score:', f1)\n",
    "    print('AUC-ROC:', roc_auc)\n",
    "    print('---------------------')\n",
    "\n",
    "    # Plot the ROC curve for the current fold\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Fold %d)' % (fold+1))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "# Compute the mean and standard deviation of the evaluation metrics over all the folds\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "mean_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83218870",
   "metadata": {},
   "source": [
    "Cost sensitive learning\n",
    "Use correct hyperparameter\n",
    "plot OOB error for every fold\n",
    "plot f1 score for train & test : https://www.bing.com/images/search?view=detailV2&ccid=7RhAWIsn&id=EFDAEB69AA4818AB3C9475F012C996C507736D0B&thid=OIP.7RhAWIsn6RONqcOdAR6t6gHaHJ&mediaurl=https%3A%2F%2Fcdn.analyticsvidhya.com%2Fwp-content%2Fuploads%2F2020%2F03%2FScreenshot-2020-03-04-at-15.08.50-850x820.png&cdnurl=https%3A%2F%2Fth.bing.com%2Fth%2Fid%2FR.ed1840588b27e9138da9c39d011eadea%3Frik%3DC21zB8WWyRLwdQ%26pid%3DImgRaw%26r%3D0&exph=820&expw=850&q=graphs+for+random+forest&simid=608001867482224477&form=IRPRST&ck=ACE74CE8E33F1BDCD8DFF63221C79789&selectedindex=9&ajaxhist=0&ajaxserp=0&vt=0&sim=11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8163f5",
   "metadata": {},
   "source": [
    "out-of-sample testing\" or \"model validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c87c2",
   "metadata": {},
   "source": [
    "https://www.bing.com/images/search?view=detailV2&ccid=HiBreHJ1&id=4AE90CD5515EF4A6E50E9C0688ACB5FE7C375F42&thid=OIP.HiBreHJ1b7h-1uQEgXJDfQHaFB&mediaurl=https%3A%2F%2Fmiro.medium.com%2Fmax%2F552%2F1*80OL6-Nn2oYwQPcS3aO3jg.png&exph=374&expw=552&q=graphs+for+random+forest&simid=608008151010657800&form=IRPRST&ck=18435DC859CC9886473DD5FB88D029A8&selectedindex=29&ajaxhist=0&ajaxserp=0&vt=0&sim=11&cdnurl=https%3A%2F%2Fth.bing.com%2Fth%2Fid%2FR.1e206b7872756fb87ed6e4048172437d%3Frik%3DQl83fP61rIgGnA%26pid%3DImgRaw%26r%3D0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
