{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2bbe5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca576dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd44e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6354407\n",
      "1       8213\n",
      "Name: isFraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Count the number of 0s and 1s in the 'isFraud' column\n",
    "fraud_counts = df['isFraud'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(fraud_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2625d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['type'])\n",
    "label\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "df[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameDest'])\n",
    "label\n",
    "df.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameOrig'])\n",
    "label\n",
    "df.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2faee02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac3de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.55, random_state=0)\n",
    "\n",
    "# Fit and apply the resampler to the entire dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "950d74b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6354407\n",
      "1    3494923\n",
      "Name: isFraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = y_resampled.value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0094790",
   "metadata": {},
   "source": [
    "## Reservoir sampling without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3833542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "# number of data points to sample from original dataset\n",
    "k= 1500000\n",
    "\n",
    "def reservoir_sampling(iterable, k, header=True):\n",
    "    reservoir = []\n",
    "    for i, item in enumerate(iterable):\n",
    "        if i < k:\n",
    "            reservoir.append(item)\n",
    "        else:\n",
    "            j = random.randint(0, i)\n",
    "            if j < k:\n",
    "                reservoir[j] = item\n",
    "    return reservoir\n",
    "\n",
    "# Open the input CSV file\n",
    "with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\") as f:\n",
    "    # Check if header line exists\n",
    "    header = True\n",
    "    first_line = f.readline()\n",
    "    if not first_line.startswith('step,type,amount,nameOrig,oldbalanceOrg,newbalanceOrig,nameDest,oldbalanceDest,newbalanceDest,isFraud,isFlaggedFraud'):\n",
    "        header = False\n",
    "        f.seek(0)  # Rewind file pointer to beginning\n",
    "\n",
    "    # Sample from remaining lines\n",
    "    sampled_lines = []\n",
    "    for i, line in enumerate(f):\n",
    "        if i < k:\n",
    "            sampled_lines.append(line)\n",
    "        else:\n",
    "            j = random.randint(0, i)\n",
    "            if j < k:\n",
    "                sampled_lines[j] = line\n",
    "\n",
    "# Open the output CSV file and write the subsample to it\n",
    "with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\transfer_learning.csv\", mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    if header:\n",
    "        writer.writerow(first_line.strip().split(','))\n",
    "    for line in sampled_lines:\n",
    "        writer.writerow(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329a5aa",
   "metadata": {},
   "source": [
    "## Pre-process larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed453d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_big=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\transfer_learning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "846a5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample_big['type'])\n",
    "label\n",
    "df_sample_big.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample_big[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample_big['nameDest'])\n",
    "label\n",
    "df_sample_big.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample_big[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample_big['nameOrig'])\n",
    "label\n",
    "df_sample_big.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample_big[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4fdb235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998721\n",
      "1    0.001279\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.645161\n",
      "1    0.354839\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.645162\n",
      "1    0.354838\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample_big.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample_big['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.1, stratify=y_resampled, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865f7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# #Upsampling via SMOTE\n",
    "# smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "# #Downsample via RandomUnderSampler\n",
    "# rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "# #Application of the resampling methods\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "# X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a30f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1a4de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e882ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8027782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step         amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0         259  218858.310000       0.000000             0.0     5170.999621   \n",
      "1         144    9664.660000     135.000000             0.0        0.000000   \n",
      "2         212    3535.920000  101588.000000             0.0        0.000000   \n",
      "3         284   18362.990000   25965.350000             0.0     5170.999621   \n",
      "4         349  137308.300000       0.000000             0.0     5170.999621   \n",
      "...       ...            ...            ...             ...             ...   \n",
      "8826762    93  137308.300000   62800.000000             0.0     5170.999621   \n",
      "8826763   285  137308.300000   62800.000000             0.0       32.745541   \n",
      "8826764   327  137308.300000   62800.000000             0.0     5170.999621   \n",
      "8826765   323  100140.215276  100140.215276             0.0        0.000000   \n",
      "8826766   409  165893.714023  165893.714023             0.0        0.000000   \n",
      "\n",
      "         newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "0             147696.51               0     1     60278    392431  \n",
      "1                  0.00               0     3    363394   4689675  \n",
      "2                  0.00               0     3    363394   6273104  \n",
      "3             454376.74               0     1    219987   3794825  \n",
      "4             147696.51               0     1     74881   4634690  \n",
      "...                 ...             ...   ...       ...       ...  \n",
      "8826762       147696.51               0     1    512921   4287954  \n",
      "8826763       147696.51               0     1    172487   4600375  \n",
      "8826764       147696.51               0     1    398384   6175542  \n",
      "8826765            0.00               0     1    520687   4995382  \n",
      "8826766            0.00               0     1    259919   5022268  \n",
      "\n",
      "[8826767 rows x 10 columns]\n",
      "         step         amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "2360459   190   21833.020000   92575.000000             0.0        0.000000   \n",
      "8700837   279  137045.460000   62889.650000             0.0     6164.889532   \n",
      "521794     20  129859.140000   61526.000000             0.0        0.000000   \n",
      "4379310   311    9871.080000   32601.000000             0.0        0.000000   \n",
      "4114157   302  238620.050000   62889.650000             0.0     6164.889532   \n",
      "...       ...            ...            ...             ...             ...   \n",
      "2373669   191    6478.050000       0.000000             0.0        0.000000   \n",
      "7789754   482  172469.674581  172469.674581             0.0        0.000000   \n",
      "8995101   470  137045.460000   62889.650000             0.0        0.000000   \n",
      "1976688   178  137045.460000       0.000000             0.0     6164.889532   \n",
      "6974382   371  239589.729651   62889.650000             0.0     6164.889532   \n",
      "\n",
      "         newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "2360459        0.000000               0     3    362801   2819095  \n",
      "8700837   150045.630000               0     1    398262   5440294  \n",
      "521794    129859.140000               0     1    389130    389004  \n",
      "4379310        0.000000               0     3    362801   2437025  \n",
      "4114157   150045.630000               0     0    305716   5493566  \n",
      "...                 ...             ...   ...       ...       ...  \n",
      "2373669        0.000000               0     3    362801   2471315  \n",
      "7789754        0.000000               0     1    112757   5355854  \n",
      "8995101        0.000000               0     1    310868   4216750  \n",
      "1976688   150045.630000               0     1    190848   5951678  \n",
      "6974382   380421.008028               0     1    419322   1373766  \n",
      "\n",
      "[984933 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# convert X_test to a pandas dataframe\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "# define a function to replace outliers with MAD for a single column\n",
    "def replace_outliers_with_mad(column):\n",
    "    median = np.median(column)\n",
    "    mad = np.median(np.abs(column - median))\n",
    "    threshold = 2.5 * mad\n",
    "    column[np.abs(column - median) > threshold] = median\n",
    "    return column\n",
    "\n",
    "# apply the function to all columns of X_train_resampled_final\n",
    "for i in range(X_train_resampled_final.shape[1]):\n",
    "    X_train_resampled_final.iloc[:, i] = replace_outliers_with_mad(X_train_resampled_final.iloc[:, i])\n",
    "\n",
    "# apply the function to all columns of X_test\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test.iloc[:, i] = replace_outliers_with_mad(X_test.iloc[:, i])\n",
    "\n",
    "# convert the numpy arrays back to pandas dataframes\n",
    "X_train_resampled_final = pd.DataFrame(X_train_resampled_final, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "\n",
    "# print the modified dataframes\n",
    "print(X_train_resampled_final)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # fit scaler on training data\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train_resampled_final)\n",
    "\n",
    "# # transform training data\n",
    "# X_train_resampled_final = scaler.transform(X_train_resampled_final)\n",
    "\n",
    "# # transform validation and test data using the same scaler\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca43564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd34545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da522fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_big = df_sample_big.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1c38e",
   "metadata": {},
   "source": [
    "### Big dataset: Pre-train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85e93208",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([      0,       4,       5,       6,       8,       9,      10,\\n                 11,      13,      16,\\n            ...\\n            8826745, 8826748, 8826749, 8826750, 8826751, 8826752, 8826756,\\n            8826761, 8826763, 8826764],\\n           dtype='int64', length=4413383)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9820\\2744889748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# train model for each fold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     history = pre_trained_model.fit(X_train_resampled_final[train], y_train_resampled_final[train],\n\u001b[0m\u001b[0;32m     64\u001b[0m                                      epochs=4, batch_size=32, validation_data=(X_train_resampled_final[val], y_train_resampled_final[val]))\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([      0,       4,       5,       6,       8,       9,      10,\\n                 11,      13,      16,\\n            ...\\n            8826745, 8826748, 8826749, 8826750, 8826751, 8826752, 8826756,\\n            8826761, 8826763, 8826764],\\n           dtype='int64', length=4413383)] are in the [columns]\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e627288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6912b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = model.layers[0]\n",
    "batch_layer = model.layers[1]\n",
    "conv2_layer = model.layers[2]\n",
    "batch2_layer = model.layers[3]\n",
    "maxpooling_layer = model.layers[4]\n",
    "flatten_layer = model.layers[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f73a8",
   "metadata": {},
   "source": [
    "## Go back to smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac218053",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.55, random_state=0)\n",
    "\n",
    "# Fit and apply the resampler to the entire dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036edbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled,  y_resampled, test_size=0.1, stratify= y_resampled, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbaa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2bdbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29beb78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# convert X_test to a pandas dataframe\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "# define a function to replace outliers with MAD for a single column\n",
    "def replace_outliers_with_mad(column):\n",
    "    median = np.median(column)\n",
    "    mad = np.median(np.abs(column - median))\n",
    "    threshold = 2.5 * mad\n",
    "    column[np.abs(column - median) > threshold] = median\n",
    "    return column\n",
    "\n",
    "# apply the function to all columns of X_train_resampled_final\n",
    "for i in range(X_train_resampled_final.shape[1]):\n",
    "     X_train_resampled_final.iloc[:, i] = replace_outliers_with_mad(X_train_resampled_final.iloc[:, i])\n",
    "   # X_train_resampled_final[:, i] = replace_outliers_with_mad(X_train_resampled_final[:, i])\n",
    "\n",
    "# apply the function to all columns of X_test\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test.iloc[:, i] = replace_outliers_with_mad(X_test.iloc[:, i])\n",
    "\n",
    "# convert the numpy arrays back to pandas dataframes\n",
    "X_train_resampled_final = pd.DataFrame(X_train_resampled_final, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "\n",
    "# print the modified dataframes\n",
    "print(X_train_resampled_final)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import module\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # compute required values\n",
    "# scaler = StandardScaler()\n",
    "# model = scaler.fit(X_train_resampled_final)\n",
    "# X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute required values\n",
    "# scaler = StandardScaler()\n",
    "# model = scaler.fit(X_test)\n",
    "# X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5908adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.keras.layers import Reshape, LSTM, Dense, TimeDistributed, Conv1D, BatchNormalization, MaxPooling1D, Flatten\n",
    "\n",
    "encoding_dim = 6\n",
    "num_features = 10 # number of input variables\n",
    "\n",
    "# Define the autoencoder to encode each feature\n",
    "input_shape = (10,)  # N is the number of input features\n",
    "\n",
    "encoder = tf.keras.layers.Dense(units=10, activation='elu', input_shape=input_shape)\n",
    "first_hidden_layer = tf.keras.layers.Dense(units=encoding_dim, activation='elu')\n",
    "decoder = tf.keras.layers.Dense(units=10, activation='sigmoid')\n",
    "\n",
    "autoencoder = tf.keras.Sequential([encoder, first_hidden_layer, decoder])\n",
    "\n",
    "# Load the pre-trained CNN\n",
    "CNN = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Freeze all trainable layers in CNN\n",
    "CNN.trainable = False\n",
    "\n",
    "V = np.zeros((num_features, encoding_dim))\n",
    "\n",
    "# 1st for loop: Encoding\n",
    "for i in range(num_features):\n",
    "    V[i] = autoencoder.predict(X_train_resampled_final[i:i+1])[0][0:encoding_dim]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Reshape the input data to match the expected input shape of the CNN model\n",
    "V = np.reshape(V, (1, 1, num_features, encoding_dim))\n",
    "V = np.transpose(V, (0, 1, 3, 2))\n",
    "V = np.reshape(V, (1, -1, num_features, 1))\n",
    "\n",
    "# Pass the input data to the pre-trained CNN model\n",
    "C = CNN(V)\n",
    "\n",
    "# Reshape the output of the CNN layer to match the expected input shape of the LSTM layer\n",
    "C = np.reshape(C, (1, C.shape[1], C.shape[2]))\n",
    "\n",
    "# Add the LSTM layers to the model\n",
    "LSTM_model = tf.keras.Sequential()\n",
    "LSTM1 = LSTM(units=128, return_sequences=True, input_shape=(None, num_features*encoding_dim+1))\n",
    "LSTM_model.add(LSTM1)\n",
    "\n",
    "# Add a fully connected layer\n",
    "LSTM_model.add(Dense(units=20, activation='tanh', kernel_regularizer=l1(0.00114)))\n",
    "\n",
    "# Add a dropout layer\n",
    "LSTM_model.add(tf.keras.layers.Dropout(0.1))\n",
    "\n",
    "# Add the output layer\n",
    "LSTM_model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.0015\n",
    "\n",
    "# Create the Adam optimizer with the defined learning rate\n",
    "opt_LSTM = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compile the model\n",
    "LSTM_model.compile(optimizer=opt_LSTM, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909ea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(LSTM_model, to_file='LSTM_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc356f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f058c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, MaxPooling1D, Flatten, LSTM, Concatenate, TimeDistributed, Dense\n",
    "\n",
    "# cnn_input = Input(shape=(None, 10, 1))\n",
    "# cnn_layer = TimeDistributed(Conv1D(64, kernel_size=3, activation='relu'))(cnn_input)\n",
    "# cnn_layer = TimeDistributed(BatchNormalization())(cnn_layer)\n",
    "# cnn_layer = TimeDistributed(Conv1D(64, kernel_size=3, activation='relu'))(cnn_layer)\n",
    "# cnn_layer = TimeDistributed(BatchNormalization())(cnn_layer)\n",
    "# cnn_layer = TimeDistributed(MaxPooling1D(pool_size=2))(cnn_layer)\n",
    "# cnn_layer = TimeDistributed(Flatten())(cnn_layer)\n",
    "\n",
    "# # lstm_input = Input(shape=(None, num_features*encoding_dim+1))\n",
    "# lstm_layer = LSTM(units=128, return_sequences=True)(cnn_layer)\n",
    "\n",
    "# concat_layer = Concatenate()([cnn_layer, lstm_layer])\n",
    "# dense_layer = Dense(64)(concat_layer)\n",
    "# output_layer = Dense(1)(dense_layer)\n",
    "\n",
    "# model = Model(inputs=[cnn_input, lstm_input], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = model.layers[0]\n",
    "batch_layer = model.layers[1]\n",
    "conv2_layer = model.layers[2]\n",
    "batch2_layer = model.layers[3]\n",
    "maxpooling_layer = model.layers[4]\n",
    "flatten_layer = model.layers[5]\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "# cnn_input = Input(shape=(None, 10, 1))\n",
    "# cnn_layer = TimeDistributed(Conv1D(64, kernel_size=3, activation='relu'))(cnn_input)\n",
    "# cnn_layer = TimeDistributed(BatchNormalization())(cnn_layer)\n",
    "# cnn_layer = TimeDistributed(Conv1D(64, kernel_size=3, activation='relu'))(cnn_layer)\n",
    "# cnn_layer = TimeDistributed(BatchNormalization())(cnn_layer)\n",
    "# cnn_layer = TimeDistributed(MaxPooling1D(pool_size=2))(cnn_layer)\n",
    "# cnn_layer = TimeDistributed(Flatten())(cnn_layer)\n",
    "\n",
    "reshape_layer = Reshape((-1, flatten_layer.output_shape[-1]))(flatten_layer.output)\n",
    "lstm_layer = LSTM(64)(reshape_layer)\n",
    "dense_layer = Dense(32, activation='relu')(lstm_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "new_model = Model(inputs=model.inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760134dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.0015\n",
    "\n",
    "# Create the Adam optimizer with the defined learning rate\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "# Compile the model\n",
    "new_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "new_model.fit(X_train_resampled_final, y_train_resampled_final, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c808e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(new_model, to_file='new_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b043f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Define the learning rate\n",
    "# learning_rate = 0.0015\n",
    "\n",
    "# # Create the Adam optimizer with the defined learning rate\n",
    "# optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "# # Compile the model\n",
    "# new_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# # Fit the model\n",
    "# new_model.fit([X_cnn_input, X_lstm_input], y_train_resampled_final, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c1865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# # Get predictions on X_test\n",
    "# y_pred = new_model.predict([X_test_cnn_input, X_test_lstm_input])\n",
    "\n",
    "# # Convert probabilities to binary predictions\n",
    "# y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# f1 = f1_score(y_test, y_pred_binary)\n",
    "# precision = precision_score(y_test, y_pred_binary)\n",
    "# recall = recall_score(y_test, y_pred_binary)\n",
    "\n",
    "# print('F1 score:', f1)\n",
    "# print('Precision:', precision)\n",
    "# print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cnn_input = np.expand_dims(X_test, axis=2) # shape: (None, 10, 1)\n",
    "X_test_lstm_input = np.expand_dims(X_test, axis=1) # shape: (None, 1, 10)\n",
    "X_test_lstm_input = np.repeat(X_test_lstm_input, 61, axis=1) # shape: (None, 61, 10)\n",
    "\n",
    "y_pred = new_model.predict([X_test_cnn_input, X_test_lstm_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cnn_input = np.expand_dims(X_test, axis=2) # shape: (None, 10, 1)\n",
    "X_test_lstm_input = np.expand_dims(X_test, axis=1) # shape: (None, 1, 10)\n",
    "X_test_lstm_input = np.transpose(X_test_lstm_input, (0, 2, 1)) # shape: (None, 10, 1)\n",
    "X_test_lstm_input = np.repeat(X_test_lstm_input, 61, axis=2) # shape: (None, 10, 61)\n",
    "\n",
    "y_pred = new_model.predict([X_test_cnn_input, X_test_lstm_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Generate predicted probabilities for the test set\n",
    "# y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# # Compute ROC curve and ROC area for each class\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# # Plot ROC curve\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
