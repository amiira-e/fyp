{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96fe4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77aebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dbbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import random\n",
    "\n",
    "# def reservoir_sampling(iterable, k, header=True):\n",
    "#     reservoir = []\n",
    "#     for i, item in enumerate(iterable):\n",
    "#         if i < k:\n",
    "#             reservoir.append(item)\n",
    "#         else:\n",
    "#             j = random.randint(0, i)\n",
    "#             if j < k:\n",
    "#                 reservoir[j] = item\n",
    "#     return reservoir\n",
    "\n",
    "# # Open the input CSV file\n",
    "# with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\") as f:\n",
    "#     # Check if header line exists\n",
    "#     header = True\n",
    "#     first_line = f.readline()\n",
    "#     if not first_line.startswith('step,type,amount,nameOrig,oldbalanceOrg,newbalanceOrig,nameDest,oldbalanceDest,newbalanceDest,isFraud,isFlaggedFraud'):\n",
    "#         header = False\n",
    "#         f.seek(0)  # Rewind file pointer to beginning\n",
    "\n",
    "#     # Sample from remaining lines\n",
    "#     sampled_lines = reservoir_sampling(f, k=2300000, header=header)\n",
    "\n",
    "# # Open the output CSV file and write the subsample to it\n",
    "# with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample1300000.csv\", mode='w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     if header:\n",
    "#         writer.writerow(first_line.strip().split(','))\n",
    "#     for line in sampled_lines:\n",
    "#         writer.writerow(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73182f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78004e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample1300000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a475b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0723ab28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef5a09b",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d941b41a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4668\\3758050434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Calculate the correlation matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcorr_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pearson'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Resize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Plot the correlation matrix as a heatmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mako'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df_sample.corr(method='pearson')\n",
    "plt.figure(figsize=(7,5)) # Resize\n",
    "# Plot the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, cmap='mako', center=0, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b32d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df_sample.corr(method='spearman')\n",
    "plt.figure(figsize=(7,5)) # Resize\n",
    "# Plot the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, cmap='mako', center=0, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e551a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10738b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_sample.corr()\n",
    "\n",
    "# Print correlation matrix\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009be1c",
   "metadata": {},
   "source": [
    "## Distribution shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['step','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for feature in features:\n",
    "    plt.subplot(2,3,features.index(feature)+1)\n",
    "    sns.distplot(df_sample[feature],hist=True,color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change the data type of column 'A' from float64 to float32\n",
    "# df_sample['amount'] = df_sample['amount'].astype('float32')\n",
    "# df_sample['oldbalanceOrg'] = df_sample['oldbalanceOrg'].astype('float32')\n",
    "# df_sample['oldbalanceDest'] = df_sample['oldbalanceDest'].astype('float32')\n",
    "# df_sample['newbalanceOrig'] = df_sample['newbalanceOrig'].astype('float32')\n",
    "# df_sample['newbalanceDest'] = df_sample['newbalanceDest'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3200a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample['step'] = df_sample['step'].astype('int32')\n",
    "# df_sample['isFlaggedFraud'] = df_sample['isFlaggedFraud'].astype('int32') \n",
    "# df_sample['isFraud'] = df_sample['isFraud'].astype('int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90be74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c850827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c998f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4726858",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c2c4bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80d76c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630000, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9678a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 629208\n",
      "Class 1 count: 792\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d2295ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f4d70",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9956a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8de52ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 314602\n",
      "Class 1 count: 125841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_resampled)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac687784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440443, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37071d3f",
   "metadata": {},
   "source": [
    "## Tomeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb7c5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cbe4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440435, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c22208",
   "metadata": {},
   "source": [
    "## ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "884b8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c99782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 311729\n",
      "Class 1 count: 125841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train_resampled_new)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd513977",
   "metadata": {},
   "source": [
    "## OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "540e71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7344156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 299818\n",
      "Class 1 count: 125841\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = np.bincount(y_train_resampled_final)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b69f5014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 69912\n",
      "Class 1 count: 88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_test)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8160d1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425659, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55a1be8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425659,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b64fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainPRIOR.csv\", index=False)\n",
    "#X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086706d5",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3996395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 591273.5910527289, 'oldbalanceOrg': 390920.264265064, 'newbalanceOrig': 413272.42196614644, 'oldbalanceDest': 709091.0302822829, 'newbalanceDest': 1062160.0893822953}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random.seed(0)\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.01, 'oldbalanceOrg': 0.07, 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "    # Replace the outliers in the test set with the trimmed means obtained from the train set\n",
    "    test_outliers = X_test.loc[X_test[col_name] > np.percentile(X_test[col_name], 100*(1-trim_props[col_name])), col_name]\n",
    "    X_test.loc[test_outliers.index, col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf41283",
   "metadata": {},
   "source": [
    "## New trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6edbbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "# # Specify columns with outliers\n",
    "# cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# # Specify the number of bootstrapped samples to create per column\n",
    "# num_samples = 50\n",
    "\n",
    "# # Specify the trimming proportions for each column\n",
    "# trim_props = {'amount': 0.01, 'oldbalanceOrg': (0.07, 0.03), 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# # Initialize empty dictionaries to store the trimmed means for each column\n",
    "# train_trimmed_means = {}\n",
    "\n",
    "# # Loop over the specified columns\n",
    "# for col_name in cols_with_outliers:\n",
    "    \n",
    "#     # Check if the trimming proportion for this column is a tuple with two values\n",
    "#     if isinstance(trim_props[col_name], tuple):\n",
    "#         # If so, perform asymmetric trimming for the oldbalanceOrg column\n",
    "#         if col_name == 'oldbalanceOrg':\n",
    "#             # Calculate the median of the bootstrapped sample for the training set\n",
    "#             train_median = np.median(train_sample)\n",
    "#             train_trimmed_means[col_name] = train_median\n",
    "#             # Replace the outliers in the training set with the trimmed means\n",
    "#             X_train_resampled_final.loc[(X_train_resampled_final[col_name] < train_trimmed_means[col_name]) | (X_train_resampled_final[col_name] > train_trimmed_means[col_name]), col_name] = train_median\n",
    "\n",
    "#             continue\n",
    "#         else:\n",
    "#             continue\n",
    "    \n",
    "#     # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "#     train_bootstrapped_samples = []\n",
    "#     train_trimmed_means_list = []\n",
    "    \n",
    "#     # Loop over the number of desired samples\n",
    "#     for i in range(num_samples):\n",
    "#         # Randomly select indices from the column in the training set\n",
    "#         train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "#         # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "#         train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "#         # Calculate the right and left trimmed means of the bootstrapped sample for the training set\n",
    "#         train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "#         train_left_trimmed_mean = np.mean(train_sample[train_sample >= np.percentile(train_sample, 100*trim_props[col_name])])\n",
    "#         train_trimmed_means_list.append((train_left_trimmed_mean, train_right_trimmed_mean))\n",
    "        \n",
    "#     # Calculate the mean of the left and right trimmed means for the training set and add it to the dictionary\n",
    "#     train_left_mean = np.mean([x[0] for x in train_trimmed_means_list])\n",
    "#     train_right_mean = np.mean([x[1] for x in train_trimmed_means_list])\n",
    "#     train_trimmed_means[col_name] = (train_left_mean, train_right_mean)\n",
    "\n",
    "#     # Replace the outliers in the training set with the trimmed means\n",
    "#     X_train_resampled_final.loc[(X_train_resampled_final[col_name] < train_trimmed_means[col_name][0]) | (X_train_resampled_final[col_name] > train_trimmed_means[col_name][1]), col_name] = np.mean(train_sample)\n",
    "\n",
    "# # Print the trimmed means\n",
    "# print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fadbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_resampled_final.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainPOST29.csv\", index=False)\n",
    "# #X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ebc1cc",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48406ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# assuming X_train and X_test are your training and test data matrices\n",
    "# standardize the data using the mean and std from the training set\n",
    "X_train_mean = np.mean(X_train_resampled_final, axis=0)\n",
    "X_train_std = np.std(X_train_resampled_final, axis=0)\n",
    "X_train_std[X_train_std == 0] = 1 # avoid division by zero\n",
    "X_train_std_inv = 1 / X_train_std\n",
    "\n",
    "X_train_stdized = (X_train_resampled_final - X_train_mean) * X_train_std_inv\n",
    "X_test_stdized = (X_test - X_train_mean) * X_train_std_inv\n",
    "\n",
    "# compute the covariance matrix for the training data\n",
    "cov_matrix_train = np.cov(X_train_stdized.T)\n",
    "\n",
    "# compute the eigenvectors and eigenvalues for the training data\n",
    "eig_vals_train, eig_vecs_train = np.linalg.eig(cov_matrix_train)\n",
    "\n",
    "# select the top k eigenvectors for the training data\n",
    "pca_train = PCA(n_components=3)\n",
    "X_train_pca = pca_train.fit_transform(X_train_stdized)\n",
    "\n",
    "# project the test data onto the selected eigenvectors from the training data\n",
    "X_test_pca = pca_train.transform(X_test_stdized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e03563db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = list(df_sample.columns)\n",
    "\n",
    "# # print the selected features\n",
    "# print(\"Selected features:\")\n",
    "# for i in range(pca_train.n_components_):\n",
    "#     # find the index of the maximum absolute value in the ith row of the components array\n",
    "#     idx = np.argmax(np.abs(pca_train.components_[i]))\n",
    "#     # print the name of the feature with the maximum absolute value in the ith row of the components array\n",
    "#     print(f\"PC{i+1}: {feature_names[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e0525f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04439417,  0.22377344,  0.27139249,  0.25914524,  0.48648755,\n",
       "        0.52512596,  0.00466999, -0.37658595, -0.39099414,  0.00135884])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dfa2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f8f47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "y_train_resampled_final = pd.Series(y_train_resampled_final)\n",
    "\n",
    "X_train_pca_df.reset_index(drop=True, inplace=True)\n",
    "y_train_resampled_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b023afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_df = X_test_pca_df.rename(columns={0: 'PC1', 1: 'PC2', 2: 'PC3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcdfba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.375449</td>\n",
       "      <td>-0.023833</td>\n",
       "      <td>0.207987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.663546</td>\n",
       "      <td>-0.792997</td>\n",
       "      <td>0.148118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.861861</td>\n",
       "      <td>-0.647088</td>\n",
       "      <td>0.110940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916809</td>\n",
       "      <td>0.056356</td>\n",
       "      <td>-2.033821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.243522</td>\n",
       "      <td>0.304982</td>\n",
       "      <td>1.206791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>-0.457779</td>\n",
       "      <td>-0.830555</td>\n",
       "      <td>-0.278836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>-1.845380</td>\n",
       "      <td>0.039085</td>\n",
       "      <td>0.245063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>2.236073</td>\n",
       "      <td>0.486411</td>\n",
       "      <td>-3.396285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>-1.889446</td>\n",
       "      <td>-0.195409</td>\n",
       "      <td>0.458546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>-0.235132</td>\n",
       "      <td>-1.158893</td>\n",
       "      <td>-0.196820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3\n",
       "0     -1.375449 -0.023833  0.207987\n",
       "1     -1.663546 -0.792997  0.148118\n",
       "2      0.861861 -0.647088  0.110940\n",
       "3      0.916809  0.056356 -2.033821\n",
       "4     -0.243522  0.304982  1.206791\n",
       "...         ...       ...       ...\n",
       "69995 -0.457779 -0.830555 -0.278836\n",
       "69996 -1.845380  0.039085  0.245063\n",
       "69997  2.236073  0.486411 -3.396285\n",
       "69998 -1.889446 -0.195409  0.458546\n",
       "69999 -0.235132 -1.158893 -0.196820\n",
       "\n",
       "[70000 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69a914c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df = X_train_pca_df.rename(columns={0: 'PC1', 1: 'PC2', 2: 'PC3', 3: 'PC4',4: 'PC5',5: 'PC6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd002ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PC1', 'PC2', 'PC3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17bb1639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107741</td>\n",
       "      <td>-0.901274</td>\n",
       "      <td>-0.836365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.843448</td>\n",
       "      <td>-1.541907</td>\n",
       "      <td>0.308826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.837729</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>2.996121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.139318</td>\n",
       "      <td>-0.264699</td>\n",
       "      <td>-0.155476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.828883</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.523382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425654</th>\n",
       "      <td>0.400689</td>\n",
       "      <td>0.367249</td>\n",
       "      <td>0.049057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425655</th>\n",
       "      <td>1.278766</td>\n",
       "      <td>-0.146993</td>\n",
       "      <td>0.214633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425656</th>\n",
       "      <td>-0.909458</td>\n",
       "      <td>0.232757</td>\n",
       "      <td>-0.103055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425657</th>\n",
       "      <td>-0.252597</td>\n",
       "      <td>0.047328</td>\n",
       "      <td>-0.202350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425658</th>\n",
       "      <td>0.598832</td>\n",
       "      <td>-0.912519</td>\n",
       "      <td>0.287508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425659 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       0.107741 -0.901274 -0.836365\n",
       "1       1.843448 -1.541907  0.308826\n",
       "2       2.837729  0.279582  2.996121\n",
       "3      -0.139318 -0.264699 -0.155476\n",
       "4      -1.828883  0.016160  0.523382\n",
       "...          ...       ...       ...\n",
       "425654  0.400689  0.367249  0.049057\n",
       "425655  1.278766 -0.146993  0.214633\n",
       "425656 -0.909458  0.232757 -0.103055\n",
       "425657 -0.252597  0.047328 -0.202350\n",
       "425658  0.598832 -0.912519  0.287508\n",
       "\n",
       "[425659 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eedf6f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425659, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f395d",
   "metadata": {},
   "source": [
    "## Scree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "433dbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # get the explained variance ratios\n",
    "# variance_ratio = pca_train .explained_variance_ratio_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(variance_ratio)+1), variance_ratio, 'o-', color='gray', linewidth=2)\n",
    "# plt.title('Scree Plot: Variance Explained')\n",
    "# plt.xlabel('Principal Components')\n",
    "# plt.ylabel('Proportion of Variance Explained')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d66dcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107741</td>\n",
       "      <td>-0.901274</td>\n",
       "      <td>-0.836365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.843448</td>\n",
       "      <td>-1.541907</td>\n",
       "      <td>0.308826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.837729</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>2.996121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.139318</td>\n",
       "      <td>-0.264699</td>\n",
       "      <td>-0.155476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.828883</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.523382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.670543</td>\n",
       "      <td>-0.512800</td>\n",
       "      <td>0.329313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3\n",
       "0  0.107741 -0.901274 -0.836365\n",
       "1  1.843448 -1.541907  0.308826\n",
       "2  2.837729  0.279582  2.996121\n",
       "3 -0.139318 -0.264699 -0.155476\n",
       "4 -1.828883  0.016160  0.523382\n",
       "5  0.670543 -0.512800  0.329313"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84d36774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install adjustText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f483b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # create a PCA object\n",
    "# pca = PCA()\n",
    "\n",
    "# # fit the PCA object to your data\n",
    "# pca.fit(X)\n",
    "\n",
    "# # get the eigenvalues\n",
    "# eigenvalues = pca_train.explained_variance_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(eigenvalues)+1), eigenvalues, 'bo-', linewidth=2)\n",
    "# plt.title('Scree Plot')\n",
    "# plt.xlabel('Principal Component')\n",
    "# plt.ylabel('Eigenvalue')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df6ee46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # create a PCA object\n",
    "# pca = PCA()\n",
    "\n",
    "# # fit the PCA object to your data\n",
    "# pca.fit(X)\n",
    "\n",
    "# # get the eigenvalues\n",
    "# eigenvalues = pca_train.explained_variance_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(eigenvalues)+1), eigenvalues, 'o-', color='gray', linewidth=1, markersize=5)\n",
    "# plt.axhline(y=1, linestyle='--', color='black', linewidth=1)\n",
    "# plt.title('Scree Plot: PCA Eigenvalues')\n",
    "# plt.xlabel('Principal Components')\n",
    "# plt.ylabel('Eigenvalues')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a04a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    " \n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc2fec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot circle\n",
    "# #Create a list of 500 points with equal spacing between -1 and 1\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# columns=X_train_resampled_final.columns.values #Store the name of the columns for labeling\n",
    "\n",
    "# x=np.linspace(start=-1,stop=1,num=1000)\n",
    "# #Find y1 and y2 for these points\n",
    "# y_positive=lambda x: np.sqrt(1-x**2) \n",
    "# y_negative=lambda x: -np.sqrt(1-x**2)\n",
    "# plt.plot(x,list(map(y_positive, x)), color='maroon')\n",
    "# plt.plot(x,list(map(y_negative, x)),color='maroon')\n",
    "\n",
    "# #Plot smaller circle\n",
    "# x=np.linspace(start=-0.5,stop=0.5,num=500)\n",
    "# y_positive=lambda x: np.sqrt(0.5**2-x**2) \n",
    "# y_negative=lambda x: -np.sqrt(0.5**2-x**2)\n",
    "# plt.plot(x,list(map(y_positive, x)), color='maroon')\n",
    "# plt.plot(x,list(map(y_negative, x)),color='maroon')\n",
    "\n",
    "# #Create broken lines\n",
    "# x=np.linspace(start=-1,stop=1,num=30)\n",
    "# plt.scatter(x,[0]*len(x), marker='_',color='maroon')\n",
    "# plt.scatter([0]*len(x), x, marker='|',color='maroon')\n",
    "\n",
    "# pca_values=pca.components_\n",
    "# #Define color list\n",
    "# colors = ['pink', 'green','purple', 'blue','red','black']\n",
    "# if len(pca_values[0]) > 5:\n",
    "#     colors=colors*(int(len(pca_values[0])/5)+1)\n",
    "    \n",
    "#     add_string=\"\"\n",
    "#     for i in range(6):\n",
    "#         xi=pca_values[0][i]\n",
    "#         yi=pca_values[1][i]\n",
    "#         plt.arrow(0,0, \n",
    "#                   dx=xi, dy=yi, \n",
    "#                   head_width=0.03, head_length=0.03, \n",
    "#                   color=colors[i], length_includes_head=True)\n",
    "#         add_string=f\" ({round(xi,2)} {round(yi,2)})\"\n",
    "# #         plt.text(pca_values[0, i], \n",
    "# #                  pca_values[1, i] , \n",
    "# #                  s=columns[i] + add_string,\n",
    "# #                  fontsize=5)\n",
    "#         plt.text(pca_values[0, i] + 0.0, pca_values[1, i] + 0.07, s=columns[i] + add_string, fontsize=8)\n",
    "        \n",
    "# plt.xlabel(f\"Component 1 ({round(pca_train.explained_variance_ratio_[0]*100,2)}%)\")\n",
    "# plt.ylabel(f\"Component 2 ({round(pca_train.explained_variance_ratio_[1]*100,2)}%)\")\n",
    "# plt.title('Variable factor map (PCA)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f3ce5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs = X_train_pca[:,0]\n",
    "# ys = X_train_pca[:,1]\n",
    "# scalex = 1.0/(xs.max() - xs.min())\n",
    "# scaley = 1.0/(ys.max() - ys.min())\n",
    "# fig, ax = plt.subplots(figsize=(14, 9))\n",
    " \n",
    "# for i, feature in enumerate(columns):\n",
    "#     ax.arrow(0, 0, pca_train.components_[0, i], \n",
    "#              pca_train.components_[1, i])\n",
    "#     ax.text(pca_train.components_[0, i] * 1.15, \n",
    "#             pca_train.components_[1, i] * 1.15, \n",
    "#             feature, fontsize=10)\n",
    " \n",
    "#     ax.scatter(xs * scalex,ys * scaley)\n",
    " \n",
    "#     ax.set_xlabel('PC1', fontsize=10)\n",
    "#     ax.set_ylabel('PC2', fontsize=10)\n",
    "#     ax.set_title('Biplot', fontsize=15)\n",
    "#     plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca619079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the PCA components (loadings)\n",
    "# PCs = pca.components_\n",
    "\n",
    "# # Use quiver to generate the basic plot\n",
    "# fig = plt.figure(figsize=(5,5))\n",
    "# plt.quiver(np.zeros(PCs.shape[1]), np.zeros(PCs.shape[1]),\n",
    "#            PCs[0,:], PCs[1,:], \n",
    "#            angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "# # Add labels based on feature names (here just numbers)\n",
    "# feature_names = np.arange(PCs.shape[1])\n",
    "# for i,j,z in zip(PCs[1,:]+0.02, PCs[0,:]+0.02, feature_names):\n",
    "#     plt.text(j, i, z, ha='center', va='center')\n",
    "\n",
    "# # Add unit circle\n",
    "# circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "# plt.gca().add_artist(circle)\n",
    "\n",
    "# # Ensure correct aspect ratio and axis limits\n",
    "# plt.axis('equal')\n",
    "# plt.xlim([-1.0,1.0])\n",
    "# plt.ylim([-1.0,1.0])\n",
    "\n",
    "# # Label axes\n",
    "# plt.xlabel('PC 0')\n",
    "# plt.ylabel('PC 1')\n",
    "\n",
    "# # Done\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf9ba8",
   "metadata": {},
   "source": [
    "## Linear Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b085d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.linear_model import Perceptron\n",
    "\n",
    "# # Create a Perceptron object\n",
    "# clf = Perceptron(random_state=0)\n",
    "\n",
    "# # Train the Perceptron on the data\n",
    "# clf.fit(X_train_resampled_final, y_train_resampled_final)\n",
    "\n",
    "# # Predict the output classes for the data points\n",
    "# y_pred = clf.predict(X_train_resampled_final)\n",
    "\n",
    "# # Check if the Perceptron correctly classified all the data points\n",
    "# if np.all(y_pred == y_train_resampled_final):\n",
    "#     print(\"Data is linearly separable\")\n",
    "# else:\n",
    "#     print(\"Data is not linearly separable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c228282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your DataFrame is called df and the class column is called 'class'\n",
    "# class0 = df_sample[df_sample['isFraud'] == 0]\n",
    "# class1 = df_sample[df_sample['isFraud'] == 1]\n",
    "\n",
    "# s = 5\n",
    "# plt.scatter(class0['step'], class0['oldbalanceOrg'], color='blue', label='Class 0',marker='.', s=s)\n",
    "# plt.scatter(class1['step'], class1['oldbalanceOrg'], color='red', label='Class 1',marker='.', s=s)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('oldbalanceOrg')\n",
    "# plt.title('Scatter plot of two classes')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd4792f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your DataFrame is called df and the class column is called 'class'\n",
    "# class0 = df_sample[df_sample['isFraud'] == 0]\n",
    "# class1 = df_sample[df_sample['isFraud'] == 1]\n",
    "\n",
    "# s=4\n",
    "# plt.scatter(class0['step'], class0['oldbalanceOrg'], color='blue', label='Class 0',marker='.', s=s)\n",
    "# plt.scatter(class1['step'], class1['oldbalanceOrg'], color='red', label='Class',marker='.', s=s)\n",
    "\n",
    "# # Fit a linear SVM to the data\n",
    "# from sklearn.svm import SVC\n",
    "# X_new = df_sample[['step', 'oldbalanceOrg']]\n",
    "# y_new = df_sample['isFraud']\n",
    "# svm = SVC(kernel='linear')\n",
    "# svm.fit(X_new, y_new)\n",
    "\n",
    "# # Plot the decision boundary\n",
    "# w = svm.coef_[0]\n",
    "# a = -w[0] / w[1]\n",
    "# xx = np.linspace(np.min(X_new['step']), np.max(X_new['step']))\n",
    "# yy = a * xx - svm.intercept_[0] / w[1]\n",
    "# plt.plot(xx, yy, 'k-', label='Decision boundary')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('oldbalanceOrg')\n",
    "# plt.title('Scatter plot of two classes with decision boundary')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917bc01",
   "metadata": {},
   "source": [
    "## Choose 3 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b10bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107741</td>\n",
       "      <td>-0.901274</td>\n",
       "      <td>-0.836365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.843448</td>\n",
       "      <td>-1.541907</td>\n",
       "      <td>0.308826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.837729</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>2.996121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.139318</td>\n",
       "      <td>-0.264699</td>\n",
       "      <td>-0.155476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.828883</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.523382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425654</th>\n",
       "      <td>0.400689</td>\n",
       "      <td>0.367249</td>\n",
       "      <td>0.049057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425655</th>\n",
       "      <td>1.278766</td>\n",
       "      <td>-0.146993</td>\n",
       "      <td>0.214633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425656</th>\n",
       "      <td>-0.909458</td>\n",
       "      <td>0.232757</td>\n",
       "      <td>-0.103055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425657</th>\n",
       "      <td>-0.252597</td>\n",
       "      <td>0.047328</td>\n",
       "      <td>-0.202350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425658</th>\n",
       "      <td>0.598832</td>\n",
       "      <td>-0.912519</td>\n",
       "      <td>0.287508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425659 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       0.107741 -0.901274 -0.836365\n",
       "1       1.843448 -1.541907  0.308826\n",
       "2       2.837729  0.279582  2.996121\n",
       "3      -0.139318 -0.264699 -0.155476\n",
       "4      -1.828883  0.016160  0.523382\n",
       "...          ...       ...       ...\n",
       "425654  0.400689  0.367249  0.049057\n",
       "425655  1.278766 -0.146993  0.214633\n",
       "425656 -0.909458  0.232757 -0.103055\n",
       "425657 -0.252597  0.047328 -0.202350\n",
       "425658  0.598832 -0.912519  0.287508\n",
       "\n",
       "[425659 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "193e538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_df=X_test_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2dd82f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.375449</td>\n",
       "      <td>-0.023833</td>\n",
       "      <td>0.207987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.663546</td>\n",
       "      <td>-0.792997</td>\n",
       "      <td>0.148118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.861861</td>\n",
       "      <td>-0.647088</td>\n",
       "      <td>0.110940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916809</td>\n",
       "      <td>0.056356</td>\n",
       "      <td>-2.033821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.243522</td>\n",
       "      <td>0.304982</td>\n",
       "      <td>1.206791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>-0.457779</td>\n",
       "      <td>-0.830555</td>\n",
       "      <td>-0.278836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>-1.845380</td>\n",
       "      <td>0.039085</td>\n",
       "      <td>0.245063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>2.236073</td>\n",
       "      <td>0.486411</td>\n",
       "      <td>-3.396285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>-1.889446</td>\n",
       "      <td>-0.195409</td>\n",
       "      <td>0.458546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>-0.235132</td>\n",
       "      <td>-1.158893</td>\n",
       "      <td>-0.196820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3\n",
       "0     -1.375449 -0.023833  0.207987\n",
       "1     -1.663546 -0.792997  0.148118\n",
       "2      0.861861 -0.647088  0.110940\n",
       "3      0.916809  0.056356 -2.033821\n",
       "4     -0.243522  0.304982  1.206791\n",
       "...         ...       ...       ...\n",
       "69995 -0.457779 -0.830555 -0.278836\n",
       "69996 -1.845380  0.039085  0.245063\n",
       "69997  2.236073  0.486411 -3.396285\n",
       "69998 -1.889446 -0.195409  0.458546\n",
       "69999 -0.235132 -1.158893 -0.196820\n",
       "\n",
       "[70000 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3b335c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df=X_train_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89ff3ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107741</td>\n",
       "      <td>-0.901274</td>\n",
       "      <td>-0.836365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.843448</td>\n",
       "      <td>-1.541907</td>\n",
       "      <td>0.308826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.837729</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>2.996121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.139318</td>\n",
       "      <td>-0.264699</td>\n",
       "      <td>-0.155476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.828883</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.523382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425654</th>\n",
       "      <td>0.400689</td>\n",
       "      <td>0.367249</td>\n",
       "      <td>0.049057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425655</th>\n",
       "      <td>1.278766</td>\n",
       "      <td>-0.146993</td>\n",
       "      <td>0.214633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425656</th>\n",
       "      <td>-0.909458</td>\n",
       "      <td>0.232757</td>\n",
       "      <td>-0.103055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425657</th>\n",
       "      <td>-0.252597</td>\n",
       "      <td>0.047328</td>\n",
       "      <td>-0.202350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425658</th>\n",
       "      <td>0.598832</td>\n",
       "      <td>-0.912519</td>\n",
       "      <td>0.287508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425659 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       0.107741 -0.901274 -0.836365\n",
       "1       1.843448 -1.541907  0.308826\n",
       "2       2.837729  0.279582  2.996121\n",
       "3      -0.139318 -0.264699 -0.155476\n",
       "4      -1.828883  0.016160  0.523382\n",
       "...          ...       ...       ...\n",
       "425654  0.400689  0.367249  0.049057\n",
       "425655  1.278766 -0.146993  0.214633\n",
       "425656 -0.909458  0.232757 -0.103055\n",
       "425657 -0.252597  0.047328 -0.202350\n",
       "425658  0.598832 -0.912519  0.287508\n",
       "\n",
       "[425659 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8913f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# #class_weights={0:1,0:75}\n",
    "# #rf_model = RandomForestClassifier(criterion='entropy', max_depth= 8, max_features='log2',n_estimators=251,oob_score=True)\n",
    "# #rf_model = RandomForestClassifier(ccp_alpha=0.01,criterion='gini', max_depth= 3, max_features='log2',n_estimators=100,oob_score=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "    \n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print classification report\n",
    "#     print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17904f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print confusion matrix\n",
    "#     print(f\"Confusion matrix for fold {fold}:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f8c0f",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c967dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# # Define the parameter space to search over\n",
    "# param_dist = {\n",
    "#     'n_estimators': randint(100, 400),\n",
    "#     'max_features': ['sqrt', 'log2','none'],\n",
    "#     'max_depth': [None] + list(range(5, 20, 5)),\n",
    "#     'min_samples_split': randint(2, 15),\n",
    "#     'min_samples_leaf': randint(1, 15),\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# # Initialize the Random Forest model\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# # Initialize the RandomizedSearchCV object\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     rf_model, \n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=10,  # Number of iterations to sample from the parameter space\n",
    "#     cv=3,  # Number of cross-validation folds to use\n",
    "# )\n",
    "\n",
    "# # Fit the RandomizedSearchCV object to the data\n",
    "# random_search.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Print the best hyperparameters and corresponding score\n",
    "# print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "# print(\"Best score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64bb5b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425659, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5c973",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01c5f344",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 169. GiB for an array with shape (22647985206,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4668\\860337097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Train and evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fold_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fold_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 (\n\u001b[0;32m    272\u001b[0m                     self._constrained_optimization(\n\u001b[1;32m--> 273\u001b[1;33m                         \u001b[0mobj_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m                     )\n\u001b[0;32m    275\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[1;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m                 \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m             )\n\u001b[0;32m    610\u001b[0m             \u001b[0m_check_optimize_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lbfgs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 624\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    625\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    306\u001b[0m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                                   finite_diff_rel_step=finite_diff_rel_step)\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[0mfunc_and_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun_and_grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m--> 262\u001b[1;33m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m# Gradient evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mobj_func\u001b[1;34m(theta, eval_gradient)\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                     lml, grad = self.log_marginal_likelihood(\n\u001b[1;32m--> 263\u001b[1;33m                         \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclone_kernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m                     )\n\u001b[0;32m    265\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0mlength_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_length_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1536\u001b[1;33m             \u001b[0mdists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlength_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sqeuclidean\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1537\u001b[0m             \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1538\u001b[0m             \u001b[1;31m# convert from upper-triangular matrix to square matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mpdist\u001b[1;34m(X, metric, out, **kwargs)\u001b[0m\n\u001b[0;32m   2248\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetric_info\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2249\u001b[0m             \u001b[0mpdist_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdist_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2250\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mpdist_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2251\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2252\u001b[0m             \u001b[0mmetric_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_TEST_METRICS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 169. GiB for an array with shape (22647985206,) and data type float64"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2410bd4c",
   "metadata": {},
   "source": [
    "## PCA-BASED MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369863b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "n_folds = 2\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "    X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "    y_pred = rf_model.predict(X_val)\n",
    "    score = rf_model.score(X_val, y_val)\n",
    "    #print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    print(f\"Confusion matrix:\")\n",
    "    # Print confusion matrix\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(f\"Classification report:\")\n",
    "    print('---------------------')\n",
    "    # Print classification report\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    # Print the OOB score\n",
    "    #print(f\"OOB score: {rf_model.oob_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685da952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(rf_model, X_test_pca_df, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888d6ec",
   "metadata": {},
   "source": [
    "## HalfRandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.experimental import enable_halving_search_cv  # Required to enable HalvingRandomSearchCV\n",
    "# from sklearn.model_selection import HalvingRandomSearchCV\n",
    "# import numpy as np\n",
    "\n",
    "# # Create the random forest model\n",
    "# rfc = RandomForestClassifier()\n",
    "\n",
    "# # Set the hyperparameters to tune and their possible values\n",
    "# param_dist = {\n",
    "#     'n_estimators': np.arange(100, 400),\n",
    "#     'max_features': ['sqrt', 'log2','auto']\n",
    "#     'max_depth': [5, 10, 15, 20, None],\n",
    "#     'min_samples_split': [2, 5, 15],\n",
    "#     'min_samples_leaf': [2, 5, 15],\n",
    "#     'bootstrap': [True, False],\n",
    "# }\n",
    "\n",
    "# # Set up the HalvingRandomSearchCV with aggressive early stopping\n",
    "# search = HalvingRandomSearchCV(rfc, param_dist, cv=5,verbose=1, \n",
    "#                                factor=2, resource='n_samples', max_resources=100, \n",
    "#                                aggressive_elimination=True, random_state=18, \n",
    "#                                scoring='accuracy', refit=True)\n",
    "\n",
    "# # Fit the HalvingRandomSearchCV object to the data\n",
    "# search.fit(X_train_pca_df, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27fb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and evaluate on the test set\n",
    "best_params = search.best_params_\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bad5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e86b11",
   "metadata": {},
   "source": [
    "## RF-PCA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec09298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "n_folds = 2\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "class_weights={0:15,1:70}\n",
    "rf_model = RandomForestClassifier(class_weight=class_weights)\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "start_time = time.time()\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "    X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "    \n",
    "#     # Print confusion matrix and classification report\n",
    "#     print(f\"Fold {fold+1}\")\n",
    "#     print(f\"Confusion matrix:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "#     print(f\"Classification report:\")\n",
    "#     print('---------------------')\n",
    "#     print(classification_report(y_val, y_pred))\n",
    "    \n",
    "#     # Get precision, recall, and f1 score for this fold\n",
    "#     report = classification_report(y_val, y_pred, output_dict=True)\n",
    "#     precision_list.append(report['weighted avg']['precision'])\n",
    "#     recall_list.append(report['weighted avg']['recall'])\n",
    "#     f1_list.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "\n",
    "# print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "# # Calculate average precision, recall, and f1 score across all folds\n",
    "# avg_precision = sum(precision_list) / n_folds\n",
    "# avg_recall = sum(recall_list) / n_folds\n",
    "# avg_f1 = sum(f1_list) / n_folds\n",
    "\n",
    "# print(f\"Average precision: {avg_precision}\")\n",
    "# print(f\"Average recall: {avg_recall}\")\n",
    "# print(f\"Average F1 score: {avg_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# # Load iris dataset\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# # Train a random forest classifier with 3 decision trees\n",
    "rf_model = RandomForestClassifier(n_estimators=2)\n",
    "rf_model.fit(X_train_pca_df, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# plot_tree(rf_model.estimators_[1], filled=True, ax=ax, max_depth=2, fontsize=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd19a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier('n_estimators': 130, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 20, 'bootstrap': False)\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     y_prob = rf_model.predict_proba(X_val)[:,1] # get probability estimates for positive class\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print confusion matrix\n",
    "#     print(f\"Confusion matrix for fold {fold}:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "    \n",
    "#     # Plot ROC curve\n",
    "#     fpr, tpr, thresholds = roc_curve(y_val, y_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     plt.plot(fpr, tpr, label=f\"Fold {fold} (AUC = {roc_auc:.2f})\")\n",
    "    \n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='Random guessing')\n",
    "# plt.xlabel('False positive rate')\n",
    "# plt.ylabel('True positive rate')\n",
    "# plt.title('ROC curve for Random Forest classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c1abe",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2023d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define the number of splits for stratified cross-validation\n",
    "# n_splits = 2\n",
    "\n",
    "# # Initialize StratifiedKFold\n",
    "# skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# # Create lists to store evaluation metrics for each fold\n",
    "# f1_scores = []\n",
    "# recall_scores = []\n",
    "# precision_scores = []\n",
    "# accuracy_scores = []\n",
    "\n",
    "# # Create lists to store ROC curve data for each fold\n",
    "# fprs = []\n",
    "# tprs = []\n",
    "# aucs = []\n",
    "\n",
    "# # Initialize the OOB error list\n",
    "# oob_error = []\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "#     print(f'Fold: {fold+1}')\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df[train_idx], y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df[val_idx], y_train_resampled_final[val_idx]\n",
    "\n",
    "#     #class_weights={0:1,0:75}\n",
    "#     rf_model = RandomForestClassifier(criterion='entropy', max_depth= 8, max_features='log2',n_estimators=251,oob_score=True)\n",
    "#     # Fit the model on the training data\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "#     # Predict the class labels for the validation set\n",
    "#     y_val_pred = rf_model.predict(X_val)\n",
    "    \n",
    "#     # Predict the class probabilities for the validation set\n",
    "#     y_val_pred_proba = rf_model.predict_proba(X_val)\n",
    "\n",
    "#     # Set the threshold\n",
    "#     threshold = 0.225\n",
    "#     # Convert the probabilities to binary predictions based on the threshold\n",
    "#     y_val_pred = (y_val_pred_proba[:,1] > threshold).astype(int)\n",
    "\n",
    "#     # Compute the evaluation metrics for the current fold\n",
    "#     conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "#     recall = recall_score(y_val, y_val_pred)\n",
    "#     accuracy = accuracy_score(y_val, y_val_pred)\n",
    "#     precision = precision_score(y_val, y_val_pred)\n",
    "#     f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "#     # Append the evaluation metrics for the current fold to the lists\n",
    "#     f1_scores.append(f1)\n",
    "#     recall_scores.append(recall)\n",
    "#     precision_scores.append(precision)\n",
    "#     accuracy_scores.append(accuracy)\n",
    "    \n",
    "#     # Compute the ROC curve and AUC for the current fold\n",
    "#     fpr, tpr, _ = roc_curve(y_val, rf_model.predict_proba(X_val)[:,1])\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "#     # Append the ROC curve data for the current fold to the lists\n",
    "#     fprs.append(fpr)\n",
    "#     tprs.append(tpr)\n",
    "#     aucs.append(roc_auc)\n",
    "\n",
    "#     # Compute the OOB error for the current fold and append to the list\n",
    "#     oob_error.append(1 - rf_model.oob_score_)\n",
    "\n",
    "#     # Print the evaluation metrics for the current fold\n",
    "#     print('Confusion matrix:\\n', conf_mat)\n",
    "#     print('Recall:', recall)\n",
    "#     #print('Accuracy:', accuracy)\n",
    "#     print('Precision:', precision)\n",
    "#     print('F1-score:', f1)\n",
    "#     print('OOB error:', 1 - rf_model.oob_score_)\n",
    "#     print('---------------------')\n",
    "    \n",
    "#     # Compute the classification report for the current fold\n",
    "#     report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "#     # Print the classification report\n",
    "#     print('Classification report:\\n', report)\n",
    "\n",
    "# # Create the ROC curve plot\n",
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# # Plot the ROC curve for each fold\n",
    "# for i in range(n_splits):\n",
    "#     ax.plot(fprs[i], tprs[i], lw=2, label='Fold %d (AUC = %0.2f)' % (i+1, aucs[i]))\n",
    "\n",
    "# # Add a dashed line representing the random guess classifier\n",
    "# ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Random guess')\n",
    "\n",
    "# # Add labels and legend to the plot\n",
    "# ax.set_xlabel('False Positive Rate')\n",
    "# ax.set_ylabel('True Positive Rate')\n",
    "# ax.set_title('Receiver Operating Characteristic')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c9809",
   "metadata": {},
   "source": [
    "## Contour plot for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4986a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "# X = X_train_pca_df.iloc[:, :2].values \n",
    "\n",
    "# # define the meshgrid\n",
    "# h = 0.02  # step size in the mesh\n",
    "# x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "# y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                      np.arange(y_min, y_max, h))\n",
    "\n",
    "# # predict the class probabilities for each meshgrid point\n",
    "# Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# # reshape the predicted probabilities into the meshgrid shape\n",
    "# Z = Z.reshape(xx.shape)\n",
    "\n",
    "# # plot the contour plot\n",
    "# plt.contourf(xx, yy, Z, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63250503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f938e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "y = y_train_resampled_final.values\n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.7, s=2)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add title and axis labels\n",
    "# add title and axis labels with smaller font size\n",
    "plt.title(\"Decision boundary with training points\", fontsize=14)\n",
    "plt.xlabel(\"PC1\", fontsize=12)\n",
    "plt.ylabel(\"PC2\", fontsize=12)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de573377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "y = y_train_resampled_final.values\n",
    "\n",
    "# shift the y-coordinate values of the positive class points\n",
    "X[y == 1, 1] += 1.8\n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.7, s=2)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add title and axis labels\n",
    "plt.title(\"Decision boundary with training points\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ce2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the plot_decision_boundary function first\n",
    "# def plot_decision_boundary(pred_func):\n",
    "#     # Set min and max values and give it some padding\n",
    "#     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "#     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "#     h = 0.01\n",
    "#     # Generate a grid of points with distance h between them\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "#     # Predict the function value for the whole gid\n",
    "#     Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     # Plot the contour and training examples\n",
    "#     plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "\n",
    "# # Train the RandomForestClassifier\n",
    "# rf_model = RandomForestClassifier()\n",
    "# rf_model.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Plot the decision boundary using the plot_decision_boundary function\n",
    "# plot_decision_boundary(lambda X_train_pca_df: rf_model.predict(X_train_pca_df))\n",
    "# plt.title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define plot_decision_boundary function here...\n",
    "# def plot_decision_boundary(pred_func):\n",
    "#     # Set min and max values and give it some padding\n",
    "#     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "#     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "#     h = 0.01\n",
    "#     # Generate a grid of points with distance h between them\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "#     # Predict the function value for the whole gid\n",
    "#     Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     # Plot the contour and training examples\n",
    "#     plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(X_train_pca_df[:, 0], X_train_pca_df[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "   \n",
    "# %matplotlib inline\n",
    "# matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "# # Train the logistic regression classifier\n",
    "# rf_model = RandomForestClassifier()\n",
    "# rf_model.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Plot decision boundary\n",
    "# #plot_decision_boundary(lambda x: rf_model.predict(x))\n",
    "# plot_decision_boundary(lambda x: rf_model.predict(x), X_train_pca_df.iloc[:, :2].values)\n",
    "# plt.title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68e29c",
   "metadata": {},
   "source": [
    "## Bubble Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e40639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample data frame\n",
    "df = pd.DataFrame({\n",
    "    'Model Name': ['Model 1', 'Model 1', 'Model 1', 'Model 2', 'Model 2', 'Model 2', 'Model 3', 'Model 3', 'Model 3'],\n",
    "    'Dataset Size': ['Small', 'Medium', 'Large', 'Small', 'Medium', 'Large', 'Small', 'Medium', 'Large'],\n",
    "    'Performance Value': [5, 0.9, 0.9, 0.7, 7, 9, 0.6, 1, 15]\n",
    "})\n",
    "\n",
    "# Define bubble sizes and colors\n",
    "bubble_sizes = df['Performance Value'] * 100\n",
    "bubble_colors = df['Performance Value']\n",
    "\n",
    "# Group the data by Model Name\n",
    "groups = df.groupby('Model Name')\n",
    "\n",
    "# Create a scatter plot for each group\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for name, group in groups:\n",
    "    ax.scatter(group['Dataset Size'], [name] * len(group), s=bubble_sizes.loc[group.index], c=bubble_colors.loc[group.index], alpha=0.5, label=name)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Dataset Size')\n",
    "ax.set_ylabel('Model Name')\n",
    "ax.set_title('Model Performance')\n",
    "\n",
    "# Add color bar and legend\n",
    "sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(vmin=bubble_colors.min(), vmax=bubble_colors.max()))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.ax.set_ylabel('Performance Value')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8157658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define the parameters for the learning curve\n",
    "# train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "# cv = 2  # number of cross-validation folds\n",
    "\n",
    "# # Generate the learning curve data\n",
    "# train_sizes, train_scores, val_scores = learning_curve(\n",
    "#     rf_model, X_train_pca_df, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    "# )\n",
    "\n",
    "# # Calculate the mean and standard deviation of the training and validation scores\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# val_scores_mean = np.mean(val_scores, axis=1)\n",
    "# val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Misclassification Error\")\n",
    "# plt.grid()\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (train_scores_mean + train_scores_std),\n",
    "#     1 - (train_scores_mean - train_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"r\",\n",
    "# )\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (val_scores_mean + val_scores_std),\n",
    "#     1 - (val_scores_mean - val_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"g\",\n",
    "# )\n",
    "# plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "# plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6532ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set up the data\n",
    "# training_samples = [23000, 73000, 124000, 162500, 220000]\n",
    "# cv_errors = [0.30, 0.30, 0.24, 0.075, 0.043]\n",
    "# training_errors = [0.27, 0.16, 0.05, 0.025,  0.025]\n",
    "\n",
    "# # Create the plot and set the grid\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.grid(True)\n",
    "\n",
    "# # Plot the data points as dots\n",
    "# # ax.plot(training_samples, cv_errors, 'o', color='green', label='Cross Validation Error')\n",
    "# # ax.plot(training_samples, training_errors, 'o', color='red', label='Training Error')\n",
    "\n",
    "# # Plot the lines connecting the dots with different colors and line styles\n",
    "# ax.plot(training_samples, cv_errors, color='green', linestyle='-', marker='o', label='Cross Validation Error')\n",
    "# ax.plot(training_samples, training_errors, color='red', linestyle='-', marker='o', label='Training Error')\n",
    "\n",
    "# # Set the axis labels and title\n",
    "# ax.set_xlabel('Training examples')\n",
    "# ax.set_ylabel('Miscalssification Error')\n",
    "# ax.set_title('Learning Curve')\n",
    "\n",
    "# # Add a legend\n",
    "# ax.legend()\n",
    "# plt.legend(loc=\"best\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a0029",
   "metadata": {},
   "source": [
    "## Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c39c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "# from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 6), sharey=True)\n",
    "\n",
    "# common_params = {\n",
    "#     \"X\": X_train_pca,\n",
    "#     \"y\": y_train_resampled_final,\n",
    "#     \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "#     \"cv\": KFold(n_splits=2, shuffle=True),\n",
    "#     \"score_type\": \"both\",\n",
    "#     \"line_kw\": {\"marker\": \"o\"},\n",
    "#     \"std_display_style\": \"fill_between\",\n",
    "#     \"score_name\": \"neg_log_loss\",\n",
    "# }\n",
    "\n",
    "# estimator = rf_model\n",
    "# LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax)\n",
    "# handles, label = ax.get_legend_handles_labels()\n",
    "# ax.legend(handles[:2], [\"Training Score\", \"Cross alidation Score\"])\n",
    "# ax.set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8008524",
   "metadata": {},
   "source": [
    "## Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d88ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#class_weights={0:1,0:75}\n",
    "    # Create a RandomForestClassifier object with the given hyperparameters\n",
    "#rf_model = RandomForestClassifier(max_features='sqrt',n_estimators=121,oob_score=True,class_weight=class_weights,random_state=1)\n",
    "clf = lgb.LGBMClassifier(objective='binary', metric='binary_logloss')\n",
    "\n",
    "train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "train_loss = []\n",
    "cv_loss = []\n",
    "    \n",
    "for size in train_sizes:\n",
    "    # Split the data into training and cross-validation sets\n",
    "    X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_pca_df, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    clf .fit(X_train_new, y_train_new)\n",
    "    \n",
    "    # Compute the cross-entropy loss on the training set\n",
    "    y_train_pred = clf .predict_proba(X_train_pca_df)\n",
    "    train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "    # Compute the cross-entropy loss on the cross-validation set\n",
    "    y_cv_pred = clf .predict_proba(X_cv)\n",
    "    cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.tree import export_graphviz\n",
    "# from IPython.display import Image\n",
    "# import pydotplus\n",
    "\n",
    "# # Visualize a decision tree from the random forest\n",
    "# tree = rf_model.estimators_[0]\n",
    "# export_graphviz(tree, out_file='tree.dot', feature_names=['newbalanceDest', 'step', 'nameDest', 'newbalanceOrig'], class_names=['class_0', 'class_1'], filled=True, rounded=True)\n",
    "\n",
    "# # Convert the .dot file to .png\n",
    "# graph = pydotplus.graph_from_dot_file('tree.dot')\n",
    "# graph.write_png('tree.png')\n",
    "\n",
    "# # Display the decision tree\n",
    "# Image(filename='tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve\n",
    "# # Get predicted probabilities for the test data\n",
    "# y_prob = rf_model.predict_proba(X_test_pca)[:,1]\n",
    "\n",
    "# # Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "# thresholds = np.arange(0.1,30,0.01)\n",
    "# precision_scores = []\n",
    "# recall_scores = []\n",
    "# f1_scores = []\n",
    "\n",
    "# for threshold in thresholds:\n",
    "#     y_pred = (y_prob >= threshold).astype(int)\n",
    "#     precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     precision_scores.append(precision[1])\n",
    "#     recall_scores.append(recall[1])\n",
    "#     f1_scores.append(f1[1])\n",
    "\n",
    "# # Find the optimal threshold that maximizes the F1-score\n",
    "# optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# # Assign the class labels based on the optimal threshold\n",
    "# y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# # Evaluate the performance of the classifier for the optimal threshold\n",
    "# confusion_matrix(y_test, y_pred)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64528a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Get predicted probabilities for the test data\n",
    "# y_prob = rf_model.predict_proba(X_test_pca)[:,1]\n",
    "\n",
    "# # Assign the class labels based on the optimal threshold\n",
    "# optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "# y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# # Print classification report on the test set\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ba105",
   "metadata": {},
   "source": [
    "## Partial dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_partial_dependence(rf_model, X_train_pca_df, features=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fab4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['newbalanceDest', 'oldbalanceOrg','nameDest']  # or ['feat1', 'feat2', 'feat3']\n",
    "# plot_partial_dependence(rf_model, X_train_pca, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef257a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [0, 1, 2] # Indices of the features in X_train_pca\n",
    "# feature_names = ['newbalanceDest', 'oldbalanceOrg', 'nameDest'] # Names of the features\n",
    "\n",
    "# plot_partial_dependence(rf_model, X_train_pca, features=features, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38890561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import partial_dependence\n",
    "# from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# # Compute partial dependence values for the feature 'feature_name'\n",
    "# pdp, axes = partial_dependence(rf_model,X_train_pca_df, feature_name='PC1')\n",
    "\n",
    "# # Create a partial dependence plot for the feature 'feature_name'\n",
    "# display = PartialDependenceDisplay.from_feature_values(feature_values=X[:, feature_index], \n",
    "#                                                        pdp_values=pdp, \n",
    "#                                                        feature_name='PC1')\n",
    "\n",
    "# # Plot the partial dependence plot\n",
    "# display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# Compute partial dependence values for the first principal component\n",
    "pdp, axes = partial_dependence(rf_model, X_train_pca_df, features=[0])\n",
    "\n",
    "# Create a partial dependence plot for the first principal component\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(axes[0], pdp[0])\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('Predicted Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937145c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "\n",
    "# X_train_pca_df = pd.DataFrame(X_train_pca, columns=[f\"PC{i+1}\" for i in range(pca_train.n_components_)])\n",
    "\n",
    "\n",
    "# # Generate PDPs for the principal components\n",
    "# fig, axs = plot_partial_dependence(clf, X_train_pca_df, features=range(pca_train.n_components_), grid_resolution=50)\n",
    "\n",
    "# # Compute the contribution of each original feature to each PC\n",
    "# pc_contributions = pca_train.components_\n",
    "\n",
    "# # Map the PDPs back to the original features\n",
    "# values = np.array(axs.pd_results_[0]['values'])\n",
    "# contributions = np.matmul(pc_contributions.T, values.T)\n",
    "# effects = np.sum(contributions.T, axis=1)\n",
    "# feature_effects = pd.DataFrame({'Feature': X_train_resampled_final.columns, 'Effect': effects})\n",
    "# for feature_name in X_train.columns:\n",
    "#     fig, ax = plt.subplots()\n",
    "#     pdp_values = axs.pd_results_[feature_name]['average']\n",
    "#     ax.plot(values[:, feature_name], pdp_values)\n",
    "#     ax.set_xlabel(feature_name)\n",
    "#     ax.set_ylabel('Predicted Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# # Choose the features to generate partial dependence plots for\n",
    "# features = [0,1,2]\n",
    "\n",
    "# # Generate partial dependence plots for the specified features\n",
    "# pdp_display = PartialDependenceDisplay.from_estimator(rf_model, X_train_pca_df, features)\n",
    "\n",
    "# # Display the PDP plots\n",
    "# pdp_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf59a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "# # Generate PDPs for the principal components\n",
    "# pdp_display = plot_partial_dependence(clf, X_train_pca_df, features=range(pca_train.n_components_), grid_resolution=50)\n",
    "\n",
    "# # Display the PDP plot\n",
    "# pdp_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b864889",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca15f9",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e885ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Define the hyperparameter space to search over\n",
    "param_dist = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "    'num_leaves': sp_randint(6, 50),\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': sp_randint(50, 200),\n",
    "    'max_depth': sp_randint(3, 15),\n",
    "    'min_child_samples': sp_randint(10, 50),\n",
    "    'min_split_gain': [0, 0.01, 0.1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ad727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the LightGBM model\n",
    "# lgb_model = lgb.LGBMClassifier(objective='binary')\n",
    "\n",
    "# # Perform the hyperparameter search using RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(lgb_model, param_distributions=param_dist, cv=3, n_iter=15,\n",
    "#                                    scoring='roc_auc', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48099ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the random search to the training data\n",
    "# random_search.fit(X_train_pca, y_train_resampled_final)\n",
    "\n",
    "# # Print the best hyperparameters found\n",
    "# print('Best hyperparameters: ', random_search.best_params_)\n",
    "\n",
    "# # Get the best LightGBM model\n",
    "# best_lgb_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the best model on the test set\n",
    "# y_pred = best_lgb_model.predict(X_test_pca)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8539a96",
   "metadata": {},
   "source": [
    "## Model Training LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define the LightGBM classifier\n",
    "# clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate=0.2, max_depth= 11, min_child_samples= 33, min_split_gain= 0, n_estimators= 185, num_leaves= 29)\n",
    "\n",
    "# # Define the cross-validation method\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X_train_resampled_final, y_train_resampled_final)):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_fold_train, y_fold_train = X_train_resampled_final.iloc[train_index],  y_train_resampled_final.iloc[train_index]\n",
    "#     X_fold_test, y_fold_test = X_train_resampled_final.iloc[test_index],  y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "#     # Train the LightGBM classifier\n",
    "#     clf.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bdb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Define the LightGBM classifier\n",
    "clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate= 0.2, max_depth= 15, min_child_samples= 33, min_split_gain= 0, n_estimators= 185, num_leaves= 20, objective='binary', metric='binary_logloss')\n",
    "\n",
    "# Define the cross-validation method\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "    X_fold_test, y_fold_test = X_train_pca_df.iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "    # Train the LightGBM classifier\n",
    "    clf.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     cm = confusion_matrix(y_fold_test, y_pred)\n",
    "#     print(f\"Confusion matrix:\\n{cm}\")\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "#     fpr, tpr, thresholds = roc_curve(y_fold_test, y_pred_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     # Plot the ROC curve\n",
    "#     plt.plot(fpr, tpr, label=f'Fold {fold} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "\n",
    "# # Plot the random classifier\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')\n",
    "\n",
    "# # Add labels and legend\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve for LightGBM Classifier')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21baab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [10,25,35],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedeef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(lgb_model, param_grid, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe977af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.fit(X_train_pca, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6125a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best params:\", grid_search.best_params_)\n",
    "# print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20869ac6",
   "metadata": {},
   "source": [
    "## Convert to PCA elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414eac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_pca_df = pd.DataFrame(X_train_pca, columns=['PC1', 'PC2', 'PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2217cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import warnings\n",
    "\n",
    "# # Ignore all warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# # Define the LightGBM classifier\n",
    "# #clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate= 0.2, max_depth= 11, min_child_samples= 13, min_split_gain= 0, n_estimators= 185, num_leaves= 10, objective='binary', metric='binary_logloss')\n",
    "# #clf = lgb.LGBMClassifier(max_depth=28,num_leaves=17,objective='binary', metric='binary_logloss',drop_rate=0.225)\n",
    "# class_weights={0:1,1:30}\n",
    "# clf = lgb.LGBMClassifier(learning_rate=0.05,max_depth=10,num_leaves=15,data_sample_strategy='goss',boosting_type='gbdt',objective='binary', metric='binary_logloss',class_weight=class_weights)\n",
    "\n",
    "# # Define the cross-validation method\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df , y_train_resampled_final)):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_fold_train, y_fold_train =X_train_pca_df .iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "#     X_fold_test, y_fold_test = X_train_pca_df .iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "#     # Train the LightGBM classifier with early stopping\n",
    "#     clf.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_test, y_fold_test)], early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     cm = confusion_matrix(y_fold_test, y_pred)\n",
    "#     print(f\"Confusion matrix:\\n{cm}\")\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "#     fpr, tpr, thresholds = roc_curve(y_fold_test, y_pred_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     # Plot the ROC curve\n",
    "#     plt.plot(fpr, tpr, label=f'Fold {fold} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# # Plot the random classifier\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')\n",
    "\n",
    "# # Add labels and legend\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve for LightGBM Classifier')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e12ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first tree\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ac36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Plot the first tree\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95173c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define graph and node attributes with desired color scheme\n",
    "graph_attr = {'size': '50,50', 'dpi': '100', 'bgcolor': 'white', 'rankdir': 'TB', 'splines': 'ortho'}\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '1.2', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Plot the first tree with color\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], graph_attr=graph_attr, node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Define node attributes with desired color scheme\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '0.4', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Set leaf node color to green\n",
    "node_attr['fillcolor'] = 'green'\n",
    "\n",
    "# Plot the first tree with colored leaf nodes\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20277109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Define node attributes with desired color scheme\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '1.2', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Set leaf node color to green\n",
    "node_attr['fillcolor'] = 'green'\n",
    "\n",
    "# Plot the first tree with colored leaf nodes\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f3c8e",
   "metadata": {},
   "source": [
    "## Misclassification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e327599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define the parameters for the learning curve\n",
    "# train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "# cv = 2  # number of cross-validation folds\n",
    "\n",
    "# # Generate the learning curve data\n",
    "# train_sizes, train_scores, val_scores = learning_curve(\n",
    "#     clf, X_train_pca, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    "# )\n",
    "\n",
    "# # Calculate the mean and standard deviation of the training and validation scores\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# val_scores_mean = np.mean(val_scores, axis=1)\n",
    "# val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Misclassification Error\")\n",
    "# plt.grid()\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (train_scores_mean + train_scores_std),\n",
    "#     1 - (train_scores_mean - train_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"r\",\n",
    "# )\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (val_scores_mean + val_scores_std),\n",
    "#     1 - (val_scores_mean - val_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"g\",\n",
    "# )\n",
    "# plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "# plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7f5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# # Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "# train_loss = []\n",
    "# cv_loss = []\n",
    "    \n",
    "# for size in train_sizes:\n",
    "#     # Split the data into training and cross-validation sets\n",
    "#     X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_pca_df, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "#     # Train the model on the training set\n",
    "#     clf.fit(X_train_new, y_train_new)\n",
    "    \n",
    "#     # Compute the cross-entropy loss on the training set\n",
    "#     y_train_pred = clf.predict_proba(X_train_pca_df)\n",
    "#     train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "#     # Compute the cross-entropy loss on the cross-validation set\n",
    "#     y_cv_pred = clf.predict_proba(X_cv)\n",
    "#     cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "# plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "# plt.xlabel('Training Set Size')\n",
    "# plt.ylabel('Cross-Entropy Loss')\n",
    "# plt.title('Learning Curve')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(clf, X_train_pca, y_train_resampled_final, cv=5)\n",
    "\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b5fed",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df40499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "# Get predicted probabilities for the test data\n",
    "y_prob = clf.predict_proba(X_test_pca_df)[:,1]\n",
    "\n",
    "# Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "thresholds = np.arange(0.1,30,0.1)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    precision_scores.append(precision[1])\n",
    "    recall_scores.append(recall[1])\n",
    "    f1_scores.append(f1[1])\n",
    "\n",
    "# Find the optimal threshold that maximizes the F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Assign the class labels based on the optimal threshold\n",
    "y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the performance of the classifier for the optimal threshold\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the class labels and probabilities for the test set\n",
    "y_test_pred = clf.predict(X_test_pca_df)\n",
    "y_test_prob = clf.predict_proba(X_test_pca_df)[:, 1]\n",
    "# Compute the false positive rate, true positive rate, and AUC for the test set\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_prob)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "# Plot the ROC curve for the test set\n",
    "plt.plot(fpr_test, tpr_test, color='blue', lw=2, label='Test ROC curve (AUC =%0.2f)' % roc_auc_test)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Test Set')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the precision, recall, and F1-score for each threshold\n",
    "print(\"Threshold\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(len(thresholds)):\n",
    "    print(f\"{thresholds[i]:.1f}\\t\\t{precision_scores[i]:.3f}\\t\\t{recall_scores[i]:.3f}\\t\\t{f1_scores[i]:.3f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Print the optimal threshold and the corresponding F1-score\n",
    "print(f\"\\nOptimal Threshold: {optimal_threshold:.1f}\")\n",
    "print(f\"Optimal F1-Score: {max(f1_scores):.3f}\")\n",
    "print(f\"Optimal Recall: {max(recall_scores):.3f}\")\n",
    "print(f\"Optimal Precision: {max(precision_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061d019",
   "metadata": {},
   "source": [
    "## Performance Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d8946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.529, 0.404, 0.448]\n",
    "# recalls = [0.784, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['f1-score', 'recall', 'precision']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#635f83'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='Default', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='RandomizedSearchCV', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='HalvingRandomSearchCV', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.529, 0.404, 0.448]\n",
    "# recalls = [0.784, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['Default', 'RandomizedSearchCV', 'HalvingRandomSearchCV']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#c7e9b8'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='f1-score', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='recall', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='precision', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "default_scores = [0.529, 0.404, 0.448]\n",
    "randomized_scores = [0.610, 0.596, 0.565]\n",
    "metrics = ['f1-score', 'recall', 'precision']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "# Set the colors for the bars\n",
    "default_colors = ['#c5d3ff', '#c5d3ff', '#c5d3ff']\n",
    "randomized_colors = ['#e9c6b8', '#e9c6b8', '#e9c6b8']\n",
    "\n",
    "# Create the figure and axes objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars for each hyperparameter search method with the specified colors\n",
    "ax.bar(x - width/2, default_scores, width, label='Default', color=default_colors, edgecolor='black')\n",
    "ax.bar(x + width/2, randomized_scores, width, label='RandomizedSearchCV', color=randomized_colors, edgecolor='black')\n",
    "\n",
    "# Add some labels and a legend\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(title='Hyperparameters used',bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "default_scores = [0.529, 0.732, 1]\n",
    "randomized_scores = [0.610, 0.834, 1]\n",
    "metrics = ['f1-score', 'recall', 'precision']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "# Set the colors for the bars\n",
    "default_colors = ['#c5d3ff', '#c5d3ff', '#c5d3ff']\n",
    "randomized_colors = ['#e9c6b8', '#e9c6b8', '#e9c6b8']\n",
    "\n",
    "# Create the figure and axes objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars for each hyperparameter search method with the specified colors\n",
    "ax.bar(x - width/2, default_scores, width, label='Default', color=default_colors, edgecolor='black')\n",
    "ax.bar(x + width/2, randomized_scores, width, label='RandomizedSearchCV', color=randomized_colors, edgecolor='black')\n",
    "\n",
    "# Add the values on each bar\n",
    "for i, v in enumerate(default_scores):\n",
    "    ax.text(i - width/2, v + 0.02, str(v), color='black', ha='center')\n",
    "for i, v in enumerate(randomized_scores):\n",
    "    ax.text(i + width/2, v + 0.02, str(v), color='black', ha='center')\n",
    "\n",
    "# Add some labels and a legend\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(title='Hyperparameters used',bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.603, 0.404, 0.448]\n",
    "# recalls = [0.854, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['Default', 'RandomizedSearchCV', ' HalvingRandomSearchCV']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#635f83'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='f1-score', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='recall', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='precision', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add score values on top of each bar\n",
    "# for i, (score1, score2, score3) in enumerate(zip(f1_scores, recalls, precisions)):\n",
    "#     ax.text(x[i] - width, score1 + 0.01, str(score1), ha='center', va='bottom', fontweight='bold')\n",
    "#     ax.text(x[i], score2 + 0.01, str(score2), ha='center', va='bottom', fontweight='bold')\n",
    "#     ax.text(x[i] + width, score3 + 0.01, str(score3), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Hyperparameter and Metric')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87793743",
   "metadata": {},
   "source": [
    "## LightGBM New trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c015c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#class_weights={0:1,1:30}\n",
    "# Define the LightGBM classifier\n",
    "#clf = lgb.LGBMClassifier(max_depth=28,num_leaves=17,objective='binary', metric='binary_logloss',drop_rate=0.225,class_weight=class_weights)\n",
    "clf = lgb.LGBMClassifier(objective='binary', metric='binary_logloss')\n",
    "# Define the cross-validation method\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# Create an empty list to store the optimized thresholds for each fold\n",
    "optimized_thresholds = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df , y_train_resampled_final)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_fold_train, y_fold_train =X_train_pca_df .iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "    X_fold_test, y_fold_test = X_train_pca_df .iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "    # Train the LightGBM classifier with early stopping\n",
    "    clf.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_test, y_fold_test)], early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "    # Evaluate the performance of the model on the testing data\n",
    "    y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "    \n",
    "    # Create an empty dictionary to store the F1-scores for each threshold\n",
    "    f1_scores = {}\n",
    "    \n",
    "    # Iterate through a range of possible threshold values\n",
    "    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        # Convert the predicted probabilities to predicted labels based on the threshold\n",
    "        y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate the classification report and select the threshold that maximizes the F1-score\n",
    "        report = classification_report(y_fold_test, y_pred, output_dict=True)\n",
    "        f1_scores[threshold] = report['1']['f1-score']\n",
    "    \n",
    "    # Select the threshold that maximizes the F1-score\n",
    "    optimized_threshold = max(f1_scores, key=f1_scores.get)\n",
    "    optimized_thresholds.append(optimized_threshold)\n",
    "    \n",
    "    # Convert the predicted probabilities to predicted labels based on the optimized threshold\n",
    "    y_pred = (y_pred_prob >= optimized_threshold).astype(int)\n",
    "    \n",
    "    # Calculate the classification report and confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eec368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_set_size = [25000, 50000, 75000, 100000, 125000, 150000, 175000, 200000, 225000]\n",
    "training_loss = [0.253, 0.250, 0.247, 0.246, 0.2455, 0.245, 0.245, 0.245, 0.245]\n",
    "cv_loss = [0.255, 0.252, 0.249, 0.2475, 0.247, 0.2465, 0.246, 0.2458, 0.2458]\n",
    "\n",
    "plt.plot(training_set_size, training_loss, label='Training Loss')\n",
    "plt.plot(training_set_size, cv_loss, label='Cross-Validation Loss')\n",
    "\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Learing Curve')\n",
    "plt.ylim(0.244, 0.256) # Set the y-axis limits\n",
    "plt.yticks([0.244, 0.246, 0.248, 0.25, 0.252, 0.254, 0.256]) # Set the y-axis tick labels\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
