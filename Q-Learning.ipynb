{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6aee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fd948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917400ef",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ccfec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a74228b",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ffe88c",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74715a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f2b2b",
   "metadata": {},
   "source": [
    "## Noisy samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939913aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdaac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flatten the array using the ravel function\n",
    "# y_train_resampled_final_flattened = np.ravel(y_train_resampled_final)\n",
    "\n",
    "# counts = np.bincount(y_train_resampled_final_flattened)\n",
    "# print(\"Class 0 count:\", counts[0])\n",
    "# print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9187674",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d223e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random.seed(0)\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.01, 'oldbalanceOrg': 0.07, 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "    # Replace the outliers in the test set with the trimmed means obtained from the train set\n",
    "    test_outliers = X_test.loc[X_test[col_name] > np.percentile(X_test[col_name], 100*(1-trim_props[col_name])), col_name]\n",
    "    X_test.loc[test_outliers.index, col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf78d39",
   "metadata": {},
   "source": [
    "## Scale train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c3e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b4b44",
   "metadata": {},
   "source": [
    "## Scale test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83707cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c9b81",
   "metadata": {},
   "source": [
    "## GOOD ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905908fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# create a new model that outputs the hidden layer\n",
    "hidden_layer_output = autoencoder.layers[1].output\n",
    "hidden_layer_model = Model(inputs=autoencoder.input, outputs=hidden_layer_output)\n",
    "\n",
    "# get the hidden layer output for a sample\n",
    "sample_hidden_output = hidden_layer_model.predict(X_train_resampled_final[0].reshape(1, -1))\n",
    "print(sample_hidden_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# extract hidden layer output from autoencoder\n",
    "hidden_layer_output = autoencoder.layers[1].output\n",
    "\n",
    "# create the mediator network with the hidden layer output as input\n",
    "mediator_input_layer = Input(shape=hidden_layer_output.shape[1:])\n",
    "mediator_hidden_layer = Dense(11, activation='relu')(mediator_input_layer)\n",
    "mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "mediator_network.compile(optimizer='adam', loss='mse')\n",
    "mediator_network.fit(hidden_layer_model.predict(X_train_resampled_final), y_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# extract hidden layer output from mediator network\n",
    "agent_hidden_layer_output = mediator_network.layers[1].output\n",
    "\n",
    "agent_input_layer = Input(shape=agent_hidden_layer_output.shape[1:])\n",
    "agent_hidden_layer = Dense(5, activation='relu')(agent_input_layer)\n",
    "agent_output_layer = Dense(2, activation='softmax')(agent_hidden_layer)\n",
    "\n",
    "agent_network = Model(inputs=agent_input_layer, outputs=agent_output_layer)\n",
    "agent_network.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92952ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediator_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c503ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f96cb8",
   "metadata": {},
   "source": [
    "## Agent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62477721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        experience = (state, action, reward, next_state, done)\n",
    "        self.buffer.append(experience)\n",
    "        if len(self.buffer) > self.max_size:\n",
    "            self.buffer.pop(0)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        index = np.random.choice(np.arange(buffer_size), size=batch_size, replace=False)\n",
    "        return [self.buffer[i] for i in index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d602597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def REWARD(action, label, fraud_class='DF', non_fraud_class='DN', reward_fraud=1, reward_non_fraud=0.5, penalty=-1):\n",
    "#     terminal = 0\n",
    "#     if label == fraud_class:\n",
    "#         if action == label:\n",
    "#             reward = reward_fraud\n",
    "#         else:\n",
    "#             reward = penalty\n",
    "#             terminal = 1\n",
    "#     else:\n",
    "#         if action == label:\n",
    "#             reward = reward_non_fraud\n",
    "#         else:\n",
    "#             reward = penalty * reward_non_fraud\n",
    "#     return reward, terminal\n",
    "\n",
    "def REWARD(action, label, lambda_val, is_fraud):\n",
    "    \"\"\"\n",
    "    Calculates the reward for a given action and label.\n",
    "    \n",
    "    Parameters:\n",
    "    - action: The action taken by the agent.\n",
    "    - label: The true label of the transaction.\n",
    "    - lambda_val: The reward value when the agent correctly classifies a non-fraudulent transaction.\n",
    "    - is_fraud: A boolean value indicating whether the transaction is fraudulent or not.\n",
    "    \n",
    "    Returns:\n",
    "    - reward: The reward value.\n",
    "    - terminal: A boolean indicating whether the episode is over or not.\n",
    "    \"\"\"\n",
    "    if is_fraud:\n",
    "        if action == label:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "            terminal = True\n",
    "    else:\n",
    "        if action == label:\n",
    "            reward = lambda_val\n",
    "        else:\n",
    "            reward = -lambda_val\n",
    "        terminal = False\n",
    "    \n",
    "    return reward, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_shape = X_train_resampled_final.shape[1]\n",
    "output_shape =X_train_resampled_final.shape[1]\n",
    "\n",
    "# Set hyperparameters\n",
    "gamma = 0.99\n",
    "epsilon = 1\n",
    "epsilon_decay = 0.9999\n",
    "epsilon_min = 0.01\n",
    "batch_size = 32\n",
    "num_episodes = 2\n",
    "\n",
    "# Initialize replay memory D with M capacity\n",
    "M = 10000\n",
    "replay_memory = ReplayBuffer(M)\n",
    "\n",
    "# Randomly initialize parameters θ\n",
    "theta_agent = np.random.normal(0, 0.1, size=(input_shape, output_shape))\n",
    "\n",
    "# Loop over episodes\n",
    "for episode in range(num_episodes):\n",
    "\n",
    "    # Shuffle D\n",
    "    np.random.shuffle(replay_memory.buffer)\n",
    "\n",
    "\n",
    "    # Initialize state s1\n",
    "    state = X_train_resampled_final[0]\n",
    "\n",
    "    # Reset the episode\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    t = 0\n",
    "\n",
    "    # Loop over time steps\n",
    "    while not done:\n",
    "\n",
    "        # Choose an action: at = πθ(st)\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.choice(output_shape)\n",
    "        else:\n",
    "            q_values = Q(state, theta_agent)\n",
    "            action = np.argmax(q_values)\n",
    "\n",
    "        # Take the action and observe the next state and reward\n",
    "        next_state = X_train_resampled_final[t+1]\n",
    "        reward, terminal = REWARD(action, y[t+1])\n",
    "\n",
    "        # Store (st, at, rt, st+1, terminalt) to M\n",
    "        replay_memory.add(state, action, reward, next_state, terminal)\n",
    "\n",
    "        # Randomly sample (sj, aj, rj, sj+1, terminalj) from M\n",
    "        batch = replay_memory.sample(batch_size)\n",
    "\n",
    "        # Set yj\n",
    "        y = np.zeros(batch_size)\n",
    "        next_state_q_values = np.zeros(batch_size)\n",
    "        for i in range(batch_size):\n",
    "            if batch['terminal'][i]:\n",
    "                y[i] = batch['reward'][i]\n",
    "            else:\n",
    "                next_state_q_values[i] = Q(batch['next_state'][i], theta_agent)\n",
    "                y[i] = batch['reward'][i] + gamma * np.max(next_state_q_values[i])\n",
    "\n",
    "        # Perform a gradient descent step\n",
    "        loss = agent_loss(batch['state'], batch['action'], y, theta_agent)\n",
    "        theta_agent -= 0.001 * loss\n",
    "\n",
    "        # Update the state and total reward\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        t += 1\n",
    "\n",
    "        # Break if the episode is done\n",
    "        if terminal:\n",
    "            break\n",
    "\n",
    "    # Decay epsilon\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "    # Print the total reward for the episode\n",
    "    print('Episode', episode + 1, '- Total Reward:', total_reward)\n",
    "\n",
    "reward, terminal = REWARD(action, y[t+1], lambda_val, X[t+1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca652ef",
   "metadata": {},
   "source": [
    "# Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef4331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921e136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb3394",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab161b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb12cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', 'type', 'nameDest', 'nameOrig', 'isFraud']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assuming df is your dataframe\n",
    "new_order = ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud', 'type', 'nameDest', 'nameOrig', 'isFraud']\n",
    "\n",
    "# create a new dataframe with columns in the desired order\n",
    "df_sample = df_sample.drop(columns=['isFraud']).assign(isFraud=df_sample['isFraud'])\n",
    "\n",
    "# check that the new dataframe has columns in the desired order\n",
    "print(df_sample.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b180cc",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bb067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final = df_sample.iloc[:, :10] # extract all rows and first 10 columns\n",
    "y_train_resampled_final = df_sample.iloc[:, -1] # extract last column of entire dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f0d8e",
   "metadata": {},
   "source": [
    "## Treat outliers on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e261af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 142324.9910912304, 'oldbalanceOrg': 172098.2591566378, 'newbalanceOrig': 574920.2068088857, 'oldbalanceDest': 829648.743959752, 'newbalanceDest': 987444.571332041}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random.seed(0)\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.01, 'oldbalanceOrg': 0.07, 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "#     # Replace the outliers in the test set with the trimmed means obtained from the train set\n",
    "#     test_outliers = X_test.loc[X_test[col_name] > np.percentile(X_test[col_name], 100*(1-trim_props[col_name])), col_name]\n",
    "#     X_test.loc[test_outliers.index, col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58cbb6c",
   "metadata": {},
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3964bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd27ee8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E3326B4048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E3326B4048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "21875/21875 [==============================] - 38s 2ms/step - loss: 0.6154\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001E3329C01F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001E3329C01F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "[[1.1854904  2.0738235  5.7322607  2.261583   1.2189875  0.87195534\n",
      "  0.35237342 1.0825322  2.1682591  3.0552363  1.8704498  3.9137554\n",
      "  0.28505397 2.833538   5.295761   0.         1.7016151  2.4321768\n",
      "  0.         0.5552448 ]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 20\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# create a new model that outputs the hidden layer\n",
    "hidden_layer_output = autoencoder.layers[1].output\n",
    "hidden_layer_model = Model(inputs=autoencoder.input, outputs=hidden_layer_output)\n",
    "\n",
    "# get the hidden layer output for a sample\n",
    "sample_hidden_output = hidden_layer_model.predict(X_train_resampled_final[0].reshape(1, -1))\n",
    "print(sample_hidden_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Dense\n",
    "# from keras.models import Model\n",
    "\n",
    "# # create the autoencoder\n",
    "# input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "# encoding_dim = 20\n",
    "# decoding_dim = 10\n",
    "\n",
    "# input_layer = Input(shape=(input_dim,))\n",
    "# hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "# output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "# autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "# autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# # extract hidden layer output from autoencoder\n",
    "# hidden_layer_output = autoencoder.layers[1].output\n",
    "\n",
    "# # create the mediator network with the hidden layer output as input\n",
    "# mediator_input_layer = Input(shape=hidden_layer_output.shape[1:])\n",
    "# mediator_hidden_layer = Dense(10, activation='relu')(mediator_input_layer)\n",
    "# mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "# mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "# mediator_network.compile(optimizer='adam', loss='mse')\n",
    "# mediator_network.fit(hidden_layer_model.predict(X_train_resampled_final), y_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# # extract hidden layer output from mediator network\n",
    "# agent_hidden_layer_output = mediator_network.layers[1].output\n",
    "\n",
    "# agent_input_layer = Input(shape=agent_hidden_layer_output.shape[1:])\n",
    "# agent_hidden_layer = Dense(5, activation='relu')(agent_input_layer)\n",
    "# agent_output_layer = Dense(2, activation='softmax')(agent_hidden_layer)\n",
    "\n",
    "# agent_network = Model(inputs=agent_input_layer, outputs=agent_output_layer)\n",
    "# agent_network.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6644e143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E32D6C1828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E32D6C1828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "21875/21875 [==============================] - 30s 1ms/step - loss: 0.6131\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001E3323B84C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001E3323B84C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "21875/21875 [==============================] - 24s 1ms/step\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E32CB99B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E32CB99B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "21875/21875 [==============================] - 31s 1ms/step - loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# create the autoencoder\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "encoding_dim = 20\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "#MSE is a common choice for reconstruction-based autoencoders.\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=1, batch_size=32)\n",
    "\n",
    "# extract hidden layer output from autoencoder\n",
    "hidden_layer_model = Model(inputs=autoencoder.input, outputs=autoencoder.layers[1].output)\n",
    "hidden_layer_output = hidden_layer_model.predict(X_train_resampled_final)\n",
    "\n",
    "# create the mediator network with the hidden layer output as input\n",
    "mediator_input_layer = Input(shape=(encoding_dim,))\n",
    "mediator_hidden_layer = Dense(10, activation='relu')(mediator_input_layer)\n",
    "mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "mediator_network.compile(optimizer='adam', loss='mse')\n",
    "mediator_network.fit(hidden_layer_output, y_train_resampled_final, epochs=1)\n",
    "\n",
    "# extract hidden layer output from mediator network\n",
    "agent_hidden_layer_output = mediator_network.layers[1].output\n",
    "\n",
    "agent_input_layer = Input(shape=agent_hidden_layer_output.shape[1:])\n",
    "agent_hidden_layer = Dense(5, activation='relu')(agent_input_layer)\n",
    "agent_output_layer = Dense(2, activation='softmax')(agent_hidden_layer)\n",
    "\n",
    "agent_network = Model(inputs=agent_input_layer, outputs=agent_output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c3276",
   "metadata": {},
   "source": [
    "## Check overfitting/underfitting in autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cc9a7",
   "metadata": {},
   "source": [
    "## Baysian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from skopt import gp_minimize, space\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the objective function to optimize\n",
    "def objective_function(params):\n",
    "    encoding_dim, learning_rate = params\n",
    "\n",
    "    # create the autoencoder\n",
    "    input_dim = X_train_resampled_final.shape[1]\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(lr=learning_rate), loss='mse')\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    val_losses = []\n",
    "    for train_index, val_index in kf.split(X_train_resampled_final):\n",
    "        X_train_fold, X_val_fold = X_train_resampled_final[train_index], X_train_resampled_final[val_index]\n",
    "        autoencoder.fit(X_train_fold, X_train_fold, epochs=1, batch_size=32, verbose=0)\n",
    "        val_loss = autoencoder.evaluate(X_val_fold, X_val_fold, verbose=0)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    # Return the average validation loss across all folds\n",
    "    return np.mean(val_losses)\n",
    "\n",
    "# Define the search space for the hyperparameters\n",
    "search_space = [\n",
    "    space.Integer(10, 20, name='encoding_dim'),\n",
    "    space.Real(0.001, 0.1, name='learning_rate'),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization to find the optimal hyperparameters\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    search_space,\n",
    "    n_calls=10,\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters and validation loss\n",
    "print(f\"Best Hyperparameters: {result.x}\")\n",
    "print(f\"Validation Loss: {result.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7427caf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(autoencoder, to_file='autoencoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91728fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(mediator_network, to_file='mediator_network.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54194c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(agent_network, to_file='agent_network.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29bb629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                220       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 430\n",
      "Trainable params: 430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a999b108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 232\n",
      "Trainable params: 232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mediator_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6b07ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agent_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f7e68",
   "metadata": {},
   "source": [
    "## Best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfba4ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E33123BCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001E33123BCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  0%|          | 0/7 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "\n",
      "job exception: Dimensions must be equal, but are 15 and 10 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_5/dense_9/Sigmoid, IteratorGetNext:1)' with input shapes: [?,15], [?,10].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 15 and 10 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_5/dense_9/Sigmoid, IteratorGetNext:1)' with input shapes: [?,15], [?,10].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13696\\2882126330.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m# Run hyperparameter optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best hyperparameters:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             )\n\u001b[1;32m--> 892\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13696\\2882126330.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# Evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 15 and 10 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_5/dense_9/Sigmoid, IteratorGetNext:1)' with input shapes: [?,15], [?,10]."
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "# Define search space for autoencoder hyperparameters\n",
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 50, 1),\n",
    "    'decoding_dim': hp.quniform('decoding_dim', 5, 20, 1),\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -1),\n",
    "}\n",
    "\n",
    "# Define function to optimize\n",
    "def optimize(params):\n",
    "    encoding_dim = int(params['encoding_dim'])\n",
    "    decoding_dim = int(params['decoding_dim'])\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    \n",
    "    # Define autoencoder architecture\n",
    "    input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(lr=learning_rate), loss='mse')\n",
    "\n",
    "    # Define cross-validation parameters\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    # Train and evaluate model using cross-validation\n",
    "    for train_idx, val_idx in kf.split(X_train_resampled_final):\n",
    "        # Split data into training and validation sets\n",
    "        train_data, val_data = X_train_resampled_final[train_idx], X_train_resampled_final[val_idx]\n",
    "\n",
    "        # Train model\n",
    "        autoencoder.fit(train_data, train_data, epochs=1, batch_size=batch_size, validation_data=(val_data, val_data), verbose=0)\n",
    "\n",
    "        # Evaluate model\n",
    "        val_loss = autoencoder.evaluate(val_data, val_data, verbose=0)\n",
    "        losses.append(val_loss)\n",
    "\n",
    "    # Calculate mean validation loss across folds\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    return {'loss': mean_loss, 'status': STATUS_OK}\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "best = fmin(fn=optimize, space=space, algo=tpe.suggest, max_evals=7)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b972cb",
   "metadata": {},
   "source": [
    "## Fit the autoencoder on the chosen hyperparameters and check over/under fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ea790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Dense\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# # create the autoencoder\n",
    "# input_dim = X_train_resampled_final.shape[1]\n",
    "\n",
    "# encoding_dim = 46\n",
    "# decoding_dim = 10\n",
    "\n",
    "# input_layer = Input(shape=(input_dim,))\n",
    "# hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "# output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# # define the optimizer with the desired learning rate\n",
    "# opt = Adam(lr=0.014369161327797432)\n",
    "\n",
    "# #MSE is a common choice for reconstruction-based autoencoders.\n",
    "# autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "# autoencoder.compile(optimizer='adam', loss='mse')\n",
    "# autoencoder.fit(X_train_resampled_final, X_train_resampled_final, epochs=10, batch_size=2)\n",
    "\n",
    "# # extract hidden layer output from autoencoder\n",
    "# hidden_layer_model = Model(inputs=autoencoder.input, outputs=autoencoder.layers[1].output)\n",
    "# hidden_layer_output = hidden_layer_model.predict(X_train_resampled_final)\n",
    "\n",
    "# # create the mediator network with the hidden layer output as input\n",
    "# mediator_input_layer = Input(shape=(encoding_dim,))\n",
    "# mediator_hidden_layer = Dense(10, activation='relu')(mediator_input_layer)\n",
    "# mediator_output_layer = Dense(2, activation='sigmoid')(mediator_hidden_layer)\n",
    "\n",
    "# mediator_network = Model(inputs=mediator_input_layer, outputs=mediator_output_layer)\n",
    "# mediator_network.compile(optimizer='adam', loss='mse')\n",
    "# mediator_network.fit(hidden_layer_output, y_train_resampled_final, epochs=1)\n",
    "\n",
    "# # extract hidden layer output from mediator network\n",
    "# agent_hidden_layer_output = mediator_network.layers[1].output\n",
    "\n",
    "# agent_input_layer = Input(shape=agent_hidden_layer_output.shape[1:])\n",
    "# agent_hidden_layer = Dense(5, activation='relu')(agent_input_layer)\n",
    "# agent_output_layer = Dense(2, activation='softmax')(agent_hidden_layer)\n",
    "\n",
    "# agent_network = Model(inputs=agent_input_layer, outputs=agent_output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "input_dim = X_train_resampled_final.shape[1]\n",
    "encoding_dim = 46\n",
    "decoding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(decoding_dim, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# Define the optimizer with the desired learning rate\n",
    "opt = Adam(lr=0.014369161327797432)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 2\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Define lists to store the MSE of training and validation sets for each fold\n",
    "train_mse = []\n",
    "val_mse = []\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, val_index in kf.split(X_train_resampled_final):\n",
    "    \n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    X_train_fold, X_val_fold = X_train_resampled_final[train_index], X_train_resampled_final[val_index]\n",
    "    \n",
    "    # Fit the autoencoder on the training set for the current fold\n",
    "    history = autoencoder.fit(X_train_fold, X_train_fold, epochs=2, batch_size=2, verbose=0, validation_data=(X_val_fold, X_val_fold))\n",
    "    \n",
    "    # Append the MSE of training and validation sets for the current fold to the lists\n",
    "    train_mse.append(history.history['loss'])\n",
    "    val_mse.append(history.history['val_loss'])\n",
    "    \n",
    "    # compute the reconstruction error for the test data\n",
    "    recon_error = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "    recon_errors.append(recon_error)\n",
    "\n",
    "# Calculate the mean and standard deviation of MSE for training and validation sets across all folds\n",
    "mean_train_mse = np.mean(train_mse, axis=0)\n",
    "std_train_mse = np.std(train_mse, axis=0)\n",
    "mean_val_mse = np.mean(val_mse, axis=0)\n",
    "std_val_mse = np.std(val_mse, axis=0)\n",
    "\n",
    "# Plot the MSE of training and validation sets against the number of epochs\n",
    "epochs = range(1, len(mean_train_mse)+1)\n",
    "plt.plot(epochs, mean_train_mse, 'b', label='Training MSE')\n",
    "plt.fill_between(epochs, mean_train_mse - std_train_mse, mean_train_mse + std_train_mse, alpha=0.2, color='b')\n",
    "plt.plot(epochs, mean_val_mse, 'r', label='Validation MSE')\n",
    "plt.fill_between(epochs, mean_val_mse - std_val_mse, mean_val_mse + std_val_mse, alpha=0.2, color='r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the distribution of reconstruction errors\n",
    "plt.hist(recon_errors, bins=10)\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Reconstruction Errors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reward function\n",
    "def reward_fn(action, label):\n",
    "    DF = [0,1,2]  # indices of fraud class\n",
    "    DN = [81,    787,   2392,   3121,   3449]  # indices of non-fraud class\n",
    "    terminal = 0  # initialize terminal flag to 0\n",
    "    if label in DF:\n",
    "        if action == label:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "            terminal = 1\n",
    "    else:\n",
    "        if action == label:\n",
    "            reward = 0.5  # set λ to 0.5\n",
    "        else:\n",
    "            reward = -0.5  # set λ to -0.5\n",
    "    return reward, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82377946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import keras\n",
    "# from keras import models, layers\n",
    "\n",
    "# # Initialize replay memory with M capacity\n",
    "# M = 10000\n",
    "# replay_memory = []\n",
    "\n",
    "# # Initialize simulation environment\n",
    "# env = None  # Replace with your own simulation environment\n",
    "\n",
    "# # Define the reward function\n",
    "# def reward_fn(action, label):\n",
    "#     # Replace with your own reward function\n",
    "#     if action == label:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "# # Define hyperparameters\n",
    "# K = 2  # Number of episodes\n",
    "# T = 2  # Number of timesteps per episode\n",
    "# gamma = 0.9  # Discount factor\n",
    "# batch_size = 32\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# # Initialize agent network with same architecture as mediator network\n",
    "# agent_network = keras.models.Sequential([\n",
    "#     keras.layers.Dense(20, activation='relu', input_shape=(10,)),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "# agent_network.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=learning_rate))\n",
    "\n",
    "# # Initialize mediator network\n",
    "# mediator_network = None  # Replace with your own mediator network\n",
    "\n",
    "# # Generate dataset D\n",
    "# hidden_layer_output = autoencoder.predict(X_train_resampled_final)\n",
    "# D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "# # Train agent\n",
    "# for k in range(K):\n",
    "#     # Shuffle dataset D\n",
    "#     np.random.shuffle(D)\n",
    "    \n",
    "#     # Initialize state\n",
    "#     state = D[0][0]\n",
    "    \n",
    "#     for t in range(T):\n",
    "#         # Choose action\n",
    "#         action = agent_network.predict(state.reshape(1, -1)).argmax()\n",
    "        \n",
    "#         # Calculate reward and terminal flag\n",
    "#         reward = reward_fn(action, D[t][1])\n",
    "#         terminal = 1 if t == T - 1 else 0\n",
    "#         print(\"Reward:\", reward) # Add this line to print the reward\n",
    "#         print(\"Terminal:\", terminal) # Add this line to print the terminal flag\n",
    "        \n",
    "#         # Update state\n",
    "#         state_next = D[t+1][0] if t < T - 1 else state\n",
    "        \n",
    "#         # Store transition in replay memory\n",
    "#         replay_memory.append((state, action, reward, state_next, terminal))\n",
    "#         if len(replay_memory) > M:\n",
    "#             replay_memory.pop(0)\n",
    "        \n",
    "#         # Sample minibatch from replay memory\n",
    "#         if len(replay_memory) >= batch_size:\n",
    "#             minibatch = random.sample(replay_memory, batch_size)\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#         X = np.zeros((batch_size, 10))\n",
    "#         y = np.zeros((batch_size, 10))\n",
    "#         for i in range(batch_size):\n",
    "#             state_i, action_i, reward_i, state_next_i, terminal_i = minibatch[i]\n",
    "#             X[i] = state_i\n",
    "#             y[i] = agent_network.predict(state_i.reshape(1, -1))\n",
    "#             if terminal_i:\n",
    "#                 y[i][action_i] = reward_i\n",
    "#             else:\n",
    "#                 y[i][action_i] = reward_i + gamma * np.max(agent_network.predict(state_next_i.reshape(1, -1)))\n",
    "        \n",
    "#         # Train agent network on minibatch\n",
    "#         agent_network.train_on_batch(X, y)\n",
    "        \n",
    "#         # Update state\n",
    "#         state = state_next\n",
    "        \n",
    "#         # Check if episode is over\n",
    "#         if terminal:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ee2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import keras\n",
    "# from keras import models, layers\n",
    "\n",
    "# # Initialize replay memory with M capacity\n",
    "# M = 10000\n",
    "# replay_memory = []\n",
    "\n",
    "# # Initialize simulation environment\n",
    "# env = None  # Replace with your own simulation environment\n",
    "\n",
    "# # Define the reward function\n",
    "# def reward_fn(action, label):\n",
    "#     # Replace with your own reward function\n",
    "#     if action == label:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "# # Define hyperparameters\n",
    "# K = 8  # Number of episodes\n",
    "# T = 8  # Number of timesteps per episode\n",
    "# gamma = 0.9  # Discount factor\n",
    "# batch_size = 32\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# # # Initialize agent network with same architecture as mediator network\n",
    "# # agent_network = keras.models.Sequential([\n",
    "# #     keras.layers.Dense(20, activation='relu', input_shape=(10,)),\n",
    "# #     keras.layers.Dense(2, activation='softmax')\n",
    "# # ])\n",
    "# # agent_network.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=learning_rate))\n",
    "\n",
    "# # #Initialize mediator network\n",
    "# # mediator_network = None  # Replace with your own mediator network\n",
    "\n",
    "# # Generate dataset D\n",
    "# hidden_layer_output = autoencoder.predict(X_train_resampled_final)\n",
    "# D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "# # Train agent\n",
    "# for k in range(K):\n",
    "#     # Shuffle dataset D\n",
    "#     np.random.shuffle(D)\n",
    "    \n",
    "#     # Initialize state\n",
    "#     state = D[0][0]\n",
    "    \n",
    "#     for t in range(T):\n",
    "#         # Choose action\n",
    "#         action = agent_network.predict(state.reshape(1, -1)).argmax()\n",
    "        \n",
    "#         # Calculate reward and terminal flag\n",
    "#         reward = reward_fn(action, D[t][1])\n",
    "#         terminal = 1 if t == T - 1 else 0\n",
    "#         print(\"Reward:\", reward) # Add this line to print the reward\n",
    "#         print(\"Terminal:\", terminal) # Add this line to print the terminal flag\n",
    "        \n",
    "#         # Update state\n",
    "#         state_next = D[t+1][0] if t < T - 1 else state\n",
    "        \n",
    "#         # Store transition in replay memory\n",
    "#         replay_memory.append((state, action, reward, state_next, terminal))\n",
    "#         if len(replay_memory) > M:\n",
    "#             replay_memory.pop(0)\n",
    "        \n",
    "#         # Sample minibatch from replay memory\n",
    "#         if len(replay_memory) >= batch_size:\n",
    "#             minibatch = random.sample(replay_memory, batch_size)\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#         X = np.zeros((batch_size, 10))\n",
    "#         y = np.zeros((batch_size, 10))\n",
    "#         for i in range(batch_size):\n",
    "#             state_i, action_i, reward_i, state_next_i, terminal_i = minibatch[i]\n",
    "#             X[i] = state_i\n",
    "#             y[i] = agent_network.predict(state_i.reshape(1, -1))\n",
    "#             if terminal_i:\n",
    "#                 y[i][action_i] = reward_i\n",
    "#             else:\n",
    "#                 y[i][action_i] = reward_i + gamma * np.max(agent_network.predict(state_next_i.reshape(1, -1)))\n",
    "        \n",
    "#         # Train agent network on minibatch\n",
    "#         agent_network.train_on_batch(X, y)\n",
    "        \n",
    "#         # Update state\n",
    "#         state = state_next\n",
    "        \n",
    "#         # Check if episode is over\n",
    "#         if terminal:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d5d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import models, layers\n",
    "import random\n",
    "\n",
    "# Initialize replay memory with M capacity\n",
    "M = 10000\n",
    "replay_memory = []\n",
    "\n",
    "# Initialize simulation environment\n",
    "env = None  # Replace with your own simulation environment\n",
    "\n",
    "# # Define the reward function\n",
    "# def reward_fn(action, label):\n",
    "#     # Replace with your own reward function\n",
    "#     if action == label:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "K = 2  # Number of episodes\n",
    "T = 2  # Number of timesteps per episode\n",
    "gamma = 0.9  # Discount factor\n",
    "batch_size = 32\n",
    "learning_rate_val = 0.001\n",
    "\n",
    "mediator_network = keras.models.Sequential([\n",
    "    keras.layers.Dense(20, activation='relu', input_shape=(10,)),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "mediator_network.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=learning_rate_val))\n",
    "\n",
    "\n",
    "# Generate dataset D\n",
    "# X_train_resampled_final_20 = np.hstack((X_train_resampled_final, np.zeros((X_train_resampled_final.shape[0], 10))))\n",
    "# hidden_layer_output = [mediator_network.predict(np.array([x]*2).reshape(2, -1))[0] for x in X_train_resampled_final]\n",
    "# D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "hidden_layer_output = mediator_network.predict(X_train_resampled_final)\n",
    "D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "# Train agent\n",
    "for k in range(K):\n",
    "    # Shuffle dataset D\n",
    "    np.random.shuffle(D)\n",
    "    \n",
    "    # Initialize state\n",
    "    state = D[0][0]\n",
    "    \n",
    "    for t in range(T):\n",
    "        # Choose action\n",
    "        action = agent_network.predict(state.reshape(1, -1)).argmax()\n",
    "        \n",
    "        # Calculate reward and terminal flag\n",
    "        reward = reward_fn(action, D[t][1])\n",
    "        terminal = 1 if t == T - 1 else 0\n",
    "        print(\"Reward:\", reward) # Add this line to print the reward\n",
    "        print(\"Terminal:\", terminal) # Add this line to print the terminal flag\n",
    "        \n",
    "        # Update state\n",
    "        state_next = D[t+1][0] if t < T - 1 else state\n",
    "        \n",
    "        # Store transition in replay memory\n",
    "        replay_memory.append((state, action, reward, state_next, terminal))\n",
    "        if len(replay_memory) > M:\n",
    "            replay_memory.pop(0)\n",
    "        \n",
    "        # Sample minibatch from replay memory\n",
    "        if len(replay_memory) >= batch_size:\n",
    "            minibatch = random.sample(replay_memory, batch_size)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        X = np.zeros((batch_size, 10))\n",
    "        y = np.zeros((batch_size, 10))\n",
    "        for i in range(batch_size):\n",
    "            state_i, action_i, reward_i, state_next_i, terminal_i = minibatch[i]\n",
    "            X[i] = state_i\n",
    "            y[i] = agent_network.predict(state_i.reshape(1, -1))\n",
    "            if terminal_i:\n",
    "                y[i][action_i] = reward_i\n",
    "            else:\n",
    "                y[i][action_i] = reward_i + gamma * np.max(agent_network.predict(state_next_i.reshape(1, -1)))\n",
    "        \n",
    "        # Train agent network on minibatch - CONCEPT OF GRADIENT DESCENT\n",
    "        agent_network.train_on_batch(X, y)\n",
    "        \n",
    "        # Update state\n",
    "        state = state_next\n",
    "        \n",
    "        # Check if episode is over\n",
    "        if terminal:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6610007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import models, layers\n",
    "import random\n",
    "\n",
    "# Initialize replay memory with M capacity\n",
    "M = 10000\n",
    "replay_memory = []\n",
    "\n",
    "# Initialize simulation environment\n",
    "env = None  # Replace with your own simulation environment\n",
    "\n",
    "# # Define the reward function\n",
    "# def reward_fn(action, label):\n",
    "#     # Replace with your own reward function\n",
    "#     if action == label:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "# Define policy\n",
    "def policy(state, model):\n",
    "    q_values = model.predict(state)\n",
    "    return np.argmax(q_values[0])\n",
    "\n",
    "# Define hyperparameters\n",
    "K = 2  # Number of episodes\n",
    "T = 2  # Number of timesteps per episode\n",
    "gamma = 0.9  # Discount factor\n",
    "batch_size = 32\n",
    "learning_rate_val = 0.001\n",
    "\n",
    "mediator_network = keras.models.Sequential([\n",
    "    keras.layers.Dense(20, activation='relu', input_shape=(10,)),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "mediator_network.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=learning_rate_val))\n",
    "\n",
    "\n",
    "# Generate dataset D\n",
    "# X_train_resampled_final_20 = np.hstack((X_train_resampled_final, np.zeros((X_train_resampled_final.shape[0], 10))))\n",
    "# hidden_layer_output = [mediator_network.predict(np.array([x]*2).reshape(2, -1))[0] for x in X_train_resampled_final]\n",
    "# D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "hidden_layer_output = mediator_network.predict(X_train_resampled_final)\n",
    "D = [(hidden_layer_output[i], y_train_resampled_final[i]) for i in range(len(hidden_layer_output))]\n",
    "\n",
    "# Train agent\n",
    "for k in range(K):\n",
    "    # Shuffle dataset D\n",
    "    np.random.shuffle(D)\n",
    "    \n",
    "    # Initialize state\n",
    "    state = D[0][0]\n",
    "    \n",
    "    for t in range(T):\n",
    "        # Choose action based on policy\n",
    "        action = policy(state.reshape(1, -1), agent_network)\n",
    "        \n",
    "        # Calculate reward and terminal flag\n",
    "        reward = reward_fn(action, D[t][1])\n",
    "        terminal = 1 if t == T - 1 else 0\n",
    "        print(\"Reward:\", reward) # Add this line to print the reward\n",
    "        print(\"Terminal:\", terminal) # Add this line to print the terminal flag\n",
    "        \n",
    "        # Update state\n",
    "        state_next = D[t+1][0] if t < T - 1 else state\n",
    "        \n",
    "        # Store transition in replay memory\n",
    "        replay_memory.append((state, action, reward, state_next, terminal))\n",
    "        if len(replay_memory) > M:\n",
    "            replay_memory.pop(0)\n",
    "        \n",
    "        # Sample minibatch from replay memory\n",
    "        if len(replay_memory) >= batch_size:\n",
    "            minibatch = random.sample(replay_memory, batch_size)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        X = np.zeros((batch_size, 10))\n",
    "        y = np.zeros((batch_size, 10))\n",
    "        for i in range(batch_size):\n",
    "            state_i, action_i, reward_i, state_next_i, terminal_i = minibatch[i]\n",
    "            X[i] = state_i\n",
    "            y[i] = agent_network.predict(state_i.reshape(1, -1))\n",
    "            if terminal_i:\n",
    "                y[i][action_i] = reward_i\n",
    "            else:\n",
    "                y[i][action_i] = reward_i + gamma * np.max(agent_network.predict(state_next_i.reshape(1, -1)))\n",
    "                    mediator_network.train_on_batch(X, y)\n",
    "    \n",
    "        # Update state\n",
    "        state = state_next\n",
    "\n",
    "        # Check if episode is over\n",
    "        if terminal:\n",
    "            break\n",
    "\n",
    "# Evaluate policy πθ\n",
    "rewards = []\n",
    "for i in range(len(D)):\n",
    "    state = D[i][0]\n",
    "    label = D[i][1]\n",
    "    action_probs = mediator_network.predict(np.array([state]*10).reshape(10, -1))\n",
    "    action = np.argmax(action_probs)\n",
    "    reward = reward_fn(action, label)\n",
    "    rewards.append(reward)\n",
    "print(\"Average reward:\", np.mean(rewards)) # Add this line to print the average reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d637de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediator_network.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
