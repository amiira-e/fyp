{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96fe4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77aebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4a9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88dbbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import random\n",
    "\n",
    "# def reservoir_sampling(iterable, k, header=True):\n",
    "#     reservoir = []\n",
    "#     for i, item in enumerate(iterable):\n",
    "#         if i < k:\n",
    "#             reservoir.append(item)\n",
    "#         else:\n",
    "#             j = random.randint(0, i)\n",
    "#             if j < k:\n",
    "#                 reservoir[j] = item\n",
    "#     return reservoir\n",
    "\n",
    "# # Open the input CSV file\n",
    "# with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\") as f:\n",
    "#     # Check if header line exists\n",
    "#     header = True\n",
    "#     first_line = f.readline()\n",
    "#     if not first_line.startswith('step,type,amount,nameOrig,oldbalanceOrg,newbalanceOrig,nameDest,oldbalanceDest,newbalanceDest,isFraud,isFlaggedFraud'):\n",
    "#         header = False\n",
    "#         f.seek(0)  # Rewind file pointer to beginning\n",
    "\n",
    "#     # Sample from remaining lines\n",
    "#     sampled_lines = reservoir_sampling(f, k=2300000, header=header)\n",
    "\n",
    "# # Open the output CSV file and write the subsample to it\n",
    "# with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample1300000.csv\", mode='w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     if header:\n",
    "#         writer.writerow(first_line.strip().split(','))\n",
    "#     for line in sampled_lines:\n",
    "#         writer.writerow(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73182f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78004e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample1300000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a475b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0723ab28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef5a09b",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d941b41a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16696\\3758050434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Calculate the correlation matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcorr_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pearson'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Resize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Plot the correlation matrix as a heatmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mako'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df_sample.corr(method='pearson')\n",
    "plt.figure(figsize=(7,5)) # Resize\n",
    "# Plot the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, cmap='mako', center=0, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b32d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df_sample.corr(method='spearman')\n",
    "plt.figure(figsize=(7,5)) # Resize\n",
    "# Plot the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, cmap='mako', center=0, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e551a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10738b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_sample.corr()\n",
    "\n",
    "# Print correlation matrix\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009be1c",
   "metadata": {},
   "source": [
    "## Distribution shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['step','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for feature in features:\n",
    "    plt.subplot(2,3,features.index(feature)+1)\n",
    "    sns.distplot(df_sample[feature],hist=True,color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change the data type of column 'A' from float64 to float32\n",
    "# df_sample['amount'] = df_sample['amount'].astype('float32')\n",
    "# df_sample['oldbalanceOrg'] = df_sample['oldbalanceOrg'].astype('float32')\n",
    "# df_sample['oldbalanceDest'] = df_sample['oldbalanceDest'].astype('float32')\n",
    "# df_sample['newbalanceOrig'] = df_sample['newbalanceOrig'].astype('float32')\n",
    "# df_sample['newbalanceDest'] = df_sample['newbalanceDest'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3200a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample['step'] = df_sample['step'].astype('int32')\n",
    "# df_sample['isFlaggedFraud'] = df_sample['isFlaggedFraud'].astype('int32') \n",
    "# df_sample['isFraud'] = df_sample['isFraud'].astype('int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90be74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c850827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c998f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4726858",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2c4bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d76c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9678a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 629208\n",
      "Class 1 count: 792\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d2295ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f4d70",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9956a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# #Upsampling via SMOTE\n",
    "# smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "# #Downsample via RandomUnderSampler\n",
    "# rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "# #Application of the resampling methods\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "# X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8de52ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_resampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16696\\3628034858.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# assuming y_train is a numpy array or a pandas series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Class 0 count:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Class 1 count:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_resampled' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_resampled)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac687784",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37071d3f",
   "metadata": {},
   "source": [
    "## Tomeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb7c5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c22208",
   "metadata": {},
   "source": [
    "## ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "884b8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c99782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 628366\n",
      "Class 1 count: 792\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train_resampled_new)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd513977",
   "metadata": {},
   "source": [
    "## OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "540e71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7344156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 620480\n",
      "Class 1 count: 792\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = np.bincount(y_train_resampled_final)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b69f5014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 69912\n",
      "Class 1 count: 88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_test)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8160d1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(621272, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55a1be8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(621272,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainPRIOR.csv\", index=False)\n",
    "#X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086706d5",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3996395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 138744.17440937104, 'oldbalanceOrg': 177822.3463019888, 'newbalanceOrig': 585744.157910874, 'oldbalanceDest': 828532.4517463046, 'newbalanceDest': 980750.6618429476}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "random.seed(0)\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.01, 'oldbalanceOrg': 0.07, 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled_final.loc[X_train_resampled_final[col_name] > np.percentile(X_train_resampled_final[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "    # Replace the outliers in the test set with the trimmed means obtained from the train set\n",
    "    test_outliers = X_test.loc[X_test[col_name] > np.percentile(X_test[col_name], 100*(1-trim_props[col_name])), col_name]\n",
    "    X_test.loc[test_outliers.index, col_name] = train_trimmed_means[col_name]\n",
    "    \n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf41283",
   "metadata": {},
   "source": [
    "## New trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6edbbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "# # Specify columns with outliers\n",
    "# cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# # Specify the number of bootstrapped samples to create per column\n",
    "# num_samples = 50\n",
    "\n",
    "# # Specify the trimming proportions for each column\n",
    "# trim_props = {'amount': 0.01, 'oldbalanceOrg': (0.07, 0.03), 'newbalanceOrig': 0.015, 'oldbalanceDest': 0.015, 'newbalanceDest': 0.01}\n",
    "\n",
    "# # Initialize empty dictionaries to store the trimmed means for each column\n",
    "# train_trimmed_means = {}\n",
    "\n",
    "# # Loop over the specified columns\n",
    "# for col_name in cols_with_outliers:\n",
    "    \n",
    "#     # Check if the trimming proportion for this column is a tuple with two values\n",
    "#     if isinstance(trim_props[col_name], tuple):\n",
    "#         # If so, perform asymmetric trimming for the oldbalanceOrg column\n",
    "#         if col_name == 'oldbalanceOrg':\n",
    "#             # Calculate the median of the bootstrapped sample for the training set\n",
    "#             train_median = np.median(train_sample)\n",
    "#             train_trimmed_means[col_name] = train_median\n",
    "#             # Replace the outliers in the training set with the trimmed means\n",
    "#             X_train_resampled_final.loc[(X_train_resampled_final[col_name] < train_trimmed_means[col_name]) | (X_train_resampled_final[col_name] > train_trimmed_means[col_name]), col_name] = train_median\n",
    "\n",
    "#             continue\n",
    "#         else:\n",
    "#             continue\n",
    "    \n",
    "#     # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "#     train_bootstrapped_samples = []\n",
    "#     train_trimmed_means_list = []\n",
    "    \n",
    "#     # Loop over the number of desired samples\n",
    "#     for i in range(num_samples):\n",
    "#         # Randomly select indices from the column in the training set\n",
    "#         train_sample_indices = np.random.choice(X_train_resampled_final.index, size=len(X_train_resampled_final), replace=True)\n",
    "        \n",
    "#         # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "#         train_sample = X_train_resampled_final.loc[train_sample_indices, col_name]\n",
    "        \n",
    "#         # Calculate the right and left trimmed means of the bootstrapped sample for the training set\n",
    "#         train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "#         train_left_trimmed_mean = np.mean(train_sample[train_sample >= np.percentile(train_sample, 100*trim_props[col_name])])\n",
    "#         train_trimmed_means_list.append((train_left_trimmed_mean, train_right_trimmed_mean))\n",
    "        \n",
    "#     # Calculate the mean of the left and right trimmed means for the training set and add it to the dictionary\n",
    "#     train_left_mean = np.mean([x[0] for x in train_trimmed_means_list])\n",
    "#     train_right_mean = np.mean([x[1] for x in train_trimmed_means_list])\n",
    "#     train_trimmed_means[col_name] = (train_left_mean, train_right_mean)\n",
    "\n",
    "#     # Replace the outliers in the training set with the trimmed means\n",
    "#     X_train_resampled_final.loc[(X_train_resampled_final[col_name] < train_trimmed_means[col_name][0]) | (X_train_resampled_final[col_name] > train_trimmed_means[col_name][1]), col_name] = np.mean(train_sample)\n",
    "\n",
    "# # Print the trimmed means\n",
    "# print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fadbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_resampled_final.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainPOST29.csv\", index=False)\n",
    "# #X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ebc1cc",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48406ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# assuming X_train and X_test are your training and test data matrices\n",
    "# standardize the data using the mean and std from the training set\n",
    "X_train_mean = np.mean(X_train_resampled_final, axis=0)\n",
    "X_train_std = np.std(X_train_resampled_final, axis=0)\n",
    "X_train_std[X_train_std == 0] = 1 # avoid division by zero\n",
    "X_train_std_inv = 1 / X_train_std\n",
    "\n",
    "X_train_stdized = (X_train_resampled_final - X_train_mean) * X_train_std_inv\n",
    "X_test_stdized = (X_test - X_train_mean) * X_train_std_inv\n",
    "\n",
    "# compute the covariance matrix for the training data\n",
    "cov_matrix_train = np.cov(X_train_stdized.T)\n",
    "\n",
    "# compute the eigenvectors and eigenvalues for the training data\n",
    "eig_vals_train, eig_vecs_train = np.linalg.eig(cov_matrix_train)\n",
    "\n",
    "# select the top k eigenvectors for the training data\n",
    "pca_train = PCA(n_components=3)\n",
    "X_train_pca = pca_train.fit_transform(X_train_stdized)\n",
    "\n",
    "# project the test data onto the selected eigenvectors from the training data\n",
    "X_test_pca = pca_train.transform(X_test_stdized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e03563db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = list(df_sample.columns)\n",
    "\n",
    "# # print the selected features\n",
    "# print(\"Selected features:\")\n",
    "# for i in range(pca_train.n_components_):\n",
    "#     # find the index of the maximum absolute value in the ith row of the components array\n",
    "#     idx = np.argmax(np.abs(pca_train.components_[i]))\n",
    "#     # print the name of the feature with the maximum absolute value in the ith row of the components array\n",
    "#     print(f\"PC{i+1}: {feature_names[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e0525f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00527169,  0.31550466,  0.19977606,  0.25067118,  0.47980606,\n",
       "        0.47087919, -0.00064823, -0.37569039, -0.45232005,  0.00207687])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dfa2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f8f47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "y_train_resampled_final = pd.Series(y_train_resampled_final)\n",
    "\n",
    "X_train_pca_df.reset_index(drop=True, inplace=True)\n",
    "y_train_resampled_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b023afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_df = X_test_pca_df.rename(columns={0: 'PC1', 1: 'PC2', 2: 'PC3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcdfba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.449825</td>\n",
       "      <td>0.279358</td>\n",
       "      <td>0.234651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.700948</td>\n",
       "      <td>0.316871</td>\n",
       "      <td>-0.737768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.128978</td>\n",
       "      <td>0.154381</td>\n",
       "      <td>-0.736118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.017036</td>\n",
       "      <td>-2.751136</td>\n",
       "      <td>1.307427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467184</td>\n",
       "      <td>2.007929</td>\n",
       "      <td>-0.212149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>-0.187102</td>\n",
       "      <td>-0.290673</td>\n",
       "      <td>-0.836653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>-1.932913</td>\n",
       "      <td>0.364358</td>\n",
       "      <td>0.580938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>2.029871</td>\n",
       "      <td>-2.639866</td>\n",
       "      <td>2.003639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>-2.025831</td>\n",
       "      <td>0.417065</td>\n",
       "      <td>0.824832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.202684</td>\n",
       "      <td>0.122889</td>\n",
       "      <td>-1.739665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3\n",
       "0     -1.449825  0.279358  0.234651\n",
       "1     -1.700948  0.316871 -0.737768\n",
       "2      1.128978  0.154381 -0.736118\n",
       "3      1.017036 -2.751136  1.307427\n",
       "4      0.467184  2.007929 -0.212149\n",
       "...         ...       ...       ...\n",
       "69995 -0.187102 -0.290673 -0.836653\n",
       "69996 -1.932913  0.364358  0.580938\n",
       "69997  2.029871 -2.639866  2.003639\n",
       "69998 -2.025831  0.417065  0.824832\n",
       "69999  0.202684  0.122889 -1.739665\n",
       "\n",
       "[70000 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69a914c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df = X_train_pca_df.rename(columns={0: 'PC1', 1: 'PC2', 2: 'PC3', 3: 'PC4',4: 'PC5',5: 'PC6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd002ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PC1', 'PC2', 'PC3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17bb1639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.028142</td>\n",
       "      <td>0.371506</td>\n",
       "      <td>-1.348922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.357583</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>0.639693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.616451</td>\n",
       "      <td>-1.263329</td>\n",
       "      <td>-0.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.491998</td>\n",
       "      <td>-0.379992</td>\n",
       "      <td>-1.661583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.916355</td>\n",
       "      <td>-0.873515</td>\n",
       "      <td>-1.459530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621267</th>\n",
       "      <td>0.565284</td>\n",
       "      <td>-0.213893</td>\n",
       "      <td>0.274537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621268</th>\n",
       "      <td>-0.396072</td>\n",
       "      <td>-0.542564</td>\n",
       "      <td>0.617484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621269</th>\n",
       "      <td>-0.502319</td>\n",
       "      <td>0.371023</td>\n",
       "      <td>-1.415950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621270</th>\n",
       "      <td>2.166407</td>\n",
       "      <td>0.210716</td>\n",
       "      <td>0.670903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621271</th>\n",
       "      <td>2.091302</td>\n",
       "      <td>1.720442</td>\n",
       "      <td>-0.214477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       1.028142  0.371506 -1.348922\n",
       "1      -1.357583  0.030093  0.639693\n",
       "2       1.616451 -1.263329 -0.184453\n",
       "3      -0.491998 -0.379992 -1.661583\n",
       "4       0.916355 -0.873515 -1.459530\n",
       "...          ...       ...       ...\n",
       "621267  0.565284 -0.213893  0.274537\n",
       "621268 -0.396072 -0.542564  0.617484\n",
       "621269 -0.502319  0.371023 -1.415950\n",
       "621270  2.166407  0.210716  0.670903\n",
       "621271  2.091302  1.720442 -0.214477\n",
       "\n",
       "[621272 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eedf6f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(621272, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f395d",
   "metadata": {},
   "source": [
    "## Scree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "433dbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # get the explained variance ratios\n",
    "# variance_ratio = pca_train .explained_variance_ratio_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(variance_ratio)+1), variance_ratio, 'o-', color='gray', linewidth=2)\n",
    "# plt.title('Scree Plot: Variance Explained')\n",
    "# plt.xlabel('Principal Components')\n",
    "# plt.ylabel('Proportion of Variance Explained')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d66dcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.028142</td>\n",
       "      <td>0.371506</td>\n",
       "      <td>-1.348922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.357583</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>0.639693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.616451</td>\n",
       "      <td>-1.263329</td>\n",
       "      <td>-0.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.491998</td>\n",
       "      <td>-0.379992</td>\n",
       "      <td>-1.661583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.916355</td>\n",
       "      <td>-0.873515</td>\n",
       "      <td>-1.459530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.728504</td>\n",
       "      <td>-0.740020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3\n",
       "0  1.028142  0.371506 -1.348922\n",
       "1 -1.357583  0.030093  0.639693\n",
       "2  1.616451 -1.263329 -0.184453\n",
       "3 -0.491998 -0.379992 -1.661583\n",
       "4  0.916355 -0.873515 -1.459530\n",
       "5  0.856921  0.728504 -0.740020"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84d36774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install adjustText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f483b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # create a PCA object\n",
    "# pca = PCA()\n",
    "\n",
    "# # fit the PCA object to your data\n",
    "# pca.fit(X)\n",
    "\n",
    "# # get the eigenvalues\n",
    "# eigenvalues = pca_train.explained_variance_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(eigenvalues)+1), eigenvalues, 'bo-', linewidth=2)\n",
    "# plt.title('Scree Plot')\n",
    "# plt.xlabel('Principal Component')\n",
    "# plt.ylabel('Eigenvalue')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df6ee46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # create a PCA object\n",
    "# pca = PCA()\n",
    "\n",
    "# # fit the PCA object to your data\n",
    "# pca.fit(X)\n",
    "\n",
    "# # get the eigenvalues\n",
    "# eigenvalues = pca_train.explained_variance_\n",
    "\n",
    "# # create a scree plot\n",
    "# plt.plot(np.arange(1, len(eigenvalues)+1), eigenvalues, 'o-', color='gray', linewidth=1, markersize=5)\n",
    "# plt.axhline(y=1, linestyle='--', color='black', linewidth=1)\n",
    "# plt.title('Scree Plot: PCA Eigenvalues')\n",
    "# plt.xlabel('Principal Components')\n",
    "# plt.ylabel('Eigenvalues')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a04a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    " \n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc2fec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot circle\n",
    "# #Create a list of 500 points with equal spacing between -1 and 1\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# columns=X_train_resampled_final.columns.values #Store the name of the columns for labeling\n",
    "\n",
    "# x=np.linspace(start=-1,stop=1,num=1000)\n",
    "# #Find y1 and y2 for these points\n",
    "# y_positive=lambda x: np.sqrt(1-x**2) \n",
    "# y_negative=lambda x: -np.sqrt(1-x**2)\n",
    "# plt.plot(x,list(map(y_positive, x)), color='maroon')\n",
    "# plt.plot(x,list(map(y_negative, x)),color='maroon')\n",
    "\n",
    "# #Plot smaller circle\n",
    "# x=np.linspace(start=-0.5,stop=0.5,num=500)\n",
    "# y_positive=lambda x: np.sqrt(0.5**2-x**2) \n",
    "# y_negative=lambda x: -np.sqrt(0.5**2-x**2)\n",
    "# plt.plot(x,list(map(y_positive, x)), color='maroon')\n",
    "# plt.plot(x,list(map(y_negative, x)),color='maroon')\n",
    "\n",
    "# #Create broken lines\n",
    "# x=np.linspace(start=-1,stop=1,num=30)\n",
    "# plt.scatter(x,[0]*len(x), marker='_',color='maroon')\n",
    "# plt.scatter([0]*len(x), x, marker='|',color='maroon')\n",
    "\n",
    "# pca_values=pca.components_\n",
    "# #Define color list\n",
    "# colors = ['pink', 'green','purple', 'blue','red','black']\n",
    "# if len(pca_values[0]) > 5:\n",
    "#     colors=colors*(int(len(pca_values[0])/5)+1)\n",
    "    \n",
    "#     add_string=\"\"\n",
    "#     for i in range(6):\n",
    "#         xi=pca_values[0][i]\n",
    "#         yi=pca_values[1][i]\n",
    "#         plt.arrow(0,0, \n",
    "#                   dx=xi, dy=yi, \n",
    "#                   head_width=0.03, head_length=0.03, \n",
    "#                   color=colors[i], length_includes_head=True)\n",
    "#         add_string=f\" ({round(xi,2)} {round(yi,2)})\"\n",
    "# #         plt.text(pca_values[0, i], \n",
    "# #                  pca_values[1, i] , \n",
    "# #                  s=columns[i] + add_string,\n",
    "# #                  fontsize=5)\n",
    "#         plt.text(pca_values[0, i] + 0.0, pca_values[1, i] + 0.07, s=columns[i] + add_string, fontsize=8)\n",
    "        \n",
    "# plt.xlabel(f\"Component 1 ({round(pca_train.explained_variance_ratio_[0]*100,2)}%)\")\n",
    "# plt.ylabel(f\"Component 2 ({round(pca_train.explained_variance_ratio_[1]*100,2)}%)\")\n",
    "# plt.title('Variable factor map (PCA)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f3ce5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs = X_train_pca[:,0]\n",
    "# ys = X_train_pca[:,1]\n",
    "# scalex = 1.0/(xs.max() - xs.min())\n",
    "# scaley = 1.0/(ys.max() - ys.min())\n",
    "# fig, ax = plt.subplots(figsize=(14, 9))\n",
    " \n",
    "# for i, feature in enumerate(columns):\n",
    "#     ax.arrow(0, 0, pca_train.components_[0, i], \n",
    "#              pca_train.components_[1, i])\n",
    "#     ax.text(pca_train.components_[0, i] * 1.15, \n",
    "#             pca_train.components_[1, i] * 1.15, \n",
    "#             feature, fontsize=10)\n",
    " \n",
    "#     ax.scatter(xs * scalex,ys * scaley)\n",
    " \n",
    "#     ax.set_xlabel('PC1', fontsize=10)\n",
    "#     ax.set_ylabel('PC2', fontsize=10)\n",
    "#     ax.set_title('Biplot', fontsize=15)\n",
    "#     plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca619079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the PCA components (loadings)\n",
    "# PCs = pca.components_\n",
    "\n",
    "# # Use quiver to generate the basic plot\n",
    "# fig = plt.figure(figsize=(5,5))\n",
    "# plt.quiver(np.zeros(PCs.shape[1]), np.zeros(PCs.shape[1]),\n",
    "#            PCs[0,:], PCs[1,:], \n",
    "#            angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "# # Add labels based on feature names (here just numbers)\n",
    "# feature_names = np.arange(PCs.shape[1])\n",
    "# for i,j,z in zip(PCs[1,:]+0.02, PCs[0,:]+0.02, feature_names):\n",
    "#     plt.text(j, i, z, ha='center', va='center')\n",
    "\n",
    "# # Add unit circle\n",
    "# circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "# plt.gca().add_artist(circle)\n",
    "\n",
    "# # Ensure correct aspect ratio and axis limits\n",
    "# plt.axis('equal')\n",
    "# plt.xlim([-1.0,1.0])\n",
    "# plt.ylim([-1.0,1.0])\n",
    "\n",
    "# # Label axes\n",
    "# plt.xlabel('PC 0')\n",
    "# plt.ylabel('PC 1')\n",
    "\n",
    "# # Done\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf9ba8",
   "metadata": {},
   "source": [
    "## Linear Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b085d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.linear_model import Perceptron\n",
    "\n",
    "# # Create a Perceptron object\n",
    "# clf = Perceptron(random_state=0)\n",
    "\n",
    "# # Train the Perceptron on the data\n",
    "# clf.fit(X_train_resampled_final, y_train_resampled_final)\n",
    "\n",
    "# # Predict the output classes for the data points\n",
    "# y_pred = clf.predict(X_train_resampled_final)\n",
    "\n",
    "# # Check if the Perceptron correctly classified all the data points\n",
    "# if np.all(y_pred == y_train_resampled_final):\n",
    "#     print(\"Data is linearly separable\")\n",
    "# else:\n",
    "#     print(\"Data is not linearly separable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c228282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your DataFrame is called df and the class column is called 'class'\n",
    "# class0 = df_sample[df_sample['isFraud'] == 0]\n",
    "# class1 = df_sample[df_sample['isFraud'] == 1]\n",
    "\n",
    "# s = 5\n",
    "# plt.scatter(class0['step'], class0['oldbalanceOrg'], color='blue', label='Class 0',marker='.', s=s)\n",
    "# plt.scatter(class1['step'], class1['oldbalanceOrg'], color='red', label='Class 1',marker='.', s=s)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('oldbalanceOrg')\n",
    "# plt.title('Scatter plot of two classes')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd4792f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your DataFrame is called df and the class column is called 'class'\n",
    "# class0 = df_sample[df_sample['isFraud'] == 0]\n",
    "# class1 = df_sample[df_sample['isFraud'] == 1]\n",
    "\n",
    "# s=4\n",
    "# plt.scatter(class0['step'], class0['oldbalanceOrg'], color='blue', label='Class 0',marker='.', s=s)\n",
    "# plt.scatter(class1['step'], class1['oldbalanceOrg'], color='red', label='Class',marker='.', s=s)\n",
    "\n",
    "# # Fit a linear SVM to the data\n",
    "# from sklearn.svm import SVC\n",
    "# X_new = df_sample[['step', 'oldbalanceOrg']]\n",
    "# y_new = df_sample['isFraud']\n",
    "# svm = SVC(kernel='linear')\n",
    "# svm.fit(X_new, y_new)\n",
    "\n",
    "# # Plot the decision boundary\n",
    "# w = svm.coef_[0]\n",
    "# a = -w[0] / w[1]\n",
    "# xx = np.linspace(np.min(X_new['step']), np.max(X_new['step']))\n",
    "# yy = a * xx - svm.intercept_[0] / w[1]\n",
    "# plt.plot(xx, yy, 'k-', label='Decision boundary')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('oldbalanceOrg')\n",
    "# plt.title('Scatter plot of two classes with decision boundary')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917bc01",
   "metadata": {},
   "source": [
    "## Choose 3 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b10bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.028142</td>\n",
       "      <td>0.371506</td>\n",
       "      <td>-1.348922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.357583</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>0.639693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.616451</td>\n",
       "      <td>-1.263329</td>\n",
       "      <td>-0.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.491998</td>\n",
       "      <td>-0.379992</td>\n",
       "      <td>-1.661583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.916355</td>\n",
       "      <td>-0.873515</td>\n",
       "      <td>-1.459530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621267</th>\n",
       "      <td>0.565284</td>\n",
       "      <td>-0.213893</td>\n",
       "      <td>0.274537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621268</th>\n",
       "      <td>-0.396072</td>\n",
       "      <td>-0.542564</td>\n",
       "      <td>0.617484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621269</th>\n",
       "      <td>-0.502319</td>\n",
       "      <td>0.371023</td>\n",
       "      <td>-1.415950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621270</th>\n",
       "      <td>2.166407</td>\n",
       "      <td>0.210716</td>\n",
       "      <td>0.670903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621271</th>\n",
       "      <td>2.091302</td>\n",
       "      <td>1.720442</td>\n",
       "      <td>-0.214477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       1.028142  0.371506 -1.348922\n",
       "1      -1.357583  0.030093  0.639693\n",
       "2       1.616451 -1.263329 -0.184453\n",
       "3      -0.491998 -0.379992 -1.661583\n",
       "4       0.916355 -0.873515 -1.459530\n",
       "...          ...       ...       ...\n",
       "621267  0.565284 -0.213893  0.274537\n",
       "621268 -0.396072 -0.542564  0.617484\n",
       "621269 -0.502319  0.371023 -1.415950\n",
       "621270  2.166407  0.210716  0.670903\n",
       "621271  2.091302  1.720442 -0.214477\n",
       "\n",
       "[621272 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "193e538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_df=X_test_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2dd82f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.449825</td>\n",
       "      <td>0.279358</td>\n",
       "      <td>0.234651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.700948</td>\n",
       "      <td>0.316871</td>\n",
       "      <td>-0.737768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.128978</td>\n",
       "      <td>0.154381</td>\n",
       "      <td>-0.736118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.017036</td>\n",
       "      <td>-2.751136</td>\n",
       "      <td>1.307427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467184</td>\n",
       "      <td>2.007929</td>\n",
       "      <td>-0.212149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>-0.187102</td>\n",
       "      <td>-0.290673</td>\n",
       "      <td>-0.836653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>-1.932913</td>\n",
       "      <td>0.364358</td>\n",
       "      <td>0.580938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>2.029871</td>\n",
       "      <td>-2.639866</td>\n",
       "      <td>2.003639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>-2.025831</td>\n",
       "      <td>0.417065</td>\n",
       "      <td>0.824832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.202684</td>\n",
       "      <td>0.122889</td>\n",
       "      <td>-1.739665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3\n",
       "0     -1.449825  0.279358  0.234651\n",
       "1     -1.700948  0.316871 -0.737768\n",
       "2      1.128978  0.154381 -0.736118\n",
       "3      1.017036 -2.751136  1.307427\n",
       "4      0.467184  2.007929 -0.212149\n",
       "...         ...       ...       ...\n",
       "69995 -0.187102 -0.290673 -0.836653\n",
       "69996 -1.932913  0.364358  0.580938\n",
       "69997  2.029871 -2.639866  2.003639\n",
       "69998 -2.025831  0.417065  0.824832\n",
       "69999  0.202684  0.122889 -1.739665\n",
       "\n",
       "[70000 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3b335c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df=X_train_pca_df.iloc[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "89ff3ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.028142</td>\n",
       "      <td>0.371506</td>\n",
       "      <td>-1.348922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.357583</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>0.639693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.616451</td>\n",
       "      <td>-1.263329</td>\n",
       "      <td>-0.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.491998</td>\n",
       "      <td>-0.379992</td>\n",
       "      <td>-1.661583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.916355</td>\n",
       "      <td>-0.873515</td>\n",
       "      <td>-1.459530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621267</th>\n",
       "      <td>0.565284</td>\n",
       "      <td>-0.213893</td>\n",
       "      <td>0.274537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621268</th>\n",
       "      <td>-0.396072</td>\n",
       "      <td>-0.542564</td>\n",
       "      <td>0.617484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621269</th>\n",
       "      <td>-0.502319</td>\n",
       "      <td>0.371023</td>\n",
       "      <td>-1.415950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621270</th>\n",
       "      <td>2.166407</td>\n",
       "      <td>0.210716</td>\n",
       "      <td>0.670903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621271</th>\n",
       "      <td>2.091302</td>\n",
       "      <td>1.720442</td>\n",
       "      <td>-0.214477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "0       1.028142  0.371506 -1.348922\n",
       "1      -1.357583  0.030093  0.639693\n",
       "2       1.616451 -1.263329 -0.184453\n",
       "3      -0.491998 -0.379992 -1.661583\n",
       "4       0.916355 -0.873515 -1.459530\n",
       "...          ...       ...       ...\n",
       "621267  0.565284 -0.213893  0.274537\n",
       "621268 -0.396072 -0.542564  0.617484\n",
       "621269 -0.502319  0.371023 -1.415950\n",
       "621270  2.166407  0.210716  0.670903\n",
       "621271  2.091302  1.720442 -0.214477\n",
       "\n",
       "[621272 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8913f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# #class_weights={0:1,0:75}\n",
    "# #rf_model = RandomForestClassifier(criterion='entropy', max_depth= 8, max_features='log2',n_estimators=251,oob_score=True)\n",
    "# #rf_model = RandomForestClassifier(ccp_alpha=0.01,criterion='gini', max_depth= 3, max_features='log2',n_estimators=100,oob_score=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "    \n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print classification report\n",
    "#     print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17904f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print confusion matrix\n",
    "#     print(f\"Confusion matrix for fold {fold}:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f8c0f",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c967dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# # Define the parameter space to search over\n",
    "# param_dist = {\n",
    "#     'n_estimators': randint(100, 400),\n",
    "#     'max_features': ['sqrt', 'log2','none'],\n",
    "#     'max_depth': [None] + list(range(5, 20, 5)),\n",
    "#     'min_samples_split': randint(2, 15),\n",
    "#     'min_samples_leaf': randint(1, 15),\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# # Initialize the Random Forest model\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# # Initialize the RandomizedSearchCV object\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     rf_model, \n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=10,  # Number of iterations to sample from the parameter space\n",
    "#     cv=3,  # Number of cross-validation folds to use\n",
    "# )\n",
    "\n",
    "# # Fit the RandomizedSearchCV object to the data\n",
    "# random_search.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Print the best hyperparameters and corresponding score\n",
    "# print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "# print(\"Best score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410bd4c",
   "metadata": {},
   "source": [
    "## PCA-BASED MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369863b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "n_folds = 2\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "    X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "    y_pred = rf_model.predict(X_val)\n",
    "    score = rf_model.score(X_val, y_val)\n",
    "    #print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    print(f\"Confusion matrix:\")\n",
    "    # Print confusion matrix\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(f\"Classification report:\")\n",
    "    print('---------------------')\n",
    "    # Print classification report\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    # Print the OOB score\n",
    "    #print(f\"OOB score: {rf_model.oob_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685da952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(rf_model, X_test_pca_df, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888d6ec",
   "metadata": {},
   "source": [
    "## HalfRandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.experimental import enable_halving_search_cv  # Required to enable HalvingRandomSearchCV\n",
    "# from sklearn.model_selection import HalvingRandomSearchCV\n",
    "# import numpy as np\n",
    "\n",
    "# # Create the random forest model\n",
    "# rfc = RandomForestClassifier()\n",
    "\n",
    "# # Set the hyperparameters to tune and their possible values\n",
    "# param_dist = {\n",
    "#     'n_estimators': np.arange(100, 400),\n",
    "#     'max_features': ['sqrt', 'log2','auto']\n",
    "#     'max_depth': [5, 10, 15, 20, None],\n",
    "#     'min_samples_split': [2, 5, 15],\n",
    "#     'min_samples_leaf': [2, 5, 15],\n",
    "#     'bootstrap': [True, False],\n",
    "# }\n",
    "\n",
    "# # Set up the HalvingRandomSearchCV with aggressive early stopping\n",
    "# search = HalvingRandomSearchCV(rfc, param_dist, cv=5,verbose=1, \n",
    "#                                factor=2, resource='n_samples', max_resources=100, \n",
    "#                                aggressive_elimination=True, random_state=18, \n",
    "#                                scoring='accuracy', refit=True)\n",
    "\n",
    "# # Fit the HalvingRandomSearchCV object to the data\n",
    "# search.fit(X_train_pca_df, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27fb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and evaluate on the test set\n",
    "best_params = search.best_params_\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bad5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e86b11",
   "metadata": {},
   "source": [
    "## RF-PCA Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec09298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "n_folds = 2\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "class_weights={0:15,1:70}\n",
    "rf_model = RandomForestClassifier(class_weight=class_weights)\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "start_time = time.time()\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "    X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "    \n",
    "#     # Print confusion matrix and classification report\n",
    "#     print(f\"Fold {fold+1}\")\n",
    "#     print(f\"Confusion matrix:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "#     print(f\"Classification report:\")\n",
    "#     print('---------------------')\n",
    "#     print(classification_report(y_val, y_pred))\n",
    "    \n",
    "#     # Get precision, recall, and f1 score for this fold\n",
    "#     report = classification_report(y_val, y_pred, output_dict=True)\n",
    "#     precision_list.append(report['weighted avg']['precision'])\n",
    "#     recall_list.append(report['weighted avg']['recall'])\n",
    "#     f1_list.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "\n",
    "# print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "# # Calculate average precision, recall, and f1 score across all folds\n",
    "# avg_precision = sum(precision_list) / n_folds\n",
    "# avg_recall = sum(recall_list) / n_folds\n",
    "# avg_f1 = sum(f1_list) / n_folds\n",
    "\n",
    "# print(f\"Average precision: {avg_precision}\")\n",
    "# print(f\"Average recall: {avg_recall}\")\n",
    "# print(f\"Average F1 score: {avg_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# # Load iris dataset\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# # Train a random forest classifier with 3 decision trees\n",
    "rf_model = RandomForestClassifier(n_estimators=2)\n",
    "rf_model.fit(X_train_pca_df, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# plot_tree(rf_model.estimators_[1], filled=True, ax=ax, max_depth=2, fontsize=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd19a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# n_folds = 2\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "# rf_model = RandomForestClassifier('n_estimators': 130, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 20, 'bootstrap': False)\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df.iloc[train_idx].values, y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df.iloc[val_idx].values, y_train_resampled_final[val_idx]\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "#     y_pred = rf_model.predict(X_val)\n",
    "#     y_prob = rf_model.predict_proba(X_val)[:,1] # get probability estimates for positive class\n",
    "#     score = rf_model.score(X_val, y_val)\n",
    "#     print(f\"Fold {fold}: Validation score = {score:.3f}\")\n",
    "    \n",
    "#     # Print confusion matrix\n",
    "#     print(f\"Confusion matrix for fold {fold}:\")\n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "    \n",
    "#     # Plot ROC curve\n",
    "#     fpr, tpr, thresholds = roc_curve(y_val, y_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     plt.plot(fpr, tpr, label=f\"Fold {fold} (AUC = {roc_auc:.2f})\")\n",
    "    \n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='Random guessing')\n",
    "# plt.xlabel('False positive rate')\n",
    "# plt.ylabel('True positive rate')\n",
    "# plt.title('ROC curve for Random Forest classifier')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c1abe",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2023d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define the number of splits for stratified cross-validation\n",
    "# n_splits = 2\n",
    "\n",
    "# # Initialize StratifiedKFold\n",
    "# skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# # Create lists to store evaluation metrics for each fold\n",
    "# f1_scores = []\n",
    "# recall_scores = []\n",
    "# precision_scores = []\n",
    "# accuracy_scores = []\n",
    "\n",
    "# # Create lists to store ROC curve data for each fold\n",
    "# fprs = []\n",
    "# tprs = []\n",
    "# aucs = []\n",
    "\n",
    "# # Initialize the OOB error list\n",
    "# oob_error = []\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_pca_df, y_train_resampled_final)):\n",
    "#     print(f'Fold: {fold+1}')\n",
    "    \n",
    "#     # Split the data into training and validation sets\n",
    "#     X_fold_train, y_fold_train = X_train_pca_df[train_idx], y_train_resampled_final[train_idx]\n",
    "#     X_val, y_val = X_train_pca_df[val_idx], y_train_resampled_final[val_idx]\n",
    "\n",
    "#     #class_weights={0:1,0:75}\n",
    "#     rf_model = RandomForestClassifier(criterion='entropy', max_depth= 8, max_features='log2',n_estimators=251,oob_score=True)\n",
    "#     # Fit the model on the training data\n",
    "#     rf_model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "#     # Predict the class labels for the validation set\n",
    "#     y_val_pred = rf_model.predict(X_val)\n",
    "    \n",
    "#     # Predict the class probabilities for the validation set\n",
    "#     y_val_pred_proba = rf_model.predict_proba(X_val)\n",
    "\n",
    "#     # Set the threshold\n",
    "#     threshold = 0.225\n",
    "#     # Convert the probabilities to binary predictions based on the threshold\n",
    "#     y_val_pred = (y_val_pred_proba[:,1] > threshold).astype(int)\n",
    "\n",
    "#     # Compute the evaluation metrics for the current fold\n",
    "#     conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "#     recall = recall_score(y_val, y_val_pred)\n",
    "#     accuracy = accuracy_score(y_val, y_val_pred)\n",
    "#     precision = precision_score(y_val, y_val_pred)\n",
    "#     f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "#     # Append the evaluation metrics for the current fold to the lists\n",
    "#     f1_scores.append(f1)\n",
    "#     recall_scores.append(recall)\n",
    "#     precision_scores.append(precision)\n",
    "#     accuracy_scores.append(accuracy)\n",
    "    \n",
    "#     # Compute the ROC curve and AUC for the current fold\n",
    "#     fpr, tpr, _ = roc_curve(y_val, rf_model.predict_proba(X_val)[:,1])\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "#     # Append the ROC curve data for the current fold to the lists\n",
    "#     fprs.append(fpr)\n",
    "#     tprs.append(tpr)\n",
    "#     aucs.append(roc_auc)\n",
    "\n",
    "#     # Compute the OOB error for the current fold and append to the list\n",
    "#     oob_error.append(1 - rf_model.oob_score_)\n",
    "\n",
    "#     # Print the evaluation metrics for the current fold\n",
    "#     print('Confusion matrix:\\n', conf_mat)\n",
    "#     print('Recall:', recall)\n",
    "#     #print('Accuracy:', accuracy)\n",
    "#     print('Precision:', precision)\n",
    "#     print('F1-score:', f1)\n",
    "#     print('OOB error:', 1 - rf_model.oob_score_)\n",
    "#     print('---------------------')\n",
    "    \n",
    "#     # Compute the classification report for the current fold\n",
    "#     report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "#     # Print the classification report\n",
    "#     print('Classification report:\\n', report)\n",
    "\n",
    "# # Create the ROC curve plot\n",
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# # Plot the ROC curve for each fold\n",
    "# for i in range(n_splits):\n",
    "#     ax.plot(fprs[i], tprs[i], lw=2, label='Fold %d (AUC = %0.2f)' % (i+1, aucs[i]))\n",
    "\n",
    "# # Add a dashed line representing the random guess classifier\n",
    "# ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Random guess')\n",
    "\n",
    "# # Add labels and legend to the plot\n",
    "# ax.set_xlabel('False Positive Rate')\n",
    "# ax.set_ylabel('True Positive Rate')\n",
    "# ax.set_title('Receiver Operating Characteristic')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c9809",
   "metadata": {},
   "source": [
    "## Contour plot for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4986a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "# X = X_train_pca_df.iloc[:, :2].values \n",
    "\n",
    "# # define the meshgrid\n",
    "# h = 0.02  # step size in the mesh\n",
    "# x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "# y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                      np.arange(y_min, y_max, h))\n",
    "\n",
    "# # predict the class probabilities for each meshgrid point\n",
    "# Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# # reshape the predicted probabilities into the meshgrid shape\n",
    "# Z = Z.reshape(xx.shape)\n",
    "\n",
    "# # plot the contour plot\n",
    "# plt.contourf(xx, yy, Z, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63250503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f938e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "y = y_train_resampled_final.values\n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.7, s=2)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add title and axis labels\n",
    "# add title and axis labels with smaller font size\n",
    "plt.title(\"Decision boundary with training points\", fontsize=14)\n",
    "plt.xlabel(\"PC1\", fontsize=12)\n",
    "plt.ylabel(\"PC2\", fontsize=12)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de573377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use the first 2 columns of X_train_pca_df to generate the meshgrid\n",
    "X = X_train_pca_df.iloc[:, :2].values \n",
    "y = y_train_resampled_final.values\n",
    "\n",
    "# shift the y-coordinate values of the positive class points\n",
    "X[y == 1, 1] += 1.8\n",
    "\n",
    "# define the meshgrid\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# predict the class probabilities for each meshgrid point\n",
    "Z = rf_model.predict_proba(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape)])[:, 1]\n",
    "\n",
    "# reshape the predicted probabilities into the meshgrid shape\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.7, s=2)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add title and axis labels\n",
    "plt.title(\"Decision boundary with training points\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ce2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the plot_decision_boundary function first\n",
    "# def plot_decision_boundary(pred_func):\n",
    "#     # Set min and max values and give it some padding\n",
    "#     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "#     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "#     h = 0.01\n",
    "#     # Generate a grid of points with distance h between them\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "#     # Predict the function value for the whole gid\n",
    "#     Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     # Plot the contour and training examples\n",
    "#     plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "\n",
    "# # Train the RandomForestClassifier\n",
    "# rf_model = RandomForestClassifier()\n",
    "# rf_model.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Plot the decision boundary using the plot_decision_boundary function\n",
    "# plot_decision_boundary(lambda X_train_pca_df: rf_model.predict(X_train_pca_df))\n",
    "# plt.title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define plot_decision_boundary function here...\n",
    "# def plot_decision_boundary(pred_func):\n",
    "#     # Set min and max values and give it some padding\n",
    "#     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "#     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "#     h = 0.01\n",
    "#     # Generate a grid of points with distance h between them\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "#     # Predict the function value for the whole gid\n",
    "#     Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     # Plot the contour and training examples\n",
    "#     plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "#     plt.scatter(X_train_pca_df[:, 0], X_train_pca_df[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "   \n",
    "# %matplotlib inline\n",
    "# matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "# # Train the logistic regression classifier\n",
    "# rf_model = RandomForestClassifier()\n",
    "# rf_model.fit(X_train_pca_df, y_train_resampled_final)\n",
    "\n",
    "# # Plot decision boundary\n",
    "# #plot_decision_boundary(lambda x: rf_model.predict(x))\n",
    "# plot_decision_boundary(lambda x: rf_model.predict(x), X_train_pca_df.iloc[:, :2].values)\n",
    "# plt.title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68e29c",
   "metadata": {},
   "source": [
    "## Bubble Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e40639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample data frame\n",
    "df = pd.DataFrame({\n",
    "    'Model Name': ['Model 1', 'Model 1', 'Model 1', 'Model 2', 'Model 2', 'Model 2', 'Model 3', 'Model 3', 'Model 3'],\n",
    "    'Dataset Size': ['Small', 'Medium', 'Large', 'Small', 'Medium', 'Large', 'Small', 'Medium', 'Large'],\n",
    "    'Performance Value': [5, 0.9, 0.9, 0.7, 7, 9, 0.6, 1, 15]\n",
    "})\n",
    "\n",
    "# Define bubble sizes and colors\n",
    "bubble_sizes = df['Performance Value'] * 100\n",
    "bubble_colors = df['Performance Value']\n",
    "\n",
    "# Group the data by Model Name\n",
    "groups = df.groupby('Model Name')\n",
    "\n",
    "# Create a scatter plot for each group\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for name, group in groups:\n",
    "    ax.scatter(group['Dataset Size'], [name] * len(group), s=bubble_sizes.loc[group.index], c=bubble_colors.loc[group.index], alpha=0.5, label=name)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Dataset Size')\n",
    "ax.set_ylabel('Model Name')\n",
    "ax.set_title('Model Performance')\n",
    "\n",
    "# Add color bar and legend\n",
    "sm = plt.cm.ScalarMappable(cmap='RdYlGn', norm=plt.Normalize(vmin=bubble_colors.min(), vmax=bubble_colors.max()))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.ax.set_ylabel('Performance Value')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8157658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define the parameters for the learning curve\n",
    "# train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "# cv = 2  # number of cross-validation folds\n",
    "\n",
    "# # Generate the learning curve data\n",
    "# train_sizes, train_scores, val_scores = learning_curve(\n",
    "#     rf_model, X_train_pca_df, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    "# )\n",
    "\n",
    "# # Calculate the mean and standard deviation of the training and validation scores\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# val_scores_mean = np.mean(val_scores, axis=1)\n",
    "# val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Misclassification Error\")\n",
    "# plt.grid()\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (train_scores_mean + train_scores_std),\n",
    "#     1 - (train_scores_mean - train_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"r\",\n",
    "# )\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (val_scores_mean + val_scores_std),\n",
    "#     1 - (val_scores_mean - val_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"g\",\n",
    "# )\n",
    "# plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "# plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6532ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set up the data\n",
    "# training_samples = [23000, 73000, 124000, 162500, 220000]\n",
    "# cv_errors = [0.30, 0.30, 0.24, 0.075, 0.043]\n",
    "# training_errors = [0.27, 0.16, 0.05, 0.025,  0.025]\n",
    "\n",
    "# # Create the plot and set the grid\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.grid(True)\n",
    "\n",
    "# # Plot the data points as dots\n",
    "# # ax.plot(training_samples, cv_errors, 'o', color='green', label='Cross Validation Error')\n",
    "# # ax.plot(training_samples, training_errors, 'o', color='red', label='Training Error')\n",
    "\n",
    "# # Plot the lines connecting the dots with different colors and line styles\n",
    "# ax.plot(training_samples, cv_errors, color='green', linestyle='-', marker='o', label='Cross Validation Error')\n",
    "# ax.plot(training_samples, training_errors, color='red', linestyle='-', marker='o', label='Training Error')\n",
    "\n",
    "# # Set the axis labels and title\n",
    "# ax.set_xlabel('Training examples')\n",
    "# ax.set_ylabel('Miscalssification Error')\n",
    "# ax.set_title('Learning Curve')\n",
    "\n",
    "# # Add a legend\n",
    "# ax.legend()\n",
    "# plt.legend(loc=\"best\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a0029",
   "metadata": {},
   "source": [
    "## Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c39c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "# from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 6), sharey=True)\n",
    "\n",
    "# common_params = {\n",
    "#     \"X\": X_train_pca,\n",
    "#     \"y\": y_train_resampled_final,\n",
    "#     \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "#     \"cv\": KFold(n_splits=2, shuffle=True),\n",
    "#     \"score_type\": \"both\",\n",
    "#     \"line_kw\": {\"marker\": \"o\"},\n",
    "#     \"std_display_style\": \"fill_between\",\n",
    "#     \"score_name\": \"neg_log_loss\",\n",
    "# }\n",
    "\n",
    "# estimator = rf_model\n",
    "# LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax)\n",
    "# handles, label = ax.get_legend_handles_labels()\n",
    "# ax.legend(handles[:2], [\"Training Score\", \"Cross alidation Score\"])\n",
    "# ax.set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8008524",
   "metadata": {},
   "source": [
    "## Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d88ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#class_weights={0:1,0:75}\n",
    "    # Create a RandomForestClassifier object with the given hyperparameters\n",
    "#rf_model = RandomForestClassifier(max_features='sqrt',n_estimators=121,oob_score=True,class_weight=class_weights,random_state=1)\n",
    "clf = lgb.LGBMClassifier(objective='binary', metric='binary_logloss')\n",
    "\n",
    "train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "train_loss = []\n",
    "cv_loss = []\n",
    "    \n",
    "for size in train_sizes:\n",
    "    # Split the data into training and cross-validation sets\n",
    "    X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_pca_df, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    clf .fit(X_train_new, y_train_new)\n",
    "    \n",
    "    # Compute the cross-entropy loss on the training set\n",
    "    y_train_pred = clf .predict_proba(X_train_pca_df)\n",
    "    train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "    # Compute the cross-entropy loss on the cross-validation set\n",
    "    y_cv_pred = clf .predict_proba(X_cv)\n",
    "    cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.tree import export_graphviz\n",
    "# from IPython.display import Image\n",
    "# import pydotplus\n",
    "\n",
    "# # Visualize a decision tree from the random forest\n",
    "# tree = rf_model.estimators_[0]\n",
    "# export_graphviz(tree, out_file='tree.dot', feature_names=['newbalanceDest', 'step', 'nameDest', 'newbalanceOrig'], class_names=['class_0', 'class_1'], filled=True, rounded=True)\n",
    "\n",
    "# # Convert the .dot file to .png\n",
    "# graph = pydotplus.graph_from_dot_file('tree.dot')\n",
    "# graph.write_png('tree.png')\n",
    "\n",
    "# # Display the decision tree\n",
    "# Image(filename='tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve\n",
    "# # Get predicted probabilities for the test data\n",
    "# y_prob = rf_model.predict_proba(X_test_pca)[:,1]\n",
    "\n",
    "# # Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "# thresholds = np.arange(0.1,30,0.01)\n",
    "# precision_scores = []\n",
    "# recall_scores = []\n",
    "# f1_scores = []\n",
    "\n",
    "# for threshold in thresholds:\n",
    "#     y_pred = (y_prob >= threshold).astype(int)\n",
    "#     precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     precision_scores.append(precision[1])\n",
    "#     recall_scores.append(recall[1])\n",
    "#     f1_scores.append(f1[1])\n",
    "\n",
    "# # Find the optimal threshold that maximizes the F1-score\n",
    "# optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# # Assign the class labels based on the optimal threshold\n",
    "# y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# # Evaluate the performance of the classifier for the optimal threshold\n",
    "# confusion_matrix(y_test, y_pred)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64528a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Get predicted probabilities for the test data\n",
    "# y_prob = rf_model.predict_proba(X_test_pca)[:,1]\n",
    "\n",
    "# # Assign the class labels based on the optimal threshold\n",
    "# optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "# y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# # Print classification report on the test set\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ba105",
   "metadata": {},
   "source": [
    "## Partial dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_partial_dependence(rf_model, X_train_pca_df, features=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fab4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['newbalanceDest', 'oldbalanceOrg','nameDest']  # or ['feat1', 'feat2', 'feat3']\n",
    "# plot_partial_dependence(rf_model, X_train_pca, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef257a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [0, 1, 2] # Indices of the features in X_train_pca\n",
    "# feature_names = ['newbalanceDest', 'oldbalanceOrg', 'nameDest'] # Names of the features\n",
    "\n",
    "# plot_partial_dependence(rf_model, X_train_pca, features=features, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38890561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import partial_dependence\n",
    "# from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# # Compute partial dependence values for the feature 'feature_name'\n",
    "# pdp, axes = partial_dependence(rf_model,X_train_pca_df, feature_name='PC1')\n",
    "\n",
    "# # Create a partial dependence plot for the feature 'feature_name'\n",
    "# display = PartialDependenceDisplay.from_feature_values(feature_values=X[:, feature_index], \n",
    "#                                                        pdp_values=pdp, \n",
    "#                                                        feature_name='PC1')\n",
    "\n",
    "# # Plot the partial dependence plot\n",
    "# display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# Compute partial dependence values for the first principal component\n",
    "pdp, axes = partial_dependence(rf_model, X_train_pca_df, features=[0])\n",
    "\n",
    "# Create a partial dependence plot for the first principal component\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(axes[0], pdp[0])\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('Predicted Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937145c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "\n",
    "# X_train_pca_df = pd.DataFrame(X_train_pca, columns=[f\"PC{i+1}\" for i in range(pca_train.n_components_)])\n",
    "\n",
    "\n",
    "# # Generate PDPs for the principal components\n",
    "# fig, axs = plot_partial_dependence(clf, X_train_pca_df, features=range(pca_train.n_components_), grid_resolution=50)\n",
    "\n",
    "# # Compute the contribution of each original feature to each PC\n",
    "# pc_contributions = pca_train.components_\n",
    "\n",
    "# # Map the PDPs back to the original features\n",
    "# values = np.array(axs.pd_results_[0]['values'])\n",
    "# contributions = np.matmul(pc_contributions.T, values.T)\n",
    "# effects = np.sum(contributions.T, axis=1)\n",
    "# feature_effects = pd.DataFrame({'Feature': X_train_resampled_final.columns, 'Effect': effects})\n",
    "# for feature_name in X_train.columns:\n",
    "#     fig, ax = plt.subplots()\n",
    "#     pdp_values = axs.pd_results_[feature_name]['average']\n",
    "#     ax.plot(values[:, feature_name], pdp_values)\n",
    "#     ax.set_xlabel(feature_name)\n",
    "#     ax.set_ylabel('Predicted Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# # Choose the features to generate partial dependence plots for\n",
    "# features = [0,1,2]\n",
    "\n",
    "# # Generate partial dependence plots for the specified features\n",
    "# pdp_display = PartialDependenceDisplay.from_estimator(rf_model, X_train_pca_df, features)\n",
    "\n",
    "# # Display the PDP plots\n",
    "# pdp_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf59a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "# # Generate PDPs for the principal components\n",
    "# pdp_display = plot_partial_dependence(clf, X_train_pca_df, features=range(pca_train.n_components_), grid_resolution=50)\n",
    "\n",
    "# # Display the PDP plot\n",
    "# pdp_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b864889",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca15f9",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e885ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Define the hyperparameter space to search over\n",
    "param_dist = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "    'num_leaves': sp_randint(6, 50),\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': sp_randint(50, 200),\n",
    "    'max_depth': sp_randint(3, 15),\n",
    "    'min_child_samples': sp_randint(10, 50),\n",
    "    'min_split_gain': [0, 0.01, 0.1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c9d1f",
   "metadata": {},
   "source": [
    "### HalvingRandomSeacrhCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9326c217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HalvingRandomSearchCV(estimator=LGBMClassifier(), factor=2, max_resources=100,\n",
       "                      param_distributions={'boosting_type': ['gbdt', 'dart',\n",
       "                                                             'goss'],\n",
       "                                           'learning_rate': [0.05, 0.1, 0.2],\n",
       "                                           'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023B9002A9C8>,\n",
       "                                           'min_child_samples': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023B900897C8>,\n",
       "                                           'min_split_gain': [0, 0.01, 0.1, 1],\n",
       "                                           'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023B8C7D4108>,\n",
       "                                           'num_leaves': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023B9003E9C8>},\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Define the hyperparameter space to search over\n",
    "param_dist = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "    'num_leaves': sp_randint(6, 50),\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': sp_randint(50, 200),\n",
    "    'max_depth': sp_randint(3, 15),\n",
    "    'min_child_samples': sp_randint(10, 50),\n",
    "    'min_split_gain': [0, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "# Define the estimator object\n",
    "estimator = lgb.LGBMClassifier()\n",
    "\n",
    "# Instantiate a HalvingRandomSearchCV object\n",
    "halving_cv = HalvingRandomSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_distributions=param_dist,\n",
    "    factor=2,\n",
    "    resource='n_samples',\n",
    "    max_resources=100,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the HalvingRandomSearchCV object to the training data\n",
    "halving_cv.fit(X_train_pca, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d77b03b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'learning_rate': 0.05, 'max_depth': 14, 'min_child_samples': 31, 'min_split_gain': 0, 'n_estimators': 138, 'num_leaves': 32}\n"
     ]
    }
   ],
   "source": [
    "print(halving_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ad727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the LightGBM model\n",
    "# lgb_model = lgb.LGBMClassifier(objective='binary')\n",
    "\n",
    "# # Perform the hyperparameter search using RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(lgb_model, param_distributions=param_dist, cv=3, n_iter=15,\n",
    "#                                    scoring='roc_auc', verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48099ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the random search to the training data\n",
    "# random_search.fit(X_train_pca, y_train_resampled_final)\n",
    "\n",
    "# # Print the best hyperparameters found\n",
    "# print('Best hyperparameters: ', random_search.best_params_)\n",
    "\n",
    "# # Get the best LightGBM model\n",
    "# best_lgb_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the best model on the test set\n",
    "# y_pred = best_lgb_model.predict(X_test_pca)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8539a96",
   "metadata": {},
   "source": [
    "## Model Training LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define the LightGBM classifier\n",
    "# clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate=0.2, max_depth= 11, min_child_samples= 33, min_split_gain= 0, n_estimators= 185, num_leaves= 29)\n",
    "\n",
    "# # Define the cross-validation method\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X_train_resampled_final, y_train_resampled_final)):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_fold_train, y_fold_train = X_train_resampled_final.iloc[train_index],  y_train_resampled_final.iloc[train_index]\n",
    "#     X_fold_test, y_fold_test = X_train_resampled_final.iloc[test_index],  y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "#     # Train the LightGBM classifier\n",
    "#     clf.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13bdb64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[306171   4069]\n",
      " [   337     59]]\n",
      "Fold 0:\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    310240\n",
      "           1       0.01      0.15      0.03       396\n",
      "\n",
      "    accuracy                           0.99    310636\n",
      "   macro avg       0.51      0.57      0.51    310636\n",
      "weighted avg       1.00      0.99      0.99    310636\n",
      "\n",
      "Confusion matrix:\n",
      "[[309140   1100]\n",
      " [   335     61]]\n",
      "Fold 1:\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    310240\n",
      "           1       0.05      0.15      0.08       396\n",
      "\n",
      "    accuracy                           1.00    310636\n",
      "   macro avg       0.53      0.58      0.54    310636\n",
      "weighted avg       1.00      1.00      1.00    310636\n",
      "\n",
      "Total runtime: 4.62 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Define the LightGBM classifier\n",
    "clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate= 0.05, max_depth= 14, min_child_samples= 22, min_split_gain= 0, n_estimators= 100, num_leaves= 37, scale_pos_weight=15, objective='binary', metric='binary_logloss')\n",
    "\n",
    "# Define the cross-validation method\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df, y_train_resampled_final)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_fold_train, y_fold_train = X_train_pca_df.iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "    X_fold_test, y_fold_test = X_train_pca_df.iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "    # Train the LightGBM classifier\n",
    "    clf.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Evaluate the performance of the model on the testing data\n",
    "    y_pred = clf.predict(X_fold_test)\n",
    "    report = classification_report(y_fold_test, y_pred)\n",
    "    cm = confusion_matrix(y_fold_test, y_pred)\n",
    "    print(f\"Confusion matrix:\\n{cm}\")\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"Classification report:\\n{report}\")\n",
    "\n",
    "    # Evaluate the performance of the model on the testing data\n",
    "    y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "    fpr, tpr, thresholds = roc_curve(y_fold_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'Fold {fold} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "\n",
    "# Plot the random classifier\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for LightGBM Classifier')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802ce91",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2bd106eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[69659   253]\n",
      " [   73    15]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     69912\n",
      "           1       0.06      0.17      0.08        88\n",
      "\n",
      "    accuracy                           1.00     70000\n",
      "   macro avg       0.53      0.58      0.54     70000\n",
      "weighted avg       1.00      1.00      1.00     70000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = clf.predict(X_test_pca_df)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Compute the classification report, including recall, precision, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "04dc9716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[69659   253]\n",
      " [   73    15]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     69912\n",
      "           1       0.06      0.17      0.08        88\n",
      "\n",
      "    accuracy                           1.00     70000\n",
      "   macro avg       0.53      0.58      0.54     70000\n",
      "weighted avg       1.00      1.00      1.00     70000\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ConfusionMatrixDisplay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16696\\2274229236.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Define the display object for the confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Negative\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Positive\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Plot the confusion matrix with colors and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ConfusionMatrixDisplay' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = clf.predict(X_test_pca_df)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Compute the classification report, including recall, precision, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\")\n",
    "print(report)\n",
    "\n",
    "# Define the display object for the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "\n",
    "# Plot the confusion matrix with colors and labels\n",
    "disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal', values_format=None)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ae1df45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_test_prob = clf.predict_proba(X_test_pca_df)[:, 1]\n",
    "\n",
    "# Calculate the false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "\n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label=f'Test Set (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for LightGBM Classifier')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21baab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [10,25,35],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedeef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(lgb_model, param_grid, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe977af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.fit(X_train_pca, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6125a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best params:\", grid_search.best_params_)\n",
    "# print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20869ac6",
   "metadata": {},
   "source": [
    "## Convert to PCA elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414eac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_pca_df = pd.DataFrame(X_train_pca, columns=['PC1', 'PC2', 'PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2217cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# import warnings\n",
    "\n",
    "# # Ignore all warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# # Define the LightGBM classifier\n",
    "# #clf = lgb.LGBMClassifier(boosting_type= 'gbdt', learning_rate= 0.2, max_depth= 11, min_child_samples= 13, min_split_gain= 0, n_estimators= 185, num_leaves= 10, objective='binary', metric='binary_logloss')\n",
    "# #clf = lgb.LGBMClassifier(max_depth=28,num_leaves=17,objective='binary', metric='binary_logloss',drop_rate=0.225)\n",
    "# class_weights={0:1,1:30}\n",
    "# clf = lgb.LGBMClassifier(learning_rate=0.05,max_depth=10,num_leaves=15,data_sample_strategy='goss',boosting_type='gbdt',objective='binary', metric='binary_logloss',class_weight=class_weights)\n",
    "\n",
    "# # Define the cross-validation method\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# # Iterate over each fold\n",
    "# for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df , y_train_resampled_final)):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_fold_train, y_fold_train =X_train_pca_df .iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "#     X_fold_test, y_fold_test = X_train_pca_df .iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "#     # Train the LightGBM classifier with early stopping\n",
    "#     clf.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_test, y_fold_test)], early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred = clf.predict(X_fold_test)\n",
    "#     report = classification_report(y_fold_test, y_pred)\n",
    "#     cm = confusion_matrix(y_fold_test, y_pred)\n",
    "#     print(f\"Confusion matrix:\\n{cm}\")\n",
    "#     print(f\"Fold {fold}:\")\n",
    "#     print(f\"Classification report:\\n{report}\")\n",
    "\n",
    "#     # Evaluate the performance of the model on the testing data\n",
    "#     y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "#     fpr, tpr, thresholds = roc_curve(y_fold_test, y_pred_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     # Plot the ROC curve\n",
    "#     plt.plot(fpr, tpr, label=f'Fold {fold} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# # Plot the random classifier\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--', label='Random Classifier')\n",
    "\n",
    "# # Add labels and legend\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve for LightGBM Classifier')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e12ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first tree\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ac36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Plot the first tree\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95173c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define graph and node attributes with desired color scheme\n",
    "graph_attr = {'size': '50,50', 'dpi': '100', 'bgcolor': 'white', 'rankdir': 'TB', 'splines': 'ortho'}\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '1.2', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Plot the first tree with color\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], graph_attr=graph_attr, node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Define node attributes with desired color scheme\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '0.4', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Set leaf node color to green\n",
    "node_attr['fillcolor'] = 'green'\n",
    "\n",
    "# Plot the first tree with colored leaf nodes\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20277109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and DPI\n",
    "fig, ax = plt.subplots(figsize=(50,50), dpi=100)\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Define node attributes with desired color scheme\n",
    "node_attr = {'shape': 'box', 'style': 'filled', 'fillcolor': '#ffffff', 'color': 'black', 'penwidth': '1.2', 'fontname': 'Arial', 'fontsize': '10'}\n",
    "\n",
    "# Set leaf node color to green\n",
    "node_attr['fillcolor'] = 'green'\n",
    "\n",
    "# Plot the first tree with colored leaf nodes\n",
    "lgb.plot_tree(clf, tree_index=0, ax=ax, show_info=['split_gain', 'internal_value', 'internal_count'], node_attr=node_attr)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f3c8e",
   "metadata": {},
   "source": [
    "## Misclassification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e327599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Define the parameters for the learning curve\n",
    "# train_sizes = np.linspace(0.1, 1.0, 5)\n",
    "# cv = 2  # number of cross-validation folds\n",
    "\n",
    "# # Generate the learning curve data\n",
    "# train_sizes, train_scores, val_scores = learning_curve(\n",
    "#     clf, X_train_pca, y_train_resampled_final, train_sizes=train_sizes, cv=cv\n",
    "# )\n",
    "\n",
    "# # Calculate the mean and standard deviation of the training and validation scores\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# val_scores_mean = np.mean(val_scores, axis=1)\n",
    "# val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Misclassification Error\")\n",
    "# plt.grid()\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (train_scores_mean + train_scores_std),\n",
    "#     1 - (train_scores_mean - train_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"r\",\n",
    "# )\n",
    "# plt.fill_between(\n",
    "#     train_sizes,\n",
    "#     1 - (val_scores_mean + val_scores_std),\n",
    "#     1 - (val_scores_mean - val_scores_std),\n",
    "#     alpha=0.1,\n",
    "#     color=\"g\",\n",
    "# )\n",
    "# plt.plot(train_sizes, 1 - train_scores_mean, \"o-\", color=\"r\", label=\"Training error\")\n",
    "# plt.plot(train_sizes, 1 - val_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation error\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7f5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_sizes = [23000, 73000, 124000, 172000, 220000]\n",
    "# # Train your model on different sizes of training sets and record the cross-entropy loss for each size\n",
    "# train_loss = []\n",
    "# cv_loss = []\n",
    "    \n",
    "# for size in train_sizes:\n",
    "#     # Split the data into training and cross-validation sets\n",
    "#     X_train_new, X_cv, y_train_new, y_cv = train_test_split(X_train_pca_df, y_train_resampled_final, train_size=size)\n",
    "    \n",
    "#     # Train the model on the training set\n",
    "#     clf.fit(X_train_new, y_train_new)\n",
    "    \n",
    "#     # Compute the cross-entropy loss on the training set\n",
    "#     y_train_pred = clf.predict_proba(X_train_pca_df)\n",
    "#     train_loss.append(log_loss(y_train_resampled_final, y_train_pred))\n",
    "    \n",
    "#     # Compute the cross-entropy loss on the cross-validation set\n",
    "#     y_cv_pred = clf.predict_proba(X_cv)\n",
    "#     cv_loss.append(log_loss(y_cv, y_cv_pred))\n",
    "\n",
    "# # Plot the learning curve\n",
    "# plt.plot(train_sizes, train_loss, label='Training Loss')\n",
    "# plt.plot(train_sizes, cv_loss, label='Cross-Validation Loss')\n",
    "# plt.xlabel('Training Set Size')\n",
    "# plt.ylabel('Cross-Entropy Loss')\n",
    "# plt.title('Learning Curve')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(clf, X_train_pca, y_train_resampled_final, cv=5)\n",
    "\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b5fed",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df40499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "# Get predicted probabilities for the test data\n",
    "y_prob = clf.predict_proba(X_test_pca_df)[:,1]\n",
    "\n",
    "# Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "thresholds = np.arange(0.1,30,0.1)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    precision_scores.append(precision[1])\n",
    "    recall_scores.append(recall[1])\n",
    "    f1_scores.append(f1[1])\n",
    "\n",
    "# Find the optimal threshold that maximizes the F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Assign the class labels based on the optimal threshold\n",
    "y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the performance of the classifier for the optimal threshold\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the class labels and probabilities for the test set\n",
    "y_test_pred = clf.predict(X_test_pca_df)\n",
    "y_test_prob = clf.predict_proba(X_test_pca_df)[:, 1]\n",
    "# Compute the false positive rate, true positive rate, and AUC for the test set\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_prob)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "# Plot the ROC curve for the test set\n",
    "plt.plot(fpr_test, tpr_test, color='blue', lw=2, label='Test ROC curve (AUC =%0.2f)' % roc_auc_test)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Test Set')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the precision, recall, and F1-score for each threshold\n",
    "print(\"Threshold\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(len(thresholds)):\n",
    "    print(f\"{thresholds[i]:.1f}\\t\\t{precision_scores[i]:.3f}\\t\\t{recall_scores[i]:.3f}\\t\\t{f1_scores[i]:.3f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Print the optimal threshold and the corresponding F1-score\n",
    "print(f\"\\nOptimal Threshold: {optimal_threshold:.1f}\")\n",
    "print(f\"Optimal F1-Score: {max(f1_scores):.3f}\")\n",
    "print(f\"Optimal Recall: {max(recall_scores):.3f}\")\n",
    "print(f\"Optimal Precision: {max(precision_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061d019",
   "metadata": {},
   "source": [
    "## Performance Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d8946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.529, 0.404, 0.448]\n",
    "# recalls = [0.784, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['f1-score', 'recall', 'precision']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#635f83'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='Default', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='RandomizedSearchCV', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='HalvingRandomSearchCV', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.529, 0.404, 0.448]\n",
    "# recalls = [0.784, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['Default', 'RandomizedSearchCV', 'HalvingRandomSearchCV']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#c7e9b8'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='f1-score', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='recall', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='precision', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "default_scores = [0.529, 0.404, 0.448]\n",
    "randomized_scores = [0.610, 0.596, 0.565]\n",
    "metrics = ['f1-score', 'recall', 'precision']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "# Set the colors for the bars\n",
    "default_colors = ['#c5d3ff', '#c5d3ff', '#c5d3ff']\n",
    "randomized_colors = ['#e9c6b8', '#e9c6b8', '#e9c6b8']\n",
    "\n",
    "# Create the figure and axes objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars for each hyperparameter search method with the specified colors\n",
    "ax.bar(x - width/2, default_scores, width, label='Default', color=default_colors, edgecolor='black')\n",
    "ax.bar(x + width/2, randomized_scores, width, label='RandomizedSearchCV', color=randomized_colors, edgecolor='black')\n",
    "\n",
    "# Add some labels and a legend\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(title='Hyperparameters used',bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "default_scores = [0.529, 0.732, 1]\n",
    "randomized_scores = [0.610, 0.834, 1]\n",
    "metrics = ['f1-score', 'recall', 'precision']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.4\n",
    "\n",
    "# Set the colors for the bars\n",
    "default_colors = ['#c5d3ff', '#c5d3ff', '#c5d3ff']\n",
    "randomized_colors = ['#e9c6b8', '#e9c6b8', '#e9c6b8']\n",
    "\n",
    "# Create the figure and axes objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars for each hyperparameter search method with the specified colors\n",
    "ax.bar(x - width/2, default_scores, width, label='Default', color=default_colors, edgecolor='black')\n",
    "ax.bar(x + width/2, randomized_scores, width, label='RandomizedSearchCV', color=randomized_colors, edgecolor='black')\n",
    "\n",
    "# Add the values on each bar\n",
    "for i, v in enumerate(default_scores):\n",
    "    ax.text(i - width/2, v + 0.02, str(v), color='black', ha='center')\n",
    "for i, v in enumerate(randomized_scores):\n",
    "    ax.text(i + width/2, v + 0.02, str(v), color='black', ha='center')\n",
    "\n",
    "# Add some labels and a legend\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_title('Scores by Metric and Hyperparameter Search Method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(title='Hyperparameters used',bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Define the data\n",
    "# f1_scores = [0.603, 0.404, 0.448]\n",
    "# recalls = [0.854, 0.818, 0.830]\n",
    "# precisions = [1, 1, 1]\n",
    "\n",
    "# # Set the x-axis labels and positions\n",
    "# labels = ['Default', 'RandomizedSearchCV', ' HalvingRandomSearchCV']\n",
    "# x = np.arange(len(labels))\n",
    "\n",
    "# # Set the width of each bar\n",
    "# width = 0.2\n",
    "\n",
    "# # Create a gradient color for the bars\n",
    "# colors = mcolors.LinearSegmentedColormap.from_list('my_colors', ['#c5d3ff', '#e9c6b8', '#635f83'])(np.linspace(0, 1, len(x)))\n",
    "\n",
    "# # Create the figure and axes objects\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Plot the bars for each hyperparameter search method with the gradient color and border\n",
    "# ax.bar(x - width, f1_scores, width, label='f1-score', color=colors[0], edgecolor='black')\n",
    "# ax.bar(x, recalls, width, label='recall', color=colors[1], edgecolor='black')\n",
    "# ax.bar(x + width, precisions, width, label='precision', color=colors[2], edgecolor='black')\n",
    "\n",
    "# # Add score values on top of each bar\n",
    "# for i, (score1, score2, score3) in enumerate(zip(f1_scores, recalls, precisions)):\n",
    "#     ax.text(x[i] - width, score1 + 0.01, str(score1), ha='center', va='bottom', fontweight='bold')\n",
    "#     ax.text(x[i], score2 + 0.01, str(score2), ha='center', va='bottom', fontweight='bold')\n",
    "#     ax.text(x[i] + width, score3 + 0.01, str(score3), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# # Add some labels and a legend\n",
    "# ax.set_ylabel('Score')\n",
    "# ax.set_title('Scores by Hyperparameter and Metric')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87793743",
   "metadata": {},
   "source": [
    "## LightGBM New trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c015c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#class_weights={0:1,1:30}\n",
    "# Define the LightGBM classifier\n",
    "#clf = lgb.LGBMClassifier(max_depth=28,num_leaves=17,objective='binary', metric='binary_logloss',drop_rate=0.225,class_weight=class_weights)\n",
    "clf = lgb.LGBMClassifier(objective='binary', metric='binary_logloss')\n",
    "# Define the cross-validation method\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# Create an empty list to store the optimized thresholds for each fold\n",
    "optimized_thresholds = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X_train_pca_df , y_train_resampled_final)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_fold_train, y_fold_train =X_train_pca_df .iloc[train_index], y_train_resampled_final.iloc[train_index]\n",
    "    X_fold_test, y_fold_test = X_train_pca_df .iloc[test_index], y_train_resampled_final.iloc[test_index]\n",
    "\n",
    "    # Train the LightGBM classifier with early stopping\n",
    "    clf.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_test, y_fold_test)], early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "    # Evaluate the performance of the model on the testing data\n",
    "    y_pred_prob = clf.predict_proba(X_fold_test)[:, 1] # predicted probabilities for class 1\n",
    "    \n",
    "    # Create an empty dictionary to store the F1-scores for each threshold\n",
    "    f1_scores = {}\n",
    "    \n",
    "    # Iterate through a range of possible threshold values\n",
    "    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        # Convert the predicted probabilities to predicted labels based on the threshold\n",
    "        y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate the classification report and select the threshold that maximizes the F1-score\n",
    "        report = classification_report(y_fold_test, y_pred, output_dict=True)\n",
    "        f1_scores[threshold] = report['1']['f1-score']\n",
    "    \n",
    "    # Select the threshold that maximizes the F1-score\n",
    "    optimized_threshold = max(f1_scores, key=f1_scores.get)\n",
    "    optimized_thresholds.append(optimized_threshold)\n",
    "    \n",
    "    # Convert the predicted probabilities to predicted labels based on the optimized threshold\n",
    "    y_pred = (y_pred_prob >= optimized_threshold).astype(int)\n",
    "    \n",
    "    # Calculate the classification report and confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eec368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_set_size = [25000, 50000, 75000, 100000, 125000, 150000, 175000, 200000, 225000]\n",
    "training_loss = [0.253, 0.250, 0.247, 0.246, 0.2455, 0.245, 0.245, 0.245, 0.245]\n",
    "cv_loss = [0.255, 0.252, 0.249, 0.2475, 0.247, 0.2465, 0.246, 0.2458, 0.2458]\n",
    "\n",
    "plt.plot(training_set_size, training_loss, label='Training Loss')\n",
    "plt.plot(training_set_size, cv_loss, label='Cross-Validation Loss')\n",
    "\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Learing Curve')\n",
    "plt.ylim(0.244, 0.256) # Set the y-axis limits\n",
    "plt.yticks([0.244, 0.246, 0.248, 0.25, 0.252, 0.254, 0.256]) # Set the y-axis tick labels\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
