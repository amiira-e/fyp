{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d48efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff27a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0639b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of column 'A' from float64 to float32\n",
    "df['amount'] = df['amount'].astype('float32')\n",
    "df['oldbalanceOrg'] = df['oldbalanceOrg'].astype('float32')\n",
    "df['oldbalanceDest'] = df['oldbalanceDest'].astype('float32')\n",
    "df['newbalanceOrig'] = df['newbalanceOrig'].astype('float32')\n",
    "df['newbalanceDest'] = df['newbalanceDest'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e47aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['step'] = df['step'].astype('int32')\n",
    "df['isFlaggedFraud'] = df['isFlaggedFraud'].astype('int32') \n",
    "df['isFraud'] = df['isFraud'].astype('int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c635c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder from Sklearn\n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['nameDest'])\n",
    "# printing label\n",
    "label\n",
    "# removing the column 'type' from df\n",
    "# as it is of no use now.\n",
    "df.drop(\"nameDest\", axis=1, inplace=True)\n",
    "# Appending the array to our dataFrame\n",
    "# with column name 'type'\n",
    "df[\"nameDest\"] = label\n",
    "# printing Dataframe\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23413d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder from Sklearn\n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['type'])\n",
    "# printing label\n",
    "label\n",
    "# removing the column 'type' from df\n",
    "# as it is of no use now.\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "# Appending the array to our dataFrame\n",
    "# with column name 'type'\n",
    "df[\"type\"] = label\n",
    "# printing Dataframe\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cffa4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameOrig'])\n",
    "label\n",
    "df.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df[\"nameOrig\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce59670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>type</th>\n",
       "      <th>nameOrig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9839.639648</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.359375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1662094</td>\n",
       "      <td>3</td>\n",
       "      <td>757869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1864.280029</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.720703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1733924</td>\n",
       "      <td>3</td>\n",
       "      <td>2188998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>439685</td>\n",
       "      <td>4</td>\n",
       "      <td>1002156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>391696</td>\n",
       "      <td>1</td>\n",
       "      <td>5828262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11668.139648</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.859375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>828919</td>\n",
       "      <td>3</td>\n",
       "      <td>3445981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step        amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "0     1   9839.639648       170136.0   160296.359375             0.0   \n",
       "1     1   1864.280029        21249.0    19384.720703             0.0   \n",
       "2     1    181.000000          181.0        0.000000             0.0   \n",
       "3     1    181.000000          181.0        0.000000         21182.0   \n",
       "4     1  11668.139648        41554.0    29885.859375             0.0   \n",
       "\n",
       "   newbalanceDest  isFraud  isFlaggedFraud  nameDest  type  nameOrig  \n",
       "0             0.0        0               0   1662094     3    757869  \n",
       "1             0.0        0               0   1733924     3   2188998  \n",
       "2             0.0        1               0    439685     4   1002156  \n",
       "3             0.0        1               0    391696     1   5828262  \n",
       "4             0.0        0               0    828919     3   3445981  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24596c67",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1968f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.99871\n",
      "1    0.00129\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=18)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f5c966",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75380a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Apply ADASYN only on the minority class of the train set\n",
    "ada = ADASYN()\n",
    "X_train_resampled, y_train_resampled = ada.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d5eb637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11438409, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a5eda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count: 5718966\n",
      "Class 1 count: 7392\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# assuming y_train is a numpy array or a pandas series\n",
    "counts = np.bincount(y_train)\n",
    "print(\"Class 0 count:\", counts[0])\n",
    "print(\"Class 1 count:\", counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d8e9a",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b68f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 109732.97, 'oldbalanceOrg': 57407.88, 'newbalanceOrig': 0.0, 'oldbalanceDest': 126466.84, 'newbalanceDest': 229808.7}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed (20)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.14, 'oldbalanceOrg': 0.24, 'newbalanceOrig': 0.25, 'oldbalanceDest': 0.22, 'newbalanceDest': 0.22}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train_resampled.index, size=len(X_train_resampled), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train_resampled.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train_resampled.loc[X_train_resampled[col_name] > np.percentile(X_train_resampled[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "\n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4952d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your original training data is stored in a pandas DataFrame called X_train\n",
    "# And assuming you have a list of selected feature names called selected_features\n",
    "selected_features = ['oldbalanceOrg', 'type', 'nameDest','amount','step']\n",
    "X_train_selected = X_train_resampled[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d8b8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>type</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>amount</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3296.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>11427</td>\n",
       "      <td>305161.156250</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1743120</td>\n",
       "      <td>8840.879883</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10548.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>736364</td>\n",
       "      <td>3120.010010</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>555402</td>\n",
       "      <td>345647.000000</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>21238</td>\n",
       "      <td>109732.968750</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11438404</th>\n",
       "      <td>92214.132812</td>\n",
       "      <td>4</td>\n",
       "      <td>514130</td>\n",
       "      <td>92214.132812</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11438405</th>\n",
       "      <td>93203.218750</td>\n",
       "      <td>4</td>\n",
       "      <td>537958</td>\n",
       "      <td>93203.218750</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11438406</th>\n",
       "      <td>158943.484375</td>\n",
       "      <td>4</td>\n",
       "      <td>548767</td>\n",
       "      <td>158943.484375</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11438407</th>\n",
       "      <td>71474.031250</td>\n",
       "      <td>4</td>\n",
       "      <td>513974</td>\n",
       "      <td>71474.031250</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11438408</th>\n",
       "      <td>95262.609375</td>\n",
       "      <td>4</td>\n",
       "      <td>514153</td>\n",
       "      <td>95262.609375</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11438409 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          oldbalanceOrg  type  nameDest         amount  step\n",
       "0           3296.000000     1     11427  305161.156250   373\n",
       "1              0.000000     3   1743120    8840.879883   406\n",
       "2          10548.000000     3    736364    3120.010010   205\n",
       "3              0.000000     1    555402  345647.000000   301\n",
       "4              0.000000     1     21238  109732.968750   353\n",
       "...                 ...   ...       ...            ...   ...\n",
       "11438404   92214.132812     4    514130   92214.132812   243\n",
       "11438405   93203.218750     4    537958   93203.218750   418\n",
       "11438406  158943.484375     4    548767  158943.484375   108\n",
       "11438407   71474.031250     4    513974   71474.031250   258\n",
       "11438408   95262.609375     4    514153   95262.609375   241\n",
       "\n",
       "[11438409 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a481c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected=X_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2934ff13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>type</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>amount</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402687</th>\n",
       "      <td>2.080000e+03</td>\n",
       "      <td>0</td>\n",
       "      <td>75898</td>\n",
       "      <td>176116.968750</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760752</th>\n",
       "      <td>5.854688e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>119926</td>\n",
       "      <td>559868.187500</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594236</th>\n",
       "      <td>2.745168e+05</td>\n",
       "      <td>3</td>\n",
       "      <td>1249878</td>\n",
       "      <td>8622.099609</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933631</th>\n",
       "      <td>7.080094e+04</td>\n",
       "      <td>3</td>\n",
       "      <td>2423326</td>\n",
       "      <td>30724.619141</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227203</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4</td>\n",
       "      <td>426875</td>\n",
       "      <td>815273.687500</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753638</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3</td>\n",
       "      <td>2617210</td>\n",
       "      <td>1305.969971</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532557</th>\n",
       "      <td>1.235073e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>1970706</td>\n",
       "      <td>26853.359375</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800777</th>\n",
       "      <td>1.291580e+04</td>\n",
       "      <td>3</td>\n",
       "      <td>2318385</td>\n",
       "      <td>28641.919922</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444235</th>\n",
       "      <td>2.710670e+05</td>\n",
       "      <td>3</td>\n",
       "      <td>1893170</td>\n",
       "      <td>10589.280273</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935763</th>\n",
       "      <td>1.263914e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>552216</td>\n",
       "      <td>65446.449219</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636262 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         oldbalanceOrg  type  nameDest         amount  step\n",
       "1402687   2.080000e+03     0     75898  176116.968750   139\n",
       "2760752   5.854688e+06     0    119926  559868.187500   213\n",
       "3594236   2.745168e+05     3   1249878    8622.099609   262\n",
       "1933631   7.080094e+04     3   2423326   30724.619141   177\n",
       "2227203   0.000000e+00     4    426875  815273.687500   186\n",
       "...                ...   ...       ...            ...   ...\n",
       "3753638   0.000000e+00     3   2617210    1305.969971   279\n",
       "1532557   1.235073e+06     3   1970706   26853.359375   154\n",
       "2800777   1.291580e+04     3   2318385   28641.919922   217\n",
       "2444235   2.710670e+05     3   1893170   10589.280273   203\n",
       "1935763   1.263914e+06     0    552216   65446.449219   177\n",
       "\n",
       "[636262 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c9db835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Select top features using Random Forest\n",
    "rf = RandomForestClassifier(random_state=6)\n",
    "rf.fit(X_train_selected, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d7b6f1",
   "metadata": {},
   "source": [
    "## Hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7f8ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "# Define your hyperparameter search space\n",
    "param_dist = { \n",
    "    'n_estimators': sp_randint(100, 400),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : sp_randint(2,3),\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d863f6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 20\n",
      "max_resources_: 100\n",
      "aggressive_elimination: True\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 5\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 3\n",
      "n_resources: 40\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 2\n",
      "n_resources: 80\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingRandomSearchCV(aggressive_elimination=True,\n",
       "                      estimator=RandomForestClassifier(random_state=6),\n",
       "                      factor=2, max_resources=100,\n",
       "                      param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                           'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001CB1F1E6788>,\n",
       "                                           'max_features': ['sqrt', 'log2'],\n",
       "                                           'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001CB591FFD08>},\n",
       "                      random_state=2, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # Required to enable HalvingRandomSearchCV\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "# Set up the HalvingRandomSearchCV with aggressive early stopping\n",
    "search = HalvingRandomSearchCV(rf, param_dist, cv=5,verbose=1, \n",
    "                               factor=2, resource='n_samples', max_resources=100, \n",
    "                               aggressive_elimination=True, random_state=2, \n",
    "                               scoring='accuracy', refit=True)\n",
    "\n",
    "# Fit the HalvingRandomSearchCV object to the data\n",
    "search.fit(X_train_selected, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e274807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and evaluate on the test set\n",
    "best_params = search.best_params_\n",
    "best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "494084e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "544eb39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 175}\n",
      "Test set accuracy: 0.7936368980074247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18cae1",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033fe26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n"
     ]
    }
   ],
   "source": [
    "#1:10\n",
    "#3:5\n",
    "#2:8\n",
    "#1:20\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 2\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "# Create lists to store evaluation metrics for each fold\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create lists to store ROC curve data for each fold\n",
    "fprs = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "# Initialize the OOB error list\n",
    "oob_error = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_selected, y_train_resampled)):\n",
    "    print(f'Fold: {fold+1}')\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_fold_train, y_fold_train = X_train_selected.iloc[train_idx], y_train_resampled.iloc[train_idx]\n",
    "    X_val, y_val = X_train_selected.iloc[val_idx], y_train_resampled.iloc[val_idx]\n",
    "    \n",
    "    class_weights = {0:1, 1: 30}  # Class 0 has weight 1, class 1 has weight 10\n",
    "    \n",
    "    # Create a RandomForestClassifier object with the given hyperparameters\n",
    "    rf_model = RandomForestClassifier(criterion= 'entropy', max_depth= 2, max_features= 'log2', n_estimators=175,oob_score=True, class_weight=class_weights)\n",
    "   \n",
    "    # Fit the model on the training data\n",
    "    rf_model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "    # Predict the class labels for the validation set\n",
    "    y_val_pred = rf_model.predict(X_val)\n",
    "\n",
    "    # Compute the evaluation metrics for the current fold\n",
    "    conf_mat = confusion_matrix(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    # Append the evaluation metrics for the current fold to the lists\n",
    "    f1_scores.append(f1)\n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Compute the ROC curve and AUC for the current fold\n",
    "    fpr, tpr, _ = roc_curve(y_val, rf_model.predict_proba(X_val)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Append the ROC curve data for the current fold to the lists\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    \n",
    "    # Compute the OOB error for the current fold and append to the list\n",
    "    oob_error.append(1 - rf_model.oob_score_)\n",
    "\n",
    "    # Print the evaluation metrics for the current fold\n",
    "    print('Confusion matrix:\\n', conf_mat)\n",
    "    print('Recall:', recall)\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('F1-score:', f1)\n",
    "    print('OOB error:', 1 - rf_model.oob_score_)\n",
    "    print('---------------------')\n",
    "\n",
    "# Create the ROC curve plot\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# Plot the ROC curve for each fold\n",
    "for i in range(n_splits):\n",
    "    ax.plot(fprs[i], tprs[i], lw=2, label='Fold %d (AUC = %0.2f)' % (i+1, aucs[i]))\n",
    "\n",
    "# Add a dashed line representing the random guess classifier\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', label='Random guess')\n",
    "\n",
    "# Add labels and legend to the plot\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver Operating Characteristic')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average F1-score:', sum(f1_scores)/len(f1_scores))\n",
    "print('Average Recall_scores:', sum(recall_scores)/len(recall_scores))\n",
    "print('Average Recall_scores:', sum(precision_scores)/len(precision_scores))\n",
    "print('Average Recall_scores:', sum(accuracy_scores)/len(accuracy_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8dedd",
   "metadata": {},
   "source": [
    "## Evaluate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320da02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the class labels for the test set\n",
    "# y_test_pred = rf_model.predict(X_test_selected)\n",
    "\n",
    "# # Compute the evaluation metrics for the test set\n",
    "# conf_mat_test = confusion_matrix(y_test, y_test_pred)\n",
    "# recall_test = recall_score(y_test, y_test_pred)\n",
    "# accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "# precision_test = precision_score(y_test, y_test_pred)\n",
    "# f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# # Print the evaluation metrics for the test set\n",
    "# print('Evaluation metrics on test set:')\n",
    "# print('Confusion matrix:\\n', conf_mat_test)\n",
    "# print('Recall:', recall_test)\n",
    "# print('Accuracy:', accuracy_test)\n",
    "# print('Precision:', precision_test)\n",
    "# print('F1-score:', f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the class labels and probabilities for the test set\n",
    "# y_test_pred = rf_model.predict(X_test_selected)\n",
    "# y_test_prob = rf_model.predict_proba(X_test_selected)[:, 1]\n",
    "# # Compute the false positive rate, true positive rate, and AUC for the test set\n",
    "# fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_prob)\n",
    "# roc_auc_test = auc(fpr_test, tpr_test)\n",
    "# # Plot the ROC curve for the test set\n",
    "# plt.plot(fpr_test, tpr_test, color='blue', lw=2, label='Test ROC curve (AUC =%0.2f)' % roc_auc_test)\n",
    "# plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve for Test Set')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79d324",
   "metadata": {},
   "source": [
    "## Evaluate test- NEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce19f292",
   "metadata": {},
   "source": [
    "Instead, threshold moving can help to optimize the performance of the classifier on the imbalanced test set by adjusting the threshold used to assign the predicted probabilities to the class labels. By setting an appropriate threshold, we can improve the balance between precision and recall and reduce the impact of the class imbalance on the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3645b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "# Get predicted probabilities for the test data\n",
    "y_prob = rf_model.predict_proba(X_test_selected)[:,1]\n",
    "\n",
    "# Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "thresholds = np.arange(0.1,10,0.01)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    precision_scores.append(precision[1])\n",
    "    recall_scores.append(recall[1])\n",
    "    f1_scores.append(f1[1])\n",
    "\n",
    "# Find the optimal threshold that maximizes the F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Assign the class labels based on the optimal threshold\n",
    "y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the performance of the classifier for the optimal threshold\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeffcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Get predicted probabilities for the test data\n",
    "y_prob = rf_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set different thresholds and compute precision, recall, and F1-score for each threshold\n",
    "thresholds = np.arange(0.1, 10, 0.01)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    precision_scores.append(precision[1])\n",
    "    recall_scores.append(recall[1])\n",
    "    f1_scores.append(f1[1])\n",
    "\n",
    "# Find the optimal threshold that maximizes the F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Assign the class labels based on the optimal threshold\n",
    "y_pred = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the performance of the classifier for the optimal threshold\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print('Average F1-score:', np.mean(f1_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
