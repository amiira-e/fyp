{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc296ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "007b26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc846dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d8c9e",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the values in the isFraud column to Non-Fraud and Fraud\n",
    "df[\"isFraud\"] = df[\"isFraud\"].map({0: \"Non-Fraud\", 1: \"Fraud\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a72ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts of the isFraud column\n",
    "counts = df['isFraud'].value_counts().rename_axis('isFraud').reset_index(name='count')\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d87092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the count of Non-Fraud and Fraud using a barplot\n",
    "plt.figure(figsize=(5.5, 5.5))\n",
    "sns.barplot(x='isFraud', y='count', data=counts, color='pink', edgecolor =\"b\")\n",
    "plt.title('Count of Non-Fraudulent & Fraudulent Transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFraud\"] = df[\"isFraud\"].replace({\"Non-Fraud\": 0, \"Fraud\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd371e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"isFraud\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cdf4e8",
   "metadata": {},
   "source": [
    "## Feature Encoding on entire dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b9d8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder from Sklearn\n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['type'])\n",
    "# printing label\n",
    "label\n",
    "# removing the column 'type' from df\n",
    "# as it is of no use now.\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "# Appending the array to our dataFrame\n",
    "# with column name 'type'\n",
    "df[\"type\"] = label\n",
    "# printing Dataframe\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5778b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameDest'])\n",
    "label\n",
    "df.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df[\"nameDest\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc78ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameOrig'])\n",
    "label\n",
    "df.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df[\"nameOrig\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f57a6d",
   "metadata": {},
   "source": [
    "# Split into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a04c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# Split the data into a 80%-20% train-test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=18)\n",
    "\n",
    "# Split the training set again into a 75%-25% train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ead6d7",
   "metadata": {},
   "source": [
    "The count of target variable without stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaecd560",
   "metadata": {},
   "source": [
    "## Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b38a972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.99871\n",
      "1    0.00129\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# # Split the data into a 80%-20% train-test split with stratification\n",
    "# X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=18, stratify=y)\n",
    "\n",
    "# # Split the training set again into a 75%-25% train-validation split with stratification\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=18, stratify=y_train_full)\n",
    "\n",
    "# Split the data into a 80%-20% train-test split with stratification\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=18, stratify=y)\n",
    "\n",
    "# Split the training set again into a 75%-25% train-validation split with stratification\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=18, stratify=y_train_full)\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "668541a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3817572, 10)\n",
      "(1272524, 10)\n",
      "(1272524, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021df25",
   "metadata": {},
   "source": [
    "# Safe-Level SMOTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9fda4",
   "metadata": {},
   "source": [
    "# Adaptive Synthetic Sampling (ADASYN): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d441e",
   "metadata": {},
   "source": [
    "# Borderline SMOTE: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662a3ab",
   "metadata": {},
   "source": [
    "# Save train, test and validation sets to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23918644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from X_val and y_val\n",
    "val_df = pd.DataFrame(X_val, columns=X_train.columns)\n",
    "val_df['isFraud'] = y_val\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "val_df.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\train.csv\", index=False)\n",
    "X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e07573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3aed3",
   "metadata": {},
   "source": [
    "# Modified Z-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns you want to check for outliers\n",
    "columns_to_trim = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Calculate modified Z-score for each column\n",
    "for col in columns_to_trim:\n",
    "    # Extract column values\n",
    "    col_values = X_train[col].values\n",
    "\n",
    "    # Calculate median and MAD\n",
    "    med = np.median(col_values)\n",
    "    mad = np.median(np.abs(col_values - med))\n",
    "    if mad == 0:\n",
    "        mad = 1e-6  # Set MAD to a small non-zero value to avoid division by zero\n",
    "\n",
    "    # Calculate modified Z-score\n",
    "    z_score = 0.6745 * (col_values - med) / mad\n",
    "\n",
    "    # Count number of lower and upper outliers\n",
    "    lower_outliers = np.sum(z_score < -2.5)\n",
    "    upper_outliers = np.sum(z_score > 2.5)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Column {col}\")\n",
    "    print(f\"Number of lower outliers for column: {lower_outliers}\")\n",
    "    print(f\"Number of upper outliers: {upper_outliers}\")\n",
    "    print(f\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b5399",
   "metadata": {},
   "source": [
    "## Skewness before removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca60a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "skewness = skew(X_train.amount)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.oldbalanceOrg)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.newbalanceOrig)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.oldbalanceDest)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.newbalanceDest)\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8189555",
   "metadata": {},
   "source": [
    "## Trim proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125178f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Extract the columns of interest\n",
    "cols = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "data = X_train[cols]\n",
    "\n",
    "# Loop over each column and determine the direction of trimming\n",
    "for col in cols:\n",
    "    # Calculate the median and interquartile range of the column\n",
    "    median = np.median(data[col])\n",
    "    iqr = np.percentile(data[col], 75) - np.percentile(data[col], 25)\n",
    "\n",
    "    # Calculate the skewness of the column\n",
    "    skewness = data[col].skew()\n",
    "\n",
    "    # Determine whether to use symmetric or asymmetric trimming based on the skewness and IQR\n",
    "    if abs(skewness) > 1.5 or iqr > 2 * abs(median):\n",
    "        print(f\"For column {col}, the data is skewed and heavy-tailed, so asymmetric trimming may be appropriate.\")\n",
    "    else:\n",
    "        print(f\"For column {col}, the data is roughly symmetric, so symmetric trimming may be appropriate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84df595",
   "metadata": {},
   "source": [
    "## Asymmetric trimmed means and Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db1a2f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set trimmed means:  {'amount': 89766.55044076391, 'oldbalanceOrg': 20633.87517058449, 'newbalanceOrig': 18301.7972135642, 'oldbalanceDest': 119290.4346150438, 'newbalanceDest': 162444.3063696169}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed (11)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the right trimming proportions for each column\n",
    "trim_props = {'amount': 0.12, 'oldbalanceOrg': 0.22, 'newbalanceOrig': 0.22, 'oldbalanceDest': 0.29, 'newbalanceDest': 0.29}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column\n",
    "train_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the training set\n",
    "    train_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train.index, size=len(X_train), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        train_sample = X_train.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the training set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        \n",
    "        # Calculate the right trimmed mean of the bootstrapped sample for the training set\n",
    "        train_right_trimmed_mean = np.mean(train_sample[train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name]))])\n",
    "        train_trimmed_means_list.append(train_right_trimmed_mean)\n",
    "        \n",
    "    # Calculate the mean of the right trimmed means for the training set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "\n",
    "    # Replace the outliers in the training set with the trimmed means\n",
    "    X_train.loc[X_train[col_name] > np.percentile(X_train[col_name], 100*(1-trim_props[col_name])), col_name] = train_trimmed_means[col_name]\n",
    "\n",
    "# Print the trimmed means for each column separately for the training set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = (X_train['amount'] == 14793.948294785117).sum()\n",
    "# print(count)\n",
    "# count = (X_train['oldbalanceOrg'] == 6367.162451237726).sum()\n",
    "# print(count)\n",
    "# count = (X_train['newbalanceOrig'] == 990.4751087978151).sum()\n",
    "# print(count)\n",
    "# count = (X_train['oldbalanceDest'] ==  10188.054727652307).sum()\n",
    "# print(count)\n",
    "# count = (X_train['newbalanceDest'] == 19552.789367260193).sum()\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29728556",
   "metadata": {},
   "source": [
    "## Skewness of treating outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "skewness = skew(X_train.amount)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.oldbalanceOrg)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.newbalanceOrig)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.oldbalanceDest)\n",
    "print(skewness)\n",
    "skewness = skew(X_train.newbalanceDest)\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48dc5d8",
   "metadata": {},
   "source": [
    "# Save train file after handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358784f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # save the trimmed train to new files\n",
    "X_train.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainAFTERHANDLINGOUTLIERS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbb386",
   "metadata": {},
   "source": [
    "# Check number of outliers after handling the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb6252",
   "metadata": {},
   "source": [
    "# Modified Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b05313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns you want to check for outliers\n",
    "columns_to_trim = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Calculate modified Z-score for each column\n",
    "for col in columns_to_trim:\n",
    "    # Extract column values\n",
    "    col_values = X_train[col].values\n",
    "\n",
    "    # Calculate median and MAD\n",
    "    med = np.median(col_values)\n",
    "    mad = np.median(np.abs(col_values - med))\n",
    "    if mad == 0:\n",
    "        mad = 1e-6  # Set MAD to a small non-zero value to avoid division by zero\n",
    "\n",
    "    # Calculate modified Z-score\n",
    "    z_score = 0.6745 * (col_values - med) / mad\n",
    "\n",
    "    # Count number of lower and upper outliers\n",
    "    lower_outliers = np.sum(z_score < -2.5)\n",
    "    upper_outliers = np.sum(z_score > 2.5)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Column {col}\")\n",
    "    print(f\"Number of lower outliers for column: {lower_outliers}\")\n",
    "    print(f\"Number of upper outliers: {upper_outliers}\")\n",
    "    print(f\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2b891",
   "metadata": {},
   "source": [
    "# Concept 1-Feature Selection using random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35692974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da18ac4",
   "metadata": {},
   "source": [
    "Add stratified K-fold Cross Validation (Good for imbalance set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8559b31",
   "metadata": {},
   "source": [
    "## Random forest selects the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c686b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define a random forest classifier with 100 trees\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=18)\n",
    "\n",
    "# Fit the random forest classifier to the training set\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances from the random forest\n",
    "importances = rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23733dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the features in decreasing order of importance\n",
    "indices = importances.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5dc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names and importance scores in two separate arrays\n",
    "feature_names = X_train.columns\n",
    "feature_importances = importances[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca7e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative importance scores\n",
    "cumulative_importances = np.cumsum(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variable importance scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(feature_importances)), feature_importances, align='center')\n",
    "plt.xticks(range(len(feature_importances)), feature_names[indices], rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Variable Importance - Mean Decrease in Gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8018c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative importance scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(feature_importances)), cumulative_importances)\n",
    "plt.xticks(range(len(feature_importances)), feature_names[indices], rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Cumulative Importance Score')\n",
    "plt.title('Cumulative Variable Importance - Mean Decrease in Gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean decrease in accuracy for each feature\n",
    "perm_importances = rfc.feature_importances_\n",
    "perm_scores = []\n",
    "for i in X_train.columns:\n",
    "    X_train_perm = X_train.copy()\n",
    "    X_train_perm[i] = np.random.permutation(X_train_perm[i])\n",
    "    perm_score = rfc.score(X_train_perm, y_train)\n",
    "    perm_scores.append(perm_score)\n",
    "    \n",
    "mean_decrease_accuracy = np.array(perm_scores) - rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the features in decreasing order of importance\n",
    "indices = mean_decrease_accuracy.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names and importance scores in two separate arrays\n",
    "feature_names = X_train.columns\n",
    "feature_importances = mean_decrease_accuracy[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb5632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative importance scores\n",
    "cumulative_importances = np.cumsum(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variable importance scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(feature_importances)), feature_importances, align='center')\n",
    "plt.xticks(range(len(feature_importances)), feature_names[indices], rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Variable Importance - Mean Decrease in Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdca1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative importance scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(feature_importances)), cumulative_importances)\n",
    "plt.xticks(range(len(feature_importances)), feature_names[indices], rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Cumulative Importance Score')\n",
    "plt.title('Cumulative Variable Importance - Mean Decrease in Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f85d9a",
   "metadata": {},
   "source": [
    "## Once RF choses best features, use them to find hyperparameters to train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad120c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Select the columns from X_train that you want to use for modeling\n",
    "selected_columns = ['newbalanceDest', 'step', 'oldbalanceOrg']\n",
    "\n",
    "# Create a new dataframe with only the selected columns\n",
    "X_train_selected = X_train[selected_columns]\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100], \n",
    "              'penalty': ['l2', 'none']}\n",
    "\n",
    "# Create a logistic regression model\n",
    "lr_model = LogisticRegression(random_state=18)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(lr_model, param_grid, cv=3)\n",
    "\n",
    "# Fit the GridSearchCV object to the selected columns of X_train and y_train\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "\n",
    "# Print the best score\n",
    "print('Best score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e266b",
   "metadata": {},
   "source": [
    "## Train logistic regression  without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9ce9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the number of splits for stratified k-fold cross-validation\n",
    "# n_splits = 5\n",
    "\n",
    "# # Initialize stratified k-fold cross-validation\n",
    "# skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# # Initialize Logistic Regression classifier\n",
    "# lr = LogisticRegression()\n",
    "\n",
    "# train_scores = []\n",
    "# val_scores = []\n",
    "\n",
    "# # Loop over the folds in the cross-validation\n",
    "# for train_index, val_index in skf.split(X_train, y_train):\n",
    "    \n",
    "#     # Split the data into training and validation sets for this fold\n",
    "#     X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "#     y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "#     # Fit the logistic regression model on the training set for this fold\n",
    "#     lr.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "#     # Predict on training set for this fold\n",
    "#     y_train_pred = lr.predict(X_train_fold)\n",
    "\n",
    "#     # Evaluate accuracy on training set for this fold\n",
    "#     train_acc = accuracy_score(y_train_fold, y_train_pred)\n",
    "\n",
    "#     # Predict on validation set for this fold\n",
    "#     y_val_pred = lr.predict(X_val_fold)\n",
    "\n",
    "#     # Evaluate accuracy on validation set for this fold\n",
    "#     val_acc = accuracy_score(y_val_fold, y_val_pred)\n",
    "\n",
    "#     # Append the scores to the lists\n",
    "#     train_scores.append(train_acc)\n",
    "#     val_scores.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433cdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loop through the folds and train models on each fold\n",
    "for fold, (train_index, val_index) in enumerate(kfolds.split(X_train, y_train)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    \n",
    "    # Reset the index of the training data to avoid errors with iloc\n",
    "    X_train_fold = X_train.iloc[train_index].reset_index(drop=True)\n",
    "    y_train_fold = y_train.iloc[train_index].reset_index(drop=True)\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_val_fold = X_train.iloc[val_index].reset_index(drop=True)\n",
    "    y_val_fold = y_train.iloc[val_index].reset_index(drop=True)\n",
    "    \n",
    "    # Train a logistic regression model on the training data\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_fold_scaled, y_train_fold)\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    y_val_pred = model.predict(X_val_fold_scaled)\n",
    "    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    print(f\"Validation accuracy: {val_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "281ccced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3817572, 10)\n",
      "(1272524, 10)\n",
      "(1272524, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "step              0\n",
       "amount            0\n",
       "oldbalanceOrg     0\n",
       "newbalanceOrig    0\n",
       "oldbalanceDest    0\n",
       "newbalanceDest    0\n",
       "isFlaggedFraud    0\n",
       "type              0\n",
       "nameDest          0\n",
       "nameOrig          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0c2640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',\n",
      "       'newbalanceDest', 'isFlaggedFraud', 'type', 'nameDest', 'nameOrig'],\n",
      "      dtype='object')\n",
      "Index(['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',\n",
      "       'newbalanceDest', 'isFlaggedFraud', 'type', 'nameDest', 'nameOrig'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n",
    "print(X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average train and validation scores\n",
    "print(\"Average training accuracy:\", sum(train_scores) / n_splits)\n",
    "print(\"Average validation accuracy:\", sum(val_scores) / n_splits)\n",
    "\n",
    "# Plot the train and validation scores for all folds\n",
    "plt.plot(train_scores, label=\"Training scores\")\n",
    "plt.plot(val_scores, label=\"Validation scores\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train and Validation Scores\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Check if the model is overfitting\n",
    "if sum(val_scores) / n_splits < sum(train_scores) / n_splits:\n",
    "    print(\"The model is overfitting.\")\n",
    "else:\n",
    "    print(\"The model is not overfitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614707d4",
   "metadata": {},
   "source": [
    "## Train logistic regression  with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b1e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best hyperparameters: {'C': 0.01, 'penalty': 'l2'}\n",
    "Best score: 0.9987091271625003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ba9eb",
   "metadata": {},
   "source": [
    "# Concept 1- Feature selection using Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# Select the top k features based on mutual information\n",
    "k = 5\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "\n",
    "# Print the names of the selected features\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd0605f",
   "metadata": {},
   "source": [
    "# Random Forest Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e6713",
   "metadata": {},
   "source": [
    "As we can see, there are hyperparameters which can be adjusted:\n",
    "The RandomForestClassifier in scikit-learn has a number of hyperparameters that can be tuned to optimize model performance. Here are some of the most commonly used ones:\n",
    "1. n_estimators\n",
    "2.max_depth\n",
    "3.min_samples_split\n",
    "4.bootstrap\n",
    "5.min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier with the desired hyperparameters\n",
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=10, min_samples_split=2, min_samples_leaf=1, max_features='auto', bootstrap=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7810042",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Mean Decrease in Gini Importance\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "#plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices])\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20049b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(rfc, X_train, y_train, n_repeats=10, random_state=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Mean Decrease in Accuracy Importance\")\n",
    "plt.bar(range(X_train.shape[1]), result.importances_mean[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4d13b",
   "metadata": {},
   "source": [
    "# Concept 1- Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad1292",
   "metadata": {},
   "source": [
    "For classification with small training samples and\n",
    "high dimensionality, feature selection plays an\n",
    "important role in avoiding overfitting problems and\n",
    "improving classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "sel=RFE(RandomForestClassifier(n_estimators=10,random_state=18,n_jobs=-1),n_features_to_select=5)\n",
    "sel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0037830",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294a594",
   "metadata": {},
   "source": [
    "# Concept 1 - Feature Selection by Gradient Boost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ca2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "605f1152",
   "metadata": {},
   "source": [
    "# Feature Selection using ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy, roc_auc_score\n",
    "from sklearn.feature_selection import Variancethreshold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c19a046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59347669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf84a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3001f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1abfdef4",
   "metadata": {},
   "source": [
    "# Concept 2- Feature Extraction -> PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b4c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "484591bf",
   "metadata": {},
   "source": [
    "# Handle class imbalance during training using threshold moving algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c31d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1218c17",
   "metadata": {},
   "source": [
    "# Cost Sensitive Learning to handle class imbalance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
