{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2bbe5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca576dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949ab2e",
   "metadata": {},
   "source": [
    "## Separate remaining data into transfer learning data and Out-sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23377b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def reservoir_sampling(iterable, k, header=True):\n",
    "    reservoir = []\n",
    "    for i, item in enumerate(iterable):\n",
    "        if i < k:\n",
    "            reservoir.append(item)\n",
    "        else:\n",
    "            j = random.randint(0, i)\n",
    "            if j < k:\n",
    "                reservoir[j] = item\n",
    "    return reservoir\n",
    "\n",
    "# Open the input CSV file\n",
    "with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\") as f:\n",
    "    # Check if header line exists\n",
    "    header = True\n",
    "    first_line = f.readline()\n",
    "    if not first_line.startswith('step,type,amount,nameOrig,oldbalanceOrg,newbalanceOrig,nameDest,oldbalanceDest,newbalanceDest,isFraud,isFlaggedFraud'):\n",
    "        header = False\n",
    "        f.seek(0)  # Rewind file pointer to beginning\n",
    "\n",
    "    # Sample from remaining lines\n",
    "    sampled_lines = reservoir_sampling(f, k=2500000, header=header)\n",
    "\n",
    "# Open the output CSV file and write the subsample to it\n",
    "with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\transfer_learning.csv\", mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    if header:\n",
    "        writer.writerow(first_line.strip().split(','))\n",
    "    for line in sampled_lines:\n",
    "        writer.writerow(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329a5aa",
   "metadata": {},
   "source": [
    "## Pre-process larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed453d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_big=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\transfer_learning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf9f6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_big.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846a5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample_big['type'])\n",
    "label\n",
    "df_sample_big.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample_big[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample_big['nameDest'])\n",
    "label\n",
    "df_sample_big.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample_big[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample_big['nameOrig'])\n",
    "label\n",
    "df_sample_big.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample_big[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4fdb235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998712\n",
      "1    0.001288\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998712\n",
      "1    0.001288\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998712\n",
      "1    0.001288\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample_big.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample_big['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865f7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a30f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a4de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e882ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1506ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1557613, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8027782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step         amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0         304  157520.530000   47407.850000             0.0            0.00   \n",
      "1         153  267217.000000       0.000000             0.0        16211.49   \n",
      "2         273    1991.940000   48955.000000             0.0            0.00   \n",
      "3         304    6426.000000   47407.850000             0.0            0.00   \n",
      "4         158  191095.750000    1307.000000             0.0        16211.49   \n",
      "...       ...            ...            ...             ...             ...   \n",
      "1557608   530  123629.480000   47407.850000             0.0        16211.49   \n",
      "1557609   273  384004.649679   47407.850000             0.0        16211.49   \n",
      "1557610   273   82601.112113   82601.112113             0.0            0.00   \n",
      "1557611   408   61046.702672   61046.702672             0.0            0.00   \n",
      "1557612   273  123629.480000   47407.850000             0.0            0.00   \n",
      "\n",
      "         newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "0             157520.53               0     1    217690    278456  \n",
      "1             162782.57               0     1    363321   2358429  \n",
      "2                  0.00               0     3    574325    349645  \n",
      "3                  0.00               0     3    579320    115605  \n",
      "4             162782.57               0     0    402727    967130  \n",
      "...                 ...             ...   ...       ...       ...  \n",
      "1557608       162782.57               0     1     82537   1828827  \n",
      "1557609       162782.57               0     1    160484   1515318  \n",
      "1557610            0.00               0     1    440182    173344  \n",
      "1557611            0.00               0     1    287575    783945  \n",
      "1557612            0.00               0     1    225509   2411980  \n",
      "\n",
      "[1557613 rows x 10 columns]\n",
      "         step     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "447306    395   75632.19       31680.00             0.0            0.00   \n",
      "171889    240    1012.91       18951.00             0.0            0.00   \n",
      "20848     379  237419.78       14355.94             0.0       135556.91   \n",
      "1087770   329   10440.17       21528.00             0.0            0.00   \n",
      "1601207   210    2164.89       14355.94             0.0            0.00   \n",
      "...       ...        ...            ...             ...             ...   \n",
      "1879180   164  209355.58        4044.00             0.0       135556.91   \n",
      "1640974   240   75632.19       14355.94             0.0       135556.91   \n",
      "289095    210     385.26       20803.00             0.0            0.00   \n",
      "509185     20   94365.39       20933.00             0.0            0.00   \n",
      "1423381   139   75632.19           0.00             0.0       135556.91   \n",
      "\n",
      "         newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "447306       251100.930               0     1  329224.0    409132  \n",
      "171889            0.000               0     3  631512.0    324590  \n",
      "20848        217266.905               0     1  213313.0   1664496  \n",
      "1087770           0.000               0     3  339047.5    116982  \n",
      "1601207           0.000               0     3  339047.5   2137489  \n",
      "...                 ...             ...   ...       ...       ...  \n",
      "1879180      217266.905               0     1  175481.0   2401408  \n",
      "1640974      217266.905               0     0  408388.0   1505546  \n",
      "289095            0.000               0     3  497151.0    766560  \n",
      "509185        94365.390               0     1   15954.0    160961  \n",
      "1423381      217266.905               0     1    1109.0   1125336  \n",
      "\n",
      "[250000 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# convert X_test to a pandas dataframe\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "# define a function to replace outliers with MAD for a single column\n",
    "def replace_outliers_with_mad(column):\n",
    "    median = np.median(column)\n",
    "    mad = np.median(np.abs(column - median))\n",
    "    threshold = 2.5 * mad\n",
    "    column[np.abs(column - median) > threshold] = median\n",
    "    return column\n",
    "\n",
    "# apply the function to all columns of X_train_resampled_final\n",
    "for i in range(X_train_resampled_final.shape[1]):\n",
    "    X_train_resampled_final.iloc[:, i] = replace_outliers_with_mad(X_train_resampled_final.iloc[:, i])\n",
    "\n",
    "# apply the function to all columns of X_test\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test.iloc[:, i] = replace_outliers_with_mad(X_test.iloc[:, i])\n",
    "\n",
    "# convert the numpy arrays back to pandas dataframes\n",
    "X_train_resampled_final = pd.DataFrame(X_train_resampled_final, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "\n",
    "# print the modified dataframes\n",
    "print(X_train_resampled_final)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca43564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dd34545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da522fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_big = df_sample_big.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1c38e",
   "metadata": {},
   "source": [
    "### Big dataset: Pre-train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94d03557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002185246F678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002185246F678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002185246F678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32426/32451 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9328WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002185267FC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002185267FC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002185267FC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32451/32451 [==============================] - 75s 2ms/step - loss: 0.1513 - accuracy: 0.9328 - val_loss: 0.1283 - val_accuracy: 0.9428\n",
      "Epoch 2/10\n",
      "32451/32451 [==============================] - 74s 2ms/step - loss: 0.1194 - accuracy: 0.9475 - val_loss: 0.1101 - val_accuracy: 0.9536\n",
      "Epoch 3/10\n",
      "32451/32451 [==============================] - 71s 2ms/step - loss: 0.1021 - accuracy: 0.9572 - val_loss: 0.0934 - val_accuracy: 0.9621\n",
      "Epoch 4/10\n",
      "32451/32451 [==============================] - 72s 2ms/step - loss: 0.0876 - accuracy: 0.9647 - val_loss: 0.0840 - val_accuracy: 0.9669\n",
      "Epoch 5/10\n",
      "32451/32451 [==============================] - 72s 2ms/step - loss: 0.0798 - accuracy: 0.9687 - val_loss: 0.0776 - val_accuracy: 0.9701\n",
      "Epoch 6/10\n",
      "32451/32451 [==============================] - 72s 2ms/step - loss: 0.0752 - accuracy: 0.9708 - val_loss: 0.0732 - val_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "32451/32451 [==============================] - 72s 2ms/step - loss: 0.0722 - accuracy: 0.9724 - val_loss: 0.0711 - val_accuracy: 0.9731\n",
      "Epoch 8/10\n",
      "32451/32451 [==============================] - 72s 2ms/step - loss: 0.0699 - accuracy: 0.9735 - val_loss: 0.0687 - val_accuracy: 0.9743\n",
      "Epoch 9/10\n",
      "32451/32451 [==============================] - 72s 2ms/step - loss: 0.0680 - accuracy: 0.9744 - val_loss: 0.0695 - val_accuracy: 0.9744\n",
      "Epoch 10/10\n",
      "32451/32451 [==============================] - 72s 2ms/step - loss: 0.0664 - accuracy: 0.9751 - val_loss: 0.0659 - val_accuracy: 0.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 elapsed time: 724.40 seconds\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002185267FCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002185267FCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002185267FCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32415/32451 [============================>.] - ETA: 0s - loss: 0.1452 - accuracy: 0.9364WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000218527A3CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000218527A3CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000218527A3CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32451/32451 [==============================] - 76s 2ms/step - loss: 0.1452 - accuracy: 0.9364 - val_loss: 0.1145 - val_accuracy: 0.9513\n",
      "Epoch 2/10\n",
      "32451/32451 [==============================] - 73s 2ms/step - loss: 0.1038 - accuracy: 0.9564 - val_loss: 0.0949 - val_accuracy: 0.9617\n",
      "Epoch 3/10\n",
      "32451/32451 [==============================] - 73s 2ms/step - loss: 0.0896 - accuracy: 0.9639 - val_loss: 0.0869 - val_accuracy: 0.9651\n",
      "Epoch 4/10\n",
      "32451/32451 [==============================] - 76s 2ms/step - loss: 0.0819 - accuracy: 0.9681 - val_loss: 0.0788 - val_accuracy: 0.9701\n",
      "Epoch 5/10\n",
      "32451/32451 [==============================] - 75s 2ms/step - loss: 0.0771 - accuracy: 0.9707 - val_loss: 0.0744 - val_accuracy: 0.9718\n",
      "Epoch 6/10\n",
      "32451/32451 [==============================] - 77s 2ms/step - loss: 0.0736 - accuracy: 0.9724 - val_loss: 0.0715 - val_accuracy: 0.9731\n",
      "Epoch 7/10\n",
      "32451/32451 [==============================] - 76s 2ms/step - loss: 0.0708 - accuracy: 0.9740 - val_loss: 0.0692 - val_accuracy: 0.9745\n",
      "Epoch 8/10\n",
      "32451/32451 [==============================] - 78s 2ms/step - loss: 0.0686 - accuracy: 0.9751 - val_loss: 0.0674 - val_accuracy: 0.9755\n",
      "Epoch 9/10\n",
      "32451/32451 [==============================] - 75s 2ms/step - loss: 0.0667 - accuracy: 0.9759 - val_loss: 0.0655 - val_accuracy: 0.9764\n",
      "Epoch 10/10\n",
      "32451/32451 [==============================] - 78s 2ms/step - loss: 0.0653 - accuracy: 0.9764 - val_loss: 0.0643 - val_accuracy: 0.9770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 elapsed time: 756.16 seconds\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021852F64438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021852F64438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021852F64438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32425/32451 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.9365WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021850D01798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021850D01798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021850D01798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32451/32451 [==============================] - 79s 2ms/step - loss: 0.1445 - accuracy: 0.9365 - val_loss: 0.1169 - val_accuracy: 0.9514\n",
      "Epoch 2/10\n",
      "32451/32451 [==============================] - 78s 2ms/step - loss: 0.1017 - accuracy: 0.9582 - val_loss: 0.0919 - val_accuracy: 0.9628\n",
      "Epoch 3/10\n",
      "32451/32451 [==============================] - 75s 2ms/step - loss: 0.0861 - accuracy: 0.9661 - val_loss: 0.0820 - val_accuracy: 0.9676\n",
      "Epoch 4/10\n",
      "32451/32451 [==============================] - 76s 2ms/step - loss: 0.0796 - accuracy: 0.9690 - val_loss: 0.0780 - val_accuracy: 0.9693\n",
      "Epoch 5/10\n",
      "32451/32451 [==============================] - 77s 2ms/step - loss: 0.0754 - accuracy: 0.9712 - val_loss: 0.0726 - val_accuracy: 0.9725\n",
      "Epoch 6/10\n",
      "32451/32451 [==============================] - 79s 2ms/step - loss: 0.0717 - accuracy: 0.9730 - val_loss: 0.0701 - val_accuracy: 0.9732\n",
      "Epoch 7/10\n",
      "32451/32451 [==============================] - 79s 2ms/step - loss: 0.0686 - accuracy: 0.9745 - val_loss: 0.0675 - val_accuracy: 0.9744\n",
      "Epoch 8/10\n",
      "32451/32451 [==============================] - 169s 5ms/step - loss: 0.0662 - accuracy: 0.9757 - val_loss: 0.0642 - val_accuracy: 0.9763\n",
      "Epoch 9/10\n",
      "32451/32451 [==============================] - 194s 6ms/step - loss: 0.0644 - accuracy: 0.9765 - val_loss: 0.0625 - val_accuracy: 0.9772\n",
      "Epoch 10/10\n",
      "32451/32451 [==============================] - 199s 6ms/step - loss: 0.0631 - accuracy: 0.9770 - val_loss: 0.0623 - val_accuracy: 0.9775\n",
      "Fold 3 elapsed time: 1104.88 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define number of folds for cross-validation\n",
    "num_folds = 3\n",
    "\n",
    "# create KFold cross-validation object\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# create arrays to store training and validation loss for each epoch\n",
    "train_losses = np.zeros((num_folds, 10))\n",
    "val_losses = np.zeros((num_folds, 10))\n",
    "\n",
    "import time\n",
    "\n",
    "# loop over the folds\n",
    "fold_no = 1\n",
    "for train, val in kfold.split(X_train_resampled_final, y_train_resampled_final):\n",
    "    \n",
    "    # create model\n",
    "    pre_trained_model = Sequential()\n",
    "    # add convolutional layer\n",
    "    pre_trained_model.add(Conv1D(filters=32, kernel_size=3, activation='tanh', input_shape=(10, 1)))\n",
    "    # add pooling layer\n",
    "    pre_trained_model.add(MaxPooling1D(pool_size=2))\n",
    "    # flatten output to feed into fully connected layer\n",
    "    pre_trained_model.add(Flatten())\n",
    "    # add fully connected layer\n",
    "    pre_trained_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    opt_new = Adam(lr=0.00033)\n",
    "    # compile model\n",
    "    pre_trained_model.compile(loss='binary_crossentropy', optimizer=opt_new, metrics=['accuracy'])\n",
    "    \n",
    "    # record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # train model for each fold\n",
    "    history = pre_trained_model.fit(X_train_resampled_final[train], y_train_resampled_final[train],\n",
    "                                     epochs=10, batch_size=32, validation_data=(X_train_resampled_final[val], y_train_resampled_final[val]))\n",
    "    \n",
    "    # record end time and calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f'Fold {fold_no} elapsed time: {elapsed_time:.2f} seconds')\n",
    "    \n",
    "    # store training and validation loss for each epoch\n",
    "    train_losses[fold_no-1] = history.history['loss']\n",
    "    val_losses[fold_no-1] = history.history['val_loss']\n",
    "    \n",
    "    # increment fold number\n",
    "    fold_no += 1\n",
    "    \n",
    "# calculate mean training and validation loss across all folds for each epoch\n",
    "mean_train_loss = np.mean(train_losses, axis=0)\n",
    "mean_val_loss = np.mean(val_losses, axis=0)\n",
    "\n",
    "# plot training and validation loss curves for each epoch\n",
    "plt.plot(mean_train_loss, label='Training Loss')\n",
    "plt.plot(mean_val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6a95c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9255759716033936\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "test_loss, test_acc = pre_trained_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1cc8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7813/7813 [==============================] - 11s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred = pre_trained_model.predict(X_test)\n",
    "\n",
    "# convert predictions from probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa767b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    249678\n",
      "           1       0.00      0.00      0.00       322\n",
      "\n",
      "    accuracy                           1.00    250000\n",
      "   macro avg       0.50      0.50      0.50    250000\n",
      "weighted avg       1.00      1.00      1.00    250000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define number of folds for cross-validation\n",
    "num_folds = 3\n",
    "\n",
    "# create KFold cross-validation object\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# create arrays to store training and validation loss for each epoch\n",
    "train_losses = np.zeros((num_folds, 10))\n",
    "val_losses = np.zeros((num_folds, 10))\n",
    "\n",
    "import time\n",
    "\n",
    "# loop over the folds\n",
    "fold_no = 1\n",
    "for train, val in kfold.split(X_train_resampled_final, y_train_resampled_final):\n",
    "    \n",
    "    # create model\n",
    "    pre_trained_model = Sequential()\n",
    "    # add convolutional layer\n",
    "    pre_trained_model.add(Conv1D(filters=32, kernel_size=3, activation='tanh', input_shape=(10, 1)))\n",
    "    # add pooling layer\n",
    "    pre_trained_model.add(MaxPooling1D(pool_size=2))\n",
    "    # flatten output to feed into fully connected layer\n",
    "    pre_trained_model.add(Flatten())\n",
    "    # add fully connected layer\n",
    "    pre_trained_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    opt_new = Adam(lr=0.00033)\n",
    "    # compile model\n",
    "    pre_trained_model.compile(loss='binary_crossentropy', optimizer=opt_new, metrics=['accuracy'])\n",
    "    \n",
    "    # record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # train model for each fold\n",
    "    history = pre_trained_model.fit(X_train_resampled_final[train], y_train_resampled_final[train],\n",
    "                                     epochs=10, batch_size=32, validation_data=(X_train_resampled_final[val], y_train_resampled_final[val]))\n",
    "    \n",
    "    # record end time and calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f'Fold {fold_no} elapsed time: {elapsed_time:.2f} seconds')\n",
    "    \n",
    "    # store training and validation loss for each epoch\n",
    "    train_losses[fold_no-1] = history.history['loss']\n",
    "    val_losses[fold_no-1] = history.history['val_loss']\n",
    "    \n",
    "    # increment fold number\n",
    "    fold_no += 1\n",
    "    \n",
    "# calculate mean training and validation loss across all folds for each epoch\n",
    "mean_train_loss = np.mean(train_losses, axis=0)\n",
    "mean_val_loss = np.mean(val_losses, axis=0)\n",
    "\n",
    "# plot training and validation loss curves for each epoch\n",
    "plt.plot(mean_train_loss, label='Training Loss')\n",
    "plt.plot(mean_val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7bd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# create model\n",
    "pre_trained_model = Sequential()\n",
    "# add convolutional layer\n",
    "pre_trained_model.add(Conv1D(filters=32, kernel_size=3, activation='tanh', input_shape=(10, 1)))\n",
    "# add pooling layer\n",
    "pre_trained_model.add(MaxPooling1D(pool_size=2))\n",
    "# flatten output to feed into fully connected layer\n",
    "pre_trained_model.add(Flatten())\n",
    "# add fully connected layer\n",
    "pre_trained_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt_new=Adam(lr=0.00033)\n",
    "# compile model\n",
    "pre_trained_model.compile(loss='binary_crossentropy', optimizer=opt_new, metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "pre_trained_model.fit(X_train_resampled_final, y_train_resampled_final, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# plot the model architecture\n",
    "plot_model(pre_trained_model, to_file='cnn.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f73a8",
   "metadata": {},
   "source": [
    "## Working on New CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c088a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2bdbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837a8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036edbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39800044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d689efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbaa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b3ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29beb78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        step         amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0        298   15948.650000       0.000000             0.0           0.000   \n",
      "1        138   44423.330000   51717.500000             0.0       57723.695   \n",
      "2        325  134768.719925    4564.000000             0.0       57723.695   \n",
      "3        308  300712.340000   51474.000000             0.0       57723.695   \n",
      "4        349   47243.760000   11262.000000             0.0           0.000   \n",
      "...      ...            ...            ...             ...             ...   \n",
      "419113   277  111168.880136  111168.880136             0.0       57723.695   \n",
      "419114   274  134768.719925   51717.500000             0.0       57723.695   \n",
      "419115    60  134768.719925   51717.500000             0.0           0.000   \n",
      "419116   449   44882.356239   44882.356239             0.0           0.000   \n",
      "419117   220   39953.091459   29059.334627             0.0       57723.695   \n",
      "\n",
      "        newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "0             0.000000               0     3  336944.0    670374  \n",
      "1        224181.060000               0     0   92881.0    180374  \n",
      "2        224181.060000               0     1   80756.0    482539  \n",
      "3        654217.020000               0     1  175711.0    597630  \n",
      "4             0.000000               0     3  161074.5     26253  \n",
      "...                ...             ...   ...       ...       ...  \n",
      "419113   224181.060000               0     1   90379.0    472585  \n",
      "419114   224181.060000               0     1  112071.0    494845  \n",
      "419115        0.000000               0     1  154830.0    240268  \n",
      "419116    36237.626509               0     1  122579.0     88980  \n",
      "419117   224181.060000               0     1   93537.0    130866  \n",
      "\n",
      "[419118 rows x 10 columns]\n",
      "         step     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "485376  278.0   22928.58            0.0             0.0           0.000   \n",
      "642214   45.0    8606.90         5764.0             0.0           0.000   \n",
      "192982  237.0  220046.83            0.0             0.0      130797.505   \n",
      "99091   328.0   83938.53        13653.5             0.0      130797.505   \n",
      "203398  307.0   74636.86            0.0             0.0      130797.505   \n",
      "...       ...        ...            ...             ...             ...   \n",
      "230877  154.0  195805.05        31725.0             0.0           0.000   \n",
      "315026  301.0   36352.03        13653.5             0.0           0.000   \n",
      "661254  238.5  163969.90        13653.5             0.0      130797.505   \n",
      "688112  280.0    3092.79            0.0             0.0           0.000   \n",
      "642560   35.0   74636.86        30807.0             0.0      130797.505   \n",
      "\n",
      "        newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "485376           0.000               0     3    291184    424837  \n",
      "642214           0.000               0     3    363649    442961  \n",
      "192982      214326.245               0     1      1853    410946  \n",
      "99091       537297.070               0     0    252825    347652  \n",
      "203398      214326.245               0     1    201182    417173  \n",
      "...                ...             ...   ...       ...       ...  \n",
      "230877      195805.050               0     1    181881    192704  \n",
      "315026           0.000               0     3    458861    630843  \n",
      "661254      706564.020               0     0     37270    676511  \n",
      "688112           0.000               0     3    455345    152073  \n",
      "642560      214326.245               0     1    214954    689599  \n",
      "\n",
      "[70000 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# convert X_test to a pandas dataframe\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "# define a function to replace outliers with MAD for a single column\n",
    "def replace_outliers_with_mad(column):\n",
    "    median = np.median(column)\n",
    "    mad = np.median(np.abs(column - median))\n",
    "    threshold = 2.5 * mad\n",
    "    column[np.abs(column - median) > threshold] = median\n",
    "    return column\n",
    "\n",
    "# apply the function to all columns of X_train_resampled_final\n",
    "for i in range(X_train_resampled_final.shape[1]):\n",
    "     X_train_resampled_final.iloc[:, i] = replace_outliers_with_mad(X_train_resampled_final.iloc[:, i])\n",
    "   # X_train_resampled_final[:, i] = replace_outliers_with_mad(X_train_resampled_final[:, i])\n",
    "\n",
    "# apply the function to all columns of X_test\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test.iloc[:, i] = replace_outliers_with_mad(X_test.iloc[:, i])\n",
    "\n",
    "# convert the numpy arrays back to pandas dataframes\n",
    "X_train_resampled_final = pd.DataFrame(X_train_resampled_final, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "\n",
    "# print the modified dataframes\n",
    "print(X_train_resampled_final)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0811d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed77df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7f9ff",
   "metadata": {},
   "source": [
    "# New CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a45c90e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAC04F0798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAC04F0798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAC04F0798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "9064/9079 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.8068WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EABF4DEAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EABF4DEAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EABF4DEAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.4284 - accuracy: 0.8069 - val_loss: 0.3620 - val_accuracy: 0.8456\n",
      "Epoch 2/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.3526 - accuracy: 0.8435 - val_loss: 0.3404 - val_accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.3392 - accuracy: 0.8492 - val_loss: 0.3319 - val_accuracy: 0.8558\n",
      "Epoch 4/10\n",
      "9079/9079 [==============================] - 20s 2ms/step - loss: 0.3291 - accuracy: 0.8540 - val_loss: 0.3217 - val_accuracy: 0.8502\n",
      "Epoch 5/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.3191 - accuracy: 0.8607 - val_loss: 0.3101 - val_accuracy: 0.8684\n",
      "Epoch 6/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.3094 - accuracy: 0.8688 - val_loss: 0.3070 - val_accuracy: 0.8692\n",
      "Epoch 7/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.3014 - accuracy: 0.8754 - val_loss: 0.2965 - val_accuracy: 0.8765\n",
      "Epoch 8/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.2952 - accuracy: 0.8812 - val_loss: 0.2896 - val_accuracy: 0.8792\n",
      "Epoch 9/10\n",
      "9079/9079 [==============================] - 20s 2ms/step - loss: 0.2892 - accuracy: 0.8861 - val_loss: 0.2806 - val_accuracy: 0.8891\n",
      "Epoch 10/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.2834 - accuracy: 0.8911 - val_loss: 0.2770 - val_accuracy: 0.8934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EABC238EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EABC238EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EABC238EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "9051/9079 [============================>.] - ETA: 0s - loss: 0.4281 - accuracy: 0.8080WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EABA5C4CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EABA5C4CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EABA5C4CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.4280 - accuracy: 0.8082 - val_loss: 0.3739 - val_accuracy: 0.8315\n",
      "Epoch 2/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.3522 - accuracy: 0.8461 - val_loss: 0.3370 - val_accuracy: 0.8548\n",
      "Epoch 3/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.3343 - accuracy: 0.8560 - val_loss: 0.3246 - val_accuracy: 0.8599\n",
      "Epoch 4/10\n",
      "9079/9079 [==============================] - 20s 2ms/step - loss: 0.3249 - accuracy: 0.8608 - val_loss: 0.3181 - val_accuracy: 0.8638\n",
      "Epoch 5/10\n",
      "9079/9079 [==============================] - 20s 2ms/step - loss: 0.3179 - accuracy: 0.8648 - val_loss: 0.3114 - val_accuracy: 0.8676\n",
      "Epoch 6/10\n",
      "9079/9079 [==============================] - 20s 2ms/step - loss: 0.3114 - accuracy: 0.8692 - val_loss: 0.3080 - val_accuracy: 0.8681\n",
      "Epoch 7/10\n",
      "9079/9079 [==============================] - 20s 2ms/step - loss: 0.3065 - accuracy: 0.8719 - val_loss: 0.3018 - val_accuracy: 0.8731\n",
      "Epoch 8/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.3029 - accuracy: 0.8735 - val_loss: 0.2971 - val_accuracy: 0.8731\n",
      "Epoch 9/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.3000 - accuracy: 0.8752 - val_loss: 0.2954 - val_accuracy: 0.8758\n",
      "Epoch 10/10\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.2979 - accuracy: 0.8769 - val_loss: 0.2940 - val_accuracy: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EABF009558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EABF009558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EABF009558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "9058/9079 [============================>.] - ETA: 0s - loss: 0.4272 - accuracy: 0.8088WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EABD78F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EABD78F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EABD78F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "9079/9079 [==============================] - 19s 2ms/step - loss: 0.4270 - accuracy: 0.8088 - val_loss: 0.3688 - val_accuracy: 0.8377\n",
      "Epoch 2/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.3535 - accuracy: 0.8452 - val_loss: 0.3448 - val_accuracy: 0.8522\n",
      "Epoch 3/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.3392 - accuracy: 0.8504 - val_loss: 0.3359 - val_accuracy: 0.8537\n",
      "Epoch 4/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.3299 - accuracy: 0.8541 - val_loss: 0.3355 - val_accuracy: 0.8348\n",
      "Epoch 5/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.3211 - accuracy: 0.8591 - val_loss: 0.3195 - val_accuracy: 0.8619\n",
      "Epoch 6/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.3131 - accuracy: 0.8648 - val_loss: 0.3098 - val_accuracy: 0.8635\n",
      "Epoch 7/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.3060 - accuracy: 0.8699 - val_loss: 0.3017 - val_accuracy: 0.8705\n",
      "Epoch 8/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.3015 - accuracy: 0.8734 - val_loss: 0.3013 - val_accuracy: 0.8723\n",
      "Epoch 9/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.2983 - accuracy: 0.8764 - val_loss: 0.2992 - val_accuracy: 0.8737\n",
      "Epoch 10/10\n",
      "9079/9079 [==============================] - 18s 2ms/step - loss: 0.2963 - accuracy: 0.8781 - val_loss: 0.2957 - val_accuracy: 0.8766\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeVxO6f/48dfderdpkRaUJCRZUrasWVpmMIx9G5EZy2fGNllmsu9jMMgwhlRGDIaZn8kaYSwzNBEzJlQjMSKyhKTU+f3RtzNu7Ul3w/V8PM7jcZ/rXNe53uec6r66zrmuo5AkSUIQBEEQBOEtoqHuAARBEARBECqaaAAJgiAIgvDWEQ0gQRAEQRDeOqIBJAiCIAjCW0c0gARBEARBeOuIBpAgCIIgCG8d0QASBEEQBOGtIxpAgiAIgiC8dUQDSBAEQRCEt45oAAmvTKFQlGg5evRoudSXkZGBQqFg8eLFZSrfqlUrvL29yyWWyurSpUsoFAq+//77QvOMGTMGDQ0Nrl69WmieTz/9FIVCwV9//VWq+vv06YOzs7NKmrm5OR9//HGxZcPDw1EoFPz++++lqhPg6NGjzJ49m/T09Hzb3Nzc6NatW6n3+ar+/PNPFAoF33zzTYXXXVY3btxAU1MThUJBbGysusN5bdzc3Ar9e5WYmFiqfeVd5x9++KHYvP7+/hgaGpYxaqG8aKk7AOG/79dff1VZnzdvHkeOHCEyMlIl3cnJqVzq09XV5ddff8XW1rZM5YOCgtDU1CyXWP7L/Pz8+OabbwgODmbu3Ln5tj9//pzNmzfTqlWrcrl2Bw4coGrVqq+8n6IcPXqUOXPm8PHHH6Ovr6+yLSQkBG1t7dda/5siODiYnJwcADZu3MiXX36p5ohen4YNG7Jhw4Z86dbW1mqIRqhIogEkvLJWrVqprFerVg0NDY186YXJzMxEU1OzxI0ShUJR4n0XpGHDhmUu+yZxc3OjcePGhIaGMnv2bDQ0VDuEw8PDSUlJYcGCBeVSn6ura7nsp6xe7pESCiZJEsHBwdSqVQsjIyM2bdrEwoULy63xmJ6enq9xqk6Ghoav9PdE+O8St8CECrV//34UCgXbtm1j3LhxWFtbo1QquX79OsnJyYwePZoGDRpgYGCApaUlXbp0ydfDVNAtsG+++QaFQsHJkyf58MMPqVq1Kubm5vTt25fbt2+rlH/5Flje7aLAwEC++OILatWqhaGhIW3atCE6OjrfMaxZswYHBwd0dXVp1KgRO3bsYMCAATg6OhZ7/Js3b6ZLly5YWVmhr6+Pk5MT06dP5+nTpyr5BgwYgLm5OZcuXcLT0xMDAwNsbW2ZNm0aWVlZKnmvX79O7969MTQ0xMTEhMGDB3Pnzp1iY4HcXqCkpCQOHz6cb1twcDAGBgb0799fTlu2bBlt2rTB3NwcQ0NDmjRpwsqVK8nOzi62roJugV24cIHOnTujp6eHhYUF48aNK/D2VXh4OO+++y41atRAT0+PevXq8cknn/DgwQM5j7+/P3PmzAFyG+F5tzLybqUVdAssJSWFkSNHYm1tja6uLg4ODsyZM0flHD9+/BiFQsG0adNYv3499erVQ19fn2bNmnHo0KFij7uknjx5wqeffkqtWrXQ0dHB1taWiRMn8vjxY5V8+/bto127dpiamqKnp4ednR39+vXj+fPncp4VK1bg7OyMgYEBVapUwcnJiXnz5pUojsjISK5evYqvry8jRowgJSWFPXv2FJh39+7ddOjQgSpVqmBgYICzszMrVqyQt/fp0wcrKyuio6Px8PDA0NCQHj16yNvXrFmDs7MzSqWSqlWr0rdvX+Lj41XquHTpEr1798bKygpdXV2srKzw9PTk0qVLpTonr+LcuXO8++67mJiYoKenh6urK9u2bStR2Z07d+Ls7Cz/fK1evbrAfJs3b8bNzU0+lw4ODvzvf/8rl/iFgokeIEEtPv30U9q3b8+GDRvIycnB1NSUpKQktLW1mTNnDpaWljx69IgdO3bQrl07jh8/TuvWrYvd77Bhw+jRowdbt27l6tWrTJkyheHDh7N3795iyy5fvpxGjRoRGBhIdnY2AQEB+Pj4cPXqVQwMDABYtWoV48ePZ8CAAaxatYp79+7x2WefkZWVhZ6eXrF1xMfH06NHDyZNmoS+vj6xsbEsWrSIs2fP5ovx6dOn9OzZk9GjRzN16lQiIyNZuHAhZmZmTJkyBcj9cvbw8OD+/ft8+eWX2Nvbs3v3boYMGVJsLABDhgxhypQpbNy4ka5du8rpKSkp7N27lyFDhmBkZCSnX716lWHDhmFnZ4empiZnz55l9uzZJCQksGrVqhLVmef69et07NgRY2Njvv32W8zMzAgODmby5MkFnreOHTsyZswYjIyM+Pvvv/nyyy85ceIE0dHRaGhoMG7cOB48eEBQUBD79+/H2NgYgAYNGhRY/6NHj2jfvj3JycnMmzcPR0dHIiMjmTt3LhcvXmT79u0q+bdv306NGjVYtGgRSqWSBQsW0L17dxISEqhevXqpjv1l2dnZ+Pj4cPr0aWbMmEHLli2Jjo5mzpw5nDlzhmPHjqGlpUVsbCzvvfceXl5ebNq0CSMjI65fv86+ffvkW1YbNmxg4sSJ+Pv74+XlhSRJxMXFFfms14uCgoJQKBQMHz4cAwMDpk6dSlBQED179lTJl/e74Onpyfr16zE3Nyc2Npa///5bJd/jx495//33GTduHDNnzpTjDAgIYOHChfj6+vLll19y69YtZs2aRevWrYmOjsbW1pacnBy8vLwwNDRk+fLl1KxZkzt37nD8+HG58VuSc1KclxtKGhoaco/o+fPnadu2LbVq1WLNmjVUqVKFjRs3MmDAAFJTUxk7dmyh+929ezd9+/alU6dOLFiwgIyMDBYuXKjScAc4dOgQQ4cOxdfXlwULFqCtrc3Vq1fz/fMnlDNJEMrZsGHDJAMDgwK37du3TwIkT0/PYvfz/PlzKSsrS2rTpo00cOBAOf3p06cSIC1atEhOW7t2rQRIkyZNUtnH3LlzJUC6d++enNayZUvJy8tLXo+NjZUAyc3NTcrJyZHTf/nlFwmQfvzxR0mSJCkzM1OqWrWq1KFDB5U64uPjJU1NTal+/frFHtOLcnJypKysLOnAgQMSIF2+fFne1r9/fwmQdu/erVKmU6dOUpMmTeT1r776SgKkAwcOqOQbOnSoBEhbt24tNo7+/ftLSqVS5Rx9+eWXEiAdP3680HLZ2dlSVlaWtGbNGklXV1dKT0+Xt/Xu3Vtq2LChSv6qVatK//vf/+T1//3vf5KmpqZ05coVlXzu7u4SIEVFRRVYb955u3jxogRIhw8flrfNmjVLAqQ7d+7kK+fq6iq9++678vrSpUslQNq7d69KvhkzZkiAdOrUKUmSJOnRo0cSINWqVUt6+vSpnO/vv/+WACkwMLDQcyRJkvTHH39IgLR27dpC8/zwww8SIK1Zs0YlPSgoSAKkLVu2SJIkSSEhIRIgxcfHF7ovX19fqWbNmkXGVJh79+5JSqVS6tKli5zWu3dvSVNTU7p586acdvfuXUlPT0/y9vYucn+9e/eWAGn79u0q6cnJyZK2trbUr18/lfTLly9Lmpqa0kcffSRJkiQlJiZKgLRhw4ZC6yjJOSmMq6urBORbRo0aJefp1q2bZGhoKN2+fVulbPv27SUTExP55z7vOu/YsUPO07BhQ8ne3l7KysqS0+7evSsZGhqq/I2cPXu2pKGhIWVmZpb6GISyE7fABLXo3bt3vjRJkggMDMTFxQWlUomWlhba2tqcPHmyxCNRXuxeB2jcuDEASUlJxZbt1q0bCoUiX9lr164BuaM8UlNT6devn0q5OnXq0Lx58xLFFxcXR//+/bG0tERTUxNtbW28vLwA8h2jtrY2Pj4++Y4nLx6AI0eOYG5ujqenp0q+QYMGlSgeyL0NlpGRwZYtW+S0kJAQ6tWrR9u2bVXynj59mnfeeQczMzM5/rFjx/Ls2bN8//kX58iRIzRv3py6deuqpA8cODBf3ps3b+Ln50eNGjXkn4u8Z7nKOkopMjISCwuLfOfY19cXIN9twa5du6JUKuX12rVrY2hoqHI9yipvwMCwYcNU0ocOHYqmpqYci6urK5qamvj6+hIWFlZg3S1atODGjRv4+voSHh7OvXv3ShxHWFgYGRkZjBgxQk4bMWIE2dnZhIaGymnHjh3j6dOnRfZ+5NHQ0MjXe3T8+HGysrLkc52nXr16uLu7y8dbvXp1atSowbx581i1ahUXLlxAkiSVMiU5J0VxdnYmKipKZfn888/l7ZGRkbzzzjtYWFiolBs2bBgPHjwo8DY5wJ07d7h48SL9+vVDS+vfmy1Vq1aVf+fztGjRgpycHHr37s0PP/zArVu3SnUMQtmIBpCgFgWNsFi0aBHjxo2jXbt27Nq1i9OnTxMVFUWnTp3yPSNTmJdHGenq6gKUqHxxZVNTUwGwtLTMV7agtJc9ePCAtm3bEhMTw6JFizh27BhRUVHyUPWXY6xSpYrKH868mF7Ml5qaipWVVb66CkorTJcuXahVqxbBwcEAnDlzhosXL6p8CQJcuXKFjh07cv/+fVavXs2JEyeIioqSRwiV9BqVNvasrCw8PDzYv38/AQEBREZGEhUVJTcaSlvvi/UX9HOYdzsr73rnKWgE28vXo6xSU1MxNjbO93CwtrY25ubmcizOzs4cOHAAIyMjPvzwQ+zs7KhXrx7r1q2Ty4waNYq1a9cSGxtLz549qVatGm3atOGXX34pNo6goCCMjIzw8PDgwYMHPHjwgJYtW2JpacnGjRvlfHnPmNWsWbPYfZqbm+d7gDrveAo7/3nbtbW1OXr0KB06dGD+/Pk0adIES0tL/P395WfFSnJOimJgYICbm5vKkjfCNCMjg/T09FL9nLx8jCX5Gffx8WHbtm2kpaUxaNAgrK2tadq0KT/++GOJjkEoG9EAEtTixZ6WPJs3b8bb25tVq1bxzjvv0KJFC9zc3Hj48KEaIswv7wvw5YeqgRL9x3bw4EFSUlLYtGkTI0aMoF27dri5ucnPF5U1poLqLs1/kHnPe0RHR3PhwgU2btyIlpYWH3zwgUq+H374gYyMDHbv3s2gQYNo06YNbm5u+Rpp5R17VFQUV65cYdWqVYwdO5YOHTrg5uaGqalpmep9sf7k5OR86Tdv3gRyv7grStWqVXn48GG+B8CzsrK4e/euSiydO3dm7969PHz4kJMnT9K4cWNGjx5NeHg4kNvjMnr0aE6fPs39+/f56aefePLkCT4+PqSkpBQaw7lz54iJieHRo0dYW1tjamqKqakp5ubm3L59m7i4OLkRVa1aNSB3vqDiFPS7nve7VNj5f/F4HRwcCA0NJSUlhYsXLzJq1CiWL1/OzJkzS3xOykqpVGJgYFCmn5O8Yyzp72e/fv04evQoaWlpHDp0CFNTU/r06cOFCxde5RCEIogGkFBpKBQKudclz++//87Zs2fVFJEqZ2dnzMzM8o3+SEhIKNGkfXlfBC8fY0n/Uy2Ih4cHd+/e5eDBgyrpL97OKonhw4ejoaHBmjVr+P777/Hx8cn3X69CoUBDQ0Ml/uzsbIKCgsoce1RUFHFxcSrpW7duzVcvlOy8labHr3PnzqSkpBAREaGSvmnTJnl7RcmrKywsTCU9LCyM7OzsAmPR1tbG3d2dlStXAhT4e2JkZET37t2ZPHky6enpKiOnXpY3F853333HkSNHVJaffvoJhUIh9wJ17NgRPT091q5dW6bjbd++Pdra2mzevFklPT4+nl9//bXQc583mq1OnToFHm9JzklpderUiX379uXr6dm0aRMmJiY0a9aswHLVqlWjYcOGbN++XeUh69TUVA4cOFBofUqlks6dOzN//nxycnKIiYl55WMQCiZGgQmVRrdu3Vi6dCnz58/H3d2dv/76i3nz5mFnZ6fu0IDcP66zZs1i/PjxDBw4kA8++IDU1FRmz55N9erV882j87J27dpRpUoVRo4cyYwZM9DQ0CA0NJTLly+XOSY/Pz9WrVrFwIEDWbBgAfb29vy///f/OHbsWKn2Y2trS5cuXfj222+RJAk/P798eby9vZkxYwb9+vVj4sSJPHr0iMDAQJ49e1am2CdPnszmzZvx9PRk7ty5VK1alY0bN3L9+nWVfE2aNKFmzZpMmjSJ9PR0jIyM2LVrV4HH2KhRIyB3RF+/fv3Q1tbGycmpwHlnPvroI9atW0f//v2ZO3cu9evX58iRIyxZsoS+ffuW+9ww586dK3CW4NatW/Pee+/Rrl07xo0bx927d2nevLk8Cszd3Z0+ffrIxxUdHY2Xlxe2trY8efKEdevWoVAo5EbD4MGDsbS0pFWrVlhZWfHPP/+wcOFCzM3Nadq0aYGx5T0D1rx580JHEHbt2pUdO3awatUqzMzMWLx4MePHj8fHx4fhw4djbm7OlStXiIuLY9myZUWeC0tLSyZPnszChQvR19end+/e3L59m1mzZmFiYiI/g3Pq1ClmzJhB7969cXBwQFNTkwMHDpCQkCDfoi3JOXkV8+bNo3Xr1nTs2JGAgACMjIwIDg7m2LFjfP3110WO/pw/fz7vv/8+3t7ejBs3joyMDBYsWICpqanKs1n+/v6kpaXh4eEh3wJcvnw5SqUy33N4QjlS80PYwhuoJKPAfv7553zb0tPTpQkTJkjW1taSUqmU3NzcpD179kj9+/dXGWFV1CiwP/74o8D6fv31VzmtsFFgL4/mKageSZKk1atXS/b29pKOjo7k6Ogobd68WfLy8pJat25d7Lk5duyY1LJlS0lfX1+ytLSURo8eLf3222/5Rmz1799fqlq1ar7yU6dOlXR1dVXSrl27JvXs2VMyMDCQqlSpIvXv3186duxYiUeB5dm2bZsESJaWliqjVl70ww8/SM7OzpKurq5kY2MjBQQESDt37sw3aqsko8AkSZJiYmKkjh07SkqlUjI3N5fGjBkjx/Hi/mJiYiQPDw/J0NBQMjMzkwYPHizFxcVJgPTll1/K+bKzs6WJEydKVlZWkoaGhsp+Xh4FJkmSdPv2bcnPz0+ytLSUtLW1JXt7e2n27Nkqo3HyRoFNnTo13/ko6Jheljc6qLAlb9TQo0ePpIkTJ0o2NjaSlpaWVKNGDWn8+PFSWlqavK+jR49KPXr0kGxsbCRdXV3J3Nxc6tKli8oowHXr1kkdOnSQLCwsJB0dHalGjRrS4MGDpUuXLhUa4+bNm4sdbZU3Um3dunVy2o8//ii1adNG0tfXlwwMDCRnZ2dp5cqV8vbevXtLlpaWhe5z9erVUsOGDSUdHR3J1NRU6tOnjxQXFydvv379ujR06FCpXr16koGBgWRkZCS5uLhIX3/9tTxisyTnpDCurq5Sy5Yti80XHR0t+fj4SEZGRpKurq7UrFmzfL9bBY0CkyRJ2r59u+Tk5CTp6OhItWvXllasWCF9+umnKn8jd+7cKXl6ekrVq1eXdHR0JEtLS6lHjx7S6dOni41NKDuFJL30SL0gCKWSmppK3bp1GTJkSKnnwhEEQRDUQ9wCE4RSSEpKYvny5XTo0AEzMzOuXr3KsmXLePbsGZ988om6wxMEQRBKSDSABKEUlEolcXFxbN26lXv37mFoaIi7uzshISH55rMRBEEQKi9xC0wQBEEQhLeOGAYvCIIgCMJbRzSABEEQBEF464gGkCAIgiAIbx3xEHQBcnJyuHnzJkZGRgVO4y4IgiAIQuUjSRKPHj0q0eS0ogFUgJs3b2JjY6PuMARBEARBKIPr168X+7Je0QAqgJGREZB7AqtUqaLmaARBEARBKIm0tDRsbGzk7/GiiAZQAfJue1WpUkU0gARBEAThP6Ykj6+Ih6AFQRAEQXjriAaQIAiCIAhvHdEAEgRBEAThrSOeARIEQXhNsrOzycrKUncYgvDG0NbWRlNTs1z2JRpAgiAI5UySJG7dusWDBw/UHYogvHFMTEywsrJ65Xn6RANIEAShnOU1fiwsLNDX1xcTqgpCOZAkifT0dFJSUgCwtrZ+pf2JBpAgCEI5ys7Olhs/VatWVXc4gvBG0dPTAyAlJQULC4tXuh0mHoIWBEEoR3nP/Ojr66s5EkF4M+X9br3q83WiASQIgvAaiNtegvB6lNfvlmgACYIgCILw1hENIEEQBOGVHT16FIVCUeTIt5CQEExMTCowqldnZWXFN998U+L8+/fvR6FQkJGR8RqjEsqDaAAJgiAI+Pr6olAo8i3x8fEVGseCBQtwd3dHX1+/2MZSYmJigTG/uMyePfuV4vnjjz8YNmxYifN36tSJ5ORklErlK9VbHNHQenViFFgF+/vOY5TamlQ30VN3KIIgCCq8vb0JDg5WSatWrVqFxpCZmUnfvn1p3bo1QUFBRea1sbEhOTlZXl+6dCn79+/n0KFDcpqhoWG+cpIkkZ2djZZW8V+BpT1+HR0drKysSlVGUA/RA1SB5oX/RYe5oczetF3doQiCIOSjq6uLlZWVypI3zPjZs2eMGzcOCwsLlEolbdu2JSoqqsj9hYSEYGtri76+Pr169SI1NbXYGObMmcPEiRNp1KhRsXk1NTVVYjU0NERLSytfWl5vyaFDh3BxcUFHR4eoqCguXbpE9+7dsbCwwMjIiFatWnH06FGVOl68BZaRkYFCoSA0NJRu3bqhr69P/fr12bdvn5z/5Z6Zb775BisrK8LDw6lfvz5GRkZ069aNO3fuyGUyMzMZM2YMVapUwdzcnBkzZjBgwAAGDBhQ7DkoTHZ2NjNmzKB69ero6uri6urK4cOH5e0ZGRmMGjUKKysrlEoltWvXZtmyZUBuAzEgIAAbGxt0dXWpWbMm/v7+ZY6lshINoAry+PFjVk3owo3VH7N1xWfqDkcQhAoiSRLpmc/VskiSVG7HMWXKFHbu3EloaChnz57FwcEBLy8v7t27V2D+06dPM2LECMaOHUtMTAweHh7Mnz+/3OIpi6lTp7Js2TJiY2NxdHTk8ePHvPfee0RGRhIdHU379u3p1q2bSq9SQWbNmsWwYcO4cOECHh4eDBo0iLS0tELzP3jwgNWrV7N161aOHDnC5cuXmTZtmrx93rx57Ny5k7CwMI4fP87NmzdVGlVlsWTJEr7++mtWrVrF+fPnad++Pe+++y6JiYlAbm9ZREQEu3bt4vLly4SGhmJjYwNAWFgYa9euJSgoiLi4OHbu3ImTk9MrxVMZiVtgFcTQ0BClIvd0P05M5uylRJo52qk3KEEQXrunWdk4zTyglrr/muuFvk7J/8yHh4er3DLy8fFhx44dPHnyhLVr1xISEoKPjw8A69evJyIigqCgICZPnpxvXytXrsTLy0v+oq9Xrx6nTp1i//79r3hUZbdw4UI6deokr7u5ueHm5iavL1myhJ07d7Jnzx5GjhxZ6H4+/PBD+vbtK+9z3bp1nD17lo4dOxaY/9mzZwQFBVGjRg0AxowZw6pVq+Ttq1evZt68eXTv3h3I7TV61QbQ0qVLmT59On369AHgq6++4vDhwwQGBrJs2TKSkpJwdHTE3d0dgFq1asllk5KSqFGjBp07d0ZTUxNbW1tatmz5SvFURqIHqAJ1aOqV+0GCpcFF39sWBEGoaB4eHsTExMhL3pd0QkICWVlZtGnTRs6rra1NixYtiI2NLXBfsbGxtG7dWiXt5fWK9mJjByAtLY1JkybRoEEDTExMMDQ0JDExkaSkpCL307hxY/mzmZkZOjo68usZCmJmZiY3fiD3FQ55+W/fvs2DBw9o0aKFvF1bW5umTZuW6thelJKSwr1791SuF0CbNm3k6+Xn58epU6dwdHRkwoQJKrfHBgwYwL1797C3t2fUqFHs3r2b7OzsMsdTWYkeoArk06kbYT9sACDy0I/APPUGJAjCa6enrclfc73UVndpGBgY4ODgkC8971bayxPQSZJU6KR05Xn7rbwYGBiorE+YMIGTJ0/yxRdfUKdOHfT09OjevTuZmZlF7kdbW1tlXaFQkJOTU6b8RZ3bsirJ9WrZsiWJiYns27ePQ4cO0atXL3r06MHmzZuxt7cnLi6OgwcPcujQIT788EMaNGjA4cOHy+1N7JWB6AGqQD0GeGKoNAbgzp+XufvwsZojEgThdVMoFOjraKllKa8Zcx0cHNDR0eHEiRNyWlZWFr///jsNGjQosIyTkxO//fabStrL6+p2/PhxRo4cSc+ePWnUqBHm5uZcv369QmOwsrLCxMSEM2fOyGlZWVmcP3++zPu0tLSkatWqKtcL4Ndff1W5XiYmJgwcOJCgoCC+++47wsLCSE9PB3JfN9GzZ09Wr17NwYMHOXbsGJcvXy5zTJWR6AGqQEamejRt0JoT5/aTk/mc1WE7mD12uLrDEgRBKJKBgQFjxoxh8uTJmJmZYWtry5IlS0hPT8fPz6/AMuPGjcPd3Z0lS5bQs2dPDh48WKLnf5KSkrh37x5JSUlkZ2cTExMD5DbCChrS/iocHBzYsWMHXl5eZGdnExAQgIZGxfcLfPzxx8ydOxc7Ozvq1KnDsmXLePLkSYkasBcuXEBHR0de19DQoHHjxvj7+zN//nxq1aqFs7Mz69at4/Lly+zevRvIfd7Jzs6OJk2aALBz5055xN6GDRvQ0tKiefPm6OnpERYWhqGhofyQ9JtCNIAqWPd3enDiXO4fge9/+k40gARB+E9YvHgxOTk5DB06lEePHuHm5saBAwcwNTUtMH+rVq3YsGEDs2bNYvbs2XTp0oXp06czb17Rt/5nzpxJaGiovO7i4gLAkSNHCn3IuKwCAwPx8/OjVatWWFhYEBAQUOiottdpxowZ3Llzh4EDB6Kjo8OYMWPo2LFjiSZTfPnhZF1dXTIyMpg8eTKPHz/mk08+ITU1FWdnZ/bs2SM/7GxgYMD8+fNJSEhAW1ubli1bEh4eDoCxsTFffvklly5dQpIkGjduzJ49ezAyMir/g1cjhVQZb9SqWVpaGsbGxjx8+JAqVaqU676vxd3CwdGW5zlZaJsY8vTuQzQ1xZ1IQXhTZGRkcPXqVWrXrv3aZwMW3kzZ2dk4ODgwcuRIAgIC1B1OpVPU71hpvr/FN28Fs3WwpF6t3C7HrAeP2XHwRDElBEEQhDdZQkICGzduJDx1EskAACAASURBVC4ujgsXLjBy5EiSk5NfaSJEoXiiAVTBFAoFXT285fW1WzaoMRpBEARB3RQKBevXr8fV1ZV27doRHx9PZGQkderUUXdobzTxDJAaDBral5Ubc2dEPXviUDG5BUEQhDeZvb09v/76q7rDeOuIHiA1cGvfiBrm9kDurNAxl6+qOSJBEARBeLuIBpAaaGgoaNvSQ15fFhyivmAEQRAE4S0kGkBq0q9fH/lzxMGdaoxEEARBEN4+laIBtGbNGnk4m6urK8ePHy9Rue+//x6FQkHPnj3ltKysLKZOnUqjRo0wMDCgevXqfPDBB9y8efN1hV8m7/btjJFe7vwZd/68zP20J2qOSBAEQRDeHmpvAG3bto0JEyYQEBDAuXPnaNeuHT4+PsW+jO7atWv4+/vTrl07lfT09HTOnj3LjBkzOHv2LLt27eLKlSv06NHjdR5GqenqaePaKPctvDlZzwnc/IOaIxIEQRCEt4faG0DLly/Hz8+PkSNH0qBBA1asWIGNjQ1r164ttEx2djaDBw9mzpw52Nvbq2wzNjYmIiKCfv36Ub9+fVq1akVgYCDR0dHFNqoqWq/3esmft/60SY2RCIIgCMLbRa0NoMzMTKKjo/H09FRJ9/T05NSpU4WWmzt3LtWqVSv0HTQve/jwIQqFAhMTk1eKt7wN8O2FlmbuW4L/PnOmyLcJC4IgVGZHjx5FoVDw4MGDQvOEhIRUur/DL2rbti3+/v7yes2aNVm9enWh+Z8/f45CoZBfIVFW5bUfoXTU2gC6e/cu2dnZWFpaqqRbWlpy69atAsucPHmSoKAg1q9fX6I6MjIymDZtGoMGDSp0Wuxnz56RlpamslQEi+pmONrnvucm8+Fjdhwo2bNPgiAI5c3X1xeFQpFviY+Pr9A4FixYgLu7O/r6+iVqLDVq1IiRI0cWuG3r1q1oa2tz+/btMsVy7tw5RowYUaayhZk+fTpubm4qaVpaWiQnJ9O1a9dyretlGzZswNzc/LXW8V+i9ltgQL433kqSVOBbcB89esSQIUNYv359iS5iVlYWAwYMICcnhzVr1hSab9GiRRgbG8tLRb7x1qfrO/LntWEbK6xeQRCEl3l7e5OcnKyy1K5du0JjyMzMpG/fvowZM6ZE+f38/Ni+fTvp6en5tm3cuJFu3brl+ye7pKpVq4a+vn6ZypaWlZUVurq6FVKXkEutDSBzc3M0NTXz9fakpKQU+AObkJBAYmIi3bt3R0tLCy0tLTZt2sTu3bvR0tIiISFBzpuVlUW/fv24evUqERERRb4U7bPPPuPhw4fycv369fI7yGIM9f33XS9nj0dUWL2CIAgv09XVxcrKSmXR1NQEcnvKx40bh4WFBUqlkrZt2xIVFVXk/kJCQrC1tUVfX59evXqRmppabAxz5sxh4sSJNGrUqEQxDx06lGfPnrFjxw6V9KSkJCIjI+VHJe7cucOAAQOoUaMG+vr6NG7cmO3btxe575dvgV2+fJl27dqhVCpp2LAhkZGR+cr4+/tTt25d9PT0sLe3Z9asWTx//hzI7YFZsGAB0dHRcg/b5s2bC7wFdv78eTw8PNDT08Pc3JzRo0erNPKGDBlCnz59+OKLL7CyssLc3Jxx48bJdZXF06dP+fjjj6lWrRpKpZL27dsTHR0tb7937x6DBg2iWrVq6OnpUa9ePTZtyn1+9dmzZ4wZMwZra2uUSiV2dnYsWbKkzLFUBLW+CkNHRwdXV1ciIiLo1evfB4IjIiJ477338uV3dHTkjz/+UEmbPn06jx49YuXKlXLPTV7jJy4ujiNHjlC1atUi49DV1VVby9vZrR41LepwIyWBR0nJXLjyN43r2RdfUBCE/wZJgqz8vRMVQlsfCuhNL4spU6awc+dOQkNDqVWrFkuWLMHLy4v4+HjMzMzy5T99+jQjRoxg4cKFvP/+++zfv59Zs2aVSywvqlq1Ku+99x7BwcEMGzZMTg8ODsbS0hIfHx8g98u9RYsWTJs2DSMjI8LDwxk0aBB16tTB1dW12HpycnLo2bMnNWrU4PTp09y/f58JEybky2dsbMymTZuwtrbm/PnzfPjhhxgbGzNp0iQGDx7MxYsXOXLkCPv37wco8Dbf48eP8fLyon379kRFRXHr1i0+/PBDxo0bx4YN/74/MiIiAisrK44ePcqVK1fo378/Li4uDB8+vNTnEXIbb7t372bz5s3UrFmTxYsX4+XlRUJCAsbGxnz++edcuXKFffv2YW5uTnx8PM+ePQPgq6++Yt++fezYsQMbGxuSkpL4559/yhRHRVH7u8AmTZrE0KFDcXNzo3Xr1nz77bckJSUxevRoAD744ANq1KjBokWLUCqVODs7q5TP++HJS3/+/Dl9+vTh7NmzhIeHk52dLfcwmZmZoaOjU4FHVzyFQkH7Np3Y8mNu79WyoFBCv5ij5qgEQSg3WemwsLp66v78JugYlDh7eHg4hoaG8rqPjw87duzgyZMnrF27lpCQELlBsX79eiIiIggKCmLy5Mn59rVy5Uq8vLyYNm0aAPXq1ePUqVPyF395GjFiBO+88w5///039vb2SJJESEgIvr6+cg+Wra0tkyZNksuMHz+evXv3smPHjhI1gPbv309CQgKRkZFYW1sDMH/+fLp3766Sb8aMGfJnOzs7/vrrL7Zv386kSZPQ09PDwMAALS0trKys5Hwv99p89913PH/+nNDQUPT09HB2dmblypW8//77LF68WH4ExNzcnFWrVqGhoYGjoyM+Pj4cPny4TA2gtLQ0vv32W8LCwvDy8gJye6zs7OzYuHEjEydOJCkpCRcXF/kZJjs7O7l8UlIS9erVo02bNigUCmrVqlXqGCqa2p8B6t+/PytWrGDu3Lk0bdqUX375hb1798onLykpieTk5BLv78aNG+zevZsbN27QtGlTrK2t5aWokWXqNHhwf/nzwQNiVmhBENTDw8ODmJgYeVm1ahWQ+/hBVlYWbdq0kfNqa2vTokULYmNjC9xXbGwsrVu3Vkl7eb28eHp6UrNmTYKDgwGIjIwkMTFRpSHw/Plz5s+fT+PGjTEzM8PQ0JDIyMgST48SGxuLnZ2d3PiBgo9n+/bttGnTBktLSwwNDZkzZ06pp2CJjY3FxcUFPT09Oa1NmzZkZ2dz5coVOc3Z2RkNjX+/xq2trUlJSSlVXXni4+N5/vy5yjXW1dXFzc1NvsZjx45l8+bNNGvWjKlTp/Lbb7/JeYcPH05UVBSOjo6MHz+eQ4cq/4u+1d4DBLkndezYsQVuO3r0aJFlQ0JCVNbt7OyQJKmcIqsYnj06UEXfjLT0e6RcvMS9h48wMzZSd1iCIJQHbf3cnhh11V0KBgYGODg45EvP+5ta0gErL5apCBoaGvj6+hISEsKcOXMIDg6mffv21K1bV86zZMkSVq1axYoVK2jYsCEGBgZ8/PHHZGZmlqiOkhzPyZMnGTRoEPPnz6dLly4YGxuzefNmvv7661IdT0HntaBroK2trZJHoVCUeTqVklzjbt26ce3aNfbs2cOhQ4fw8PBg/PjxLF68mObNm5OYmMi+ffs4dOgQvXv3xsfHh++//75M8VQEtfcACaClrYWbS26rO+d5Nmu2iF4gQXhjKBS5t6HUsZTT8z8ODg7o6Ohw4sQJOS0rK4vff/+dBg0aFFjGyclJpYcAyLdenoYPH86NGzfYtWsXu3btyjdP3PHjx+nVqxeDBg2iSZMm1K5dm7i4uBLv38nJicTERJVBOy8fz4kTJ6hTpw7Tpk3Dzc2NunXrcu3aNZU8Ojo6ZGdnF1vX2bNnefr0qZx26tQpNDU1qVevXoljLo26deuipaWlco3z5up78RpbWFgwfPhwwsLCWLp0Kd9++628zdjYmAEDBrBhwwa2bNnCtm3bKmxambKoFD1AAvTr3YfIkz8DELbzO6aP8VVvQIIgCP/HwMCAMWPGMHnyZMzMzLC1tWXJkiWkp6cXOiHtuHHjcHd3Z8mSJfTs2ZODBw+W6PmfpKQk7t27R1JSEtnZ2cTExAC5jbAXn096We3atenUqRMfffQR2tra9OnTR2W7g4MDP//8M7/++ivGxsYsXbqUu3fvlvgceHl5YW9vzwcffMDSpUu5f/++yvM+eXVcvXqV7du34+rqys8//8zu3btVblPZ2dmRkJDA+fPnqVGjBkZGRvJzSnmGDh3KnDlz8PX1ZebMmdy6dYvx48fj6+tb7KCe4rx4TvPo6urSoEEDRo0axaeffoqJiQk1a9Zk0aJFZGVlybcSp0+fTosWLXByciIjI4M9e/bIjaOlS5diY2ND06ZNUSgU/PDDD/LxVVaiB6iS6D+sJ9qauQ9o/x11ptj/EARBECrS4sWL6d27N0OHDqVZs2bEx8dz4MABTE1NC8zfqlUrNmzYQGBgIE2bNuXgwYNMnz692HpmzpyJi4sLs2bN4vHjx7i4uODi4sLvv/9ebFk/Pz/u37/PgAED8s3fM2vWLBo3bkzXrl3p1KkTtra2+R5gLoqmpiY//fQTT548oXnz5owaNYqFCxeq5Hn//ff55JNPGDt2LC4uLpw5c4aAgACVPH379qVLly506NCBatWq5Ru+D2BoaMiBAwe4ffs2rq6u9OvXDy8vL/mZrFfx4MED+ZzmLXnn4csvv+S9995j8ODBNGvWjMTERA4cOICxsTGQe8tt6tSpNG7cmA4dOqBUKgkLC5NjXrhwIa6urjRv3pwbN26wZ8+eQm+RVgYK6b/2wEwFSEtLw9jYmIcPHxY5f1B5a+rUmvOxuV2qO/YdoY93xwqrWxCE8pGRkcHVq1epXbs2SqVS3eEIwhunqN+x0nx/ix6gSqSbz7//jawJC1ZjJIIgCILwZhMNoErE98OB8ufoY2JWaEEQBEF4XUQDqBJxcKyNjXXuENS068n8ceVvNUckCIIgCG8m0QCqZDp16CJ//mpjqBojEQRBEIQ3l2gAVTIf+A6WP+/fJ+YDEgRBEITXQTSAKpmOXd0xNsyd5+H2X5e4//CRmiMSBEEQhDePaABVMhoaGrRwawvkzgq9Nkz0AgmCIAhCeRMNoEpoUP9/X44atnOTGiMRBEEQhDeTaABVQn2H9EBbSxeAhDNRYlZoQRAEQShnogFUCRkYGtDQsRkAzx4/5qeIX9QckSAIQtGOHj2KQqHgwYMHheYJCQnBxMSkAqN6NRkZGSgUihK9wyzPN998g5WV1WuMSigvogFUSb3X4z3585rvQtQXiCAIbwVfX18UCkW+JT4+vsJiSExMxM/Pj9q1a6Onp0edOnWYNWsWmZmZBebPa3QVtYSEhJQ5HqVSSXJyMp06dSpxmWHDhvHHH3+Uuc6SEg2tVyfeBl9JDR85iDkLpwHw+1ExK7QgCK+ft7c3wcGqr+GpVq1ahdV/6dIlcnJyWLduHQ4ODvz55598+OGHPHnyhKVLl+bL7+7uTnJysrw+fvx40tLSVI4h70WeL8rOzkahUKi8pb0wpW1k6OnpoaenV6oygnqIHqBKqlZtG2xr1AUg7WYyf1yquP/CBEF4O+nq6mJlZaWyaGpqAvDs2TPGjRuHhYUFSqWStm3bEhUVVeT+QkJCsLW1RV9fn169epGamlpk/rwGmKenJ/b29vTo0QN/f3927dpVYH4dHR2VWPX09PIdg56entxb8uOPP+Lo6Iiuri63b9/m1KlTdO7cmapVq2JiYkLnzp25cOGCvP+Xb4FdunQJhULB7t27adeuHfr6+vneVP9yz8y0adNo1aoVGzduxNbWFhMTE4YOHcqTJ0/kPA8fPqR///7o6+tTo0YNvv76a1q1asW0adOKPF9Fefr0KWPHjqVatWoolUo6dOjAuXPn5O13795lwIABmJubo6enR/369eU3u2dkZDBq1CisrKxQKpXUrl2bZcuWlTmWyko0gCqxLp27yp9XhHynxkgEQSgrSZJIz0pXyyJJUrkdx5QpU9i5cyehoaGcPXsWBwcHvLy8uHfvXoH5T58+zYgRIxg7diwxMTF4eHgwf/78Utf78OFDzMzMXjV8Hjx4wPLlywkJCeHPP//E1NSUx48fM3LkSE6dOsXJkyepUaMG77zzDk+fPi1yXwEBAUyfPp2YmBhsbW0ZNGgQOTk5heb/66+/OHjwIPv27ePHH39k//79LF++XN7+8ccfEx0dzb59+9i/fz/79+/nr7/+eqXjnTBhAuHh4YSFhREdHU2NGjXw8vIiLS0NyG2Y/f333xw4cIDY2FgCAwPl87x06VIiIiLYtWsXly9fJjQ0FBsbm1eKpzISt8AqsQ9H+rJx0xoA9u/ZCYvnqDkiQRBK6+nzp7Tc0lItdZ8edBp9bf0S5w8PD8fQ0FBe9/HxYceOHTx58oS1a9cSEhKCj48PAOvXryciIoKgoCAmT56cb18rV67Ey8tL7sWoV68ep06dKtUDxQkJCQQGBpZL78OzZ8/YsGED9evXl9M8PT1V8gQFBWFkZMTJkyfp0qXLy7uQTZs2DS8vLwBmzZqFq6srSUlJ2NnZFZhfoVCwceNG9PX1adiwIQMHDuTw4cPMmDGD1NRUtm7dyk8//USHDh0ACA4OpmbNmmU+1vv37xMUFMT27dvlY8zrgQoNDeWTTz4hKSkJV1dXXF1dAVRiT0pKwtHREXd3dwBq1apV5lgqM9EDVIm1bOuGSRVzAG7FXuL+g4dqjkgQhDeZh4cHMTEx8rJq1SogtyGSlZVFmzZt5Lza2tq0aNGC2NjYAvcVGxtL69atVdJeXi/KzZs38fb2pm/fvowcObIMR6PK0NBQpfEDkJyczMiRI6lbty5VqlTB1NSUzMxMkpKSitxX48aN5c/W1tYApKSkFJrfwcEBff1/G6LW1tZy/vj4eLKzs2nRooW83dzcHHt7+5If3Evi4uLIzs5WuV5KpRJXV1f5eo0dO5aQkBBcXV2ZNm0aZ86ckfP6+flx6tQpHB0dmTBhAocPHy5zLJWZ6AGqxBQKBa1atmV/xE/kZGezbusupo0Zru6wBEEoBT0tPU4POq22ukvDwMAABweHfOl5t9IUCkW+9JfTXi5TFjdv3sTDw4PWrVvz7bfflnk/LzIwMMiXNnjwYJ4+fUpgYCA2Njbo6urSrFmzQked5dHW1pY/5x1/UbfAXsyfVyYvf1HntqxKcr169uxJYmIie/bs4dChQ7Rv3x5/f3/mz59Py5YtSUxMZN++fRw6dIhevXrRo0cPNm/eXOaYKiPRA1TJfTD035ejbt7xZv3wCcLbQKFQoK+tr5alsMZJaTk4OKCjo8OJEyfktKysLH7//XcaNGhQYBknJyd+++03lbSX1wvyzz//0LFjR5o1a0ZwcHCJRmqVhSRJnDhxgkmTJuHt7U3Dhg0BePSoYt+/WLduXTQ1NVV6YFJTU7l69WqZ91mvXj00NTVVrldGRgZnz55VuV6WlpaMGDGCLVu28MUXX6g0Nk1MTBg4cCBBQUF89913hIWFkZ6eXuaYKiPRA1TJ9ezzLjp+SjKzMog/c5rs7Gx5VIYgCEJFMDAwYMyYMUyePBkzMzNsbW1ZsmQJ6enp+Pn5FVhm3LhxuLu7s2TJEnr27MnBgweLff7n5s2bdOzYEVtbW5YuXcqdO3fkbeU9541CoaBOnTqEhobSuHFjUlNTmTx5Mrq6uuVaT3GqVq3KwIEDmThxIkZGRpiZmREQEICOjk6xDdjnz58TExOjkqZUKnF0dGTkyJHyPqtXr86CBQuA3HmKAD7//HNat26Nk5MT6enp7N27V24cLVmyBDs7O5o0aQLAzp075dF8bxLRA1TJ6enp4dzw/2aFfvKE3WJWaEEQ1GDx4sX07t2boUOH0qxZM+Lj4zlw4ACmpqYF5m/VqhUbNmwgMDCQpk2bcvDgQaZPn15kHQcPHiQ+Pp7IyEhq1qyJtbW1vLwOmzZtIjk5mSZNmjBixAimTJmilpmq886Rt7c3np6eeHp6Urt2bZRKZZHlUlNTcXFxUVl69uwJwPLly3n33XcZOHAgrq6u/PPPPxw4cAAjIyMAtLS0mDx5Ms7Oznh4eGBoaMh33+WONjYwMGD+/Pk0a9aMli1bcvv2bcLDw1/vSVADhVSe4yTfEGlpaRgbG/Pw4UOqVKmi7nBYOG8ZATP9Aegy8AMitoSqOSJBEAqTkZHB1atXS/QFJggFSUtLo3r16qxbt47BgwcXX+AtU9TvWGm+v0UP0H/AiJGDUZDbFRolZoUWBEF4o0RFRbF9+3YSEhKIiopi4MCBKJVKunXrpu7Q3miiAfQfYGVtha1t7qzQD5OT+fNSnJojEgRBEMpLTk4OixYtokmTJnh7e5Odnc0vv/xS4Gs8hPIjGkD/EXmTbgGs2ChmhRYEQXhTtGzZknPnzvH48WNSU1PZv38/Tk5O6g7rjScaQP8RH33oK3/eH17we3EEQRAEQSgZ0QD6j2jm5oKJce5bmZMvX+KBmBVaEARBEMpMNID+IxQKBe5t2gKQk5PNui071RyRIAiCIPx3iQbQf8iI4R/InzdvE7NCC4IgCEJZiQbQf0i37j7oaOfOeRD3+xmys7PVHJEgCIIg/DeJBtB/iK6uLs5N/m9W6PQn/HzwqHoDEgRBEIT/qErRAFqzZo08o6OrqyvHjx8vUbnvv/8ehUIhT/2dR5IkZs+eTfXq1dHT06Njx45cvHjxdYRe4fr36y1/XrNpkxojEQRB+NfRo0dRKBQ8ePCg0DwhISFqedVESdWsWZPVq1cDue/ZUigURb4CIj4+HoVCwZ9//vlK9ZbXfoTSUXsDaNu2bUyYMIGAgADOnTtHu3bt8PHxISkpqchy165dw9/fn3bt2uXbtmTJEpYvX87q1auJiorCysqKrl27Vvhbfl8H32FDUChyL9uZSDErtCAI5cPX1xeFQpFviY+Pr7AYEhMT8fPzo3bt2ujp6VGnTh1mzZpFZmZmgfkzMzMxNzdn/vz5BW5ftGgR5ubmhZYvipaWFsnJyXTt2rXUZYsyZMgQ+vTpo5JWu3ZtkpOTcXR0LNe6XjZ9+nTc3Nxeax3/JWpvAC1fvhw/Pz9GjhxJgwYNWLFiBTY2Nqxdu7bQMtnZ2QwePJg5c+Zgb2+vsk2SJFasWEFAQADvv/8+zs7OhIaGkp6ezpYtW1734bx2FhYW1LL7v1mhU5L5M/aymiMSBOFN4e3tTXJysspSu3btCqv/0qVL5OTksG7dOi5evMhXX33FN998w+eff15gfh0dHYYMGUJISAgFvdYyODiYoUOHoqOjU6Z4rKysKuTt8JqamlhZWaGlpfXa6xL+pdYGUGZmJtHR0Xh6eqqke3p6curUqULLzZ07l2rVquHn55dv29WrV7l165bKPnV1denQoUOh+3z27BlpaWkqS2Xm8463/HlVcJgaIxEE4U2iq6uLlZWVyqKpqQnk/p0cN24cFhYWKJVK2rZtS1RUVJH7CwkJwdbWFn19fXr16kVqamqR+b29vQkODsbT0xN7e3t69OiBv78/u3YVPvmrn58fCQkJ/PLLLyrpx48fJy4uTv6eiIuLo0ePHlhaWmJoaEiLFi2IjIwsdL8F3QL77bffaNq0KUqlkubNm3P+/HmVMllZWYwYMQI7Ozv09PSoX78+gYGB8vbp06cTFhbGzp075R62EydOFHgL7MiRI7i5uaGrq0v16tUJCAhQGfjStm1bJk6cyKeffoqpqSnW1tbMmzevyPNbnHv37jFkyBBMTEwwMDDg3XffJSEhQd5+9epVunXrhqmpKQYGBjg7O3PgwAG57KBBg6hWrRp6enrUq1ePTZX8MQ21NoDu3r1LdnY2lpaWKumWlpbcunWrwDInT54kKCiI9evXF7g9r1xp9rlo0SKMjY3lxcbGprSHUqFGf/Rvw2/fbjErtCBUZpIkkZOerpaloF6RspoyZQo7d+4kNDSUs2fP4uDggJeXF/fu3Ssw/+nTpxkxYgRjx44lJiYGDw+PQm9VFeXhw4eYmZkVur1Ro0Y0b96c4OBglfSNGzfSokULnJ2dAXj06BHdunXj8OHDnD17ls6dO9OtWzdu3LhRojjyyjds2JCzZ88yc+ZMJk+erJInOzsbW1tbfvjhB/766y+mT5/O1KlT5QbctGnT6N27N926dZN72Fq2bJmvruvXr/POO+/g7u7O+fPnWb16Nd988w2LFi3Kd4ympqacOXOGhQsXMnPmTI4cOVKi4ynI0KFDiYmJYc+ePZw8eZLMzEzeffddnj9/DsCYMWPk95T98ccfLFq0CH19fQA+//xzrly5wr59+4iNjWXNmjVUrVq1zLFUhErR36ZQKFTWJUnKlwa5P4BDhgxh/fr1mJubl8s+AT777DMmTZokr6elpVXqRlCjRs6Ymlpw/34K/8TF8uDBg0r9YKEgvM2kp0+53MxVLXXXPxuN4v++oEoiPDwcQ0NDed3Hx4cdO3bw5MkT1q5dS0hICD4+PgCsX7+eiIgIgoKC8jUEAFauXImXlxfTpk0DoF69epw6dYr9+/eXOJ6EhAQCAwNZtmxZkflGjBiBv78/q1evxtDQkMePH7Njxw6WL18u52nWrBnNmjWT1xctWsSuXbsIDw9n9OjRxcby3XffoVAoCAoKQqlU4uTkxLVr1/jkk0/kPEqlktmzZ8vrtWvX5sSJE2zfvp33338fQ0NDlMrcqUysrKwKrWv16tXY29uzcuVKFAoFjo6O3Lhxg5kzZzJ9+nSVY8pbr1u3LoGBgRw+fBgPD49ij+dlsbGx7N27l9OnT9OiRQsAwsLCsLW15eeff6ZXr14kJSUxePBgGjVqBKDyCEpSUhIuLi7yM0Z2dnaljqGiqbUHyNzcHE1NzXw9MykpKfl6cCD3lyExMZHu3bujpaWFlpYWmzZtYvfu3WhpaZGQkCD/UJV0n5Db7VulShWVpTJTKBS4t8+dFVrKyWH9FtELJAjCq/Pw8CAmJkZeVq1aBeT+7c3KyqJNmzZyXm1tbVq0aEFsbGyBf5kbIAAAIABJREFU+4qNjaV169YqaS+vF+XmzZt4e3vTt29fRo4cWWTegQMHkpOTw7Zt24DcwTWSJDFgwAA5z+PHj/H396dBgwaYmJhgaGhIfHx8sQNuXjweFxcXuQFT2PGsWbMGNzc3qlWrhqGhIcHBwSWu48W63N3dVf5pb9OmDQ8fPuTmzZtyWuPGjVXKWVtbk5KSUqq6XqxTR0eH5s2by2kWFhbUrVtXvsbjx49n9uzZtG3bltmzZ6vcshs7diybN2+mWbNmTJ06ld9++61McVQktfYA6ejo4OrqSkREBL169ZLTIyIieO+99/Lld3R05I8//lBJmz59Oo8ePWLlypXY2Nigra2NlZUVERERuLi4ALnPGh07dowvvvji9R5QBfpo5HD2/L/chs93W8OYPHaEmiMSBKEgCj096p+NVlvdpWFgYICDg0O+9LxbaaXpWX+V2283b97Ew8OD1q1b8+233xab39jYmD59+hAcHIyfnx/BwcH06dNH5Z/ZSZMmceTIEZYsWYKDgwN6enr06tWrxCPESnI8W7Zswd/fn+XLl9OyZUuMjIxYvHgxMTExJarjxboKOtegeg20tbVV8igUCnJyckpV18v7LyqWUaNG4ePjw549ezh48CALFy5kxYoVjB07lm7dunHt2jX27NnDoUOH8PDwYPz48SxevLhM8VQEtY8CmzRpEhs2bGDjxo3ExsYyceJEkpKS5C7JDz74gM8++wzI7V50dnZWWUxMTDAyMsLZ2RkdHR0UCgUTJkxg4cKF/Pjjj/z555/4+vqir6/PoEGD1Hmo5crb0xNd3dw/bleif5Pv0QqCULkoFAo09PXVshTWOCktBwcHdHR0OHHihJyWlZXF77//ToMGDQos4+TklK8XoCS9Av/88w8dO3akWbNmBAcHo6FRsq8pPz8/Tp48SXh4OCdPnsw3SOb48eOMGDGCXr160ahRIywsLLh27VqJ9p13PDExMTx79qzQ4zl+/Djt2rVj9OjRuLi44ODgkG8aAR0dnWJn8XdycuLkyZMqjZJTp05hYmKCtbV1iWMuDScnJzIzM1UebE9JSSE+Pl7lGtva2jJmzBh+/PFHxo8fz4YNG+RtFhYWDB8+nLCwMJYuXVqixqs6qf0ZoP79+5OamsrcuXNJTk7G2dmZvXv3UqtWLSD3vmJJfwHyTJkyhadPnzJ27Fju379Py5YtOXjwIEZGRq/jENRCR0cH56YuRP9/9u48rIrqf+D4+7JvsosoCmjIYq7gipiZ5oaYmJkLaIrZT3MvkoLSyrTM/OZeKosa7qS5oriViCuKWiIKorghuYQbO+f3Bzl5ZVFcuETn9TzzPPfOnJnzmbnA/XDmzDkH48jJus/mmD280a2TpsOSJKkKMjY2ZsSIEQQGBmJpaYm9vT3Tp0/n/v37JT6NCzBmzBg8PT2ZPn06vXr1Yvv27Y/t/3PlyhVeffVV7O3tmTFjBn/++aeyraw+MwDt27fHycmJQYMG4eTkxCuvvKK23cnJiaioKLp3744QQq0vzZPw8/Pj008/ZdiwYXzyySekpKSo9TF6UMeKFSuIiYnBwcGBiIgIjh07Rv369ZUyjo6O7NmzhzNnzmBpaVli/81Ro0Yxe/Zsxo0bx4gRI0hMTOTzzz/ngw8+KFfMJcnKyirWIlWtWjXc3Nzw9vYmICCAH3/8EWNjYwIDA3F0dKRHjx5A0Wfao0cP6tevz82bN9mzZ4+SHIWEhNCyZUsaNGhAdnY2mzdvLjU5rjSEVExmZqYARGZmpqZDKdPMWbMEIADR+S1/TYcjSZIQIisrS5w6dUpkZWVpOpRyGTx4sHjjjTdK3Z6VlSVGjx4trK2thb6+vmjbtq04dOiQsn337t0CELdu3VLWhYaGitq1awtDQ0Ph4+MjZsyYIczMzEqtIzw8XPmb9ujyJKZOnSoAMXXq1GLbUlJSRPv27YWhoaGwt7cXCxYsEG3bthUffPCBUsbOzk7MmTNHCCFEXl6eAMTGjRuV7fv27RONGzcWenp6wt3dXaxZs0YA4uTJk8o18vf3F2ZmZsLCwkK8//77IjAwUHh4eCjHSE9PFx07dhQmJiYCEHv37hVnz55VO44QQuzatUt4eHgIPT09YWtrKz7++GORn5+vbH80diGE8Pb2FgEBAaVen+Dg4BKvbceOHYUQQly/fl0MHDhQmJmZCSMjI9GtWzeRnJys7D9ixAhRr149oa+vL2xsbMSgQYPEjRs3hBBCTJ48Wbi6ugpDQ0NhaWkpfH19RWpqaukf1jMo63esPN/fKiGe43OSVcTt27cxMzMjMzOzUneIvnHjBtWrV0cIgZm1LX/9eVXTIUnSf152djapqanK9D6SJD1fZf2Olef7W+N9gKSnZ2VlhUM9ZwAyr6dz8o+Sn8aQJEmSJEmdTID+5bx7/jMq9Jywf/9UH5IkSZJUEWQC9C83Yti7yuutG9dpMBJJkiRJ+veQCdC/XAO3Blha2QBwOTmx1GHpJUmSJEn6h0yA/uVUKhWeHf4eFVoUsnh5lIYjkiRJkqTKTyZAVcDId/8ZJj5y+QoNRiJJkiRJ/w4yAaoCOnXohIFB0YSHp48eIC8vT8MRSZIkSVLlJhOgKkBXV5eGHn/Pe5aTxeaYXRqOSJIkSZIqN5kAVRH+g/6Z9XhBaKQGI5EkSZKkyk8mQFWE/1sDUamKPs5Dv25/ppmYJUmSymvPnj2oVCr++uuvUstERESUOPdVZZWdnY1KpXrsHGYP++GHHx47b5lUOcgEqIqwsLDA8e8J9/66cU2OCi1JUrm88847qFSqYsujs5m/aD179sTe3h4DAwNq1qyJv78/V65cKbHsg6SrrCUiIuKpYzEwMODq1au89tprT7zP4MGDOXny5FPX+aRkovXsZAJUhfTw7aa8nhcqR4WWJKl8unbtytWrV9WWunXrVmgMHTp0YPXq1SQlJREVFUVKSgp9+vQpsaynp6darH379i12Dm+//Xax/QoKCigsLHyieGxtbdHT03vi+A0NDalevfoTl5c0RyZAVcjIIe8pr+Wo0JIklZe+vj62trZqi7a2NgA5OTmMGTMGGxsbDAwM8PLy4vDhw2UeLyIiAnt7e4yMjPD19eXGjRuPjWH8+PG0bt0aBwcHPD09CQoK4sCBkp9u1dPTU4vV0NCw2DkYGhoqrSXr1q3D1dUVfX19rl27RlxcHB07dsTKygpzc3M6duzIiRMnlOM/egvs9OnTqFQqNmzYQLt27TAyMqJZs2YcOXJE2efRlpmgoCBat25NWFgY9vb2mJub4+/vz71795QymZmZvP322xgZGWFnZ8e8efNo3bo1QUFBj71epcnKymLkyJFUr14dAwMD2rdvz7Fjx5Tt169fp1+/flhbW2NoaIiLiwuRkZHKeb/33nvY2tpiYGBA3bp1+e677546lspKJkBViKuLK5bVawBw6Vwi169f13BEkiQJIcjLKdDI8jz7An700UdERUWxZMkSjh49ipOTE126dCl19PmDBw8ydOhQRo4cSUJCAh06dGDKlCnlqvPmzZtERkbi6emJrq7uM8X/119/MXPmTCIiIvj999+xsLDg7t27DBs2jLi4OPbt24ednR3du3cnKyurzGMFBwcTEhJCQkIC9vb2DBgwoMwWpVOnTrF9+3a2bt3KunXriI6OZubMmcr2UaNGER8fz9atW4mOjiY6OppTp0490/mOGzeOTZs2ERkZSXx8PHZ2dnTp0oXbt28DRYnZuXPn2LZtG4mJicyZMwdLS0sAZsyYQUxMDD///DNJSUksWbKEOnXqPFM8lZGOpgOQnq+2nbzYuCIKIQThy38mcMxwTYckSf9p+bmFLBz7q0bqHj6rPbr62k9cftOmTZiYmCjvu3Xrxpo1a7h37x4LFiwgIiKCbt2KbrUvWrSImJgYQkNDCQwMLHasWbNm0aVLF6UVw9nZmbi4uCfqUDxx4kTmzp3L/fv3ad26NZs2bXricyhNTk4OixcvxsXFRVnXuXNntTKhoaFUq1aNffv20alTp1KPFRQURJcuXQCYNGkSHh4epKWl4ejoWGJ5lUpFWFgYRkZGvPzyy/Tv35+dO3fy6aefcuPGDVasWMH69etp3749AOHh4dSuXfupz/XWrVuEhoayevVq5RwftEAtWbKE0aNHk5aWhoeHBx4eHgBqsaelpeHq6oqnpycADg4OTx1LZSZbgKqYEUMDlNc/RcpRoSVJenIdOnQgISFBWWbPng1ASkoKeXl5tG3bVimrq6tLy5YtSUws+YGLxMRE2rRpo7bu0felCQwM5NixY2zfvh1tbW0GDRr0zK1ZJiYmaskPwNWrVxk2bBj169fH1NQUCwsLcnNzSUtLK/NYjRs3Vl7XrFkTgIyMjFLLOzk5YWRkpLbPg/LJyckUFBTQsmVLZbu1tTX16tV78pN7xNmzZykoKFD7vAwMDPDw8FA+r5EjRxIREYGHhwdBQUEcOnRIKRsQEEBcXByurq6MGzeOnTt3PnUslZlsAapiXn/1dQwMjcjOus/phIPk5uaWqwOfJEnPl46eFsNntddY3eVhbGyMk5NTsfUPkg+VSlVs/aPrHt3naVhbW2NtbY2zszNubm7UqVOHAwcOPHECVRJjY+Ni6wYOHEhWVhZz5syhTp066Ovr4+7uTm5ubpnHevh23IPzL+sW2KO371QqlVK+rGv7tJ7k8+rVqxfnz59n8+bN7Nixg1deeYUPP/yQKVOm0KpVK86fP8/WrVvZsWMHvr6+9OzZk59++umpY6qMZAtQFaOjo0PDlk0ByM3NYvO2qpm5S9K/hUqlQldfWyNLaclJeTk5OaGnp0dsbKyyLi8vjyNHjuDm5lbiPg0aNODAgQNq6x59/yQefJnn5OSUe9/HHTc2NpYJEybQtWtXXn75ZQDu3LnzXOt5nPr166Otra3WAnPjxg1SU1Of+pjOzs5oa2urfV7Z2dkcPXpU7fOqUaMGQ4cOZfny5XzzzTcsXLhQ2WZubk7//v0JDQ1l2bJlREZGcv/+/aeOqTKSLUBV0GD//hz5NQ6AHxZH4uvT7TF7SJIklc7Y2JgRI0YQGBiIpaUl9vb2TJ8+nfv37xMQEFDiPmPGjMHT05Pp06fTq1cvtm/f/tj+P4cOHeLQoUN4eXlhYWHBuXPn+Oyzz3jppZeeqfWnJCqVipdeeoklS5bQuHFjbty4QWBgIPr6+s+1nsexsrKif//+jB8/nmrVqmFpaUlwcDB6enqPTWDz8/NJSEhQW2dgYICrqyvDhg1TjlmrVi2++uoroGicIoBPPvmENm3a0KBBA+7fv8+WLVuU5Gj69Ok4OjrSpEkTAKKiopSn+aoS2QJUBfn38UdLq+ijPbg3Ro4KLUnSM/v6669588038ff3x93dneTkZLZt24aFhUWJ5Vu3bs3ixYuZM2cOTZs2Zfv27YSEhJRZh6GhIT///DMdO3bExcWFoUOH0rBhQ3799dcXkpgsXbqUq1ev0qRJE4YOHcpHH32kkZGqH1yjrl270rlzZzp37kzdunUxMDAoc78bN27QrFkztaVXr14AzJw5E29vb/r374+HhweXL19m27ZtVKtWDSi6WxAYGEjDhg3p0KEDJiYmLFu2DChKeKdMmYK7uzutWrXi2rVrz6UjemWjEvLbsZjbt29jZmZGZmYmpqammg7nqdRt4Mr5xCQAEo6foEnjRhqOSJL+G7Kzs0lNTX2iLzBJKsnt27epVasWP/74IwMHDtR0OJVOWb9j5fn+li1AVVTPPt2V1/MWylGhJUmSKqvDhw+zevVqUlJSOHz4MP3798fAwIAePXpoOrQqTSZAVdTIQf+MCh29+RcNRiJJkiSVpbCwkGnTptGkSRO6du1KQUEBv/32G2ZmZpoOrUqTnaCrKBcnF6xsa3Aj/RoXz5/mzz//lPPTSJIkVUKtWrVSm6ZCqhiyBagKa9vZ6+9XgrBlazUaiyRJkiRVJjIBqsJGvvOu8nrF8lUajESSJEmSKheZAFVhnV7phMHfo58mnjz43AcSkyRJkqR/K5kAVWHa2tq83LpoIKvc3Gw2bYnRcESSJEmSVDnIBKiKe8evv/J64WL5OLwkSZIkgUyAqjx/X3+0tLQBOLhvhxwVWpIkSZKQCVCVZ2Zmhn2DlwDIzPyThIQTGo5IkqSqaM+ePahUKv76669Sy0RERGhkqoknVbt2bebOnQsUzbOlUqnKnAIiOTkZlUrF77///kz1Pq/jSOUjE6D/ALVRoX+I1GAkkiRVVu+88w4qlarYkpycXKFx9OzZE3t7ewwMDKhZsyb+/v5cuXKlxLK5ublYW1szZcqUErdPmzYNa2trcnNzyx2Hjo4OV69e5fXXXy/3vmXx8/OjT58+auvq1q3L1atXcXV1fa51PSokJITmzZu/0Dr+TTSeAM2fP1+Zz8PDw4O9e/eWWvbnn3+mefPmmJubY2xsTNOmTZXJ2x64e/cuo0aNonbt2hgaGuLm5saCBQte9GlUaqP8Riqvt0dv1GAkkiRVZl27duXq1atqS926dSs0hg4dOrB69WqSkpKIiooiJSWlWMLwgJ6eHn5+fkRERJR4ez88PBx/f3/09PSeKhZbW9sKmR1eW1sbW1tbdHTk2MQVSaMJ0KpVqxg3bhzBwcEcO3aMdu3a0a1bN9LS0kosb2lpSXBwMPv37+fEiRMMGTKEIUOGsG3bNqXM+PHjiY6O5qeffiIxMZHx48czevRofvnlvzsdRP2X6mNZqwYAl9KSuHbtmoYjkqT/DiEEednZGlnK2+dPX18fW1tbtUVbu6gPYU5ODmPGjMHGxgYDAwO8vLw4fPhwmceLiIjA3t4eIyMjfH19uXHjxmNjGD9+PK1bt8bBwQFPT0+CgoI4cOAAeXl5JZYPCAggJSWF3377TW393r17OXv2LAEBAQCcPXuWnj17UqNGDUxMTGjZsiW7du0qNY6SboEdOHCApk2bYmBgQIsWLTh+/LjaPnl5eQwdOhRHR0cMDQ1xcXFhzpw5yvaQkBAiIyOJiopSWthiY2NLvAW2e/dumjdvjr6+PrVq1SI4OJiCggJlu5eXF+PHj+eDDz7AwsKCmjVr8uWXXz72+pbl5s2b+Pn5KY0M3t7epKSkKNtTU1Pp0aMHFhYWGBsb07BhQ+X79+bNmwwYMIDq1atjaGiIs7MzS5cufaZ4XjSNppszZ84kICCAYcOGAfD999+zbds2FixYwLRp04qVf/XVV9Xejx07liVLlhAbG0uXLl0A2L9/P4MHD1bKDh8+nB9//JEjR47wxhtvvNDzqczadmnLxvCfEQhCw1bzycejNR2SJP0n5OfkMHtwyS0YL9qYJWvRfU4z0n/00UdERUWxZMkSHBwcmD59Ol26dCE5ORlLS8ti5Q8ePMjQoUOZOnUqvXv3Jjo6mkmTJpWrzps3bxIZGYmnpye6urollmnUqBEtWrQgPDyc9u3bK+vDwsJo2bIlDRs2BODOnTv06NGDqVOnoqenR3h4OD169ODMmTPUrl37sbE82L9Lly4sX76clJQUxo4dq1amoKAAe3t71q5di5WVFbGxsbz33nvY2dnRu3dvgoKCOH36NDk5OSxatAgAKysrLly4oHacixcv0r17d959911++uknTp06xbvvvouhoSEhISFq5xgYGMihQ4eIjY1l6NCheHl50aFDhye7wI/w9/fnwoULbN68GWNjYwIDA/H29ub3339HR0eHESNGoFKp+O233zA2NuaPP/7AyMgIgE8++YQzZ86wdetWrK2tSU5OrvRjz2msBSg3N5f4+Hg6d+6str5z587ExcU9dn8hBDt37iQpKYlXXnlFWe/l5cWGDRu4fPkyQgh2797NmTNnlASpJDk5Ody+fVttqWpGDvpnVOhVq+S0GJIkFbdp0yZMTEyU5a233gLg3r17LFiwgG+//ZZu3brRoEEDFi1ahKGhIaGhoSUea9asWXTp0oWgoCCcnZ0ZM2ZMmX+HHzZx4kSMjY2xsrIiLS3tsS34Q4cOZe3atdy9exco6gqxZs0apfUHwN3dneHDh9OwYUOcnZ2ZNm0aderUKbOT88OWLVuGSqUiNDSUBg0a4OPjw4QJE9TKGBgYMHnyZJo3b07dunXx9/fH39+f1atXA2BiYoKBgYFaS1tJid3cuXOpV68es2bNwtXVld69ezNp0iRmzJihVs7d3Z2QkBDq16/PkCFDaNasGTt37nyi83lUYmIiW7ZsISwsjLZt29K0aVMiIyM5f/48GzcWdZ1IS0vDy8uLRo0aUa9ePXx8fGjXrp2yrVmzZjRv3hxHR0c6deqEt7f3U8VSUTTWAnT9+nUKCgqoUaOG2voaNWqQnp5e6n6ZmZnY2dmRk5ODtrY28+fPV+ukNnv2bN59911q166Njo4OWlpaLF68GC8vr1KPOW3aND7//PNnP6lK7PV2r2NgbET2vfsk/nGQ7OxsDJ7Tf4aSJJVOR1+fMUs080+HTjn7r3To0EGtz6Tx3yPJp6SkkJeXR9u2bZVturq6tGzZksTExBKPlZiYiK+vr9q6Nm3aEB0d/dg4AgMDCQgI4MKFC3z++ecMGjSITZs2oVKpSizfv39/JkyYwKpVqwgICGDVqlUIIejXr59S5u7du0yePJnNmzdz9epV8vPzycrKKrXLRUnn06xZM7W/m23atClWbv78+YSFhXHhwgWysrLIzc0td8fjxMREPD091c63bdu2ZGZmcuXKFWrVqgVA48aN1farWbMmGRkZ5arr4Tr19PRo0aKFss7Gxob69esrn+XYsWMZNWoUW7dupVOnTvTp00dpYRs5ciRvvfUW8fHxvP766/j6+tK6deuniqWiaLwT9KM/0EKIUn/IAapVq0ZCQgKHDx/mq6++YsKECezZs0fZPnv2bA4cOMCGDRuIj4/nu+++Y+TIkezYsaPUY3788cdkZmYqy8WLF5/5vCobbW1tXm7bFIC8/Bw2bHj8HyFJkp6dSqVC18BAI0tZf0tLYmxsjJOTk7LUrFkTQOlLVJ6/188y5pi1tTXOzs68/vrrrFy5ki1btnDgwIFSy5uZmdGnTx/Cw8OBos7Pffr0wdTUVCkzYcIEfvnlF6ZOncrevXtJSEigQYMGT/yE2JOcz/Lly/nwww8ZNmwY27dvJyEhgUGDBpX7KbSSrmtJn8GjrUcqlYrCwsJy1fXo8cuK5b333iMlJYWBAwdy/Phx3N3dmT9/PgA9evTgwoULjB49mkuXLtGhQweCgoKeKpaKorEEyNraGm1t7WKtPRkZGcVahR6mpaWFk5MTTZs25YMPPqBPnz5Kf6GsrCw++eQTZs6ciY+PD40bN2bUqFG8/fbbxZoOH6avr4+pqanaUhW9M/CfUaEXha7UYCSSJP2bODk5oaenR2xsrLIuLy+PI0eO4ObmVuI+DRo0KJa0lJXElObBF/Pj+pMEBASwb98+Nm3axL59+9Ruf0FRp+ihQ4fi6+tLo0aNsLGxKdb3piwNGjQgISFBLY5Hz2fv3r20a9eO//u//6NZs2Y4OTkVG0ZAT09PrTNzaXXt27dPLSmJi4vD3NxcSUqftwfJ4MMd2zMyMkhOTlb7jO3t7RkxYgTr1q1j7NixLF68WNlmY2PDkCFDiIyMZMaMGSxcuPCFxPq8aCwB0tPTw8PDg5gY9fmpYmJi8PT0fOLjCCGUH8i8vDzy8vLQ0lI/LW1t7afOiquSwb6D0fr7iY7DB3bKUaElSXoixsbGjBgxgsDAQKKjo5VOuffv3y+WaDwwZswYoqOjmT59OmfOnGHu3LmPvf116NAh5s6dS0JCAhcuXGD37t0MGDCAl156qcTbTQ9r3749Tk5ODBo0CCcnJ7W+oVCUxEVFRXH8+HESEhIYMGBAua6Bn58fBQUFDBs2jMTERDZt2sTMmTOL1XHw4EFiYmI4c+YMn3zyCceOHVMr4+joyPHjxzlz5gzXr18nPz+/WF2jRo3i3LlzjBs3jtOnT7Nu3To+//xzPvjgg3LFXJKsrCwSEhLUlpSUFNzc3PD29iYgIIC4uDiOHz+On58fjo6O9OjRAyj6TLdv305qairx8fHs2bNHSY5CQkLYsGEDycnJ/P7772zevLnU5LjSEBq0cuVKoaurK0JDQ8WpU6fEuHHjhLGxsTh//rwQQgh/f38RFBSklJ86darYvn27SElJEYmJieK7774TOjo6YtGiRUqZ9u3bi5dfflns3r1bnDt3ToSHhwsDAwMxf/78J44rMzNTACIzM/P5nWwl4djEWQACEIcOHtZ0OJJU5WRlZYlTp06JrKwsTYdSLoMHDxZvvPFGqduzsrLE6NGjhbW1tdDX1xdt27YVhw4dUrbv3r1bAOLWrVvKutDQUFG7dm1haGgofHx8xIwZM4SZmVmpdZw4cUJ06NBBWFpaCn19feHo6Cj+7//+T1y6dOmJzmHq1KkCEFOnTi22LSUlRbRv314YGhoKe3t7sWDBAtG2bVvxwQcfKGXs7OzEnDlzhBBC5OXlCUBs3LhR2b5v3z7RuHFjoaenJ9zd3cWaNWsEIE6ePKlcI39/f2FmZiYsLCzE+++/LwIDA4WHh4dyjPT0dNGxY0dhYmIiALF3715x9uxZteMIIcSuXbuEh4eH0NPTE7a2tuLjjz8W+fn5yvZHYxdCCG9vbxEQEFDq9QkODlb+/j+8dOzYUQghxPXr18XAgQOFmZmZMDIyEt26dRPJycnK/iNGjBD16tUT+vr6wsbGRgwaNEjcuHFDCCHE5MmThaurqzA0NBSWlpbC19dXpKamlv5hPYOyfsfK8/2t0QRICCHmzZsnHBwclB+oX3/9VdnWvn17MXjwYOV9cHCwcHJyEgYGBsLCwkK0adNGrFy5Uu14V69eFe+8846oVauWMDAwEC4uLuK7774ThYWFTxxTVU6ARn8xVvmhH/LOBE2HI0lVzr81AZKkf4vnlQCphJD3QR51+/ZtzMzMyMyrK9gDAAAgAElEQVTMrHL9gc6mnsW5njMAdWq7kHbxtIYjkqSqJTs7m9TUVGWEe0mSnq+yfsfK8/2t8afApIpVv259LGsXdTK/eCmJK5dLnmNHkiRJkqoymQD9B3l2/aeTeeiiVRqMRJIkSZI0QyZA/0Hv+w9XXq/9+WcNRiJJkiRJmiEToP+gzl6dMaxWNMJrYuJhsrKyNByRJEmSJFUsmQD9B2lpaeHq1QgoGhX65zWbNRyRJEmSJFUsmQBVIFFYyF9RP5N/86amQ2FI/38GAYtYIvsBSZIkSf8tMgGqQOmTJnE1OJiM777TdCi84/sOWjpFo0IfOrRbjgotSZIk/afIBKgCmfn2BiAz6mfuHz2q0ViqmVSjdqO6ANy+e4O4veWfo0eSJEkq3Q8//ICtrW259mndunWln0S0qpAJUAUycm+G+Vt9AEif/DkiL0+j8bzR21t5vfBHOTmqJElFk25qa2vTtWtXTYfywr3zzjuoVKoyl2cxePBgTp48Wa59tmzZQkhIyDPV+yRkoiUToApXfcIEtM3NyTlzhps/RWo0ltED31de79q9VYORSJJUWYSFhTF69GhiY2NJS0t74fXlafAfwVmzZnH16lVlAQgPDy+27lG5ublPdHxDQ0OqV69erpgsLS0xMTEp1z7S05EJUAXTsbDA5sOiGX2vz5lDXnq6xmKpX7c+lg42AFy6epYL51/8HztJkiqve/fusXr1akaMGEGPHj2IiIhQthUWFlK7dm1++OEHtX2OHj2KSqXi3LlzAGRmZjJ8+HBsbGwwNTXltdde4/jx40r5yZMn07RpU8LCwqhXrx76+voIIYiOjsbLywtzc3OsrKzo0aMHKSkpanXFxcXRtGlTDAwMaN68OevXr0elUpGQkKCUOXXqFN27d8fExIQaNWrg7+/P9evXSzxfMzMzbG1tlQXA3Ny82LrWrVszYcIERo8ejZWVFT4+PgB8/fXXvPzyyxgZGWFvb8/YsWO5f/++cvxHb4EFBQXRunVrwsLCsLe3x9zcHH9/f+7du6eUebRlxtbWlhkzZjBo0CBMTExwdHRU+1wAfvvtNxo1aoSBgQGtWrUiKioKlUrF6dNPP9XRsWPHaN++PQYGBlSvXp2RI0eqDZkSExND8+bNMTIywsLCgnbt2nHlStHMAvHx8bzyyiuYmJhgampKixYt1H4GKguZAGmAWe/eGDZrRuH9+1yb9rVGY2nT5aFRoX+Qt8Ek6b9s1apVuLi44OLigp+fH+Hh4coDElpaWvTr14/ISPWW6+XLl9OmTRvq1auHEAJvb2/S09PZsmUL8fHxuLu707FjR24+9PRrcnIyq1evJioqSkle7t27x4QJEzh8+DA7d+5ES0sLX19fCgsLAbhz5w4+Pj40atSIo0eP8uWXXzJx4kS1WK5evUr79u1p2rQpR44cITo6mmvXrtG3b99nvjaLFi3CzMyM/fv3M3v2bAB0dXWZP38+p06dIjQ0lE2bNj329tWpU6fYvn07W7duZd26dURHRzNz5swy9/nmm29o164dCQkJDB06lHfffZfU1FQAbt26hY+PDy1btuTYsWN8+umnxa5Led2+fZsuXbpQq1Yt4uPjWb58OZs3b2b8+PFA0Vxcvr6+dO3ald9//519+/YxZMgQZf+3336b+vXrEx8fz5EjR/jwww/R0dF5ppheiOc7R2vVUBGzwWedPi1ONXhZnHJxFXd+++2F1fM40b9FK7PDN3Lz1FgcklRVlDRTtYeHh7Czs6vwxcPDo1yxe3p6iu+//14IIUReXp6wtrYWMTExyvajR48KlUolzp8/L4QQoqCgQNjZ2Yl58+YJIYTYuXOnMDU1FdnZ2WrHfemll8SPP/4ohBBi0qRJQldXV2RkZJQZS0ZGhgDEyZMnhRBCLFiwQFhZWald10WLFglAHDt2TAghxKeffio6d+6sdpyLFy8KQCQlJT32/AGxbt26YutbtWolWrdu/dj9ly5dKuzs7JT3CxYsEDVq1FDeT5w4UZiamop79+4p60aPHi3at2+vVtfEiROV9zVq1BDDhg1T3hcUFAgzMzMRHh4uhBDif//7n6hZs6bIzc1VysyZM0cAIjExsdRYH63nYbNnzxbVq1dXu9ZRUVFCW1tb3Lx5U1y+fFkA4sCBA8X2LSwsFPr6+mLlypWl1v2sntds8JUwJftvMHBxwdLPj5tLlpD+5RTqbdyAlr5+hcfR2aszBmbGZGfeI/HMEe7dvYexiXGFxyFJVVl6ejqXL1/WdBhlSkpK4tChQ/z89/Q4Ojo6vP3224SFhdGpUycAmjVrhqurKytWrCAoKIhff/2VjIwMpYUlPj6eu3fvYmVlpXbsrKwstdtZDg4OxfrGpKSk8Omnn3LgwAGuX7+utPykpaXRsGFDkpKSaNy4sdrs3y1btlQ7Rnx8PLt37y6xD01KSgrOzs5Pe3lo3rx5sXXbt2/n66+/5vTp09y+fZuCggJycnLIz88vtcXDyckJIyMj5X3NmjXZsWNHmXU3btxYea2lpUWNGjXIyMgAij63pk2boqurq5R59LqUV2JiIh4eHmrXum3bthQUFHD27FlatmxJv3796NChA6+//jqdOnWib9++1KhRA5VKxbhx4/Dz8yM0NFTZ5ujo+EwxvQgyAdIg69Gjub11K3lpadxYuIjqo0dVeAwqlQpXr4YkbD5IfkEuqyJ/Yeh7Ax6/oyRJT6y8j0Jrot7Q0FDy8/Oxs7NT1gkh0NXV5datW1hYWAAwcOBAli9fTlBQEMuXL6dLly5YW1sDRf2EatasyZ49e4od39zcXHltbFz8nywfHx/q1KnDokWLqFWrFoWFhTRs2FDpcCyEKPZUlnhk/LLCwkJ8fHz45ptvih2/Zs2aT3glSvZozMnJyfj4+DB27FimTZuGhYUFO3fuZOTIkWUmQA8nKlD0N/hBsleasvZ5kutSXmUd88H6FStWEB8fT3R0ND/99BMhISHs3r0bd3d3vv76awYPHsyWLVvYsmULn332GVFRUXh7exerS5NkAqRB2ibG1PjkYy6PG8+NRYsw8+mBngay5CFvD2Ds5oMAREaulQmQJD1nR44c0XQIZcrPz2fp0qV89913dO7cWW3bm2++SWRkJKNGFf2DNmDAAEJCQoiPj2ft2rUsWLBAKevu7k56ejo6Ojrl+o//xo0bJCYm8uOPP9KuXTsAYmNj1cq4uroSGRlJTk4O+n+3lj96Xd3d3YmKisLR0fGF9zk5ePAgurq6TJ8+XVm3dOnSF1pnSVxdXdmwYQN5eXlKovSsP28NGjQgKiqK7OxspRUoLi4OHR0d6tevr5Tz8PDAw8OD4OBgmjVrxsqVK3F3dwfAzc0NNzc3PvjgA3x9fVmyZEmlS4BkJ+gK9tc19ae+qnXpgnHbtojcXNKnfKWREZmH9h6Ktm7RH4vDR3997H8jkiRVLZs2beLWrVsEBATQsGFDtaVPnz6EhoYqZevWrYunpycBAQHk5+fzxhtvKNs6depEmzZt6NWrF9u2beP8+fPExcUREhJS5peyhYUFVlZWLFy4kOTkZHbt2sWECRPUygwYMIDCwkKGDx9OYmIi27ZtY8aMGcA/rRLvv/8+N2/epH///hw6dIhz586xfft2hg4dSkFBwfO8ZDg5OXHv3j0WLFjAuXPnCA8PV7tOFWXQoEHcu3ePkSNHcvr0aTZv3sysWbMAHjuOUUZGBgkJCWpLRkYGgwcPBmDo0KH88ccfxMTEMH78eAICAjA3NycpKYmQkBAOHDhAWloaW7duJTU1FTc3NzIzMxk7diy//fYbFy5cYO/evRw9ehQ3N7cXfi3KSyZAFejMwX382rcXx9avUdapVCpsP/sUlZ4e92JjubNtW4XHZWJsQq0mDgDcuXeTPTH7KjwGSZI050FfDTMzs2Lb3nzzTRISEjj60Oj1AwcO5Pjx4/Tu3RtDQ0NlvUqlYsuWLbzyyisMHToUZ2dn+vXrx/nz56lRo0ap9WtpabFy5Uri4+Np2LAh48eP59tvv1UrY2pqysaNG0lISKBp06YEBwfz2WefASitFLVq1WLfvn0UFBTQpUsXGjZsyNixYzEzM0NL6/l+3bVq1Ypp06bxxRdf0KhRI6Kiopg6depzreNJWFpasmHDBvbv30+TJk344osvil2X0oSHh9OsWTO1JSwsDFNTU6Kjo7l8+TIeHh70798fb29v/ve//wFgYmLCiRMn8PX1pX79+rz//vt8+OGHvPPOO+jq6pKens7AgQNxdnamf//+9O7dm+Dg4Bd+LcpLJTTR5FDJ3b59GzMzMzIzMzE1NX0+By0o4PKbvbD7ZROn7Gshlizh5Vc7KZv/nDOX6/PmoWNjQ70tW9Cu4I7Io74ay7yQokc7B771Pj+tnluh9UtSVZGdnU1qaip169Z97BeQ9GwiIyMZMmQImZmZaonYf11oaCijRo3i9u3bxfoPVQVl/Y6V5/tbtgBVlHPnqLVjNwAN0q5wY+wYzh6MUzZbDX8XXXt78jMyuD5nToWHN85vtPJ6z28V3wolSZL0OEuXLiU2NpbU1FTWr1/PxIkT6du3738++QkLC2Pfvn2kpqYSFRVFSEgIAwcOrJLJz/MkE6CKUr8+qoc6yLU7kcgfH03g/PGiZmUtfX1sPy0aQOvmTz+R/QwjeD4NJwcnLOoWPZZ6+VoyZ0+fq9D6JUmSHic9PR0/Pz/c3NwYP348b731FgsXLtR0WBp3+fJl+vfvj6urK4GBgfj5+TF3rmzFfxx5C6wEL+QW2ANffAGTJgGQo6PDqu6v0nH6bOxcijqIXRo7jjvbtmHYrBkOkT+hes73rcvS/b1ebF34CwBB479i2sxPKqxuSaoq5C0wSXqx5C2wf6uQEOhTNCO8fn4+Prvi2PL5J2ScL2pxqfFxEFpGRmQdO0bm3wOSVZTRfu8przdt2VihdUuSJElSRZIJUEXT0oKICGjSBACLu/d5fVcsUV8Gc/PKZXRtbbEeXdQfJ+PbGeTfulVhoXX16oqBedEIpaeT4/nrVmaF1S1JkiRJFUkmQJpgbAy//AJ/DwXveO06LfceZO2UEG5fz8DSbyD6zs4UZGby52MmyXueVCoVLl4NAcgvyGNFxLoKq1uSJEmSKpJMgDTFwQGiouDv0Uo9zqbicPgoa6d8yv17d7GdXNRP6K81a7l/9FiFhTX47f7K69VrZAIkSZIkVU0yAdKkdu1g/nzlbaejv2N48iRRUz9Dy9kZszd7A5D++eeI/PwKCend3sPQ1tMG4EjCbxTkP9/RUyVJkiSpMpAJkKa9+y78PceOdmEhb+w/RvapU/z8zWQsRo9C28yMnKQkbkVGVkg4JkYm1GrqCMDdrL/YtmFPhdQrSZIkSRVJJkCVwcyZ8NprABhlZdNr/1H+PPUHm0PnYzluLAB/zppN3rVrFRJOjze6K6+XLV1TRklJkiQJYMeOHahUKu7evQvA4sWLsba2LnOfkJAQmjdv/sx1P6/j/NfIBKgy0NWF1auhXj0AbG7+Rbf437lw/Cj7Lqeg36Qxhffvc+3rrysknPF+o+HvOfR+i4upkDolSaoc4uLi0NbWpmvXrpoO5YWLiopCW1ubtLS0Ere7uroyZsyYpzr2wIEDOXXq1LOEV0x+fj4qlYpNmzaprQ8KCmJbBcwjWbt27So1wKJMgCoLKyvYsAFMTABwvnCJ1mdSST58gMQmrggtLe5sjeZu7IufqLS+fX3M6xX953Llz3OcPJr0wuuUJKlyCAsLY/To0cTGxpaaGDxPeXl5L7yO0vTs2RMrKyuWLFlSbNu+fftISkoiICDgqY5taGiIjY3Ns4b4RExMTLCysqqQuqoSmQBVtOzbpW97+WWIjARVUfNL2+OJOF3J4PTxeM51aIMA0r/8gsKcnBceZptObZXXSxavfOH1SZKkeffu3WP16tWMGDGCHj16EBERoWwrLCykdu3a/PDDD2r7HD16FJVKxblzRYO5ZmZmMnz4cGxsbDA1NeW1117j+PHjSvnJkyfTtGlTwsLCqFevHvr6+gghiI6OxsvLC3Nzc6ysrOjRowcpKSlqdcXFxdG0aVMMDAxo3rw569evR6VSkZCQoJQ5deoU3bt3x8TEhBo1auDv78/169dLPF9dXV38/f2JiIjg0UkRwsLC8PDwoMnfY7YtWbIEDw8PTExMsLW1xc/Pjz///LPUa1nSLbCvvvpKuS7vvvsuOY/8LT948CCdOnXCysoKMzMzOnTooHZujo6OAPj4+KBSqXBycgKK3wIrLCxk0qRJ2NnZoa+vj7u7OzEx/7TmJycno1KpWL9+Pe3bt8fIyIimTZty8ODBUs/nSezevZvmzZujr69PrVq1CA4OpqDgnwdpVq1aRcOGDTEwMMDKyorXX3+drKwsAHbu3EmLFi0wMjLCwsICLy8vLl269EzxPI5MgCrSpXiY1QRO/VJ6mZ49YcoU5W2P+N+xyrxD0vV0UurVJu9CGjcWL37hoY7yH6683rp9ywuvT5IkzVu1ahUuLi64uLjg5+dHeHi4khhoaWnRr18/Ih95IGP58uW0adOGevXqIYTA29ub9PR0tmzZQnx8PO7u7nTs2JGbN28q+yQnJ7N69WqioqKUL/h79+4xYcIEDh8+zM6dO9HS0sLX15fCwkIA7ty5g4+PD40aNeLo0aN8+eWXTJw4US2Wq1ev0r59e5o2bcqRI0eIjo7m2rVr9O3bt9RzDggI4Ny5c/z666/KugeJ4MOtP3l5eXz11VecOHGCdevWcfbs2XK1Di1fvpwvv/ySr7/+msOHD2Ntbc2PP/6oVubOnTsMGTKEuLg49u/fj6OjI927d+fevXsAHD58GIBly5Zx9epVDhw4UGJd3333HbNmzeJ///sfJ06c4LXXXqNHjx5KkvpAcHAwQUFBJCQkUK9ePQYMGKCWsJTHxYsX6d69O56enhw/fpy5c+fyww8/MG3aNAAuXbrEwIEDGT58OKdPn2bPnj288cYbQNG19fX1pWPHjvz+++/ExcUxbNiwp4qjXISGzZs3Tzg6Ogp9fX3h7u4ufvvtt1LLRkVFCQ8PD2FmZiaMjIxEkyZNxNKlS4uVO3XqlPDx8RGmpqbCxMREtGrVSly4cOGJY8rMzBSAyMzMfKpzKtWGsUJMMhVisrkQCStLL1dYKMTbbwsBQoDItq0h5r7xupjR11tsattKJDZqLHLKcT5Po6CgQBhYGglA6GjpioyrN15ofZJUVWRlZYlTp06JrKysf1Z6eAhhZ1fxi4dHuWL39PQU33//vRBCiLy8PGFtbS1iYmKU7UePHhUqlUqcP39eCFH0d8LOzk7MmzdPCCHEzp07hampqcjOzlY77ksvvSR+/PFHIYQQkyZNErq6uiIjI6PMWDIyMgQgTp48KYQQYsGCBcLKykrtui5atEgA4tixY0IIIT799FPRuXNnteNcvHhRACIpKanUulq1aiUGDRqkvA8LCxOGhobi1q1bpe4TFxcnAHH//n0hhBAxMTECEHfu3FFis7KyUsq3aNFCjBo1Su0YHh4ewqOMzygvL08YGRmJrVu3Ku8BsXHjRrVywcHBasexsbER33zzjVqZZs2aiTFjxgghhDh79qwAREREhLL9+PHjAhBnz54tNR47OzsxZ86cErd99NFHokGDBqKwsFBZN2vWLGFmZiaEEOLgwYMCEJcuXSq277Vr1wQgYmNjS637YSX+jv2tPN/fGm0BWrVqFePGjSM4OJhjx47Rrl07unXrVup9Z0tLS4KDg9m/fz8nTpxgyJAhDBkyRK3zV0pKCl5eXri6urJnzx6OHz/Op59+WjkmJfT+Dpr6gSiEde/BkfCSy6lUEBYG7u4A6Kdfwy/lClqFhZy2sybNRJ/0L6cUa7J9nrS0tHD2ehmA/MI8lodV7LxkklSlpKfD5csVv6SnP3GISUlJHDp0iH79+gGgo6PD22+/TVhYmFKmWbNmuLq6smLFCgB+/fVXMjIylBaW+Ph47t69i5WVFSYmJsqSmpqqdjvLwcGB6n+PhP9ASkoKAwYMoF69epiamlK3bl0A5fsgKSmJxo0bq/0tb9mypdox4uPj2b17t1rdrq6uyvFLExAQwNq1a7lz5w5QdPurd+/emJubqx27Z8+e2NvbU61aNTp16gQUtXw8icTERNq0aaO27tH3165dY/jw4Tg7O2NmZoa5uTlZWVnl6ot18+ZNMjIyaNu2rdr6tm3bkpiYqLaucePGyuuaNWsCkJGR8cR1PSwxMRFPT09Uf3fheFBnZmYmV65cwd3dnVdffZUGDRrQt29fFi9ezF9//QWAjY0Nfn5+dOrUiZ49ezJ79mzSy/Gz+7R0XngNZZg5cyYBAQFKU9f333/Ptm3bWLBggdJs9rBXX31V7f3YsWNZsmQJsbGxdOnSBShq0uvevTvTp09XytX7++kqjdPShp5zQNcQDi+CTeMgLwvajCxe1sgI1q+HFi3g2jXMfv+DvjVrsNLCkJO1q6Nz4ijm22Mw7dL5hYU76K3+fLihqMk1av0vjP2kApokJakqsrWt9PWGhoaSn5+PnZ2dsk4Iga6uLrdu3cLCwgIoerpp+fLlBAUFsXz5crp06aL0dSksLKRmzZrs2bOn2PEfTiaMjY2Lbffx8aFOnTosWrSIWrVqUVhYSMOGDcnNzVViefjL9cG6hxUWFuLj48M333xT7PgPvuBL0q9fP8aPH8+qVat49dVXiY2N5YsvvlC237lzhy5dutC9e3ciIyOxsbEhJSUFb29vJb7nwd/fn8zMTGbNmoW9vT36+vq0aNGiXHU8uCYlXatH1+nq6iqvH2x7cMuxvMr6fFQqFTo6OuzcuZO4uDi2b9/OrFmzCAkJ4eDBgzg4OLBs2TLGjx9PdHQ0K1asICQkROkX9KJorAUoNzeX+Ph4OndW/wLv3LkzcXFxj91fCMHOnTtJSkrilVdeAYo+uM2bN+Ps7EyXLl2wsbGhVatWrF+//oWcw1PR0oLu30LbovF92PYx/PZtyWXr1IF160BPDwC7mF10060GKhUJ9jU4MeMbCu7ee2Ghvtf7XbT1i3Lkoyf3kputuac1JOlf7cgRuHSp4pcjR54ovPz8fJYuXcp3331HQkKCshw/fhwHBwe1fj8DBgzg5MmTxMfHs3btWgYOHKhsc3d3Jz09HR0dHZycnNSWssbEuXHjBomJiYSEhNCxY0fc3Ny49chE0K6urpw4cUKt4/CRR87P3d2dP/74A0dHx2L1l5R0PVCtWjXeeustwsPDlc7ZD//DferUKW7cuME333xDu3btcHFxKXdLiZubW7E+O4++37t3L+PGjaNbt268/PLLaGtrK60kANra2mhra5fZT8fKygobGxtiY2PV1sfFxeHm5laumMujQYMG7Nu3Ty0pjYuLw9zcXEk+tbS08PLy4osvvuDYsWOoVCp++eWfPrHu7u588skn7N+/HxcXF6Wl8UXRWAJ0/fp1CgoKqFGjhtr6GjVqlNn0lZmZiYmJCXp6enh7ezNnzhxef/11oKjp7u7du3z99dd07dqV7du34+vrS+/evdU6uD0qJyeH27dvqy0vlEoFnT6HVz8per9rCuz4vKjHz6PatIGHnrpwW7WWNta1EFoqDpvr88fXX72wME2MTKjZrA4A97Iz2bR2xwurS5Ikzdm0aRO3bt0iICCAhg0bqi19+vQhNDRUKVu3bl08PT0JCAggPz9f6cgK0KlTJ9q0aUOvXr3Ytm0b58+fJy4ujpCQkGLJysMsLCywsrJi4cKFJCcns2vXLiZMmKBWZsCAARQWFjJ8+HASExPZtm0bM2bMAP5pvXj//fe5efMm/fv359ChQ5w7d47t27czdOjQx3buDQgIIC4ujgULFjB06FC11gwHBwd0dXWZPXs2586dY/369UydOvXJLzBFdywWLVpEREQEZ86cITg4mKQk9SFGnJycWLp0KadPn2b//v0MGjRI7ZafSqXC3t6eHTt2kJ6eXixJfCAwMJCpU6eyZs0akpKSCAwM5I8//njqMY0edvnyZbUkOSEhgVu3bjFq1CjOnTvHuHHjOH36NOvWrePzzz/ngw8+AIqSoWnTpnHkyBHS0tKIiorixo0buLm5kZycrCQ+aWlpREdHk5KS8kITNkBznaAvX74sABEXF6e2fsqUKcLFxaXU/QoKCsTZs2fFsWPHxIwZM4SZmZnYvXu32jH79++vto+Pj4/o169fqcecNGmSAIotz70TdEn2zS7qGD3JVIgtHxV1gC7JuHFKp+hCa2uxafhgMaOvt/j+zW7iwq4dLyy896a8r1yPPt0DXlg9klRVlNVBs7Lq0aOH6N69e4nb4uPjBSDi4+OVdfPmzROAWsfhB27fvi1Gjx4tatWqJXR1dUWdOnXEwIEDRVpamhCi6O9tkyZNiu0XExMj3NzchL6+vmjcuLHYs2ePAMS6deuUMvv27RONGzcWenp6wsPDQyxfvlwA4vTp00qZM2fOCF9fX2Fubi4MDQ2Fq6urGDdunFrn3NK4uLgILS0tcfHixWLbli1bJhwcHIS+vr5o27at+OWXX9Q6aT+uE7QQQnzxxRfCyspKmJiYiCFDhogPP/xQrfPykSNHhIeHh9DX1xfOzs4iKiqqWMfjdevWCScnJ6GjoyNeeuklIUTxTtAFBQXis88+Uz6DZs2aiW3btinbH3SCfhC7EEL8+eefAhB79+4t9frY2dmV+F25bNkyIYQQu3btEh4eHkJPT0/Y2tqKjz/+WOTn5wshhPj9999F586dhbW1tdDX1xcuLi5i/vz5Qgghrly5It544w1ha2sr9PT0hKOjo/j8889L/cyeVydolRAvsCdtGXJzczEyMmLNmjX4+voq68eOHUtCQkKZLTYPGzZsGBcvXmTbtm3k5uZibGzMpEmTCAkJUcpMnDiR2NhY9u0reRDBnJwctWbV27dvU6dOHTIzMzE1NX3KMyyHw5FNEI0AACAASURBVIthc1GWjPsg6PF9UX+hh+XnQ/fu8PdYDqJRI1a41eMq+eihov+MuVjXcXjuoSWlJeHq6AoCalo5cjnjHCot1eN3lKT/qOzsbFJTU6lbt27lePiiCouMjGTIkCFkZmZiaGio6XCkClLW79jt27cxMzN7ou9vjd0C09PTw8PDQ21wJoCYmBg8PT2f+DhCCCV50dPTo0WLFsWaFc+cOYODQ+nJgb6+PqampmpLhWoxDHotAJUWHF1a9IRYwSOzv+vowKpV8PfAV6qTJ+l7OwezrBxyEaz5NJDMjOc/V5iLvQtmTkUjjF69cZ7DsSeeex2SJElPYunSpcTGxpKamsr69euZOHEiffv2lcmP9FQ0+hj8hAkTWLx4MWFhYSQmJjJ+/HjS0tL4v//7PwAGDRrExx9/rJSfNm0aMTExnDt3jtOnTzNz5kyWLl2Kn5+fUiYwMJBVq1axaNEikpOTmTt3Lhs3bmTkyBKetKpMmg6AN0NBSwdOroE1gyH/kRGfLSyKpsv4O0HTiY6mb6E+Jtm53M+6z5ovPuburZslHPzZtH7tn4T0pwg5OaokSZqRnp6On58fbm5ujB8/nrfeeouFCxdqOizp3+qxN8lKsHXrVrX7hHPnzhVNmjQR/fv3Fzdv3izXsebNmyccHByEnp6ecHd3F7/++quyrX379mLw4MHK++DgYOHk5CQMDAyEhYWFaNOmjVi5sviAgqGhoUq5Jk2aiPXr15crphc2EOKTOL1FiC+si/oELestRO794mU2bxZCpVL6BF1o7iHmvdFZzOjrLSI+GCnu37n9XEPaELtBudfr6li+gdUk6b/m39gHSJL+TTTaB6hRo0Z88803dO/enZMnT9KiRQsmTJjArl27cHNzIzy8lAH+/iXKcw/xhUjZBSsGQH4WOLaD/itAv5p6mW+/hY8+AkAYGJBY245djZzI0dXB1smZt0KmoGdo9FzCKSwsxKiGCTnXs9DS0ub82UvUqaehcU0kqZKTfYAk6cXSaB+g1NRUGjRoAEBUVBQ9evRg6tSpzJ8/n61btz7NIaWHvfQa+P8MetXg/F5Y5gtZf6mX+fBD+PvWnyo7G+eM63gmpaErID35DOu/nUL+cxqgS0tLC5e2DQEoLCxgebgcFVqSJEn6d3uqBEhPT4/79+8DsGPHDmUwQ0tLyxc/hs5/hYMnDP4FDMzh0mFY4gP3bvyzXaWChQuLRooGdG5n4nrxEi2T0tDR1uHiHyfYNOsbCvLzS6mgfPz79lNeb9y08bkcU5KqsqdoXJck6Qk8r9+tp0qAvLy8mDBhAl9++SWHDh3C29sbKHraqnbt2s8lMAmw84B3NoNxdUg/ARHd4c5Dg0QaGhaNFP33KJtGd+7gcuEizS9cQ1tXl5QjB9m24HvEUw5t/rD3fN9F26BoVOhjifu4m5n1zMeUpKrowfQCD/5JlCTp+Xrwu/XwVB5P46nmAps7dy4jR45k7dq1LFiwQJk7ZuvWrXTt2vWZApIeYdsQ3tkCS3vCn6chvBsM2gDmRSM0Y2dXlAS1bw85OVhk/sVLyanoNWlM7F/pJMbuQc/QiI4BI4rN01Ie1QyrYdusDpf3p3I/5w6/rNzGwPd6PaeTlKSqQ1tbG3Nzc2WqBCMjo2f63ZMkqYgQgvv375ORkYG5uTna2tqP36kMGhsIsTLTeCfoktxMLUqC/koDszow6Beweumf7cuWwaBBQNHjWml16nBrcgg7t28EIWjZ6y3a9R/8TCEMn/o+i4LnA9Cr02DWxUQ80/EkqaoSQpCenq42j5MkSc+Hubk5tra2Jf5jUZ7v76dKgI4ePYquri6NGjUC4JdffiE8PJwGDRowefJk9P6evPPfqlImQACZl4uSoBvJYGJblATZuP6z/aOPip4OA/K1tbncxpNbwR+xM7xoLrF2A96h5Rt9nrr6pItJuDoUjQpdw8Key9dS0dbV6FBSklSpFRQUkJcnJxGWpOdFV1e3zJafF54AtWjRgqCgIN58803OnTvHyy+/jK+v7/+zd99xWZf7H8df92QLsocgIMsJooI4wD0zNUvKUVmWdRraPr9TnWxa1inNbaWWlpqZlrtShgMF9x6IqMhG9rzH9/fHF0EEDEFL8no+HjyK777vkz7e5/p+PtdFQkICw4cPZ9asWbd6ybvKXRuAAIoy4buRkHkSzO1g4jpwCZT3GQwwYgRUduKVaU0o/ngGSW08iP1enppgwOR/EThwWKNvb+NvR/5ZebLF6M3xRAzt1rTPIwiCIAi3yR1vgz979ixBQUEArFmzhvDwcH744QeWLVvG2rVrG3NJoaEsHeXCaNfOUJIjd4ddTpD3qVSwciX4+wNgWlGOdvp0AgO7Ejp6LAB/fLOAU7uiG337kOtmhV62cBWlhben1V4QBEEQ/kqNCkCSJGGs7Cz6448/GDZMHlFwd3cnOzv79j2dUDdzW/n1l3t3KMuH5aMgeZe8z9oafv0VydoaAKuCAkpHj6bH2AkEDhoOksSWeZ9z/sC+Rt36+YlPVf37roTtfP/OXk7vTRMtv4IgCEKz0qgA1LVrVz744AOWL19OTExMVRv8hQsXcHJyuq0PKNTD1FqeLNErAiqKYMUYOPeHvM/PD8Xq1UhK+X9e60OHKPvvf+k/aQpte/dFMhrZ8MXHXD5x6wub3tf9Pkwc5Zk3E9OOMGfdf1g3fzcbvjxMfpZojRcEQRCah0YFoFmzZnHw4EGef/553nzzTXwqVyj/6aefbmkld6GJtBYw7kfwHQz6Mlj5MJzaKO8bPBjFZ59VHWo6YwbS3r0MeXYabbp2x6DTsW7m+6QlnrmlWyqVSno80qfq96PJu/lwzZP8snEdq97bx8FtFzEamj7vkCAIgiDcSbe1Db6srAyVStXkyYn+bnd1EXRd9BXw82Q4+QsoVPDAYuj4IEgS0mOPoVi+HACDjQ2q06fRt2zJuk+mc+n4UUwtrYh8Zwb2Hp4Nvt2BjAM88OEDXFl2BUOhoWp7Z+8IIntNxdPPjb4TAnBs3Qy+O0EQBOEf4453gV1z4MABTp06hUKhoG3btgQHBzf2UneVZheAAAx6+OU5OLoKUMD9X0Lwo1BejiE4GNXJkwAYO3dGGRdHhdHATx+8TVriGSxa2vLw9E+wcXZp8O22X9zO61teJ3FJIgUJ1cufWJq15JHe0wjy7kWn/u6EjvBGY9K0yaoEQRAEoSHueADKzMwkMjKSmJgYbGxskCSJ/Px8+vbty6pVq3BwcGj0w98NmmUAAjAaYfMrsH+J/PvQmRA6BdLT0fv6oi4qAkCaNAnFN99QWlzEj+/+H9mXkmnh4MTD732Cla19g2+XlJ/EtKhpHP79MKnfpWIoqh4N6ubTnwd7Po+zqyMR4/1p3d7utn5UQRAEQbjRHW+Df+GFFygsLOTEiRNcvXqV3Nxcjh8/TkFBAS+++GKjHlq4DZRKGP45hD0v/77lddj5OTg7I61Zg7Fy1kzF0qUwZw5mllY8+Ob72Di5UJCVwU8fvE1JQX6Db+dt7c3K4SsZ8+AYfD/0xSrYqmpfQuJ2PljzJHsORbFxzhF+++YEJQWiZV4QBEG4OzRqBMja2po//viDbt1qToIXHx/PoEGDmv307812BOgaSYKojyB2pvx7+OvQ9z8UPv00Vl9/LR+iUqHYuhUGDCA/M4NV77xO0dUcnLx9eOjtjzAxN7+F20l8c/wbZh+YTV5cHunfZ6Avrp79NsRvEA/2eI6Wtjb0HONLQFjdU5gLgiAIQlPc8REgo9FYZ6GzRqOpmh9I+BspFNDvTRgwXf49dib89haWc+eS20ZeP0xhMMDYsZCYiLWjEw++9QFmVi3ISEpk/cz30FWU38LtFEzuOJlFAxfRum9r2nzgjW1n26r98Wd/4/01T3Lo1B52fHeKX2cfJi9TrJQtCIIg/H0aNQI0cuRI8vLyWLlyJa6urgBcuXKF8ePHY2Njw/r162/7g/6Vmv0I0PX2LZJfhQF0fYIS+0gMAwZiVSzXA9G2LezdCy3k8PPje/+horQEr85dGfnqm6jUt9bRl1KYwkvRL3Eq5xQFuwvIWplFWXFZ1f6wtsN5oPsULC2s6Dbck6CBHqhUYj0xQRAEoenueBH05cuXGTlyJMePH8fd3R2FQsGlS5fo1KkT69evp1WrVo1++LvBPyoAARxcDr++AEjQ6WHSYsywXbgAk4rKmpzhw+GXX0ClIuXUcdZ+9A76inL8w3oz7MVXUSpvrYurVF/K+3HvsyFpAxU5FVSsqiA5IblqfwtLRx6LeA3/VsHYtbKk74QAnDz/Ad+zIAiC8Lf6y9rgf//9d06fPo0kSbRr1w4/Pz+mT5/OkiVLGnvJu8I/LgABHPsJfn4aJAN6j2FcmnWC1idOoLr2yvLf/4YZMwC4cPgA62e+j9Ggp2P/wQx86vlbrtmRJImVp1fyacKn6Iw6NAkazn57jpLi4qpjwtqN4MHuUzDVmtGxbytC7/dGa6q+bR9ZEARBuLf8ZQHoRkeOHCE4OBiDwfDnB9/F/pEBCORZon+aBIYKcgu6UrDmHB4pl6mKNt9/D+PGAXAmbhebZs9Ekox0HfEA4eMnNapw+WDGQV6JeYXs0mw0eRr4EQ7tOVS1v0ULZyZFvI6vayCWtiZEPOKPZ8eGt+ILgiAIwjV3vAhaaKba3gePrAS1KTaW+zH62JLheN3abU8+CQnyyvL+Yb0YOEVup9+/4Wf2rfuxUbcMdgpm9X2rCXQIRGejQzdZR+S/IzGv7DIrKEhn9oaX+X7PXK5m5LNp3lG2fX1ctMwLgiAId5QIQPcanwEwYS0KU0ucO6aQ29KG3MqV4ykrg1GjIC0NgI59B9Hn0ckA7F69nENbNzTqlo7mjiwdvJRI/0hQwomAE4xZOIYevarXjYs7to531j5FYvoxEvdn8v30vZzcnSpWmRcEQRDuCBGA7kWevWDiesxczWnpW0y6kzOlNjbyvtRUGD1aDkNAl+Gj6D7mEQB2LF3EiZjtjbqlRqXhre5v8V6P99AqtRwyHsJmmg3/+fA/mJrKq8sX5qcy65eXWLF3AUUFxUQtP836zw+RlyFa5gVBEITb65ZqgB544IGb7s/LyyMmJkbUADUXaUcxfD2K82vVUCTRJicb1bVJLB97DJYuBYUCSZKI/vYrDm75FYVSyYiX/o1vSI+bX/smTuSc4KWol0grTsNMbcYUlyl889Y3xMXFVR1j1dKdJyNex8epHQqVgpD7vOg80AOVWmR2QRAEoW53rAh60qRJDTpu6dKlDb3kXemeCUAAmafJ/+9IUqOVmOrK8ExLR1FaOW/P//4HL78MgGQ0sm3hl5yI+QOVWs3oN6bTulNQo297tewqr8e+zr60fQA8FvAYhhgD7/z3HcrLKydhVCgJ7TyWh4MfQ6PSYu1szoDH2uLsZd2kjywIgiD8M/1tXWD/FPdUAAKk7EQujR1BSSo4mBRif/SKvEOphE2bYMgQAIwGAxtnfcK5+D2oTUwY8uxL+IaEoVQ1brV3vVHPl4e+ZOlxOTCHOofyhOMTTJsyjYTKYmwASztPnujzOn72/gB06ONG2Kg2omVeEARBqEEEoCa61wIQQPnh3SSNmwxG8G6RhUlCjrzD2hr27QN/OXzodTrWz3yPi0flVnaLlra0j+hPx76DsHF2adS9tyVv4+3db1OqL8XFwoVPe3/Kpm82MX36dHQ6eU0xhVJJcJdHmBg4EbVKg9ZKw4CJbfHqJFrmBUEQBJkIQE10LwYggMxPPiBn6feozXT4VKShOFlZfOznJ4egykJpXVkZe39exbGo3ym9bvV4jw6BdOw3CJ+QHqjrWCvuZhJzE5kWPY2LBRfRKrW8HfY23iXePP744xw6VD1vkJVjGx6NeI22tr4AtOpkx4DxAVhYmzTx0wuCIAjNnQhATXSvBiBjaSlJw4ahS0vH3jcfh/3ZkF65qvuQIbBxI1z3usug13H+QDzHtm8j+egheRV6wNTSinbh/ejYbxD27q0bfP+CigLe3Pkm0SnRAET6R/Jy0Mt8+smnfPDBB+j1egCUKjWduo3jsQ7j0Kg0oFXS+0EfOvZyQ6EUq8wLgiDcq0QAaqJ7NQABFO6IIuVf/wIleHdPw2R1IZRULpfx6qvw6ad1nleQlcmxqN85Hv07RTnZVdtd/ALo1G8w/mG90VS2u9+MUTKy+Ohi5h+ej4REoEMgn/f5nJTTKTz++OMcO3as6lhbN38e6v0qHa29AbBsZcH9kzvQ0tmiCd+AIAiC0FyJANRE93IAArj83PMUbd+OubspHq5nUawogcoMxLffwqOP1nuu0Wgg+chBjm3/jfMH9iFVrjWmNTMjoGcEnfoPwdGrzZ8uqxGbEsu/d/6bwopC7Ezt+F+f/9HBpgPvv/8+H3/8cdVUC2qNlo5hExnnPxYzpRqjAtoPcCdiZBvRMi8IgnCPEQGoie71AKS7coXzw+9DKivD9X43rE/uhk2VrfFaLcTEQPfuf3qd4rxcjkf/wfEdv5GXkVa13cHTm079BhPQKwJTC8t6z79UcIlp0dM4l3sOtULNq91eZVzAOPbv389jjz3GqVOnqo51a9ORQaHT6GLlKW+w1jDiyfZ4+Nk26jsQBEEQmh8RgJroXg9AANmLvyLr889R2bakzVPuqOavg/2V9UDOzrB/P7i5NehaktHI5ZPHObZjG+fi92Co7OxSa03w696Tjv0H4+bfrs5RoRJdCdP3TGdL8hYARniP4O2wt1HoFfz3v//ls88+q1ouw8TElOB+T3C/+0isFGokwC7QljGPd0BrJlrmBUEQ/uma3WKo8+fPx8vLC1NTU7p06cLOnTvrPfbnn3+ma9eu2NjYYGFhQVBQEMuXL6/3+ClTpqBQKJg1a9adePR/LLvHH0Pbpg2Gq7lkJreFVyeCZ2UBdHq6vGZYaWmDrqVQKvHo0InhL77GlAXf0vfxp7F3b42+opyTsTtY/c4bLHv5WfZv+JmS67rKAMw15nwS/gmvdX0NlULFhqQNPLrlUbJ12cycOZNdu3bh6yt3hJWXlxG3ZT7f7n2LhIoUFMDVI1eZ98ZO4nel3M6vRxAEQWjm/vYRoNWrVzNx4kTmz59Pz549WbRoEV9//TUnT57Ew8Oj1vHR0dHk5uYSEBCAVqtl48aNvPLKK2zatInBgwfXOHb9+vVMnz6drKwsXnvtNaZNm9agZxIjQLLiffFceuwxUCjwXPUDZsfmwgtLIK/yP5mBA+GDDyAk5JavLUkSaefOcGzHb5zZE4uuXH7FplSp8enWnY79BtG6YxAKZXVGj0+L57XY17hadhVrE2tm9p5JD7celJSU8OabbzJ79uyq0SAzMzP6P/ACIVb9sZXk0R+jmxnjng3Ezt68id+MIAiCcDdqVq/AQkNDCQ4OZsGCBVXb2rZty6hRo5gxY0aDrhEcHMzw4cN5//33q7ZduXKF0NBQtm3bxvDhw5k2bZoIQI1w5fXXKfh1A6bt2+O5ehWKxU/DtKWgu+6gsDCYNg0eeADUt/6qqaK0hNN7Yjm2fRvp589VbW/h4ETHvgNp32cAVnbyhIfpxem8FPUSx3OOo0DBi8Ev8mSHJ1EoFMTGxjJp0iSSkpKqrhES1ovOXZ+nfYU9ShRUKKFVhAtjHvRHqborBkAFQRCE26TZvAKrqKjgwIEDDBo0qMb2QYMGsWfPnj89X5Iktm/fzpkzZwgPD6/abjQamThxIq+99hrt27f/0+uUl5dTUFBQ40eQOb3+OkorK8pOnCB39Wp49ht4byKYX1evExcHkZHg1RpmzoTc3Fu6h9bMnE79hzD+oy+Y+MmXBA2+DxMLCwqyMtj94wq+eu4J1n3yLokJe3E0dWDZ0GWM8R2DhMTsg7N5KfoliiqKCA8P5+jRozz33HNV146P28WKJU9y3CyOLI0RrREyo9KY+UYsR09m3a6vSRAEQWhm/tYAlJ2djcFgwMnJqcZ2Jycn0tPT6z0vPz8fS0tLtFotw4cPZ86cOQwcOLBq/yeffIJarebFF19s0HPMmDEDa2vrqh93d/fGfaB/ILW9PQ4vySNnWbNmo8/Ohn9/Bwe3w3N9wOm6EZ+UVHjjDXB1gWenwJkzt3w/R09v+j/xDFMWfsfQ51+hVdsOSJKRpIMJ/PLZByx+bhLxP65imvcU3gl7B41Sw/ZL2xm3eRxJ+UlYWFgwd+5ctm/fTuvW8iSMxcXFLJ71NrEnPybdtYQKJKyKjER9eZTPZyVQUFxxO74qQRAEoRm5K94B3Nj9I0nSTeeJsbKy4vDhwyQkJPDhhx/y8ssvEx0dDcCBAweYPXs2y5Yt+9O5Zq75v//7P/Lz86t+Ll++3OjP8k/UMjIS0w4dMBYWkjGzciJE/74wNwqSc2Dh/0GQY/UJZeWwcDEEBED/XvDbb1WzRDeURmtCu959iZz+MZO+WEjXEQ9g1sKa4tyrxK9fwzdTn0JafYiP7V/C2cSRC/kXGLdpHNsvbgegX79+HD16lKeffrrqmlE7tjP7s3EUehznagslahSYnC5k4Ws7mTUrnuRL+fU9jiAIgvAP87fWAFVUVGBubs6aNWsYPXp01fapU6dy+PBhYmJiGnSdyZMnc/nyZbZt28asWbN4+eWXUV5XPGswGFAqlbi7u5OcnPyn1xM1QLWVHjtO8tixIEl4LFuGRffQ2gclbIeP3oLN8VBhrLnPyxmmvQJPPQdmZo16hvqW3jCxsOBKawO77JLIs9LxVMeneC7oOVRKuWtt27ZtTJ48mZSU6k6wIUOGMHrM/1FwSI+ZPKciRiRK7bX0GOxJz56txLIagiAIzUyzK4Lu0qUL8+fPr9rWrl07Ro4c2eAi6CeffJLz588THR1NTk4OaWlpNfYPHjyYiRMnMmnSJPwrVzW/GRGA6pb+3nvk/rASrbc33uvXodBq6z7w6lX47C34ejlkFdXcZ6mFR0bAmzOhtXejn6W+pTcybco4616Ec3AnPu7/KdYm1gDk5eXx8ssvs3Tp0qpjra2t+fzzWVjZdOfM7jRaFlf/USgzUdA6xIlh97fB3EostCoIgtAcNKsAdK0NfuHChYSFhbF48WK++uorTpw4QevWrXn00Udxc3OrCkMzZsyga9eutGnThoqKCjZv3swbb7zBggULmDx5cp338PT0FF1gt4GhoIDzQ4dhyMnB4aWXsJ/y9M1P0OthzUr45H04cq7mPiUQHgCv/QeGToAGvq68UX1Lb1SojWR6wMNjXyYkqH/V69CNGzfy9NNP1wjJAwYM4OWXX8bCviPRW5KxTC3HBPl4gwLMva0YNLIN7r4tG/xaVRAEQfjrNasABPJEiDNnziQtLY0OHTrwxRdfVHV19enTB09PT5YtWwbAW2+9xerVq0lJScHMzIyAgACmTp1KZGRkvdcXAej2yf/1V1JffwOFqSneGzeibdWw2aBJSICZH8C6jWC44fWYtyU88RD86z1o2arRz3Zt6Y2Df2ykJCunaruJix29ho6tWnrj6tWrTJ06lRUrVtQ439fXl+eee44+Q8ew5fc0Sk/l46ivfpUqWWsIGeBBUG83tKZiZmlBEIS7TbMLQHcbEYDqJ0kSlx59jJKEBNQuLjhOm0qLESNqTFh4U6mpMG8uLJgHuTdMN2CthOEd4PnXoduDoG7cqyfJaOT0kb2sXjML8wvFqIzyqI1aq8Wvey869huEW0B71q9fz0svvcTFixdrnG9hYcGjjz7Ko09O4fBFDWd2p9G6GDSVo0JGlQLPLg70GOyJnVv9a5kJgiAIfy0RgJpIBKCbq0hO5uKkJ9BXvkYyCQjA8dVXsezVs+EXKS2F77+HLz6Hk6dq7tMAXa1g0lgY/hy4BDXqFZnBaGD+3tns/P0n/C5Z0rKoumbJ1rUVHfsNwq9nBNtjYpk7dy47duyodY1+/frx7HPPITl2Jvr3izhn6bE1Voc9Szdzug9qjU+wEyrNXdFUKQiCcM8SAaiJRAD6c8ayMq4uX07O4q8wFhYCYNEjDMdXX8W0XbuGX0iS4I8/YNYs2Ly59n4/NQzxhbHPQmAkWDrWPuZPRF2K4j87/4NZVgWd0hzwTDXHUCHP/aNUqWlh74BCpSLtah7bj5xg98nTVOj0Na5hb2PNkLBuhHQMIrcQKDJgJalQoASUKNQq7NyscHS3wdTKBKVShVKllP+pVqNUKlGqVChUqsptlf9UVf5ct63qGJUSpUp93TFKFCoVqsptihrXV6E1MxM1SoIg3NNEAGoiEYAaTp+bS87CReT+8ANS5SrvLUaMwGHq1IbXB11z5gx8+SUsWwYlJTX3OSqhuymMHgahj4LvYFDX04VWhwv5F5gWNY2k/CTMDBqeMXkA7YkcMs6fq3VsaYWOhOQU9iQmk11U8znUKiXBHq709PHEraX1rX2+O8zRqw1Dn3sZe/fWf/ejCIIg/C1EAGoiEYBuXUVKClmzZlOwcSMACo2GlhMmYD/laVQ2Nrd2sdxc+OormDMHUm5Yxd1cAV010MsReo2DoPHg0qlBly3WFfP27rf5/eLvAIz2Gc1zrSehLy5DMhgwGg0YDdU/er2O2D1xrFizlp374mtdL7BtACMGDsDayYfLl/KxLZewNkiAETCi1iqwdTajhYMpSpWE0WCo8z7y70YkgwGDQV95jLF6n776HKmObddTa7T0Hj+JzkPuE6NBgiDcc0QAaiIRgBqv9PgJMj/7jJK9ewFQtmiB/ZSnaTlhAkqTWyxq1ulg3Tr59VhcXM19SqCjBkK1EBQEQeOg01iwsL/pJSVJYumJpcw+OBujZKS9XXs+Df8U9xY3X/4kMTGRefPmsWTJklprxbm4uPDk5KdwCxvBliNF2KSV06FCjbkkBxCFEryDHOgQ7oab/+1tpZckCUkyUpyXy2+L5pB8+AAAXkFdGPzsNCxsWt62ewmCINztRABqIhGAmkaSJIp37SLz088oP3sWALWLCw5TFZ8NywAAIABJREFUX8R6xAgUKtWtX3TfPpg9G9askecXul5rlRyE2ppCwFA5DPkOApWm3svFpcbxeuzr5JXnoVQoCW8VzsP+DxPmGoZSUX8xc1FREStWrGDOnDmcPHmyxj6NRsODDz5Ez5Hj2ZNnQ+6ZAoLKVbgZqj+vjZM5HcLd8O/ujKlF/c/XGJIkcWjrRmK/X4JBp8OshTWDn5lKmy4ht/U+giAIdysRgJpIBKDbQzIYyP91A1mzZ6OvXNzWJCAAx1dewaJXz8aNhKSkwLx5sGhR7VXnbRQQooXOWrB1gE6Rchhy7lDnpVKLUnk37l32pO6p2uZh5cFY/7GM8hlVNYt0nZ9NkoiOjmbOnDn88ssvGI015zbq0qULD0x4knT7YBKOXaVDqYp2FSq0la30Ko0S325OdAh3w8nz9v43ln0pmc1zPiPrUjIAgQOHETHxCTQmprf1PoIgCHcbEYCaSASg28tYVkbuihVkL1rctI6x65WUwPLl8uux06dr7jNRQJBGDkO2SnDuBJ0nQIcHwcKu1qWS8pNYc2YNvyT+QqFOfj4TlQlDvYbysP/DtLdvf9NHuXjxIgsXLuSrr74iJyenxj57e3seeXQSFkFD+e1cBe6FEkHlahyua6V38LCiQ4Qbvt2c0GgbMTpWB31FBbtWfcuBTb8Actv/sBdfw8mrzW25viAIwt1IBKAmEgHoztDn5pKzaDG533/f9I6xa4xG+P13OQht3VpznwLw10CoRn5NptKC/xC5cNpnQK1XZCW6EjZf2Myq06s4k3umantH+45E+kcy2HMwpur6R1FKS0tZtWoVc+bM4dChQzX2qVQq7rt/JAH9HmJ3kQPG7AqCylX46VSoK0eFtGZqAro70z7cDVsXi8Z9HzdIPnqIrfO/oDj3KkqVml4PT6TrfaMbPnGlIAhCMyICUBOJAHRnVaRcIWv2bAo2bAAqO8bGj8f+mSm33jF2vVOn5Db6b7+VJ1q8XisL6GKADhpQK8DCUS6aDhoPTjVHoSRJ4kjWEVafWc225G3ojHJYszaxZrTPaMb6jb1p0bQkScTFxTFnzhx++ukn9DfULHXo0IG+oydyybYLZ1LL6FihJrBChc11o0Jufja0D3fDO8gBlbppYaWkIJ/fF88hMUEuTPfo0Ikh/3oZK7ubF4wLgiA0NyIANZEIQH+N0uMnyPzfZ5TEXdcx9vRTcseYaRPqVXJy5Db6uXPhypWa+2zMoasJBOrAsjJYuIdCjxfAfxgoa76CyinNYV3iOtacWUNqcSoAChT0dOvJw/4P08utFypl/a+t0tLSWLRoEYsWLSK9sg6q6lFsbLjvwXFIbQexJ1ONh05JULkaH72Ka9VRZi20tOvpQvvebljZNv47kSSJYzt+I+rbxejLyzG1sGTAU8/jH9ar0dcUBEG424gA1EQiAP115I6x3WR+9hnlZ+TXTmoXFxxefBHr+xvZMXaNTgdr18IXX0D8DfP4aNTQwwPaZoNT5TZbbwh7DgLHgda8xuEGo4FdV3ax8sxKdl/ZXbXd1cKVh/wf4gHfB7A1ta33USoqKli7di1z5swh7oaWfoVCQd+Bg3HrMZr9+laoyqFTuYognRrzynXMFApo3dGeDuFuuLezRalsXCv91dQrbJ7zGRlJ8gSQ7SMG0G/S02jNzP/kTEEQhLufCEBNJALQX6+qY+zLL6vXGPP3x/HVV7Do1avpc+fs3SvXCf30E9wweSC+LuBcBO568FCDjR2EPAXdngJLh1qXulxwmR/P/si6xHXkl+cDoFFqGOw5mEj/SAIdAm/6vAcOHGDu3LmsXLmS8vLyGvt8fH0JHvIwSS27kFOmxkenJFinwV1X/RrMys6U9r1dadvDFfMWDZ8N+xqDXk/cTz+wb/0akCSsnZwZ9vyruPoF3PK1BEEQ7iYiADWRCEB/H2NZGbnff0/2wkVVHWPmYd1xfPVVzNrfvBurQS5dktvoFy+GvLza+5WAiwo8VdDGDO4bB31fAnvfWoeW6cvYlryNVadXcTzneNX2ANsAIv0jGeY1DHNN/SMrWVlZfPPNN8yfP5/Lly/X2GdpaUnvYWMo9unPRYMttgYFQRVqAvVq1JX5TalW0KazIx3C3XDxsb7lkJhy8jib5/2PwuwsFEolYWMeIXT0WJRNGXUTBEH4G4kA1EQiAP39DHl5ZC9aTO6KFdUdY/fdh8O0qWhbtWr6DYqL4bvv5CB0+HD9xykBNxV08Yexz8DIJ8G8dqg5nn2c1WdWs+XCFsoN8qiOlcaKkT4jGes/Fi9rr3pvodfr+fXXX5k7dy5RUVG19nftEY51lxGcM/VDo1ARUKGiByZYl1b/0bV1taB9bzf8QpxuaYLFsuIitn+zgNO7YwBw9WvLsBdewdrRucHXEARBuFuIANREIgDdPersGBs3DrtnpqBueZuWecjOhpgYiIqSf26Y4bkGtQKC2sGwMdC/P4SGwnVLfOSX57M+cT2rz6zmcmH1qE6oSygP+z9MH/c+qJXqei9//Phx5s2bx3fffUfJDQvCurl74NfnAS7Zd0evtcRJr6AHJviUKsEg/zFWaZS06exAu56uuPrZNHhU6NTOKP74ZgEVpSVozczo/8SztO3dV6wnJghCsyICUBOJAHT3KT1RucbYtY4xKyvsnn4K24kTm9YxVpeMDIiOrg5Elct51MnUFHr2hD59oG9f6NYNtFqMkpG41DhWnVlFbEosRkmeKdrR3JGH/B5ijO8YHMxr1xddk5eXx9KlS5k3bx7nz5+/4ZamBPW9j3yv/pRYuWNihGBJS3dMUBdWt9xbO5jRtqcLAWEuWFj/+Tps+ZkZbJ77P1LPyAHQv0c4Ayb/C1MLyz89VxAE4W4gAlATiQB0d6rqGPvf/yivnP1Z7ewsd4yNvL9pHWM3c+WKHIh+2wK/b4G0q/Ufa24OvXrJYahvX+jShdSyTH46+xNrz63lapl8rlqhpn/r/kT6R9LVqWu9Iy1Go5GtW7cyZ84ctt440SPgH9gNTcehFDgHo1CqcTUqGGpuhX2uAWOFHLoUSgWeHe1o19MVj/a2KFX1zytkNBiIX7+GPT/9gGQ0YmXnwNDnX8a9XceGf1+CIAh/ExGAmkgEoLubZDCQv2EDWbOv6xjz88PxtVdvT8fYn0k8A8s/ga3r4Uwe5N/kj5CVFfTuDX37ogvvxW8tM1md+BOHMqtnivax8SHSP5L7vO/DUlv/aMu5c+eYN28eS5curbUivb2jM67d7yPHtQdqa0c0EgywtCRYr6Eio6zqOAtrLQE9XGjbwxVrB7N675V27gyb53xGXkYaKBSE3D+GHmPHo1Lf3gVcBUEQbicRgJpIBKDmwVheXr3GWGUgMO9e2THW4TZ0jP3pAxjg9Cb4dSbsOQDJBkjWQ+FN/kjZ2EB4OJmh7VnXKo8ligRKjHJAMVebM6LNCCL9I/FtWbvr7JqioiKWL1/O3Llza61Ir1Ao8OgQSnmbcDTeoSg1JgSYmTKiRQtMUkopL65+RdYqoCXterriFWSPWlN79KyitISob7/ieNTvADh5+zDshVexdb0NReiCIAh3gAhATSQCUPNyxzvGGuLSPoibAyc3wFWDHIbSreBCBeTk13ua0c6WlOA2bPEsZYtnGeddTUChINgxmEcCHqG/R380qrpHXSRJIioqijlz5vDrr7/WWpHezLIFlu3CUQX0R+vsg6VGzbhW9vgUKcg+nw+Vf/JNLNT4hzrTrqcrdm61R6DO7tvN74vmUFZchNrEhL6PPUXHfoNFgbQgCHcdEYCaSASg5qki5QpZX86m4Nc72DH2Z3LOw975cOh70JeCJEG5E+i7wIVyiN0ld53Vo7ClOXt8NewLsCChrQWFni6M8X+Qh/wewtmi/tb0y5cv8+2337J06VKSkpJq7bd08UbTtj8W7fugtrBmqKc9/U0tKDydT3Fu9WSMTl4taNfTFZ+ujmhNq7vVCnOy2Tr/cy4dPwpAm67dGTTlBcxbWDfmWxIEQbgjRABqIhGAmreykyfJ/OwzivfIS07c0Y6x+hTnwP5vYN8iKKkMPCbWEPw4tIiAhBNyh1lMDOTm1nuZTBs1CQEWJLS1RNVvAAP6Pk2oa3eUiroLmY1GIzt37mTJkiX89NNPtVrplSo1pm1CsOg0EDOvYNq72jDe0wmbtHIuHcvBaJT/OlCbqPDt6ki7nq44ebVAoVAgGY0c2LSenSu/w2jQY2HTkiH/egnPwODb8pUJgiA0lQhATSQC0D9D0bU1xv7KjrEb6Urh6GrYMxdy5PW3UGqg40PQ43mwD4CjR6tb7mNj4YYC5+ul2Wo42ckJ0wFD6fjQC7Twq787q6CggB9//JElS5bUWn8MQGVpi0X7flh2HICrZxsmBrUi2Kjh4v4s8jKqg5OtqwXterriF+qEmaWWzOQkNn35KVevyPMcBQ8bSe9HHkOtvfVlOQRBEG4nEYCaSASgfw7JaKRgwwYyZ82u2TH26itY9O7919WxGI1wbhvsmQMXqxdTpU1/eSV67z7yiqd6PRw6VB2Idu6UZ62uR66rDYo+fbEZMhoGDwZHxzqPO336NEuXLuW7776rtSo9gIlbWyw6DsS2QzgPdvdhtLsDhSfzSDyQiV4n1xYp1Qq8g+RJFp08zdi5chmHt20CwN7Dk2EvvIqDh2djvyFBEIQmEwGoiUQA+ueRO8a+J3vRor+nY+x6KQcqC6Z/gcoJEnHqKAehDg/A9UXPOh3s318ViKTdu1GUltZ5WYNWQ8XkxzF7611wcanzGL1ez9atW1myZAkbNmxAr9fX2K/QmGDu3wvLTgMZ2K8Pk0Ja43BVz6ndaWRdKqw6zsrOlLY9XDC3SiV2xQJK8vNQaTSEj3uczkNGoFDWP9eQIAjCnSICUBOJAPTPZcjLI3vxV+QuX17VMWbevTuWfSKwjIjAxKv+Nbtuu9xk2LsADi4HXeUoj5UrdH8WujwGpnUUGJeXQ3w80o4dFP22AdP9h9FU1FzdvkKr4tzY/lj/90Na+Xat9/aZmZmsWLGCJUuWcOLEiVr71S1dsOw4kA4R9/Gv+0Lpbd+CpH0ZnInPoKJUDk4KBbj6mlCUvYmM83KBtGdgMIOfnYZlS9vGfS+CIAiNJAJQE4kA9M9X1TG2YaPcqVVJ09oDy3A5DJmHdEP5V9S1lFyFA0vlgumiDHmb1koOQaHPgI17/eeWlZEfs41L38/F98coTMurw1CpVsG2oW3IfmESYUEjaWfbrs5XfpIksX//fpYsWcLKlSvJz7+hbV+hxNSzM87dhvLsxLFM7OFNwblCTu5KJfVcXtU1lMrjlOVHIxl0mFm1YNAzU/HpGtrkr0cQBKGhRABqIhGA7h0VFy9SGBVFUUwMJfsPyK+cKinMzbHo3h3LiAgsI8LRON/hFdL15XBsjVwnlHW68iFU8muxHi+AS+DNz8/MpPjDdzBZvAR1WUXV5hKtglUD7Nj4QFu6dhhCP49+dHHqgkZZe36h0tJS1q1bx5IlS9i+fXut/UpTK6w69GXEQ+P4vwlDcVWpObUnlVNx6ZQWVGA05KAr3oxkyAKgQ7/B9HvsKTR/VfedIAj3NBGAmkgEoHuToaiY4rg9FMXEUBwTiz4rq8Z+k4AALMPDsewTgVlg4J3rJJMkSPwD9nwJF2Krt3uFQ48XwWeA/O6pPunpMHMm0oIFKMqql8EoNlXywwBbvh1ij9G2JRGtIujn0Y+erj0x15jXukxycnLV3EIXL16stV/j6E3HvqN488XJjOjmx+UTVzm1O5XkYxnoSnZjKD8AgKmlA/2fnEZAjz8JcIIgCE0kAlATiQAkSJJE+alTFMXEUBQdQ+nRozVelamsrbHo3RvLiHAsevW6cxMtph6GuLlw/GeQKl9vObSVW+g7PgTqm6zynpYGH38MixbJtUOVis1UrBhgy3dD7CmwUKFVaglzDaOfRz8iWkVgZ2ZX4zJGo5Ho6GiWLFnC2rVrKbsuVAGgUuPQoRePPvY47zzzMIoyOB2XxpE/dpOX+itIxYASa5e+hI4cg1+oCybmYk0xQRBuPxGAmkgEIOFG+txcinfupCg6hqJdu6o6yQBQKjELDMQyIlwupA4IuP3t9XmXYd9COLAMKorkbZbOEDoFuk4Cs5sEsCtXYMYM+OorqKh+NVZuYcpPw1sxL0JDoYU8mqVAQWfHzvTz6Edf9754tPCo+Rh5eaxevZolS5YQHx9f61aaFvb0GjqGD954nrDA9pw/fImopQsoyDwuX1/dCjPrYfiG+NCupysuPtZiSQ1BEG4bEYCaSAQg4WYkvZ7SI0fkMBQbS/mZMzX2q52c5FdlEeFYhIWhtLC4fTcvzYOD38LehVCYKm/TWEDwoxD2L7DxqP/cy5fho4/gm29q1DoZrFtwcHwE8yLUHCg9V+MUHxsf+nn0o59Hv1pF1CdOnGDp0qV8+913ZN/wuhDANSCYZ56azEtPT+Tszp3Ervgag74cFCZozAeg0vpj42RO254uBHR3wbyFmEhREISmaXYBaP78+Xz66aekpaXRvn17Zs2aRe/eves89ueff+ajjz4iMTERnU6Hr68vr7zyChMnTgRAp9Px1ltvsXnzZpKSkrC2tmbAgAF8/PHHuLq6Nuh5RAASboUuLY2imFi5dmjvXqTr5ulRaDSYd+taWUgdgdbT8/bcVF8BJ36WC6Yz5NEVlBoIngi9XwVrt/rPvXgRPvwQli6VJ168pmVLCl+cwpb7fPjtahz70/djkKq7ypzMnarC0PVF1Dqdjk2bNrFkyVI2bd6E0VCzLV9tYka/YaOY9lgkOXujyUiSQ5batD0q0z4oFCYolQo8A+1p19MV93a2KJViVEgQhFvXrALQ6tWrmThxIvPnz6dnz54sWrSIr7/+mpMnT+LhUfv/zUZHR5Obm0tAQABarZaNGzfyyiuvsGnTJgYPHkx+fj4PPvggTz31FIGBgeTm5jJt2jT0ej379+9v0DOJACQ0lrG8nJL4BLl2KCYG3eXLNfZrW7fGovJVmXm329BmL0mQFAW7ZsGFGHmbygS6PgG9XgIrp/rPvXABPvgAvv0Wrg8tdnbw2mvkT55AbN5Boi5HsevKLkr11cHOSmtVZxF1eno6y5cvZ8Hir7mQeLbWLZ3cvbi/Z1dcS/KwMtVi1sIea+eR5GVVz3lkYa3Ft5sTfiHO2LtbildkgiA0WLMKQKGhoQQHB7NgwYKqbW3btmXUqFHMmDGjQdcIDg5m+PDhvP/++3XuT0hIICQkhIsXL9YZqm4kApBwO0iSRMWF5KowVLJ/f40RF4W5ORY9wipfl0WgcbpJWGmI5N0Q9WH1UhtqMwh9GnpMBQu7+s9LTJSD0PLl8pId19jbwxtvwLPPUmaiYl/aPnZc3kH05Wiull2tOqyuImpJkti3bx/zFn7FmjWrKS+puZyHUqmkXStXurRypJ2bC8FDxmBiEcbZ+CzKiqtfz7V0NscvxBm/ECda2Js17fsRBOEfr9kEoIqKCszNzVmzZg2jR4+u2j516lQOHz5MTEzMTc+XJIkdO3Zw//33s379egYOHFjncX/88QeDBg0iLy+vzi+kvLyc8uu6ZAoKCnB3dxcBSLitDEVFFO+R2+yLYmMxZGXX2G/Stm1VGDIL7NS4NntJgqRoOQilJMjbtJby7NJhz4OZTf3nnj0L778PP/xQMwg5OspB6JlnwNwcg9HAkawj7Li0g+2XtpNSlFJ16PVF1P3c++Hewp3i4mJWrl7D5/MWcerg3lq3tTDR0qW1G0P79Obp/84gL0vD2fgMko9lY9BVP4eztzV+IU74dHXEzFLUCwmCUFuzCUCpqam4ubmxe/duevToUbX9o48+4ttvv+XMDcWl1+Tn5+Pm5kZ5eTkqlYr58+fzxBNP1HlsWVkZvXr1IiAggBUrVtR5zPTp03n33XfrvI8IQMKdIBmNlF1rs4+JoezosZpt9jY2cpt9eDiWvXuhsrlJcKnzBhKc+w12fADp8hIVmFpD2AvQ/Rkwsar/3NOn4b33YNWqGs+EszP8+98wZQpUTmwoSRKJeYnsuLSDHZd3cDLnZI1L3VhEnZh4nve/mM/a1T9QcjWj1q3d7Voy4ZGHefH/3sK2pSPnD2VxNj6dK2dyqx5FqVTg3t4WvxAnvDo5oDG5Q/MxCYLQ7DS7ALRnzx7CwsKqtn/44YcsX76c06dP13me0WgkKSmJoqIitm/fzvvvv8/69evp06dPjeN0Oh0PPfQQly5dIjo6ut4vQ4wACX83/dWrcpt9TAxFu3bXbrMPCqqahNHE37/hdTGSBKc3QtRHkFkZTsxsoedUCHkKtDfpUDt5Et59F378seZ2V1f4z39g8mQwqTkPUVpRGlGXo9hxeUetImpnC2f6ucthKNA+kO/XbuWzOQs5s28HkkFX4zpKhYLunQN56tl/MXbceCSdinMJGZyNz6ixKKvaRIV3kD1+Ic64B7REqRKLsArCvazZBKCmvgK7ZvLkyVy+fJlt27ZVbdPpdIwdO5akpCR27NiBnd1NaiBuIGqAhL+TpNdTevhw1SSM5edqtqZXtdn3icCie/eGtdkbjXLXWPTHkFN5PQtH6P0ydJkEmpssVXHsmByE1q6tub1VK3jzTXjiCaijmDu/PJ/YlNg6i6hbaFtUFVE7Gdvw7ufL2LL2B0rSEmtdx8xEy/ChQ5n8zLP079+fwuxyzsZncDY+nYLs6kkZzaw0+HR1wi/ECSfPFqJ4WhDuQc0mAIFcBN2lSxfmz59fta1du3aMHDmywUXQTz75JOfPnyc6OhqoDj/nzp0jKioKBweHW3omEYCEu4kuNZWi2FiKoivb7K+biVmh0WAeEiJPwtinD9o/K/I36OHYj3IQyqtc3sLKFcJfhc4TQX2T2pojR+QgtG5dze0eHnIQevzxOoMQQJm+rN4iahOVCWEuYfRu1YczCbBsyU9cid9CeXF+revY29oybsIEJk6cSHBwMJnJhZyNzyDxQAalhdWjSC0czPALccI/xBkbp9rLfAiC8M/UrALQtTb4hQsXEhYWxuLFi/nqq684ceIErVu35tFHH8XNza0qDM2YMYOuXbvSpk0bKioq2Lx5M2+88QYLFixg8uTJ6PV6xowZw8GDB9m4cSNO13XW2Nraom1A27EIQMLdylhWRklCgjwJY0wMupSUGvu1Xl7ynEN9+mDeJRiFpp4lJww6OPw9xHwKBZXXsPGA8Nch8BFQqet/iEOHYPp0+PXXmts9PeGtt+DRR6G++8JNi6iVCiWd7DvhadaZfX8UcujX7RScjaeiorzWdXx9fZk4cSLjx4+ndWtPUk7lcjY+naQj2ejLq1+9Oba2wi/EGZ+ujlhY32TpEEEQmr1mFYBAnghx5syZpKWl0aFDB7744gvCw8MB6NOnD56enixbtgyAt956i9WrV5OSkoKZmRkBAQFMnTqVyMhIQF7A0cvLq877REVF1aoTqosIQEJzILfZX6gKQyUHDtRos1daWmLRq5cciMJ7o67rNbC+HA58Czs/g6LKomTbNtDn39BhDChvUmC8f78chDZtqrnd2xvefhsmTAD1TYIUf15E3dLElha6tpzemk9p3CEyLp7DcH2HWqWwsDDGjx/P2LFjsWlhy4UjWZyNz+DSyatIRvmvOIUCWgW0xC/EGe8gB7RmN382QRCan2YXgO42IgAJzZGhsJDi3burlugwXK1+zYRCgWmnjlhGRGDVpw8mbdvWrJGpKIH938CuL6AkR97mEAB9/g/a3g/KmxQX79snB6GtW2tu9/GB//4Xxo2DBrb0pxWlsfPKTnZd2cW+tH2U6EuqPwJKlLnO6H8rIf/gWVIyMmudr1arGTRoEBMmTOD+++9HadSQeCCTs/HppCdVF5arNEq8OtnjF+KER3s7VGpRPC0I/wQiADWRCEBCcycZjZQdO0ZRTAyF0dGUnzxVY7/a0bGqbqhGIXV5EcQvgt1fQlmevM2pI/T9D/gPlYdR6hMXB++8A7//XnO7n5+8PTKywUEIQGfQcSjzELuu7GLnlZ0k5tUskDZPNIXtpVw6eYn0/MJa51tYWDB69GgmTJhA//79Kc7VcS4hnbPxGeSmVwcrEws1PsGO+IU449LGGoVYhkMQmi0RgJpIBCDhn0aXkVE551AsxXFxSCXXjaxoNJiHhlbWDkWgdXeHsnyImw9x86CiMly4BkO/N6FN/5sHoV275MCzY0fN7W3bytsfeujmI0r1SC9OZ9eVXey6sou9aXsp1smzS5uWK3FMUFIQV8CxpFTyS8tqnevk5ERkZCQTJkygS5cu5KQUcyY+nXMJGZTkV1QdZ2lrgl83eeZpOzfLW35GQRD+XiIANZEIQMI/WY31yqKjaxdSt2mDZR958VZzf08UCfNh3yLQVYYm9+7Q7y3wqnvB4ioxMfIrsNjYmtvbt5dfmT3wQKOCEMijQ4ezDrPryi5iU3aRmHcWpRE8rphhtc9I0slMjl5Oo1Snr3Wur68vEyZMYPz48Xh5eXPlbC5n4zNIOphJRVl18bSdmyV+IU74dnPCyvYm0wQIgnDXEAGoiUQAEu4VkiRRkZREUXQ0RdExlBw8WGNhVKWVFZa9e2EZGoyF+jDqU8tBXznC4hUOfd8Cj9Cb3QCiouSRn127au7r1EkOQqNG3XxEqQEyijPYdWUXv57dwZGcBFrmGfBLtKTsUBGHLqZyKjUTfR3F06GhoYwfP57IyEhsbexIPpbD2fh0Lh7PwWio/KtRAa4+NviFONEm2BFTi/o73ARB+HuJANREIgAJ9ypDfr5cSF35usyQl1e9U6HArENbLFsZsCQOkxZlcm7xGSjXCLkF139hSYLt2+URobi4mvuCguT5hUaMaHIQAtAZdfxxPp6lh7aSnBGPf3oxHommnEvK5OClVJIyc7jxLz2VSsWgQYMYP348o0aNQoWW8wczORufQeq56u9AqVbQur0dfiHOeHaxnj8eAAAgAElEQVSyQ60Ry3AIwt1EBKAmEgFIEEAyGCg9erSqzb78hqVp1NYmWDrkYulSioVTBcr2w+Qg5NzhJheV4Lff5CAUH19zX5cu8ojQ8OG3JQgBFJfrWZ5wjO8PbcE68xAd0wtQp+s5dCmVQ5dSSc0rqHWOhYUFo0aNYvz48QwcOJDSAn3VMhw5V4qqjtOaqvAOdsQvxAk3v5YoRfG0IPztRABqIhGABKE2XVoaRTGxFMXEyIXU189IrZIwdyzH0rUMy/AItA+8Cw7+9V9MkmDLFjkIHThQc1/79jBgAPTuLf84Ojb52SVJYndiDkt3n+P06e10yj+Gd24RGXlFHLp4hQOXr5BfXLt42tHRkcjISMaPH09ISAhXU4vlZTgS0im6Wj05o4W1Fp9u8szT9u6WYhkOQfibiADURCIACcLNGcvKKImPr6od0qWm1thvYq3DMtALy8jnMYsYjqK+CRElCTZulGuEDh2q+xh/fwgPrw5ErVs3aYToYk4x38VdZOOeU3hfTaB9wWlM9DqSs3PZfymFI1fSKC+rXTzt4+PD+PHjGT9+PD5tfEg7n8/Z+HQSD2RSXlJ9fEtn86riaWsHsQyHIPyVRABqIhGABKHhJEmiIjGRwuhoin7fQumxU1xfZKM0U8uF1AOHYdGrF+qWLeu6CPzyC8yYAQkJ8u/1cXevDkO9e8vt9Y3oJisq1/PzwRS+23UOTfJRAguO4lCRg95g4HR6FrvTLnH+UjZGfe1n6dy1M49PfJzIyEjs7Ry4dCKHs/EZXDiajUFXXWxt52aBV6AD3kEOYmRIEP4CIgA1kQhAgtB4hrw8ijZ8T9Evyyk+m4uh4rpwolRiFhSEZZ8+WEZEYOLnWzsU5ObC7t1y+/zOnfKSG/raIzJV7OygV6/qUaLOnf90CY7rGY0SOxOzWbYriTNHjhJYcAzvkgsokSit0HEkJ4tdKcmkJ+dyY/W0UqUkNDyUpx9/mgcfeBCtypSkw1mcjU8n5Uxe1TIcAJYtTfAKdMAryB5XXxtUKjH7tCDcbiIANZEIQIJwe0jJcZR+/1+K9p+iKNWU8vyaLeRqV5eq5TnMQ0NRmtYx305xsbzcxs6d8k9cHFw3kWMtFhbQo0f1CFFoKJiZNeh5k7KK+C7uIlv2nqJN9hHaFZ7EzCjX+hTo9RwuK2DXiVNcvZhX61y1qZruA7rzzKRnGDtiLIYKuHgsmwtHsrl4Igd9RfXIkIm5mtYd7fAOdMC9nS1aU7EumSDcDiIANZEIQIJwmyXvgh0foju1j6JUEwrTLSjJNEXSVc85pDA1xSI0FPOQELReXmi9PNG2alV7RXudDg4elMNQbKw8v1Bubv331migW7fqQNSzJ9jY3PRxC8t0rD2QwvJdiZhePEyngmPY66rXVjM6OrMn8zI7YvdSkF67k0xrraXLwC4Mv2844+8bTysrd1JO55J0JIvko9mUFuqqjlWplbi3bYlXkAOeHe0xb6G9+XcpCEK9RABqIhGABOEOkCQ4vwOiPoQrBzDqFRRftaZIF0jRuQL06Rm1z1Gr0bq7y4HI0xOtlycmXl5ovbxQ2drKr8+MRjh5svqV2c6dcOVK/c+hUMiTMPbuXf3azNm5zkONRomYs1ks3X2B80ePVL0eu/bSzsrRGZVHG7YePcCWDVspzi+ufTutArtOdgRFBDFs2DDC24ZjV+DOlWP5JB3JpiCr9LqDwaWNNV6d5FdlNo6iiFoQboUIQE0kApAg3EGSBGe3QdQHkH5M3mRiTXnr8RTluVF27jwVF5KpSE6u0Wp/I2WLFmg9PTHx8qwMSJWjRh4eKNPSqsNQbCycO3fzZ/Lxqdlp5u1dq9MsMbOI7+KS2Rp3Et+rR2hXeApTo7yOmNrElIDefcnWmLN24wY2bdxERXlFHTf6//buPD6uut7/+Gv2LZNkksm+N1uzdkna0tUiiCwuIG78FFBULgpcFq9XXLiCCn2IXvEqtloXUBBFroC9baEWsEA3iqUbXZI0e5NmnezbTGbO74+TTDLN0rRJOw35PB+P85jkzJwz32l8MG8/3w3MKWbCFoaRvyafDyz7AHn6xYTVJ9J6wk1zdeCmrhHxNtIWOJm3MIqoZLsMohbiLCQATZMEICEuAp8PTvwf/HMdNA/tVm+NhAU3QWQGSngKgx477tYBBqqr1VBUWYm7qkqddj/Rf7o0GgxxcaOqRmmYQu2YGhrQHTmCZudOOHRo8plm8fEjYWjNGnVtoqGZZp39Hp7/1ymeeasMW+1BFnQeIcIz0gWXurCI7DVXUHK6iS1bt7Jl6xaaGpvGfRtdqA57oR37AjuJixNZGrWS7M5ibHUxdFcpYwdRFzpJWxhFfJYMohZiPBKApkkCkBAXkc8L770AO9aBq3zs81oDOFLAkQYRaeBIw2dLwN1jxu1y466tx11ZyUBVJe7KKnydY8fkDNOYzRhTUjDFx2Hz+TC3tmIoL0d79Cgaj2fC63A41LFDw1WioiK8Oj07Spp4alclVUcOsaDjMKl91f7usbCYOPLWfJDsFWsor6tn8+bNbNmyhf1nLvw43DadBmu2FfsCNRCFOh0scV9OZvsizPVOFM9I9cdo0ZNaEEnagiiS82QQtRDDJABNkwQgIYLAOwjHXoLafdBWCa5KaK8G7/hdSX72eH8wUhwpeHUxuLsNuF0e3PXNDAxXjmpr1QHU49D4fNhMJuxaLZauLoz1dWgGBsZ9LaDOKlu+3F8lOpmWx5OHmnl171EyXYfJ7TqBSRlpd1zmfHJXX07W8lW0d/ewdetWtmzZwvbt2+npGTtuCMAYa/SHIXtGKEk988lsX0xqWwGGgZHZclq9hqT5EaQtcJJa6MQWZpr830uI9zEJQNMkAUiIS4TPC5314KoYCUX+xyoYmLjaA4A5zF85UkJT8Aw6GPCHIxfuKnWs0WBzc+B1ioJ5oB9rbx/W/j6s/f3oJqsQ6fVQVMTAZSvZETOfX/SE42mrJbunjKS+U2iHFhDSaHWkLVxMzurLSS9aig8Nb7zxBps3b2bz5s1UVlaOe3uDxUBIfgjWBVZCC0KJ16aT5iokzVVIWH/UyAs1EJMWyryFUcxbEEV4jAyiFnOLBKBpkgAkxCygKNDrGicYDT12N0x+vc7k71rzWhNx94fh7tKr4aihnYHqGnUgdl8fKApGtxtrX68aivp6MUy2OCPQnVvAm8Uf4onwHAzuJrK7y4hxjwQtvdlC9rKV5KxaS1J+ARqNlhMnTvi7ynbu3InX6x1zX41GQ1xOHCGFIXjne4mLSiGtbQFprgKie1ICXmt0QvrCKPKKUohOsaORDVvF+5wEoGmSACTE+4C7V60SjReQ2mvAN1mA0UBoAoojlUFdPO7+UAa69Lhb3bgb23FXn0KpqsLa04O1Tw1EJvf4XXWKVkvr0pX836KreNIYR3xvNVk9ZYQNjsz4soQ5yF29ltzVlxOVkoZGo6GtrY1t27axZcsWtm7disvlGvf+zhgnWSuyCFkQQn/MILEdmaS5CojvzEKn6PyvG7T0Y83wkrU4jmWLCzCbpKtMvP9IAJomCUBCvM95B6Hz1PiVI1cleMYfl+NnicAXmorHF8tAvx13p57Buna0RyvQV1ZhbW/HPM4YIp/JRN1lH+DpxR9hi89EZvdJMnvKMftGXutISCZvzeXkrPoAoc5otbleL2+//ba/q+zIkSPjNstkMrFs1TIyV2QSkhtKf5se66kYktpyMPpGxg25dX10xtYTkgU5C5NYlLCAWFusTLMXs54EoGmSACTEHKYo0NM8fjhqq1Sfm4zewqA5mf66CJS3XZgPHMEwznpGnhA7lcUr+e2C63jHC9ndpaT1VaNXRrq94ufnkbfmcrKWrcIcEuI/X1NTw5YtW9iyZQuvvfYa/ROsl5SXl8eHrv4QmZdloeittJUOYq51YvHY/a/xagapCyulNaaK8Gw9ecnZFEYVkhuZi0U/tS1EhLhUSACaJglAQogJDXSpXWvjBaSOWlB8ga9PuxxPTxG+5/+JYfcutON0lfWFhVFRsIQ/zF/LMb2ejN5yEvvr/VPqNTo96UVLyF11OWmLl6AftT1Ib28vr7/+Olu2bGHz5s2cOnVq3GY7HA6uvvpqrr32WpJTs6guddF2wouuMzDkNIRUUhVxhJrIo8TEO8h35pMenk5aWBrzwuYRY42RSpG4ZEkAmiYJQEKI8+L1qOOLXBVw6C9w9IWRQBS3EIq/inJiEN+vfo129240vsCwpADddjtVWYW8kF5MtdVEjOd0wD5kBouN+StWkbvqchLm56LRjiyIqCgKhw8f9oehvXv3Mt5/4rVaLStWrOAjH/kIq5ZdjrbHQemBerpPBQ66brM0UB1+jOaQappDauk0tWIz2pgXNs8fiOaFzWNe+DwSQhLQa2U9IhFcEoCmSQKQEGJGtFXBnl/Cu0/D4NCeX440WHE3xF0Bf/s7ypNPojl0aMylXq2WTnsoDXGJbE8rpC7Mho12bL5e/2usEU7y11xOzqq1OJNSxtyjubmZV155hc2bN7Nt2zY6OjrGbWZKSgrXXXcdV679MMnhedQd7+JUiQvljEloA7pemm2naA6pocVW6w9FaMCgNZASmuIPRMPhKDUsFZNOBlyLi0MC0DRJABJCzKieFti3UT36hrbNsEXBsn+DJV+Ginp4+mmUZ55BM85Grm6DgY7QUNpCw9mfnE5lpAOdvh89IzPZIpPTyF9zOfNXfoCQiMgx9/B4POzatctfHTpx4sS4TbVarVxxxRV8+KprKExbjrfDQnN1Jy113fgGx35dePQDNNtqaLRVjwlFABo0JIQkkB6ePlI5GgpIdqN9zP2EmA4JQNMkAUgIcUG4e9Rq0J4n1PFCAMYQKPoCXPZVCImDf/4Tnn4a/vY3GGeV6F6zhY6wUNpCw6h2RlAaHYXHpKBh+D/lGhLzC8lf80EylizHZB1/McTy8nJ/GNqxYweeCRZ6LCgoYPny5RQXFZOVWkCEKYHWut5JQ5HP6KErtJk6Szl15pNjQtGwKEvUmFA0L2weTotTxhmJ8yIBaJokAAkhLiivB46+CDt/Bk1H1XNaPRR8GlbeA9HzobsbXnxRDUOvvjpm81afRkO3LWQoDIVS77BTFemgxzIyDkdrMJJRvIzc1ZeTumAxOv34Y3S6urp49dVX2bx5M1u3bqWhYeJFJG02G0VFRSxdupTiomIyk/MxecNpru2eNBRpTD48EV202uuoMpzgpPE9usYJRQB2o520sDTSw9L9XWppYWnE2+LRaXVjLxBiiASgaZIAJIS4KBQFTr4Ku/4Hqt4aOZ91Nay8F1KWq7+fOgXPPgt//CMcPTrmNl6TiQ6rjQ67HVdoCPUOO6ccdnrNRv9rDDY7uSvXkLt6LXGZ8yessPh8Pt59913/itTvvvsuvjMGa58pOjqapUuXsnTpUoqKislIzGWw00BTdSfNNV0ThiK9RYMuykNPeCuN1ipK9Uco8x7Fx/jvZ9KZSA1NVatG4SODsFNCUzDqjONeI+YWCUDTJAFICHHRnfqXGoSO/x8Md2clLVMrQlnXgFarBqaDB9Ug9Oyz0NQ05jaDTictoWF0Aq5QG3UOO/XhIbgNI9UfW4STgss/RM6qtUTEJ0zarO7ubt5991327dvnP6qrq8/6cTIyMliyZIkaihYXkxKbRVejh+aarklDkcmqxxanw+fspT20gVpzKaWDR6nurMbtG3+1bZ1GR6I9caRqNNSdlhaWhs1gO2tbxfuHBKBpkgAkhAialpOw++dw6M/gHfrCd2bDyn9Xu8j0Q5UOjwe2b1fD0EsvwRkrTysaDZ6cHOrDnHR0tNFh1VMXbqcxzIZXNzJ1PjIqloIPX0vOmg9iDQufUhMbGxt55513AkJRW1vbpNfo9XoKCgpGKkWLi4kJS6b1VM+UQpEzOQRLLPRHdNBsq6XKV0plZyUVHRV0e7onfN8Ya4w/DCWEJJBgT1AfQxJkEPb7kASgaZIAJIQIuq4GePtX8M7vYWBo+ro9Di77mjpo2jzqv00dHfC//6uGoTffHHMrxWJhYPVqSsNjaWhoQjPQwmlHCC12K8pwV5gCcc4Y8i+/kvkfuR6jZeqrQCuKQnl5eUAoevfddydcoXqYzWajuLg4IBTZdBH+QHS2UBSVbCcq2Y4pVqErrIlTmiqqhkJRRXsFrf2tk76/3WgnMSSR+JB4EkISiA+JJzEk0f+z1TD+AHJx6ZIANE0SgIQQl4z+Ttj/FOxdD12n1XOmMFhyGyz7KthjAl9fWQl/+pMahsrKxt4vNpaej13PvtAEqk+WY2urpMOup8M6sleYzqeQGOogZ9lKMm/4JMaoqHNutsfj4b333guoEh09enTchRlHGz2eaOnSpSxeVAT9Jv94oqbqLlrrJw9F0Sl2opJDscRBk66Oys5KqjqrqO+up66rjvqeelz9428uO1qEOYJ4WzwJ9pFwNDosyfpGlx4JQNMkAUgIcckZHIDDf1W7x1pK1XM6Eyy8CVb8O0SmB75eUeDtt9VZZH/+M4zXRVVYSOsnPsPLEelUvvMvnC0n8Jnc9BtHttrQ+hS0gFanQ2swoDMa0ZnN6AwGNFodOp0OjU6HTqdHq9eh1erQ6vXq64ePoXP9Hg8VdfWUVp+ipKqaksoqGlvPHkSSExIoyM1hQV4uC/LzyM3KZrBfR2fLAB3NA7Q39tPRPIDi04JGA+gADRqNDqPVgDMhlKhkB5EJDsKiLYRHW8E6yOme09R113Gq+5QajrrrqO+u51T3KbrcXWdtV5Qlyh+Iho/hoBQbEotBazjrPcTMmnUBaP369fz4xz/m9OnT5OXl8bOf/YzVq1eP+9oXXniBRx99lJMnT+LxeMjMzOTrX/86N998s/81iqLw8MMPs3HjRtra2li2bBm//OUvycvLm1J7JAAJIS5ZPh+UvqxOoT+1b+ikBnI+CqvuhYSisdcMDMDWrWpVaMsWdfzQaFotyoc+RM11N/LnyDxq3niN5Ob3MGu78eou7Ho8Xf0D1LraqXG1U+vqoMbVTp97/DWJ/M3VaIgLt5McEU5SRDjJEeFE20PQas/WVgMarRU0NrR6G2ZbOLZwB/bICMJjnTgTo4lKjSUyIYpepc8fioarRnVdddT1qL/3DvZO+k5ajZZoa/SYcDT8c4w1Rqb0XwCzKgA999xz3Hzzzaxfv56VK1fy61//mt/+9rccO3aM5OTkMa/fsWMHbW1tzJ8/H6PRyObNm/n617/Oli1b+PCHPwzAj370Ix555BGeeuopsrKy+OEPf8ibb75JSUkJdvvZB71JABJCzArVe2DXz6D0lZFzqavVKfQZVwxVQ87Q2grPPaeGobffHvt8SAi+T36S9z74Mf6oS+LgoeM4m2pJ7agnrfM0yd0NhLt78KFB0aiDrX0aDej16BIT0CcnoU9IRJ8QjyYiAsXnw+fz4hscxOfz4RscxOv1ovi8eAcH8Xm9Q4f6s3dwkLrGJkoqqymprqGsppaK+tN4Br1j2zqKyaAnxRlJijOCpMhwkiLCCDMZ1Sn85/E1p9VZMZjtmEPCsIU7CI2KxBEbRXisE1uYA59VT7u+l0bF5a8kDR/13fUMeAcmvb9eoyfGFqOOObIn+LvahgOS0+JEq9FOeg8x1qwKQMuWLWPx4sVs2LDBfy4nJ4frr7+edevWTekeixcv5rrrruMHP/gBiqIQHx/Pvffeyze/+U0ABgYGiImJ4Uc/+hH/9m//dtb7SQASQswqTcdh18/hyF/BN7Q9Rky+OoU+7xOgm2CT0tJStYvs6adhvKntyckon/oUtRn57LLEsqUvhH21Xdh62slqqyWrXT1y2k9hGxi7arXWasWcm4u5oABLYQHmggIMCQnnvMqzx+PhyJEjAeOJjh07dtbxRDExMSxdupQlS5awaEEhGakphBgNdLe6cNU303a6mc6WVnra2+jv7sAz0IVvsAcmWIdoPBqtDos9zF9JsoU7sIY5wGag1+SlU99Pq66b07RQP9CoBqSeegZ9g5Pe16g1Eh8SP2aAdlxIHFGWKCItkTIGaRyzJgC53W6sVivPP/88N9xwg//8Pffcw8GDB3njjTcmvV5RFF5//XU+9rGP8dJLL/GhD32IiooK0tPTeffdd1m0aJH/tR//+McJDw/nD3/4w5j7DAwMMDBqCmlnZydJSUkSgIQQs0vHKdi7QR007R6aGh6WDCvugkWfB+MEa+L4fLBzp1oV+utfoWuC8S8mE77582lKzeZIRDL/NMSw3RBDszWc2L42stpqye08xeK+08Q3VaMbGDsLTBcergaignzM+eqj/jwGWXd1dbF//3727dvnn31WU1Nz1uuio6MpLCwMOHJycjCb1UHgg+5BmmuaaapqpLWuifbGFrpaWunpaMfd24Hi60Xx9aAoPaBMPsvtTAazBVt4ONYwB3q7Ba9VR79JocvQj0vXQ6OmjTpfMzXeBgY1k1e8QJ3F5rQ41cPsJNISSaQlcuScxUmkORKH2YFeO0EIfp+ZNQGovr6ehIQEdu3axYoVK/znH330Uf7whz9QUlIy7nUdHR0kJCQwMDCATqdj/fr13HbbbQDs3r2blStXUldXR3x8vP+a22+/nerqarZt2zbmfg899BAPP/zwuO8jAUgIMev0tcE7v1On0fc0q+csEbD0dvWwjd0sdeTaPti0SQ1D27aB9+xfxANhDmoS0tkfmsCB8GRKolI5GZlI5EAnS/obWDHYRFpLNeaaChgcW/nQx8Vhyc8fFYzy0U1huMKZGhoaxqxP1N7eftbrdDod2dnZY4JRYmJiQLXK6/HR2dpHR1Mf7U29tDV04apvpr1RrSIpvh4YCkfDQQmlR31k8orPmUwhIejsVhSrngEz9BjdtOl6adZ1UG9op9Xax6B+al/fGjQ4zI4xwejMsOS0OAk1hs7qfdhmXQDavXs3y5cv959/5JFHePrppyfcrdjn81FRUUF3dzevvfYaP/jBD3jppZdYu3atPwDV19cTFxfnv+YrX/kKtbW1vPLKK2PuJxUgIcT7kqcPDj4Lu38BbZXqOb0FFt8My+8CR8rk1zc1wZ49cPgwHDmiHqWlasVoCqodcZxwpnAiKnUoFCWRHm3jA9pW5rfXElJVhqeiYtwxOsbUVMyFBVjyCzAX5GPOyUFrNo/zLhNTFIWTJ0+yb98+9u/fz5EjRzh06BDNzc1Tuj48PDwgEC1YsIC8vDxstrGVNK/HR0dLHx3NfXQ09dLepD52NPXR1daP4nMPBaKhCpKvB0XpBV8PGk0vGm0fiq8Hr7sbRZnav685PAxTlANtZAiecAM9doU26wDN+k5aB1y09LXg6nfhm+L9APRaPZHmwGAUYY4YE5ScFucluU7SrAlA0+0CG/blL3+Z2tpatm3bdl5dYGeSMUBCiPcVnxeOb1Jnjp0+qJ7T6CD/E+o4odiCqd+rrw+OH1fD0OhgNMkGqqP1642URSZxIiqNk7GpGHOySU+JIlvXg72qjP733sNz6tTYC/V6TJmZQ5WifCwFBZgyM9FMsMHrZBobGzl8+HDAcezYMdzu8bfaGE2j0ZCRkTGmWpSamopWO/6g5UGPl86W/pFg5A9JvXS3Dfh3PgE1tKH0D1WRetDp+zFZ3BiM/Wg0fXg9nfS0NzLQ0zFhG/VGE464eCLiEwmPi8cY7QCHhf5QLe1KFy19Lf6jta9VfexvpWNg4nuOx6K3BISl4YpSpCUSp9kZcP5i7dU2awIQqIOgi4qKWL9+vf9cbm4uH//4x6c8CPpLX/oS5eXl7Nixwz8I+r777uM///M/ATVoRUdHyyBoIcTcpihQ+aY6c6z89ZHz6VeoQShtzfgzx6aiuXkkDA2Ho6NHoXfy6eLDWqxhVMam0ZudS2j+fOITItD63PSXlNL33nt4W1rGXKMxmzHn5PgDkTk/H2NKCpoJgshkPB4PJSUlY4JRXV3dlK4PCQmhoKAgIBQVFBQQFhY26XWDHi+dzf20D1WLOppHqkfdbRPPJFN8/Si+NhSvC62uA2jDN+hisN+FokzcbRkS6SQiPpGI+AQi4hNxxCcSEZ+IPdKJx+fB1e+aMCCNPt832Delf5dhocbQkS63ofFKy+OXsyZxzTnd52xmVQAangb/q1/9iuXLl7Nx40Z+85vfcPToUVJSUrjllltISEjwh6F169ZRXFxMeno6brebrVu38s1vfpMNGzbw5S9/GVCnwa9bt44nn3ySzMxMHn30UXbs2CHT4IUQYtjpQ+rMsaMvwHAXSfwidQp9zkdhJtao8fmgomJstaisbEpT030aDW1xyfjy8gnNy8IbYqPP46G7/jT9x47h6x67B5jWbsecn4eloNAfjPQxMec9rqW1tZUjR44EhKL33nuPvr6pBYCUlBR/99lwMMrIyECnO/u/76Dbq3arNQ2NO2rupaulj95OD71dbvq73GP+GRXFh+LrQPG2ofhcKF4XvqGghDJxm3V6EyERMYTHJhCRkEh0SjJRqclExCdgMI3teuz19KrhqL9lTGAaDk3Dz0004+1L+V/i3qJ7z/rvcC5mVQACdSHExx57jNOnT5Ofn8/jjz/OmjVqKly7di2pqak89dRTAHz3u9/lueee49SpU1gsFubPn88999zDZz7zGf/9hhdC/PWvfx2wEGJ+fv6U2iMBSAgxZ7RVwZ5fwrtPw/D/q4+YByvuhgX/DwznNu5mSnp74dixgGqRcuQImnF2tx+Pz2xBk5eHb14a7tBQ+nwK3a2t9FZWoozTjaWLcmLOno8+MgJdeDi68HC0YWHoh37WhYejCwtDFx6Oxmo9a1jyer2Ul5f7A9GhQ4c4fPgwVVVVU2q/2WwmPz9/TDdaZOQkg9PHofgU+ns89Ha66ety09vlpm8oHPV1us949DDo7kHxteHzukYFpDYUXzuTTf3XGcIw2aKwhsdgj4wjPCaeyMQkHHHR2MJMWOxGzPTNbh8AAB25SURBVCGGcReiVBSFTnfnSCgaPvpbuCz2MlYkrBjnHc/frAtAlxoJQEKIOaenBfZtVI++oW0zbNGw5MuQdz04s86/e2yqGhv9oWjgwCH69h/EVnYCg2fyRQWHKTEx+ObNw+OIoF+npbuzi+7GxrOuFzSaxmBAGz4UjsLC0TkCw5J2KCjpz/hZYzTS0dHBe++9N6YbrXucStV44uPjx4Si7OxsjMbpj59RFAV3vzcgGPV1uentdNPT0U9HcwNdLafpbW9koKeZQXcris91lqn+BjS6CDQ6B1pdBCarE5sjlpCIWGzhNqyhRqyhRix2Axa7ceT3ECM6w4VZ5FEC0DRJABJCzFnuHrUatOcJ6KgdOR8xD7KvhexrIOmyiRdXnGleL8rJkzTu+hcNO9/Gd/gIkZWlJLlOo+XsX1+KVouSlMRgXByDsbG4IyLoDwlh0OvF296Bt6NdfWxvRzlzi5BzoLVa0YaPDUea0FBOe70cb23lWGMjx2prea+8nJNVVVMKZgaDgZycHH8XWkFBAdnZ2SQlJU2pG+18Dbq99Ha5aTvdSnN1La11tbQ31tPdeprejkbcvS4mqxpptKFotI6hgBSBRquGJDQ2NBoNJquewssTWfrReTPabglA0yQBSAgx53k9cPRFOPycOnDaO6pryRwOWR9Ww1D6FWC+uP+ddA/6OFxSR8lre2l7+11sJUfJbq4mu7mKyL7Oqd0kOhoWLoRFi2DhQpSFC1Hi4/F2d+Ntbx85OjpG/d4x9nxn55SXBRit1+fjpNvNSY2GEp+X0r4+TnR20jEwtWqX0WgkPT2drKwsMjMz/Y+ZmZnEx8df8LV8vIMe2hsbcNWfwnXqFM01NbjqTtHeWI+nf+yq4H4aoz8YZV+2gmvvvGHi154HCUDTJAFICCFGGehSZ42VvAyl26Bv1A7uWgOkrR6pDoUlXvTmdfR62F3ewpulzRw9UEpY2XGym6uY31zN/OYqMltrMA1Oobpjs0FhYUAwoqAAJll/SPH58HV2BgaliULTqOd8PWNDgqIoNA4OUjIwQOnQUTLQT6XbzdmXoxxhNRqZFxNDRmISGakpZKRnkDU/m6z8fGJSUtDZ7WguUPVIURT6ujpx1dXiqq/DVX+KtvpTuOpP0dHYGLDG0aKrP8EHv3jbjL6/BKBpkgAkhBAT8A6qu9CXbIUTW8FVHvh8bOFIGIpbcOHHDZ1BURSqW3t562QLb5U2s6e8ld6+AdJcdeQ2VZDbWEFxWzU5DeXYus6+SjQ6HcyfPxKIhh8jIqbXTrcbb2fnlEJTr8tF6enTHG9upqynh2qPm2q3mxqPB/c5foWHarWkGI2kWKykhYUyzxHBvOho0uPiCI9yorOHorWHqI+hdnR2O1q7HV1o6MjPdjua8xiXNOjx0NF4GledGogScvJInJ93zveZjASgaZIAJIQQU9RSpoahkpehZi8Bq/qFJkDW1WogSlsN+ou/eeeg18ehU+28VdbCzrIWDtS24/UpoCjEdrWS31zBB/vqWdJeTVJNKebacTaFHU9ycmAgWrRIPXcBA5+iKCj9/Xi7uvB1deFua6O2spLSkhJOVlRwsqaG8rp6KpoaqW5rw3uOX+8ROh2pRiPJBiOpRiMpRgMpBiPJRiPWM9ZW0pjN/qCks9vRhoais4egtYeiC7Wrj6N/D7GPnA+1ozGbL0g3nQSgaZIAJIQQ56GnRe0iK9mqdpl5Ri2CaAyBjCvUMJR5FVinV0E5X139HvZWuNhZ1sxbJ1uoaA7sior19XG9tpW1fXXkNpRjLzmK5ujRcfcwG8PhUMPQ6GA0fz4YDBfo00zM4/FQVVVFWVkZpaWllJWV+X+uqak5p5lxADEmEykGIyk6HSlGgxqQDEaSDAaM57HwJHo9kV/6EtH3zfF1gC41EoCEEGKaPP3q4Onh6lD3qK0yNFpIXq52k2VfC5HpQWtmfXsfO8taeOtkC7tOtuDqCVxHKDbUzJqUUK7Ruihuq8J+4igcOAAHD8JUprebTJCfH1gpKiyEkJAL9InOrr+/n/Ly8oBQNPxzfX39Od1Lq9WSHB3NvNhY5jmdpIWHk2oLIdViIV6rQdPTq46RGqpaebu6/BvsOu+6i6i77pzRzyYBaJokAAkhxAzy+dQ9yEpeVo/GI4HPO7NGwlDikplZhfq8mqlw7HQnO0+q3WX7qly4BwNneM2PtbM608mq9EiW+doxHzsyEogOHIDTp8/+RhoNZGaO7UKLiblAn2zquru7OXny5JiqUVlZGS3jbEcyGYPBwLx58/yz07KyssjIyCAzKYlYux291YouPHxG2y8BaJokAAkhxAXUXgMlr0DJFqjaCaO3SrBGjowbSr8cjGN3Xr9Y+j1e3qlyqRWishaOnQ6cYm/UaSlOdbAq08nqjCjy4kPRNjepYWg4EB08CKWlU9r6g9jYsYOt09PhfLqYLoC2trZxq0alpaV0dk5x+YEhZrOZrKws9u/fj/48NrSdiASgaZIAJIQQF0l/B5x8Va0Mlf1D/X2YzgTz1qrVoayrITQuWK0EoKV7gF1DXWU7y1qo7whcJdlhNbAiw8nqDCerMp0kOqzqE93d6grXoytFR47AVNb8CQmBBQtGAtGCBWoocjguwCc8P4qi0NzcPG7VqKysbMJ901JSUqa8fchUSQCaJglAQggRBF4P1OxRw9CJLdB+xoys+MUjU+xj8i76FPvRFEWhoqXHXx3aW9FK90DgQOk0p41VQ2FoeXokoeZRg6EHB+HEicBK0YED0NY2tQaEhUFq6sTHDHctnS+fz0d9ff2YYFRaWkp6ejqbN2+e0feTADRNEoCEECLIFAWaT4wMoj71TuDz4ckjYShlJegu/kyr0TxeH4dqh6bbn2zh4PB0+yE6rYYFiWGsyoxidaaThUnhGHRndG0pCtTWBgaigweheopT80ebBQFJUZQZnwovAWiaJAAJIcQlpqsRSl9Rw1DFP2FwVPeTKQwyr1QDUcaVYAn+l3tnv4e95a3+AdUVLYHT7UNMei6bF+GvEKVHhUwcBlwuOHRIDURHj6qBqKpKfZzK9PzxzIKAdD4kAE2TBCAhhLiEuXuhYodaHSp9BXqaR57T6iFlxUh1yJEarFYGqGvvU9ceKlPHELX1Bm7NERdmZmWGk9WZTlZmOHGGTGHRSK8X6uvVMDTeUVNz/gEpPHzygBQWdn73vcAkAE2TBCAhhJglfD6o2z/SVdZ8PPD56Fw1CM2/Th1DFMRxQ8OGp9ur3WXNvFPVNma6fU5cqDrdPsPJ0rQIzIbzWBpgDgYkCUDTJAFICCFmKVfF0BT7rVC9G5RR24hG50LRF6Hw05dEN9mwfo+XfZUudp5UB1QfP3O6vV7LklQHqzLU8UO5caFotTMQ5N6HAUkC0DRJABJCiPeBXpc6xf7EFnWLjsGh6dh6C+R/Qg1DicWXRFVotOauAXaXt/j3L2voDJxuH241sCwtghXpTlakR5IRPcn4oekYHDx7QPKeyz71ozgc6nT+fftm9N9fAtA0SQASQoj3mb52OPxX2P8kNB0bOR+TD0VfUKtC5ktvXIuiKJQ3d/vHDu0pb6XHHRg6nCEmlqdHsiI9kuXzIkmJtF6YQHSm6QaklBT1dTNIAtA0SQASQoj3KUWB2n2w/yk4+sLIbDKDdagqdBskXBpjhcbj8fo4UtfBnvJW9pS38q9qF/2ewPFD8WFmlqc7/aEoPtwSnMaeLSDNmwevvjqjbykBaJokAAkhxBzQ1waHnlOrQs0nRs7HFqhVoYJPg/nS/g4YGPRysKad3eWt7Klo5UBNGx5v4Nd6SqRVrQ6lO1k+L5Io+xRmmF0MijLjQVMC0DRJABJCiDlEUaBm71BV6EXwDm1RYbBBwY3qWKGExUFt4lT1ub38q9rFnvJWdpe3cqSuI2BBRoDM6JChQBTJZfMiCbcag9TamScBaJokAAkhxBzV64JDf1GrQi2lI+fjFgxVhT4FJnvQmneuuvo9vFPlYvdJtUJ07HRnwL6sGg3kxoWyfF4kKzIiWZIagd0c3FW1p0MC0DRJABJCiDlOUdR9yf71JBz7+0hVyBgCBZ9Uq0LxC4PbxvPQ1uPm7cpWf4WorKk74HmdVkNBQpi/QlScEoHFeB5rEAWJBKBpkgAkhBDCr9cFB59Vu8hay0bOxy9Sq0L5nwRTSLBaNy1NXf3srXCxp1ydYVbV2hvwvEGnYVGyQ60QpUeyMDkck/7SDUQSgKZJApAQQogxFAWqd6lVoeObwOtWzxvtUPgpNQzFLQhqE6errr3PP8NsT3kL9R2BaxCZDVqKUyL8M8wKEsLQn7mpaxBJAJomCUBCCCEm1dMKB/+kVoVc5SPn4xdD8Rch/0Yw2oLWvJmgKArVrb3sqVC7y/aUt9DS7Q54TYhJz9K0CFYMDaiesVWqz5MEoGmSACSEEGJKFAWq3hqqCv0f+IY2OTWFqosrFn1BnVb/PqAoCiebuofCkDqouqMvcFPXcKuBy9Ii/RWiC7ZK9QQkAE2TBCAhhBDnrLsZDg2NFXJVjJxPKFarQnmfAKM1aM2bacObuu4dqhDtq3TRPRC4d9jFXqVaAtA0SQASQghx3nw+qHpTrQqd2Ay+oVBgClOrQsVfhJi84LbxAhgcWqV69xRXqV6ZEUlc2MyuUi0BaJokAAkhhJgR3U0jY4XaqkbOJy4dqgrdAIYgbVVxgQ2vUj08hujMVao/U5zEjz5ZOKPvKQFomiQACSGEmFE+H1TuUKtCJVtHqkLmMCj8rBqGonOC2sQLrc/tZX91G7vLW9hd3sqXVqXx0QXxM/oeEoCmSQKQEEKIC6arEQ4+o1aF2mtGziddpgah3I+/b6tCF5oEoGmSACSEEOKC8/mg4vWhqtDLoHjV8+ZwWHCTGoaisoPbxlnmXL6/g7560fr160lLS8NsNlNUVMRbb7014Wt/85vfsHr1ahwOBw6HgyuvvJJ9+/YFvKa7u5u77rqLxMRELBYLOTk5bNiw4UJ/DCGEEOLcaLWQcSV89k9w/zH44HchLBn62+HtDfDLpfD7a9Qd6z39Z7+fOCdBDUDPPfcc9957L9/5znc4cOAAq1ev5pprrqGmpmbc1+/YsYObbrqJf/7zn+zZs4fk5GSuuuoq6urq/K+57777eOWVV3jmmWc4fvw49913H3fffTd///vfL9bHEkIIIc6NPRbWfAPuOQif+1/Ivg40OqjZDS/eDj+dD698G5qOg3TczIigdoEtW7aMxYsXB1RocnJyuP7661m3bt1Zr/d6vTgcDp544gluueUWAPLz8/nMZz7Dgw8+6H9dUVER1157LT/4wQ+m1C7pAhNCCBF0nfVw4BnY/wfoPDVy3mADZ6baPebMGnrMhog00M3endxnwrl8f+svUpvGcLvd7N+/nwceeCDg/FVXXcXu3bundI/e3l48Hg8RERH+c6tWrWLTpk3cdtttxMfHs2PHDkpLS/mf//mfCe8zMDDAwMCA//fOzs5z/DRCCCHEDAuNhw/8J6z+Opx8VR0rdPJV8PTA6YPqMZpWDxHpo8JRNkRlqSFplm/LcSEELQC1tLTg9XqJiYkJOB8TE0NDQ8OU7vHAAw+QkJDAlVde6T/385//nK985SskJiai1+vRarX89re/ZdWqVRPeZ926dTz88MPn90GEEEKIC0mrg6wPq4fXA65KaCmB5hJoKR16LFODUUuJepzYHHiPsKRR1aLMoXCUDTZncD7TJSBoAWjYmUtiK4oypWWyH3vsMf785z+zY8cOzGaz//zPf/5z9u7dy6ZNm0hJSeHNN9/ka1/7GnFxcQFBabRvfetb3H///f7fOzs7SUpKOs9PJIQQQlwgOoNa1YnKgpyPjpz3+aCr/oxQNPTY2wIdtepR/lrg/SwRY7vSnJlqYNIGfZ7UBRW0AOR0OtHpdGOqPU1NTWOqQmf6yU9+wqOPPsqrr75KYeHIKpJ9fX18+9vf5sUXX+S6664DoLCwkIMHD/KTn/xkwgBkMpkwmUzT/ERCCCFEkGi1EJaoHhlXBD7X6xobilpKoL0W+lxQs0c9RjNYITLjjK60bIiYB3rjxftcF1DQApDRaKSoqIjt27dzww03+M9v376dj3/84xNe9+Mf/5gf/vCHbNu2jeLi4oDnPB4PHo8H7RmpVafT4fMF7kcihBBCzAnWCEi+TD1Gc/dCa5nafTYcippLofUkeHqh4bB6jKbRqYOtR4ei4XFGJvvF+0wzIKhdYPfffz8333wzxcXFLF++nI0bN1JTU8Mdd9wBwC233EJCQoJ/Rthjjz3Ggw8+yLPPPktqaqq/ehQSEkJISAihoaF84AMf4Bvf+AYWi4WUlBTeeOMN/vjHP/LTn/40aJ9TCCGEuOQYrRC3QD1G8w6q+5a1DFeMSkfCkbtLDUitJ6FkS+B1oQmjxhdljRpnFAUXcAf48xX0laDXr1/PY489xunTp8nPz+fxxx9nzZo1AKxdu5bU1FSeeuopAFJTU6murh5zj+9973s89NBDADQ0NPCtb32Lf/zjH7hcLlJSUrj99tu57777pjS2CGQavBBCCDGGokDX6ZGutNHdat2NE19nDh87+NqZBeHJ6gDvGSRbYUyTBCAhhBDiHPS1BXalDf/cVgVMEDOKvggf/dmMNmNWrAMkhBBCiPcJiwOSlqrHaJ5+tbtsuAttOBy1lKmDrINIApAQQgghLgyDGWLz1WM0n1dd0yiIJAAJIYQQ4uLS6mZ8/M85NyGo7y6EEEIIEQQSgIQQQggx50gAEkIIIcScIwFICCGEEHOOBCAhhBBCzDkSgIQQQggx50gAEkIIIcScIwFICCGEEHOOBCAhhBBCzDkSgIQQQggx50gAEkIIIcScIwFICCGEEHOOBCAhhBBCzDmyG/w4FEUBoLOzM8gtEUIIIcRUDX9vD3+PT0YC0Di6uroASEpKCnJLhBBCCHGuurq6CAsLm/Q1GmUqMWmO8fl81NfXY7fb0Wg0M3rvzs5OkpKSqK2tJTQ0dEbvLc6d/D0uLfL3uLTI3+PSIn+Ps1MUha6uLuLj49FqJx/lIxWgcWi1WhITEy/oe4SGhsr/gC8h8ve4tMjf49Iif49Li/w9Jne2ys8wGQQthBBCiDlHApAQQggh5hzdQw899FCwGzHX6HQ61q5di14vPZCXAvl7XFrk73Fpkb/HpUX+HjNHBkELIYQQYs6RLjAhhBBCzDkSgIQQQggx50gAEkIIIcScIwFICCGEEHOOBKCLaP369aSlpWE2mykqKuKtt94KdpPmpHXr1rFkyRLsdjvR0dFcf/31lJSUBLtZYsi6devQaDTce++9wW7KnFZXV8fnP/95IiMjsVqtLFy4kP379we7WXPS4OAg3/3ud0lLS8NisTBv3jy+//3v4/P5gt20WU0C0EXy3HPPce+99/Kd73yHAwcOsHr1aq655hpqamqC3bQ554033uDOO+9k7969bN++ncHBQa666ip6enqC3bQ575133mHjxo0UFhYGuylzWltbGytXrsRgMPDyyy9z7Ngx/vu//5vw8PBgN21O+tGPfsSvfvUrnnjiCY4fP85jjz3Gj3/8Y37xi18Eu2mzmkyDv0iWLVvG4sWL2bBhg/9cTk4O119/PevWrQtiy0RzczPR0dG88cYbrFmzJtjNmbO6u7tZvHgx69ev54c//CELFy7kZz/7WbCbNSc98MAD7Nq1S6rUl4iPfOQjxMTE8Lvf/c5/7sYbb8RqtfL0008HsWWzm1SALgK3283+/fu56qqrAs5fddVV7N69O0itEsM6OjoAiIiICHJL5rY777yT6667jiuvvDLYTZnzNm3aRHFxMZ/61KeIjo5m0aJF/OY3vwl2s+asVatW8dprr1FaWgrAoUOH2LlzJ9dee22QWza7yVKSF0FLSwter5eYmJiA8zExMTQ0NASpVQLUnYPvv/9+Vq1aRX5+frCbM2f95S9/Yf/+/fzrX/8KdlMEUFFRwYYNG7j//vv59re/zb59+/j3f/93TCYTt9xyS7CbN+d885vfpKOjg/nz56PT6fB6vTzyyCPcdNNNwW7arCYB6CLSaDQBvyuKMuacuLjuuusuDh8+zM6dO4PdlDmrtraWe+65h3/84x+YzeZgN0cAPp+P4uJiHn30UQAWLVrE0aNH2bBhgwSgIHjuued45plnePbZZ8nLy+PgwYPce++9xMfHc+uttwa7ebOWBKCLwOl0otPpxlR7mpqaxlSFxMVz9913s2nTJt58800SExOD3Zw5a//+/TQ1NVFUVOQ/5/V6efPNN3niiScYGBhAp9MFsYVzT1xcHLm5uQHncnJy+Nvf/hakFs1t3/jGN3jggQf47Gc/C0BBQQHV1dWsW7dOAtA0yBigi8BoNFJUVMT27dsDzm/fvp0VK1YEqVVzl6Io3HXXXbzwwgu8/vrrpKWlBbtJc9oVV1zBkSNHOHjwoP8oLi7mc5/7HAcPHpTwEwQrV64cszREaWkpKSkpQWrR3Nbb24tWG/h1rdPpZBr8NEkF6CK5//77ufnmmykuLmb58uVs3LiRmpoa7rjjjmA3bc658847efbZZ/n73/+O3W73V+bCwsKwWCxBbt3cY7fbx4y/stlsREZGyrisILnvvvtYsWIFjz76KJ/+9KfZt28fGzduZOPGjcFu2pz00Y9+lEceeYTk5GTy8vI4cOAAP/3pT7ntttuC3bRZTabBX0Tr16/nscce4/Tp0+Tn5/P444/LtOsgmGjc1ZNPPskXvvCFi9sYMa61a9fKNPgg27x5M9/61rcoKysjLS2N+++/n6985SvBbtac1NXVxYMPPsiLL75IU1MT8fHx3HTTTfzXf/0XRqMx2M2btSQACSGEEGLOkTFAQgghhJhzJAAJIYQQYs6RACSEEEKIOUcCkBBCCCHmHAlAQgghhJhzJAAJIYQQYs6RACSEEEKIOUcCkBBCTIFGo+Gll14KdjOEEDNEApAQ4pL3hS98AY1GM+a4+uqrg900IcQsJXuBCSFmhauvvponn3wy4JzJZApSa4QQs51UgIQQs4LJZCI2NjbgcDgcgNo9tWHDBq655hosFgtpaWk8//zzAdcfOXKED37wg1gsFiIjI7n99tvp7u4OeM3vf/978vLyMJlMxMXFcddddwU839LSwg033IDVaiUzM5NNmzZd2A8thLhgJAAJId4XHnzwQW688UYOHTrE5z//eW666SaOHz8OQG9vL1dffTUOh4N33nmH559/nldffTUg4GzYsIE777yT22+/nSNHjrBp0yYyMjIC3uPhhx/m05/+NIcPH+baa6/lc5/7HC6X66J+TiHEDFGEEOISd+uttyo6nU6x2WwBx/e//31FURQFUO64446Aa5YtW6Z89atfVRRFUTZu3Kg4HA6lu7vb//yWLVsUrVarNDQ0KIqiKPHx8cp3vvOdCdsAKN/97nf9v3d3dysajUZ5+eWXZ+xzCiEuHhkDJISYFS6//HI2bNgQcC4iIsL/8/LlywOeW758OQcPHgTg+PHjLFiwAJvN5n9+5cqV+Hw+SkpK0Gg01NfXc8UVV0zahsLCQv/PNpsNu91OU1PTeX8mIUTwSAASQswKNpttTJfU2Wg0GgAURfH/PN5rLBbLlO5nMBjGXOvz+c6pTUKIS4OMARJCvC/s3bt3zO/z588HIDc3l4MHD9LT0+N/fteuXWi1WrKysrDb7aSmpvLaa69d1DYLIYJHKkBCiFlhYGCAhoaGgHN6vR6n0wnA888/T3FxMatWreJPf/oT+/bt43e/+x0An/vc5/je977HrbfeykMPPURzczN33303N998MzExMQA89NBD3HHHHURHR3PNNdfQ1dXFrl27uPvuuy/uBxVCXBQSgIQQs8Irr7xCXFxcwLns7GxOnDgBqDO0/vKXv/C1r32N2NhY/vSnP5GbmwuA1Wpl27Zt3HPPPSxZsgSr1cqNN97IT3/6U/+9br31Vvr7+3n88cf5j//4D5xOJ5/85Ccv3gcUQlxUGkVRlGA3QgghpkOj0fDiiy9y/fXXB7spQohZQsYACSGEEGLOkQAkhBBCiDlHxgAJIWY96ckXQpwrqQAJIYQQYs6RACSEEEKIOUcCkBBCCCHmHAlAQgghhJhzJAAJIYQQYs6RACSEEEKIOUcCkBBCCCHmHAlAQgghhJhzJAAJIYQQYs75/zkJS8+Zur0gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_dim = 10\n",
    "\n",
    "# Define a custom scaling function\n",
    "def scale(x):\n",
    "    mean = K.mean(x)\n",
    "    std = K.std(x)\n",
    "    return (x - mean) / std\n",
    "\n",
    "# Create K-fold cross-validator\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store training and validation loss for each fold\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "# Loop over each fold\n",
    "for fold, (train_index, val_index) in enumerate(kfold.split(X_train_resampled_final, y_train_resampled_final)):\n",
    "    print(f'Fold {fold + 1}...')\n",
    "    \n",
    "    # Split data into training and validation sets for this fold\n",
    "    X_train_fold = X_train_resampled_final.iloc[train_index]\n",
    "    y_train_fold = y_train_resampled_final.iloc[train_index]\n",
    "    X_val_fold = X_train_resampled_final.iloc[val_index]\n",
    "    y_val_fold = y_train_resampled_final.iloc[val_index]\n",
    "    \n",
    "    # Create model\n",
    "    model_new = Sequential()\n",
    "    model_new.add(Lambda(scale, input_shape=(input_dim,)))\n",
    "    model_new.add(Dense(32, activation='tanh', kernel_regularizer=regularizers.l1(0.000811)))\n",
    "    model_new.add(Dense(1, activation='sigmoid'))\n",
    "    opt_new = Adam(lr=0.00033)\n",
    "    model_new.compile(loss='binary_crossentropy', optimizer=opt_new, metrics=['accuracy'])\n",
    "    \n",
    "    # Train model on this fold's training data\n",
    "    history = model_new.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, verbose=1, validation_data=(X_val_fold, y_val_fold))\n",
    "    \n",
    "    # Append this fold's training and validation loss to the lists\n",
    "    train_loss.append(history.history['loss'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    \n",
    "    # Plot this fold's training and validation loss\n",
    "    plt.plot(history.history['loss'], label=f'Fold {fold + 1} Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label=f'Fold {fold + 1} Validation Loss')\n",
    "    \n",
    "# Plot the average training and validation loss across all folds\n",
    "plt.plot(np.mean(train_loss, axis=0), label='Average Training Loss', color='black', linewidth=2)\n",
    "plt.plot(np.mean(val_loss, axis=0), label='Average Validation Loss', color='red', linewidth=2)\n",
    "\n",
    "# Add labels and legend to the plot\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Across Folds')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25681a",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0434abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.save('pre_trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1efac9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "pre_trained_model = load_model('pretrained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f56a0a0",
   "metadata": {},
   "source": [
    "## Extract learnt weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3afa61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_weights = pre_trained_model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9984974",
   "metadata": {},
   "source": [
    "## Transfer learnt weights to the new CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9349452",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.layers[0].set_weights(cnn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765efa8",
   "metadata": {},
   "source": [
    "## Create LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41d4fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "\n",
    "# Define LSTM model\n",
    "LSTM_model = Sequential()\n",
    "LSTM_model.add(LSTM(units=50, return_sequences=True, dropout=0.2, recurrent_dropout=0.2,input_shape=(X_train_resampled_final.shape[1], 1))\n",
    "        )\n",
    "# Add drop out layer\n",
    "LSTM_model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "LSTM_model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a9f9d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAB9FE0798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAB9FE0798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAB9FE0798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13618/13618 [==============================] - 262s 19ms/step - loss: 0.2595 - accuracy: 0.8399\n",
      "Epoch 2/10\n",
      "13618/13618 [==============================] - 259s 19ms/step - loss: 0.2193 - accuracy: 0.8547\n",
      "Epoch 3/10\n",
      "13618/13618 [==============================] - 261s 19ms/step - loss: 0.2171 - accuracy: 0.8558\n",
      "Epoch 4/10\n",
      "13618/13618 [==============================] - 402s 30ms/step - loss: 0.2165 - accuracy: 0.8558\n",
      "Epoch 5/10\n",
      "13618/13618 [==============================] - 412s 30ms/step - loss: 0.2157 - accuracy: 0.8567\n",
      "Epoch 6/10\n",
      "13618/13618 [==============================] - 424s 31ms/step - loss: 0.2154 - accuracy: 0.8566\n",
      "Epoch 7/10\n",
      "13618/13618 [==============================] - 5615s 412ms/step - loss: 0.2149 - accuracy: 0.8569\n",
      "Epoch 8/10\n",
      "13618/13618 [==============================] - 287s 21ms/step - loss: 0.2148 - accuracy: 0.8573\n",
      "Epoch 9/10\n",
      "13618/13618 [==============================] - 1422s 104ms/step - loss: 0.2149 - accuracy: 0.8572\n",
      "Epoch 10/10\n",
      "13618/13618 [==============================] - 267s 20ms/step - loss: 0.2150 - accuracy: 0.8576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eab9fd6d08>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.fit(X_train_resampled_final, y_train_resampled_final, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "610752f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23512\\2809969009.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "score = LSTM_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1dd046",
   "metadata": {},
   "source": [
    "# New steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a041765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-train CNN model\n",
    "pretrained_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "pretrained_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "pretrained_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Transfer learning to create new CNN\n",
    "new_cnn = Sequential(pretrained_cnn.layers[:-2])\n",
    "for layer in new_cnn.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "# The TimeDistributed layer is used to apply the same CNN layers to every time step of the input sequence. The output of this layer is \n",
    "# then passed to an LSTM layer, which is followed by a Dense layer with a softmax activation function to predict the class labels.\n",
    "# Add RNN layers to create CNN-RNN model\n",
    "cnn_rnn = Sequential([\n",
    "    TimeDistributed(new_cnn, input_shape=input_shape),\n",
    "    LSTM(64),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Train CNN-RNN model\n",
    "cnn_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_rnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Thaw CNN model\n",
    "for layer in new_cnn.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add attention layer\n",
    "attention = Sequential([\n",
    "    Dense(1, activation='tanh'),\n",
    "    Flatten(),\n",
    "    Activation('softmax')\n",
    "])\n",
    "cnn_rnn_attention = Sequential([\n",
    "    TimeDistributed(new_cnn, input_shape=input_shape),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    TimeDistributed(attention),\n",
    "    Dot(axes=1),\n",
    "    Flatten(),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Train CNN-RNN-Attention model\n",
    "cnn_rnn_attention.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_rnn_attention.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e600620a",
   "metadata": {},
   "source": [
    "## Soidisant feature fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab87643",
   "metadata": {},
   "source": [
    "https://www.bing.com/videos/search?&q=feature+fusion+deep+learning&docid=603484746686478091&mid=ED175C063F17E1FDCFCEED175C063F17E1FDCFCE&view=detail&FORM=VDRVRV&rvsmid=083DA2472C6F7DD33EE1083DA2472C6F7DD33EE1&ajaxhist=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67aeb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "# Pre-train CNN model\n",
    "pretrained_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "pretrained_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "pretrained_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Transfer learning to create new CNN\n",
    "new_cnn = Sequential(pretrained_cnn.layers[:-2])\n",
    "for layer in new_cnn.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add RNN layers to create CNN-RNN model\n",
    "cnn_rnn = Sequential([\n",
    "    TimeDistributed(new_cnn, input_shape=input_shape),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "# Add merge layer\n",
    "merged = concatenate([cnn_rnn.output, new_cnn.output])\n",
    "\n",
    "# Add dense layer for classification\n",
    "output_layer = Dense(num_classes, activation='softmax')(merged)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[cnn_rnn.input, new_cnn.input], outputs=output_layer)\n",
    "\n",
    "# Train model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, validation_data=([x_test, x_test], y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce39c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the objective function\n",
    "def objective_function(X, y):\n",
    "    # Initialize theta with zeros\n",
    "    n_features = X.shape[1]\n",
    "    theta = np.zeros(n_features)\n",
    "    \n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    J = -1/m * np.sum(y*np.log(h) + (1-y)*np.log(1-h))\n",
    "    return J\n",
    "\n",
    "# Define the MBOA function\n",
    "def MBOA(dim, maxiter, Bf, c, a, p, x,y):\n",
    "    # Initialization\n",
    "\n",
    "    n = len(df.columns)\n",
    "    X = np.random.rand(n, dim)\n",
    "    I = np.zeros(n)\n",
    "    F = np.zeros(n)\n",
    "\n",
    "    # Step 1: Set the initial generation/iteration number G=0\n",
    "    G = 0\n",
    "\n",
    "    # Step 2: Generate initial population of n butterflies  = (i=1,2,..,n)\n",
    "\n",
    "    # define the size of the population\n",
    "    n = 10000\n",
    "\n",
    "    # extract the variables of interest\n",
    "    variables = X_train_resampled_final.iloc[:, :dim]\n",
    "\n",
    "    # define the ranges for each variable\n",
    "    ranges = [(0, 10000)]*dim\n",
    "\n",
    "    # generate the initial population\n",
    "    population = []\n",
    "    for i in range(n):\n",
    "        butterfly = []\n",
    "        for j in range(variables.shape[0]):\n",
    "            var_range = ranges[j]\n",
    "            var_value = np.random.uniform(var_range[0], var_range[1])\n",
    "            butterfly.append(var_value)\n",
    "        population.append(butterfly)\n",
    "\n",
    "\n",
    "    # Main loop\n",
    "    while G < maxiter:\n",
    "        # Calculate stimulus intensity for each butterfly\n",
    "        for i in range(Bf):\n",
    "            I[i] = objective_function(X[:, i], y)\n",
    "            F[i] = c * I[i]**a\n",
    "\n",
    "        # Find the best butterfly\n",
    "        best_butterfly = X[:, np.argmin(I)]\n",
    "\n",
    "        # Update each butterfly in the population\n",
    "        for i in range(n):\n",
    "            r = np.random.rand()\n",
    "            if r < p:\n",
    "                # Move towards the best butterfly\n",
    "                X[:, i] += np.random.rand(dim) * (best_butterfly - X[:, i])\n",
    "                # Determine mutual relationship vector and update butterfly positions\n",
    "                j = np.random.randint(n)\n",
    "                if i != j:\n",
    "                    MutualVector = (X[:, i] - X[:, j]) / np.linalg.norm(X[:, i] - X[:, j])\n",
    "                    X[:, i] += np.random.rand(dim) * MutualVector\n",
    "                    X[:, j] += np.random.rand(dim) * MutualVector\n",
    "                   # Calculate fitness value of the new butterfly\n",
    "                    I[i] = fitness(X[:, i], fun)\n",
    "                    # Update the best butterfly if a new one is found\n",
    "                    if I[i] < best_fitness:\n",
    "                        best_butterfly = X[:, i]\n",
    "                        best_fitness = I[i]\n",
    "\n",
    "                    # Update the mutation probability\n",
    "                    p = p * alpha\n",
    "\n",
    "                    # Store the best fitness value of this iteration\n",
    "                    best_fitness_values.append(best_fitness)\n",
    "\n",
    "\n",
    "    # Return the best butterfly and its fitness value\n",
    "    return best_butterfly, best_fitness, best_fitness_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b439111",
   "metadata": {},
   "source": [
    "## Freeze layer in NEW CNN (DO NOT FREEZE IN PRE-TRAINED CNN): To be done b4 training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers in the pre-trained model\n",
    "for layer in model_new.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a72a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the objective function\n",
    "def objective_function(X, y):\n",
    "    # Initialize theta with zeros\n",
    "    n_features = X.shape[1]\n",
    "    theta = np.zeros(n_features)\n",
    "    \n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    J = -1/m * np.sum(y*np.log(h) + (1-y)*np.log(1-h))\n",
    "    return J\n",
    "\n",
    "# Define the MBOA function\n",
    "def MBOA(dim, maxiter, Bf, c, a, p, x, y):\n",
    "    \n",
    "    # Initialization\n",
    "    \n",
    "    I = np.zeros(Bf)\n",
    "    F = np.zeros(Bf)\n",
    "    best_fitness_values = []\n",
    "    \n",
    "    # Step 1: Set the initial generation/iteration number G=0\n",
    "    G = 0\n",
    "    \n",
    "    # Step 2: Generate initial population of n butterflies  = (i=1,2,..,n)\n",
    "    \n",
    "    # define the size of the population\n",
    "    n = 10000\n",
    "\n",
    "    # extract the variables of interest\n",
    "    variables = X_train_resampled_final.iloc[:, :dim]\n",
    "\n",
    "    # define the ranges for each variable\n",
    "    ranges = [(0, 10000)]*dim\n",
    "\n",
    "    # generate the initial population\n",
    "    population = []\n",
    "    for i in range(n):\n",
    "        butterfly = []\n",
    "        for j in range(variables.shape[0]):\n",
    "            var_range = ranges[j]\n",
    "            var_value = np.random.uniform(var_range[0], var_range[1])\n",
    "            butterfly.append(var_value)\n",
    "        population.append(butterfly)\n",
    "\n",
    "\n",
    "    # Main loop\n",
    "    while G < maxiter:\n",
    "        # Calculate stimulus intensity for each butterfly\n",
    "        for i in range(Bf):\n",
    "            I[i] = objective_function(X[:, i], y)\n",
    "            F[i] = c * I[i]**a\n",
    "        \n",
    "        # Find the best butterfly\n",
    "        best_butterfly = X[:, np.argmin(I)]\n",
    "\n",
    "        # Update each butterfly in the population\n",
    "        for i in range(n):\n",
    "            r = np.random.rand()\n",
    "            if r < p:\n",
    "                # Move towards the best butterfly\n",
    "                X[:, i] += np.random.rand(dim) * (best_butterfly - X[:, i])\n",
    "                # Determine mutual relationship vector and update butterfly positions\n",
    "                j = np.random.randint(n)\n",
    "                if i != j:\n",
    "                    MutualVector = (X[:, i] - X[:, j]) / np.linalg.norm(X[:, i] - X[:, j])\n",
    "                    X[:, i] += np.random.rand(dim) * MutualVector\n",
    "                    X[:, j] += np.random.rand(dim) * MutualVector\n",
    "                   # Calculate fitness value of the new butterfly\n",
    "                    I[i] = fitness(X[:, i], fun)\n",
    "                    # Update the best butterfly if a new one is found\n",
    "                    if I[i] < best_fitness:\n",
    "                        best_butterfly = X[:, i]\n",
    "                        best_fitness = I[i]\n",
    "\n",
    "                    # Update the mutation probability\n",
    "                    p = p * alpha\n",
    "\n",
    "                    # Store the best fitness value of this iteration\n",
    "                    best_fitness_values.append(best_fitness)\n",
    "\n",
    "        # Increment the generation number\n",
    "        G += 1\n",
    "\n",
    "\n",
    "    # Return the best butterfly and its fitness value\n",
    "    return best_butterfly, best_fitness, best_fitness_values\n",
    "\n",
    "# Call the function\n",
    "best_butterfly, best_fitness = MBOA(objective_function, 5, 50, 10, 1, 2, 0.8, X_train_resampled_final)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Objective function\n",
    "def f(X):\n",
    "    return sum([x**2 for x in X])\n",
    "\n",
    "# Butterfly Optimization Algorithm\n",
    "def butterfly_optimization(f, dim, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    # Initialize\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    \n",
    "    G = 0\n",
    "    n = Bf\n",
    "    \n",
    "    # Generate initial population of n butterflies  = (i=1,2,..,n)\n",
    "    \n",
    "    X = [[random.uniform(-5,5) for _ in range(dim)] for _ in range(n)]\n",
    "    I = [f(x) for x in X]\n",
    "    best_index = I.index(min(I))\n",
    "    best = X[best_index]\n",
    "    while G < Maxiter:\n",
    "        # Calculate fragrance\n",
    "        F = [c * I[i]**a for i in range(n)]\n",
    "        # Find the best butterfly\n",
    "        best_index = F.index(max(F))\n",
    "        best = X[best_index]\n",
    "        # Update each butterfly\n",
    "        for i in range(n):\n",
    "            # Move towards best butterfly\n",
    "            if random.random() < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j])\n",
    "            # Mutual relationship\n",
    "            else:\n",
    "                j = random.randint(0,n-1)\n",
    "                while j == i:\n",
    "                    j = random.randint(0,n-1)\n",
    "                MutVect = [random.uniform(-1,1) for _ in range(dim)]\n",
    "                # Collaboration strategy\n",
    "                X[i] = [X[i][k] + random.uniform(0,1) * MutVect[k] * abs(X[j][k] - X[i][k]) for k in range(dim)]\n",
    "            # Update fitness value\n",
    "            I[i] = f(X[i])\n",
    "        # Update the best value\n",
    "        if min(I) < f(best):\n",
    "            best_index = I.index(min(I))\n",
    "            best = X[best_index]\n",
    "        G += 1\n",
    "    return best, f(best)\n",
    "\n",
    "# Call the function\n",
    "best_butterfly, best_fitness = butterfly_optimization(f, dim=5, Maxiter=50, Bf=10, c=1, a=2, p=0.8)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Butterfly Optimization Algorithm\n",
    "# def butterfly_optimization(f, dim, Maxiter, Bf, c, a, p, X_train):\n",
    "#     # Initialize\n",
    "#     G = 0\n",
    "#     n = Bf\n",
    "#     if len(X_train) < n:\n",
    "#         n = len(X_train)\n",
    "    \n",
    "#     X = [X_train[i] for i in range(n)]\n",
    "    \n",
    "#     I = [f(x) for x in X]\n",
    "#     best_index = I.index(min(I))\n",
    "#     best = X[best_index]\n",
    "#     while G < Maxiter:\n",
    "#         # Calculate fragrance\n",
    "#         F = [c * I[i]**a for i in range(n)]\n",
    "#         # Find the best butterfly\n",
    "#         best_index = F.index(max(F))\n",
    "#         best = X[best_index]\n",
    "#         # Update each butterfly\n",
    "#         for i in range(n):\n",
    "#             # Move towards best butterfly\n",
    "#             if random.random() < p:\n",
    "#                 for j in range(dim):\n",
    "#                     X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j])\n",
    "#             # Mutual relationship\n",
    "#             else:\n",
    "#                 j = random.randint(0,n-1)\n",
    "#                 while j == i:\n",
    "#                     j = random.randint(0,n-1)\n",
    "#                 MutVect = [random.uniform(-1,1) for _ in range(dim)]\n",
    "#                 # Collaboration strategy\n",
    "#                 X[i] = [X[i][k] + random.uniform(0,1) * MutVect[k] * abs(X[j][k] - X[i][k]) for k in range(dim)]\n",
    "#             # Update fitness value\n",
    "#             I[i] = f(X[i])\n",
    "#         # Update the best value\n",
    "#         if min(I) < f(best):\n",
    "#             best_index = I.index(min(I))\n",
    "#             best = X[best_index]\n",
    "#         G += 1\n",
    "#     return best, f(best)\n",
    "\n",
    "# # X_train_resampled_final = X_train_resampled_final.values.tolist()\n",
    "\n",
    "# # Call the function\n",
    "# best_butterfly, best_fitness = butterfly_optimization(f, dim=5, Maxiter=50, Bf=10, c=1, a=2, p=0.8, X_train=X_train_resampled_final)\n",
    "\n",
    "# # Print the best butterfly and its fitness value\n",
    "# print(\"Best butterfly:\", best_butterfly)\n",
    "# print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa284d65",
   "metadata": {},
   "source": [
    "# Work refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d612d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function\n",
    "def f(X):\n",
    "    return sum([x**2 for x in X])\n",
    "\n",
    "def butterfly_optimization(f, X, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    # Initialization\n",
    "    \n",
    "    n = len(X) # Obtain length of X_train_resampled_final\n",
    "    print(\"n\",n)\n",
    "    \n",
    "    dim = len(X[0])\n",
    "    print(\"dim\",dim)\n",
    "    \n",
    "    I = [f(x) for x in X]\n",
    "    best_index = I.index(min(I))\n",
    "    best = X[best_index]\n",
    "    G = 0\n",
    "    while G < Maxiter:\n",
    "        # Calculate fragrance\n",
    "        F = [c * I[i]**a for i in range(n)]\n",
    "        # Find the best butterfly\n",
    "        best_index = F.index(max(F))\n",
    "        best = X[best_index]\n",
    "        # Update each butterfly\n",
    "        for i in range(n):\n",
    "            # Move towards best butterfly\n",
    "            if random.random() < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j])\n",
    "            # Mutual relationship\n",
    "            else:\n",
    "                j = random.randint(0,n-1)\n",
    "                while j == i:\n",
    "                    j = random.randint(0,n-1)\n",
    "                MutVect = [random.uniform(-1,1) for _ in range(dim)]\n",
    "                # Collaboration strategy\n",
    "                X[i] = [X[i][k] + random.uniform(0,1) * MutVect[k] * abs(X[j][k] - X[i][k]) for k in range(dim)]\n",
    "            # Update fitness value\n",
    "            I[i] = f(X[i])\n",
    "        # Update the best value\n",
    "        if min(I) < f(best):\n",
    "            best_index = I.index(min(I))\n",
    "            best = X[best_index]\n",
    "        G += 1\n",
    "    return best, f(best)\n",
    "\n",
    "# Convert Pandas DataFrame to list of lists\n",
    "X_train_resampled_final_list = X_train_resampled_final.values.tolist()\n",
    "\n",
    "# Call the function with the modified input data\n",
    "best_butterfly, best_fitness = butterfly_optimization(f, X_train_resampled_final_list, Maxiter=3, Bf=10, c=1, a=2, p=0.8)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c16e2d",
   "metadata": {},
   "source": [
    "# Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5810f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# @ Input 1: Objective function\n",
    "\n",
    "def f(X):\n",
    "    return sum([x**2 for x in X])\n",
    "\n",
    "# @ Input 2:  = (1, 2,3,   , ),\n",
    "\n",
    "# X_train_resampled_final_list = X_train_resampled_final.tolist()\n",
    "X_train_resampled_final_list = X_train_resampled_final.values.tolist()\n",
    "\n",
    "def butterfly_optimization(f, X, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    # Initialization\n",
    "    \n",
    "    n = len(X) # Obtain length of X_train_resampled_final\n",
    "    \n",
    "    # @ Input 3: dim= no. of dimensions \n",
    "\n",
    "    dim = len(X[0])\n",
    "    \n",
    "    I = [f(x) for x in X]\n",
    "    \n",
    "    best_index = I.index(min(I))\n",
    "    \n",
    "    best = X[best_index]\n",
    "    \n",
    "    G = 0\n",
    "    \n",
    "    while G < Maxiter:\n",
    "        \n",
    "        # Calculate fragrance\n",
    "        F = [c * I[i]**a for i in range(n)] # Equation(8)\n",
    "        \n",
    "        print(type(F))\n",
    "\n",
    "        # Find the best butterfly\n",
    "        best_index = F.index(max(F))\n",
    "        best = X[best_index]\n",
    "        \n",
    "        # Update each butterfly\n",
    "        \n",
    "        for i in range(n):\n",
    "            \n",
    "            # Move towards best butterfly\n",
    "            if random.random() < p:\n",
    "                for j in range(dim):\n",
    "                    #X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j]) # Equation (9)\n",
    "                    X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j]) # Equation (9)\n",
    "                    #X[i][j] += pow(random.uniform(-1, 1),2) * abs(best[j] - X[i][j]) * F[i]\n",
    "\n",
    "            # Mutual relationship\n",
    "            else:\n",
    "                j = random.randint(0,n-1)\n",
    "                while j == i:\n",
    "                    j = random.randint(0,n-1)\n",
    "                MutVect = [random.uniform(-1,1) for _ in range(dim)]\n",
    "                \n",
    "                # Collaboration strategy\n",
    "                X[i] = [X[i][k] + random.uniform(0,1) * MutVect[k] * abs(X[j][k] - X[i][k]) for k in range(dim)]\n",
    "            # Update fitness value\n",
    "            I[i] = f(X[i])\n",
    "        # Update the best value\n",
    "        if min(I) < f(best):\n",
    "            best_index = I.index(min(I))\n",
    "            best = X[best_index]\n",
    "        G += 1\n",
    "    return best, f(best)\n",
    "\n",
    "    \n",
    "# Call the function with the modified input data\n",
    "# Define sensor modality c, power exponent a and switch probability p \n",
    "best_butterfly, best_fitness = butterfly_optimization(f, X_train_resampled_final_list, Maxiter=3, Bf=10, c=1, a=2, p=0.8)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8dd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def f(X):\n",
    "    # Calculate the mutual information between each feature and the target variable\n",
    "    scores = mutual_info_classif(X, y_train_resampled)\n",
    "    # Return the sum of the scores as the fitness value\n",
    "    return sum(scores)\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    n = len(X)\n",
    "    dim = X.shape[1]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    #F = [decimal.Decimal(random.uniform(0, 1)) for i in range(n)]\n",
    "    F = [c * I[i]**a for i in range(n)]\n",
    "    fitness = [mutual_info_classif(X[i], y)[0] for i in range(n)]\n",
    "    best = X[fitness.index(max(fitness))]\n",
    "    best_fitness = max(fitness)\n",
    "    for t in range(Maxiter):\n",
    "        for i in range(n):\n",
    "            eps = decimal.Decimal(random.gauss(0, 1))\n",
    "            for j in range(dim):\n",
    "                X[i][j] += eps * F[i] * abs(best[j] - X[i][j])\n",
    "            score = mutual_info_classif(X[i], y)[0]\n",
    "            if score > fitness[i]:\n",
    "                fitness[i] = score\n",
    "                if score > best_fitness:\n",
    "                    best_fitness = score\n",
    "                    best = X[i]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "            F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * t), 1.5))\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def f(X):\n",
    "    # Calculate the mutual information between each feature and the target variable\n",
    "    scores = mutual_info_classif(X, y_train_resampled)\n",
    "    # Return the sum of the scores as the fitness value\n",
    "    return sum(scores)\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    n = len(X)\n",
    "    dim = X.shape[1]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    #F = [decimal.Decimal(random.uniform(0, 1)) for i in range(n)]\n",
    "    F = [c * I[i]**a for i in range(n)]\n",
    "    fitness = [mutual_info_classif(X[i], y)[0] for i in range(n)]\n",
    "    best = X[fitness.index(max(fitness))]\n",
    "    best_fitness = max(fitness)\n",
    "    for t in range(Maxiter):\n",
    "        for i in range(n):\n",
    "            eps = decimal.Decimal(random.gauss(0, 1))\n",
    "            for j in range(dim):\n",
    "                X[i][j] += eps * F[i] * abs(best[j] - X[i][j])\n",
    "            score = mutual_info_classif(X[i], y)[0]\n",
    "            if score > fitness[i]:\n",
    "                fitness[i] = score\n",
    "                if score > best_fitness:\n",
    "                    best_fitness = score\n",
    "                    best = X[i]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "            F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * t), 1.5))\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "# Call the function with the modified input data\n",
    "# Define sensor modality c, power exponent a and switch probability p \n",
    "best_butterfly, best_fitness = butterfly_optimization(f, X_train_resampled_final_list, Maxiter=3, Bf=10, c=1, a=2, p=0.8)\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4394805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "\n",
    "# Objective function: Sphere function\n",
    "def f(X):\n",
    "    return sum([x**2 for x in X])\n",
    "\n",
    "# # Rosenbrock\n",
    "# def f(X):\n",
    "#     # return sum([100 * (X[i+1] - X[i]**2)**2 + (1 - X[i])**2 for i in range(len(X)-1)])\n",
    "    \n",
    "#     f(x,y)=(1-x)^2+100(y-x^2)^2 \n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    dim =10\n",
    "    n=10\n",
    "    \n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # calculate initial stimulus intensity for each butterfly\n",
    "    I = np.zeros(Bf)\n",
    "    for i in range(Bf):\n",
    "        I[i] = f(X[i])\n",
    "        \n",
    "    #I = [f(x) for x in X]\n",
    "    \n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "    #F = [decimal.Decimal(random.uniform(0, 1)) for i in range(n)]\n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "    # Find the best butterfly\n",
    "    best_index = F.index(max(F))\n",
    "    best = X[best_index]\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    #for G in range(Maxiter):\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "            F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * G), 1.5))\n",
    "            G=G+1\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "# Call the function with the modified input data\n",
    "# Define sensor modality c, power exponent a and switch probability p \n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final_list, y_train_resampled, Maxiter=1000, Bf=10, c=3, a=4, p=0.85)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "207c02a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[Decimal('-1.0036459433275418') Decimal('-1.0500539756244074')\n Decimal('-1.0381301392414428') Decimal('0.0')\n Decimal('-0.8854737885679519') Decimal('-0.9137187392207512')\n Decimal('0.0') Decimal('1.745857723069965')\n Decimal('0.13649614700511065') Decimal('-1.7288943780954473')].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\384193563.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m \u001b[0mbest_butterfly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbutterfly_optimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;31m# Print the best butterfly and its fitness value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\384193563.py\u001b[0m in \u001b[0;36mbutterfly_optimization\u001b[1;34m(X, y, Maxiter, Bf, c, a, p)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# Initialize butterfly positions and calculate initial stimulus intensity for each butterfly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecimal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;31m# Initialize stimulus strength and find the best butterfly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\384193563.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# Initialize butterfly positions and calculate initial stimulus intensity for each butterfly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecimal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;31m# Initialize stimulus strength and find the best butterfly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\384193563.py\u001b[0m in \u001b[0;36mfitness\u001b[1;34m(X, y, k, alpha)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# Calculate classification error rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"requires_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                     \u001b[1;34m\"if it contains a single sample.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m                 )\n\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[Decimal('-1.0036459433275418') Decimal('-1.0500539756244074')\n Decimal('-1.0381301392414428') Decimal('0.0')\n Decimal('-0.8854737885679519') Decimal('-0.9137187392207512')\n Decimal('0.0') Decimal('1.745857723069965')\n Decimal('0.13649614700511065') Decimal('-1.7288943780954473')].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "\n",
    "# Objective function: KNN classification with feature selection\n",
    "# def fitness(X, y, k=5, alpha=0.5):\n",
    "#     # X: feature matrix (num_samples x num_features)\n",
    "#     # y: target vector (num_samples,)\n",
    "#     # k: number of nearest neighbors to consider in KNN\n",
    "#     # alpha: importance of classification quality vs subset length (0 <= alpha <= 1)\n",
    "    \n",
    "#     from sklearn.neighbors import KNeighborsClassifier\n",
    "#     from sklearn.metrics import accuracy_score\n",
    "    \n",
    "#     clf = KNeighborsClassifier(n_neighbors=k)\n",
    "#     clf.fit(X, y)\n",
    "    \n",
    "#     # Calculate classification error rate\n",
    "#     y_pred = clf.predict(X)\n",
    "#     error_rate = 1 - accuracy_score(y, y_pred)\n",
    "    \n",
    "#     # Calculate fitness\n",
    "#     num_selected = X.shape[1]\n",
    "#     num_total = X.shape[1]\n",
    "#     fitness_value = alpha * (1 - error_rate) + (1 - alpha) * (num_selected / num_total)\n",
    "    \n",
    "#     return fitness_value\n",
    "\n",
    "def fitness(X, y, k=5, alpha=0.5):\n",
    "    # X: feature matrix (num_samples x num_features)\n",
    "    # y: target vector (num_samples,)\n",
    "    # k: number of nearest neighbors to consider in KNN\n",
    "    # alpha: importance of classification quality vs subset length (0 <= alpha <= 1)\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Calculate classification error rate\n",
    "    y_pred = clf.predict(X)\n",
    "    error_rate = 1 - accuracy_score(y, y_pred)\n",
    "\n",
    "    # Calculate fitness\n",
    "    num_selected = X.shape[1]\n",
    "    num_total = X.shape[1]\n",
    "    fitness_value = alpha * (1 - error_rate) + (1 - alpha) * (num_selected / num_total)\n",
    "\n",
    "    return fitness_value\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    dim = X.shape[1]\n",
    "    n = Bf\n",
    "    \n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # Initialize butterfly positions and calculate initial stimulus intensity for each butterfly\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)]\n",
    "    I = [fitness(X[i], y) for i in range(n)]\n",
    "    \n",
    "    # Initialize stimulus strength and find the best butterfly\n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])**decimal.Decimal(a) for i in range(n)]\n",
    "    best_index = I.index(max(I))\n",
    "    best = X[best_index]\n",
    "    best_fitness = I[best_index]\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "            I[i] = fitness(X[i], y)\n",
    "            if I[i] > best_fitness:\n",
    "                best = X[i]\n",
    "                best_fitness = I[i]\n",
    "            F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * G), 1.5))\n",
    "            G=G+1\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b8fbbe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'fitness' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\1697484995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m \u001b[0mbest_butterfly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbutterfly_optimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;31m# Print the best butterfly and its fitness value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\1697484995.py\u001b[0m in \u001b[0;36mbutterfly_optimization\u001b[1;34m(X, y, Maxiter, Bf, c, a, p)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m          \u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecimal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Convert all values to Decimal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'fitness' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    dim = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # Load the KNN classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "        \n",
    "    # calculate initial stimulus intensity for each butterfly\n",
    "#     I = np.zeros(Bf)\n",
    "#     for i in range(Bf):\n",
    "#         I[i] = f(X[i])\n",
    "     # In the butterfly optimization function, modify the calculation of initial stimulus intensity for each butterfly to include the fitness function\n",
    "    I = np.zeros(Bf)\n",
    "    for i in range(Bf):\n",
    "         I[i] = fitness(X[i], y, k)\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "    #F = [decimal.Decimal(random.uniform(0, 1)) for i in range(n)]\n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "    # Find the best butterfly\n",
    "    best_index = F.index(max(F))\n",
    "    best = X[best_index]\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    #for G in range(Maxiter):\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                \n",
    "            # Convert X to numpy array and select the features\n",
    "            X_selected = np.array(X)[i,:]\n",
    "            X_selected = X[:, X_selected > 0]\n",
    "            \n",
    "            # Fit the KNN classifier on the training set\n",
    "            clf.fit(X_train[:, X_selected], y_train)\n",
    "            \n",
    "            # Predict the labels of the validation set\n",
    "            y_pred = clf.predict(X_val[:, X_selected])\n",
    "            \n",
    "            # Calculate the classification error rate\n",
    "            error_rate = sum(y_pred != y_val) / len(y_val)\n",
    "            \n",
    "            # Calculate the number of selected features\n",
    "            num_selected = sum(selected_features)\n",
    "\n",
    "            # Calculate the fitness value\n",
    "            fitness = alpha * (1 - error_rate) + beta * num_selected / num_features\n",
    "\n",
    "            # Append the fitness value to the list of fitness values\n",
    "            fitness_values.append(fitness)\n",
    "\n",
    "            # Return the fitness value\n",
    "            return fitness\n",
    "\n",
    "           \n",
    "\n",
    "            # Modify the while loop to update the best butterfly and its fitness value at each generation\n",
    "            while G < Maxiter:\n",
    "                for i in range(Bf):\n",
    "                        # Generate a random number r from [0,1]\n",
    "                        r = random.uniform(0, 1)\n",
    "                        if r < p:\n",
    "                            for j in range(dim):\n",
    "                                X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "                        else:\n",
    "                            j = random.randint(0, n-1)\n",
    "                            for k in range(dim):\n",
    "                                X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "                        for j in range(dim):\n",
    "                            X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                            X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                        F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * G), 1.5))\n",
    "\n",
    "                        # Calculate the fitness value for the updated butterfly\n",
    "                        fitness_val = fitness(X[i], y, k)\n",
    "\n",
    "                        # Update the best butterfly and its fitness value if necessary\n",
    "                        if fitness_val > best_fitness:\n",
    "                            best_fitness = fitness_val\n",
    "                            best = X[i]\n",
    "\n",
    "                        G=G+1\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6847051f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10, 421231]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\2064752712.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_fitness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m \u001b[0mbest_butterfly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbutterfly_optimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;31m# Print the best butterfly and its fitness value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\2064752712.py\u001b[0m in \u001b[0;36mbutterfly_optimization\u001b[1;34m(X, y, Maxiter, Bf, c, a, p, k)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m          \u001b[1;31m#I[i] = fitness(X[i], y, k)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecimal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Convert all values to Decimal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\2064752712.py\u001b[0m in \u001b[0;36mfitness\u001b[1;34m(X, y, k)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Split the data into training and validation sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Load the KNN classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2415\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2417\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    332\u001b[0m         raise ValueError(\n\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         )\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10, 421231]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fitness(X, y, k):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "    # Load the KNN classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Fit the KNN classifier on the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels of the validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    # Calculate the classification error rate\n",
    "    error_rate = sum(y_pred != y_val) / len(y_val)\n",
    "\n",
    "    # Calculate the number of selected features\n",
    "    num_selected = sum(X > 0)\n",
    "\n",
    "    # Calculate the fitness value\n",
    "    fitness = (1 - error_rate) * (1 + num_selected)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p, k):\n",
    "    \n",
    "    dim = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # calculate initial stimulus intensity for each butterfly\n",
    "    I = np.zeros(Bf)\n",
    "    for i in range(Bf):\n",
    "         #I[i] = fitness(X[i], y, k)\n",
    "        I[i] = fitness(X[i,:], y, k)\n",
    "\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "    # Find the best butterfly\n",
    "    best_index = F.index(max(F))\n",
    "    best = X[best_index]\n",
    "    best_fitness = fitness(best, y, k)\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                \n",
    "            # Convert X to numpy array and select the features\n",
    "            X_selected = np.array(X)[i,:]\n",
    "            X_selected = np.where(X_selected > 0)[0]\n",
    "            \n",
    "            if len(X_selected) == 0:\n",
    "                fitness_val = decimal.Decimal('-inf')\n",
    "            else:\n",
    "                fitness_val = fitness(X_selected, y, k)\n",
    "\n",
    "            # Update the stimulus intensity\n",
    "            if fitness_val > I[i]:\n",
    "                I[i] = fitness_val\n",
    "            \n",
    "            # Check if the updated butterfly is better than the previous best\n",
    "            if fitness_val > best_fitness:\n",
    "                best = X[i]\n",
    "                best_fitness = fitness_val\n",
    "            \n",
    "        # Update the generation/iteration number\n",
    "        G += 1\n",
    "        \n",
    "        # Update the functional response F\n",
    "        F = [decimal.Decimal(c) * decimal.Decimal(I[i])**decimal.Decimal(a) for i in range(n)]\n",
    "        \n",
    "        # Print the current best fitness value after every 10 iterations\n",
    "        if G % 10 == 0:\n",
    "            print(\"Iteration {}: Best Fitness Value = {}\".format(G, best_fitness))\n",
    "    \n",
    "    # Convert the best solution to numpy array and select the features\n",
    "    best_selected = np.array(best)\n",
    "    best_selected = np.where(best_selected > 0)[0]\n",
    "    \n",
    "    return best_fitness, best_selected\n",
    "\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5,k=3)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be6b6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fitness(X, y, k):\n",
    "#     # Split the data into training and validation sets\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "#     # Load the KNN classifier\n",
    "#     clf = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "#     # Fit the KNN classifier on the training set\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     # Predict the labels of the validation set\n",
    "#     y_pred = clf.predict(X_val)\n",
    "\n",
    "#     # Calculate the classification error rate\n",
    "#     error_rate = sum(y_pred != y_val) / len(y_val)\n",
    "\n",
    "#     # Calculate the number of selected features\n",
    "#     num_selected = sum(X > 0)\n",
    "\n",
    "#     # Calculate the fitness value\n",
    "#     fitness = (1 - error_rate) * (1 + num_selected)\n",
    "\n",
    "#     return fitness\n",
    "\n",
    "# def butterfly_optimization(X, y, Maxiter, Bf, c, a, p, k):\n",
    "    \n",
    "#     dim = X.shape[1]\n",
    "#     n = X.shape[0]\n",
    "#     decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "#     # calculate initial stimulus intensity for each butterfly\n",
    "#     I = np.zeros(Bf)\n",
    "#     for i in range(Bf):\n",
    "#         X[i] = np.where(X[i] > 0, 1, 0)\n",
    "#         I[i] = fitness(X[i], y, k)\n",
    "\n",
    "#     X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "#     F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "#     # Find the best butterfly\n",
    "#     best_index = F.index(max(F))\n",
    "#     best = X[best_index]\n",
    "#     best_fitness = fitness(np.where(best > 0, 1, 0), y, k)\n",
    "    \n",
    "#     # Set the initial generation/iteration number G=0\n",
    "#     G=0\n",
    "#     while G < Maxiter:\n",
    "#         for i in range(Bf):\n",
    "                    \n",
    "#             # Generate a random number r from [0,1]\n",
    "#             r = random.uniform(0, 1)\n",
    "            \n",
    "#             if r < p:\n",
    "#                 for j in range(dim):\n",
    "#                     X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "#             else:\n",
    "#                 j = random.randint(0, n-1)\n",
    "#                 for k in range(dim):\n",
    "#                     X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "                    \n",
    "#             for j in range(dim):\n",
    "#                 X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "#                 X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                \n",
    "#             # Convert X to numpy array and select the features\n",
    "#             X = [[float(X[i][j]) for j in range(dim)] for i in range(n)]\n",
    "#             X = np.array(X)\n",
    "#             X = np.where(X > 0, 1, 0)\n",
    "            \n",
    "#             # Calculate the fitness values of all butterflies\n",
    "# I = [fitness(X[i], y, k) for i in range(Bf)]\n",
    "\n",
    "# # Find the best butterfly\n",
    "# best_index = I.index(max(I))\n",
    "# best = X[best_index]\n",
    "# best_fitness = I[best_index]\n",
    "\n",
    "# # Set the initial generation/iteration number G=0\n",
    "# G = 0\n",
    "\n",
    "# # Create an empty list to store the best fitness value at each generation\n",
    "# best_fitness_list = []\n",
    "\n",
    "# # Run the optimization loop for Maxiter iterations\n",
    "# while G < Maxiter:\n",
    "    \n",
    "#     # Calculate the stimulus intensity of all butterflies\n",
    "#     F = [c * I[i]**a for i in range(Bf)]\n",
    "    \n",
    "#     # Generate a new population of butterflies\n",
    "#     X_new = np.zeros((Bf, dim))\n",
    "#     for i in range(Bf):\n",
    "        \n",
    "#         # Generate a random number r from [0,1]\n",
    "#         r = random.uniform(0, 1)\n",
    "        \n",
    "#         # Calculate the new position of the butterfly based on the random number and the best butterfly\n",
    "#         if r < p:\n",
    "#             for j in range(dim):\n",
    "#                 X_new[i][j] = X[i][j] + (r**2) * abs(best[j] - X[i][j]) * F[i]\n",
    "#         else:\n",
    "#             j = random.randint(0, Bf-1)\n",
    "#             for k in range(dim):\n",
    "#                 X_new[i][k] = X[i][k] + (r**2) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "        \n",
    "#         # Clamp the position of the butterfly to the search space\n",
    "#         for j in range(dim):\n",
    "#             X_new[i][j] = max(X_new[i][j], -Bf)\n",
    "#             X_new[i][j] = min(X_new[i][j], Bf)\n",
    "    \n",
    "#     # Select the features for each butterfly\n",
    "#     X_new = np.where(X_new > 0, 1, 0)\n",
    "    \n",
    "#     # Calculate the fitness values of the new population of butterflies\n",
    "#     I_new = [fitness(X_new[i], y, k) for i in range(Bf)]\n",
    "    \n",
    "#     # Update the best butterfly if there is a better one in the new population\n",
    "#     if max(I_new) > best_fitness:\n",
    "#         best_index = I_new.index(max(I_new))\n",
    "#         best = X_new[best_index]\n",
    "#         best_fitness = I_new[best_index]\n",
    "    \n",
    "#     # Update the population of butterflies if there is a better one in the new population\n",
    "#     if max(I_new) > max(I):\n",
    "#         X = X_new\n",
    "#         I = I_new\n",
    "    \n",
    "#     # Append the best fitness value to the list of best fitness values\n",
    "#     best_fitness_list.append(best_fitness)\n",
    "    \n",
    "#     # Increment the generation/iteration number\n",
    "#     G += 1\n",
    "\n",
    "# return best, best_fitness, best_fitness_list\n",
    "\n",
    "\n",
    "# best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5,k=3)\n",
    "\n",
    "# # Print the best butterfly and its fitness value\n",
    "# print(\"Best butterfly:\", best_butterfly)\n",
    "# print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "baa33694",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10, 421231]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\1391872066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fitness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitness_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0mbest_butterfly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbutterfly_optimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Print the best butterfly and its fitness value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\1391872066.py\u001b[0m in \u001b[0;36mbutterfly_optimization\u001b[1;34m(X, y, Maxiter, Bf, c, a, p, k)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecimal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Convert all values to Decimal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\1391872066.py\u001b[0m in \u001b[0;36mfitness\u001b[1;34m(X, y, k)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mX_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_selected\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2415\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2417\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    332\u001b[0m         raise ValueError(\n\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         )\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10, 421231]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fitness(X, y, k):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    X_selected = X[:, X.sum(axis=0) > 0]\n",
    "    clf.fit(X_train[:, X_selected], y_train)\n",
    "    y_pred = clf.predict(X_val[:, X_selected])\n",
    "    error_rate = sum(y_pred != y_val) / len(y_val)\n",
    "    num_selected = X_selected.shape[1]\n",
    "    fitness = 1 - error_rate + num_selected / X.shape[1]\n",
    "    return fitness\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p, k):\n",
    "    \n",
    "    dim = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # Calculate initial stimulus intensity for each butterfly\n",
    "    I = np.zeros(Bf)\n",
    "    for i in range(Bf):\n",
    "        I[i] = fitness(X[i], y, k)\n",
    "        \n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "    # Find the best butterfly\n",
    "    best_index = F.index(max(F))\n",
    "    best = X[best_index]\n",
    "    best_fitness = fitness(best, y, k)\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    fitness_values = []\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                \n",
    "            # Convert X to numpy array and select the features\n",
    "            X_selected = np.array(X)[i,:]\n",
    "            X_selected = X[:, X.sum(axis=0) > 0]\n",
    "            \n",
    "                    # Evaluate the fitness of the new butterfly\n",
    "        fitness_value = fitness(X_selected, y, k)\n",
    "        \n",
    "        # Update the intensity of the butterfly if its fitness improves\n",
    "        if fitness_value > I[i]:\n",
    "            I[i] = fitness_value\n",
    "            \n",
    "        # Update the global best if the new butterfly is better\n",
    "        if fitness_value > best_fitness:\n",
    "            best = X[i]\n",
    "            best_fitness = fitness_value\n",
    "    \n",
    "    # Update the value of F for the next generation\n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "    \n",
    "    # Add the best fitness value of the current generation to the list of fitness values\n",
    "    fitness_values.append(best_fitness)\n",
    "    \n",
    "    # Increase the generation/iteration number\n",
    "    G += 1\n",
    "\n",
    "    return best, best_fitness, fitness_values\n",
    "\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5,k=3)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f6a13c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421231, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# @ Input 1: Objective function\n",
    "def f(X, X_train, y_train):\n",
    "    X_train_subset = X_train[:, X.astype(bool)]\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    scores = cross_val_score(clf, X_train_subset, y_train, cv=5)\n",
    "    return -np.mean(scores)\n",
    "\n",
    "# @ Input 2: X = training set\n",
    "# @ Input 3: Maxiter = Maximum number of iterations\n",
    "# @ Input 4: Bf = Butterfly population factor\n",
    "# @ Input 5: c = Constant factor\n",
    "# @ Input 6: a = Exponent factor\n",
    "# @ Input 7: p = Probability factor\n",
    "\n",
    "def butterfly_optimization(X_train, y_train, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    # Initialization\n",
    "    \n",
    "    n, dim = X.shape\n",
    "    \n",
    "    I = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        I[i] = f(X[i], X_train_resampled_final_array, y_train_resampled)\n",
    "        \n",
    "    best_index = np.argmin(I)\n",
    "    \n",
    "    best = X[best_index]\n",
    "    \n",
    "    G = 0\n",
    "    \n",
    "    while G < Maxiter:\n",
    "        \n",
    "        # Calculate fragrance\n",
    "        F = [c * I[i]**a for i in range(n)]\n",
    "        \n",
    "        # Find the best butterfly\n",
    "        best_index = np.argmax(F)\n",
    "        best = X[best_index]\n",
    "        \n",
    "        # Update each butterfly\n",
    "        for i in range(n):\n",
    "            \n",
    "            # Move towards best butterfly\n",
    "            if np.random.random() < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += np.random.uniform(-1,1) * abs(best[j] - X[i][j])\n",
    "                    \n",
    "            # Mutual relationship\n",
    "            else:\n",
    "                j = np.random.randint(0,n-1)\n",
    "                while j == i:\n",
    "                    j = np.random.randint(0,n-1)\n",
    "                MutVect = np.random.uniform(-1,1,dim)\n",
    "                # Collaboration strategy\n",
    "                X[i] = X[i] + np.random.uniform(0,1) * MutVect * abs(X[j] - X[i])\n",
    "                \n",
    "            # Update fitness value\n",
    "            I[i] = f(X[i], X_train_resampled_final_array, y_train_resampled)\n",
    "        \n",
    "        # Update the best value\n",
    "        if min(I) < f(best, X_train_resampled_final_array, y_train_resampled):\n",
    "            best_index = np.argmin(I)\n",
    "            best = X[best_index]\n",
    "            \n",
    "        G += 1\n",
    "    \n",
    "    # Get the index of the important features in the best butterfly\n",
    "    important_features_index = np.where(best > 0.5)[0]\n",
    "    \n",
    "    # Print the important features\n",
    "    print(\"Important features:\")\n",
    "    for index in important_features_index:\n",
    "        print(\"Feature\", index+1)\n",
    "    \n",
    "    return best, f(best, X_train_resampled_final, y_train_resampled)\n",
    "\n",
    "X_train_resampled_final_array = np.array(X_train_resampled_final)\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final_array, y_train_resampled, 100, 10, 0.8, 2, 0.5)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b20db",
   "metadata": {},
   "source": [
    "## Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a27d403",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn_genetic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1404\\3420680288.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn_genetic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGASearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgenetic_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeneticSelectionCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn_genetic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInteger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mContinuous\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn_genetic'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from sklearn_genetic import GASearchCV\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "_, axes = plot.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for axis, image, label in zip(axes, data.images, data.target):\n",
    "    axis.set_axis_off()\n",
    "    axis.imshow(image, cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "    axis.set_title('Training: %i' % label)\n",
    "    param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "              'bootstrap': Categorical([True, False]),\n",
    "              'max_depth': Integer(2, 30),\n",
    "              'max_leaf_nodes': Integer(2, 35),\n",
    "              'n_estimators': Integer(100, 300)}\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# The main class from sklearn-genetic-opt\n",
    "evolved_estimator = GASearchCV(estimator=classifier,\n",
    "                              cv=cv,\n",
    "                              scoring='accuracy',\n",
    "                              param_grid=param_grid,\n",
    "                              verbose=True)\n",
    "\n",
    "evolved_estimator.fit(X_train_pca, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c32f15",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15364\\752503140.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Convert X_train_resampled_final to a pandas DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mX_train_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_resampled_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train_resampled_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature Selection:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_resampled_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pds\n",
    "import numpy as num\n",
    "\n",
    "estimators = DecisionTreeClassifier()\n",
    "models = GeneticSelectionCV(\n",
    "    estimators, cv=3, verbose=0,\n",
    "    scoring=\"accuracy\", max_features=5,\n",
    "    n_population=70, crossover_proba=0.5,\n",
    "    mutation_proba=0.2, n_generations=50,\n",
    "    crossover_independent_proba=0.5,\n",
    "    mutation_independent_proba=0.04,\n",
    "    tournament_size=3, n_gen_no_change=10,\n",
    "    caching=True, n_jobs=-1)\n",
    "models = models.fit(X_train_resampled_final, y_train_resampled_final)\n",
    "# Convert X_train_resampled_final to a pandas DataFrame\n",
    "X_train_df = pd.DataFrame(X_train_resampled_final, columns=X_train_resampled_final.columns)\n",
    "print('Feature Selection:', X_train_df.columns[models.support_])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
