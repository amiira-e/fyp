{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc296ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cddab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"isFraud\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21266eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e35c6",
   "metadata": {},
   "source": [
    "# It is important to consider the strengths and limitations of each type of graph when selecting the most appropriate visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a949de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c7b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"isFraud\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc9b65",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c725d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20a415",
   "metadata": {},
   "source": [
    "# Unimodial vs Multimodial (Shape distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b09736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['step','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "plt.figure(figsize=(20,8))\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for feature in features:\n",
    "    plt.subplot(2,3,features.index(feature)+1)\n",
    "    sns.distplot(df[feature],hist=True,color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"isFraud\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb115b0f",
   "metadata": {},
   "source": [
    "# Payment Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef814e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create New DataFrame with Count\n",
    "new_df = df[\"type\"].value_counts().rename_axis('types_of_transaction').reset_index(name='counts')\n",
    "new_df.head()\n",
    "\n",
    "#Set lables and values\n",
    "my_labels = new_df.types_of_transaction\n",
    "my_values = new_df.counts\n",
    "\n",
    "#Visualize the pie chart\n",
    "fig=plt.figure(figsize=(3,3)) # Resize\n",
    "wp= {'linewidth':0.5,'edgecolor':\"black\"}\n",
    "ax=fig.add_axes([0,0,1,1]) # Add axis to the figure\n",
    "ax.axis('equal')\n",
    "explode=(0.1,0.1,0.1,0.1,0.1)\n",
    "ax.pie(my_values, labels=my_labels, autopct='%1.2f%%',explode=explode,shadow=True,wedgeprops=wp)\n",
    "font = {'fontname':'Comic Sans MS'} # Change font\n",
    "plt.title('Type of Transactions',fontsize=20,color='purple',**font,fontweight='bold')\n",
    "plt.legend(['CASH_OUT', 'PAYMENT', 'CASH_IN','TRANSFER','DEBIT'])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db763947",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"isFraud\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2521db2",
   "metadata": {},
   "source": [
    "# Barplot to show class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the values in the isFraud column to Non-Fraud and Fraud\n",
    "df[\"isFraud\"] = df[\"isFraud\"].map({0: \"Non-Fraud\", 1: \"Fraud\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a72ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts of the isFraud column\n",
    "counts = df['isFraud'].value_counts().rename_axis('isFraud').reset_index(name='count')\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d87092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the count of Non-Fraud and Fraud using a barplot\n",
    "plt.figure(figsize=(5.5, 5.5))\n",
    "sns.barplot(x='isFraud', y='count', data=counts, color='pink', edgecolor =\"b\")\n",
    "plt.title('Count of Non-Fraudulent & Fraudulent Transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"isFraud\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFraud\"] = df[\"isFraud\"].replace({\"Non-Fraud\": 0, \"Fraud\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd371e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"isFraud\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cdf4e8",
   "metadata": {},
   "source": [
    "# Feature Encoding on Whole Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64965a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder from Sklearn\n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['type'])\n",
    "# printing label\n",
    "label\n",
    "# removing the column 'type' from df\n",
    "# as it is of no use now.\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "# Appending the array to our dataFrame\n",
    "# with column name 'type'\n",
    "df[\"type\"] = label\n",
    "# printing Dataframe\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameDest'])\n",
    "label\n",
    "df.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df[\"nameDest\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df['nameOrig'])\n",
    "label\n",
    "df.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df[\"nameOrig\"] = label\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17994959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows in the dataset\n",
    "num_rows_df = df.shape[0]\n",
    "print(\"Number of rows in the dataset:\", num_rows_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a58c8",
   "metadata": {},
   "source": [
    "Aim 1: Train all models in the following way:\n",
    "-Apply only Cost-Sensitive Learning without handling class imbalance in pre-processing stage\n",
    "-Handle outliers using Trimmed Mean with Bootstrap (constant)\n",
    "-Use the same set of selected features (constant)\n",
    "\n",
    "Aim 2: Train all models in the following way:\n",
    "-Apply only Cost-Sensitive Learning with handling class imbalance in pre-processing stage\n",
    "-Handle outliers using Trimmed Mean with Bootstrap (constant)\n",
    "-Use the same set of selected features (constant)\n",
    "\n",
    "Based on which one is better, we use it as the technique for class imbalance\n",
    "\n",
    "Aim 3:Train all models in the following way:\n",
    "-Apply the class imbalance obtained\n",
    "-\n",
    "-Vary set of features to train models-Using feature selection method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8220d43",
   "metadata": {},
   "source": [
    "# Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5e19f7",
   "metadata": {},
   "source": [
    "Both approaches can be used to handle class imbalance in machine learning, but they have different trade-offs.\n",
    "\n",
    "Pre-processing techniques such as oversampling the minority class or undersampling the majority class can be used to balance the class distribution in the training data. These techniques can help the machine learning algorithm to better learn the patterns in the minority class, and can lead to better performance on the test data.\n",
    "\n",
    "Cost-sensitive learning, on the other hand, involves assigning different costs to misclassifying different classes. For example, you might assign a higher cost to misclassifying the minority class than the majority class. This can help the machine learning algorithm to pay more attention to the minority class, but it does not address the underlying class imbalance in the training data.\n",
    "\n",
    "In general, it's a good idea to try both approaches and see which one works best for your dataset. If your dataset is highly imbalanced and pre-processing techniques do not lead to satisfactory results, then you might want to try cost-sensitive learning. However, if your dataset is moderately imbalanced, pre-processing techniques might be sufficient.\n",
    "\n",
    "It's worth noting that pre-processing techniques can be computationally expensive, especially if the dataset is large. Cost-sensitive learning, on the other hand, is usually less computationally expensive since it involves modifying the learning algorithm itself rather than the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f57a6d",
   "metadata": {},
   "source": [
    "# Split into train, validation and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d4121",
   "metadata": {},
   "source": [
    "The data is split into 80% training and 20% test.\n",
    "Then, the training set is split into 75% training and 25% validation sets\n",
    "THE MAIN IDEA OF A VALIDATION SET IS TO PREVENT THE MODEL FROM OVERFITTING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e517e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X = df.drop('isFraud', axis=1)\n",
    "# y = df['isFraud']\n",
    "# # Split the data into a 80%-20% train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=18)\n",
    "# # Split the training set again into a 75%-25% train-validation split\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a04c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df['isFraud']\n",
    "\n",
    "# Split the data into a 80%-20% train-test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=18)\n",
    "\n",
    "# Split the training set again into a 75%-25% train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662a3ab",
   "metadata": {},
   "source": [
    "# Save train, test and validation files to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23918644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from X_val and y_val\n",
    "val_df = pd.DataFrame(X_val, columns=X_train.columns)\n",
    "val_df['isFraud'] = y_val\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "val_df.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\train.csv\", index=False)\n",
    "X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e07573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf5b47",
   "metadata": {},
   "source": [
    "# Handle Class Imbalance in train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b7bc9",
   "metadata": {},
   "source": [
    "The reason for this is that when we split the data, we want to ensure that the distribution of the target variable (i.e., the classes) is similar across the different sets. If we were to balance the classes prior to splitting, we could inadvertently introduce bias into the data by changing the distribution of the target variable.\n",
    "\n",
    "Therefore, it is usually best to split the data first, and then apply techniques to handle class imbalance on the training set only. This ensures that the validation and test sets remain representative of the original data distribution, while the training set is balanced to avoid bias towards the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95061a48",
   "metadata": {},
   "source": [
    "### Threshold algorithm to handle class imbalance in train set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import confusion_matrix, f1_score\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # Train a random forest classifier on the imbalanced data\n",
    "# rfc = RandomForestClassifier()\n",
    "# rfc.fit(X_train, y_train)\n",
    "\n",
    "# # Calculate the confusion matrix for the default threshold (0.5)\n",
    "# y_pred = rfc.predict(X_test)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# # Calculate the F1 score for the minority class\n",
    "# minority_class_f1_score = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# # Set the initial threshold to 0.5\n",
    "# threshold = 0.5\n",
    "\n",
    "# # Repeat the threshold-moving algorithm until the desired performance is achieved\n",
    "# while minority_class_f1_score < 0.7:\n",
    "#     # Adjust the threshold\n",
    "#     threshold += 0.1\n",
    "    \n",
    "#     # Predict the class probabilities using the random forest classifier\n",
    "#     y_prob = rfc.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "#     # Apply the new threshold to the probabilities\n",
    "#     y_pred = np.where(y_prob > threshold, 1, 0)\n",
    "    \n",
    "#     # Calculate the confusion matrix and F1 score for the new threshold\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     tn, fp, fn, tp = cm.ravel()\n",
    "#     minority_class_f1_score = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "# # Use the final threshold to predict the class labels on the test set\n",
    "# y_prob = rfc.predict_proba(X_test)[:, 1]\n",
    "# y_pred = np.where(y_prob > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.metrics import sensitivity_score, specificity_score\n",
    "\n",
    "# def threshold_moving_algorithm(model, X_train, y_train, X_val, y_val, start_threshold=0.5, step_size=0.01):\n",
    "#     \"\"\"\n",
    "#     Implements the threshold moving algorithm to adjust for class imbalance in the training set.\n",
    "    \n",
    "#     Args:\n",
    "#     - model: a binary classification model that has a `predict_proba` method\n",
    "#     - X_train: the feature matrix of the training set\n",
    "#     - y_train: the target variable of the training set\n",
    "#     - X_val: the feature matrix of the validation set\n",
    "#     - y_val: the target variable of the validation set\n",
    "#     - start_threshold: the initial threshold to use when making predictions\n",
    "#     - step_size: the amount to increment the threshold by on each iteration\n",
    "    \n",
    "#     Returns:\n",
    "#     - best_threshold: the threshold that maximizes the F1 score on the validation set\n",
    "#     - best_f1: the F1 score achieved by the model with the best threshold on the validation set\n",
    "#     \"\"\"\n",
    "#     best_threshold = start_threshold\n",
    "#     best_f1 = 0\n",
    "    \n",
    "#     for threshold in np.arange(start_threshold, 1, step_size):\n",
    "#         y_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "#         y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        \n",
    "#         # calculate sensitivity and specificity of the model on the training set\n",
    "#         sensitivity = sensitivity_score(y_train, y_pred)\n",
    "#         specificity = specificity_score(y_train, y_pred)\n",
    "        \n",
    "#         # adjust the threshold based on the ratio of sensitivity to specificity\n",
    "#         if sensitivity > specificity:\n",
    "#             threshold -= step_size\n",
    "#         else:\n",
    "#             threshold += step_size\n",
    "            \n",
    "#         # make predictions on the validation set and calculate the F1 score\n",
    "#         y_val_pred = (y_pred_proba >= threshold).astype(int)\n",
    "#         f1 = f1_score(y_val, y_val_pred)\n",
    "        \n",
    "#         # update the best threshold and F1 score if applicable\n",
    "#         if f1 > best_f1:\n",
    "#             best_threshold = threshold\n",
    "#             best_f1 = f1\n",
    "            \n",
    "#     return best_threshold, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415fc4e6",
   "metadata": {},
   "source": [
    "## Theses outlier detection are only on the unimodial variables. Rememeber 'step' is multimodial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1cb0d",
   "metadata": {},
   "source": [
    "# Multivariate Outlier detection - Beware many assume normality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3aed3",
   "metadata": {},
   "source": [
    "# Identify outliers using Modified Z-score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cda345",
   "metadata": {},
   "source": [
    "Modified Z-score can be used when the data is skewed and heavy-tailed, as it does not assume any specific distribution of the data. However, it is important to note that modified Z-score is still based on the assumption that the data has a unimodal distribution, and may not be effective for detecting outliers in multi-modal data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd792f0",
   "metadata": {},
   "source": [
    "we calculate the modified Z-score for each value in the column using the formula z_score = 0.6745 * (X_train[col] - med) / mad. The constant 0.6745 corresponds to the 75th percentile of the standard normal distribution, and is used to make the modified Z-score consistent with the standard Z-score.\n",
    "\n",
    "Finally, we count the number of lower and upper outliers in the column by checking which values have a modified Z-score below -3 or above 3, respectively. The results are printed for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12717ff1",
   "metadata": {},
   "source": [
    "The warning message you received indicates that some of the values in your data caused a division by zero or an invalid value when calculating the modified Z-score. This can happen if the median absolute deviation (MAD) is zero, which can occur if all values in a column are identical.\n",
    "\n",
    "To avoid this warning message, you can add a check to make sure that the MAD is not zero before calculating the modified Z-score. Here's an updated version of the code that includes this check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Select the columns you want to check for outliers\n",
    "# columns_to_trim = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# # Convert data to a numpy array if necessary\n",
    "# if not isinstance(X_train, np.ndarray):\n",
    "#     X_train = np.array(X_train)\n",
    "\n",
    "# # Calculate modified Z-score for each column\n",
    "# for i, col in enumerate(columns_to_trim):\n",
    "#     # Extract column values\n",
    "#     col_values = X_train[:, i]\n",
    "\n",
    "#     # Calculate median and MAD\n",
    "#     med = np.median(col_values)\n",
    "#     mad = np.median(np.abs(col_values - med))\n",
    "#     if mad == 0:\n",
    "#         mad = 1e-6  # Set MAD to a small non-zero value to avoid division by zero\n",
    "\n",
    "#     # Calculate modified Z-score\n",
    "#     z_score = 0.6745 * (col_values - med) / mad\n",
    "\n",
    "#     # Count number of lower and upper outliers\n",
    "#     lower_outliers = np.sum(z_score < -3)\n",
    "#     upper_outliers = np.sum(z_score > 3)\n",
    "\n",
    "#     # Print results\n",
    "#     print(col)\n",
    "#     print(f\"Number of lower outliers: {lower_outliers}\")\n",
    "#     print(f\"Number of upper outliers: {upper_outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d02f67",
   "metadata": {},
   "source": [
    "# identify outliers in train set using MAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630d62b9",
   "metadata": {},
   "source": [
    "If outliers are removed from the test set, the distribution of the test set may be different from that of the real-world data. This can lead to over-optimistic performance estimates on the test set, which may not generalize well to the real-world data.\n",
    "\n",
    "Therefore, it is important to identify and remove outliers only from the training set and not touch the test set. The model should be evaluated on the untouched test set, which should represent the real-world distribution of the data. By doing so, we can obtain unbiased performance estimates of the model on the real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Define the columns of interest\n",
    "columns_to_trim = ['amount', 'oldbalanceOrg', 'newbalanceOrig','oldbalanceDest', 'newbalanceDest']\n",
    "# Define the threshold for outliers\n",
    "threshold = 2\n",
    "# Loop over the columns of interest and calculate the number of outliers for each column in the train set\n",
    "for column in columns_to_trim:\n",
    "    # Calculate the median and MAD for the column in the train set\n",
    "    median_train = np.median(X_train[column])\n",
    "    abs_deviation_train = np.abs(X_train[column] - median_train)\n",
    "    mad_train = np.median(abs_deviation_train)\n",
    "    # Calculate the upper and lower thresholds based on the MAD\n",
    "    upper_threshold = median_train + threshold * mad_train\n",
    "    lower_threshold = median_train - threshold * mad_train\n",
    "    # Identify the number of outliers in the train set for each threshold\n",
    "    num_upper_outliers_train = np.sum(X_train[column] > upper_threshold)\n",
    "    num_lower_outliers_train = np.sum(X_train[column] < lower_threshold)\n",
    "    \n",
    "    print(f\"Number of upper outliers in {column} in train set:{num_upper_outliers_train}\")\n",
    "    print(f\"Number of lower outliers in {column} in train set:{num_lower_outliers_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Define the columns of interest\n",
    "# columns_to_trim = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# # Define the threshold for outliers\n",
    "# threshold = 2\n",
    "\n",
    "# # Loop over the columns of interest and calculate the number of outliers for each column in the train set\n",
    "# for column in columns_to_trim:\n",
    "#     # Calculate the median and MAD for the column in the train set\n",
    "#     median_train = np.median(X_train[column])\n",
    "#     abs_deviation_train = np.abs(X_train[column] - median_train)\n",
    "#     mad_train = np.median(abs_deviation_train)\n",
    "\n",
    "#     # Calculate the upper and lower thresholds based on the MAD\n",
    "#     upper_threshold = median_train + threshold * mad_train\n",
    "#     lower_threshold = median_train - threshold * mad_train\n",
    "\n",
    "#     # Identify the number of outliers in the train set for each threshold\n",
    "#     num_upper_outliers_train = np.sum(X_train[column] > upper_threshold)\n",
    "#     num_lower_outliers_train = np.sum(X_train[column] < lower_threshold)\n",
    "\n",
    "#     print(f\"Number of upper outliers in {column} in train set: {num_upper_outliers_train}\")\n",
    "#     print(f\"Number of lower outliers in {column} in train set: {num_lower_outliers_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c0b68",
   "metadata": {},
   "source": [
    "# Handle outliers-Trimmed mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7658be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # Define the fraction of data to trim from both ends\n",
    "# frac = 0.1\n",
    "\n",
    "# # Define the columns to apply the trimmed mean to\n",
    "# columns_to_trim = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "\n",
    "# # Split the dataset into training and test sets\n",
    "# #train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainbeforetrim.csv\", index=False)\n",
    "# X_test.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\testbeforetrim.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the trimmed range and mean for each column on the training set only\n",
    "# trimmed_ranges = {}\n",
    "# for col in columns_to_trim:\n",
    "#     trimmed_min = np.percentile(X_train[col], frac*100)\n",
    "#     trimmed_max = np.percentile(X_train[col], (1-frac)*100)\n",
    "#     trimmed_mean = np.mean(X_train[col][(X_train[col] >= trimmed_min) & (X_train[col] <= trimmed_max)])\n",
    "#     trimmed_ranges[col] = (trimmed_min, trimmed_max, trimmed_mean)\n",
    "\n",
    "# # Replace outliers with the trimmed mean on the training set\n",
    "# for col in columns_to_trim:\n",
    "#     X_train.loc[(X_train[col] < trimmed_ranges[col][0]), col] = trimmed_ranges[col][2]\n",
    "#     X_train.loc[(X_train[col] > trimmed_ranges[col][1]), col] = trimmed_ranges[col][2]\n",
    "\n",
    "# # Replace outliers with the trimmed mean on the test set\n",
    "# for col in columns_to_trim:\n",
    "#     X_test.loc[(X_test[col] < trimmed_ranges[col][0]), col] = trimmed_ranges[col][2]\n",
    "#     X_test.loc[(X_test[col] > trimmed_ranges[col][1]), col] = trimmed_ranges[col][2]\n",
    "\n",
    "# # Print the trimmed ranges and the first few rows of the training set with the trimmed columns\n",
    "# print(\"Trimmed Ranges:\")\n",
    "# for col in columns_to_trim:\n",
    "#     print(col, trimmed_ranges[col])\n",
    "# print(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a5cb4",
   "metadata": {},
   "source": [
    "How can I treat outliers without losing information?\n",
    "\n",
    "Treating outliers without losing information can be a challenging task, as outliers may contain important information about the underlying population. However, there are some methods that can be used to reduce the impact of outliers on the analysis while preserving the integrity of the data.\n",
    "\n",
    "One approach is to use robust statistics, which are less sensitive to outliers than their classical counterparts. For example, instead of using the regular mean, you could use a robust estimator of central tendency, such as the median or the trimmed mean, which discard a certain percentage of the data from both tails of the distribution.\n",
    "\n",
    "Another approach is to transform the data to make it more symmetric or to stabilize the variance. For example, you could use a logarithmic or a power transformation to reduce the effect of extreme values or use a Box-Cox transformation to find the optimal transformation for your data.\n",
    "\n",
    "A third approach is to use nonparametric methods, which do not make any assumptions about the underlying distribution of the data. For example, you could use nonparametric tests, such as the Wilcoxon rank-sum test or the Kruskal-Wallis test, which are less sensitive to outliers than their parametric counterparts.\n",
    "\n",
    "Finally, if the outliers are due to measurement error or other data quality issues, you may consider removing them from the analysis or imputing them using appropriate techniques, such as multiple imputation or mean substitution. However, it is important to carefully consider the impact of these approaches on the analysis and to report any assumptions or limitations associated with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f849504",
   "metadata": {},
   "source": [
    "However, it is important to keep in mind that using trimmed mean with bootstrap may result in loss of information and sensitivity to the choice of trimming percentage. Additionally, it may not be appropriate in certain situations, such as when the outliers are not due to measurement error or when they contain important information about the underlying population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd46810",
   "metadata": {},
   "source": [
    "# Estimate direction and proportion of trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44de088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from statsmodels.robust import mad\n",
    "# import numpy as np\n",
    "\n",
    "# # Specify columns with outliers\n",
    "# cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# # For each specified column, determine if symmetric or asymmetric trimming is appropriate and by what amount\n",
    "# for col_name in cols_with_outliers:\n",
    "#     # Calculate MAD for the column in the train set\n",
    "#     mad_train = mad(X_train[col_name])\n",
    "#     # Calculate median for the column in the train set\n",
    "#     median_train = np.median(X_train[col_name])\n",
    "    \n",
    "#     # Determine whether to use symmetric or asymmetric trimming for the column in the train set\n",
    "#     if mad_train > 0:\n",
    "#         left_trim_train = np.sum(X_train[col_name] < median_train - 2 * mad_train) / len(X_train[col_name])\n",
    "#         right_trim_train = np.sum(X_train[col_name] > median_train + 2 * mad_train) / len(X_train[col_name])\n",
    "        \n",
    "#         if left_trim_train == right_trim_train:\n",
    "#             print(f\"Symmetric trimming is appropriate for column {col_name} in the train set\")\n",
    "#         elif left_trim_train > right_trim_train:\n",
    "#             print(f\"Asymmetric trimming to the left by {left_trim_train:.2f}% is appropriate for column {col_name} in the train set\")\n",
    "#         else:\n",
    "#             print(f\"Asymmetric trimming to the right by {right_trim_train:.2f}% is appropriate for column {col_name} in the train set\")\n",
    "#     else:\n",
    "#         print(f\"No trimming is appropriate for column {col_name} in the train set\")\n",
    "\n",
    "#     # Calculate MAD for the column in the test set\n",
    "#     mad_test = mad(X_test[col_name])\n",
    "#     # Calculate median for the column in the test set\n",
    "#     median_test = np.median(X_test[col_name])\n",
    "    \n",
    "#     # Determine whether to use symmetric or asymmetric trimming for the column in the test set\n",
    "#     if mad_test > 0:\n",
    "#         left_trim_test = np.sum(X_test[col_name] < median_test - 2 * mad_test) / len(X_test[col_name])\n",
    "#         right_trim_test = np.sum(X_test[col_name] > median_test + 2 * mad_test) / len(X_test[col_name])\n",
    "        \n",
    "#         if left_trim_test == right_trim_test:\n",
    "#             print(f\"Symmetric trimming is appropriate for column {col_name} in the test set\")\n",
    "#         elif left_trim_test > right_trim_test:\n",
    "#             print(f\"Asymmetric trimming to the left by {left_trim_test:.2f}% is appropriate for column {col_name} in the test set\")\n",
    "#         else:\n",
    "#             print(f\"Asymmetric trimming to the right by {right_trim_test:.2f}% is appropriate for column {col_name} in the test set\")\n",
    "#     else:\n",
    "#         print(f\"No trimming is appropriate for column {col_name} in the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae54828",
   "metadata": {},
   "source": [
    "# Calculate value of trimmed mean with which to replace outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy library\n",
    "import numpy as np\n",
    "\n",
    "# # Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the number of bootstrapped samples to create per column\n",
    "num_samples = 50\n",
    "\n",
    "# Specify the trimming proportions for each column\n",
    "trim_props = {'amount': 0.2, 'oldbalanceOrg': 0.2, 'newbalanceOrig': 0.27, 'oldbalanceDest': 0.25, 'newbalanceDest': 0.29}\n",
    "\n",
    "# Initialize empty dictionaries to store the trimmed means for each column separately for the train and test set\n",
    "train_trimmed_means = {}\n",
    "#test_trimmed_means = {}\n",
    "\n",
    "# Loop over the specified columns\n",
    "for col_name in cols_with_outliers:\n",
    "    \n",
    "    # Initialize empty lists to store the bootstrapped samples and the trimmed means for the train and test set\n",
    "    train_bootstrapped_samples = []\n",
    "    #test_bootstrapped_samples = []\n",
    "    train_trimmed_means_list = []\n",
    "    #test_trimmed_means_list = []\n",
    "    \n",
    "      # Check if the trimming proportion for this column is 0\n",
    "    if trim_props[col_name] == 0:\n",
    "        # If so, skip this column and move on to the next one\n",
    "        continue\n",
    "    \n",
    "    # Loop over the number of desired samples\n",
    "    for i in range(num_samples):\n",
    "        # Randomly select indices from the column in the training set\n",
    "        train_sample_indices = np.random.choice(X_train.index, size=len(X_train), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the training set\n",
    "        # is a line of code that creates a bootstrapped sample for a particular column (col_name) in the training set.\n",
    "        train_sample = X_train.loc[train_sample_indices, col_name]\n",
    "        \n",
    "        # Randomly select indices from the column in the test set\n",
    "        #test_sample_indices = np.random.choice(X_test.index, size=len(X_test), replace=True)\n",
    "        \n",
    "        # Create a bootstrapped sample by indexing into the column with the selected indices for the test set\n",
    "        #test_sample = X_test.loc[test_sample_indices, col_name]\n",
    "        \n",
    "        # Append the bootstrapped samples to the list for the train and test set\n",
    "        train_bootstrapped_samples.append(train_sample)\n",
    "        #test_bootstrapped_samples.append(test_sample)\n",
    "        \n",
    "        # Calculate the trimmed mean of the bootstrapped sample for the train set\n",
    "        train_trimmed_mean = np.mean(train_sample[(train_sample >= np.percentile(train_sample, 100*trim_props[col_name])) & (train_sample <= np.percentile(train_sample, 100*(1-trim_props[col_name])))] )\n",
    "        train_trimmed_means_list.append(train_trimmed_mean)\n",
    "        \n",
    "        # Calculate the trimmed mean of the bootstrapped sample for the test set\n",
    "        #test_trimmed_mean = np.mean(test_sample[(test_sample >= np.percentile(test_sample, 100*trim_props[col_name])) & (test_sample <= np.percentile(test_sample, 100*(1-trim_props[col_name])))] )\n",
    "        #test_trimmed_means_list.append(test_trimmed_mean)\n",
    "\n",
    "    # Calculate the mean of the trimmed means for the train set and add it to the dictionary\n",
    "    train_trimmed_means[col_name] = np.mean(train_trimmed_means_list)\n",
    "    \n",
    "    # Calculate the mean of the trimmed means for the test set and add it to the dictionary\n",
    "    #test_trimmed_means[col_name] = np.mean(test_trimmed_means_list)\n",
    "    \n",
    "# Print the trimmed means for each column separately for the train and test set\n",
    "print(\"Train set trimmed means: \", train_trimmed_means)\n",
    "#print(\"Test set trimmed means: \", test_trimmed_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d88c46",
   "metadata": {},
   "source": [
    "# Perform asymmetric trimming based on bootstrapped trimmed mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Specify columns with outliers\n",
    "cols_with_outliers = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Specify the trimming proportions for each column\n",
    "trim_props = {'amount': 0.2, 'oldbalanceOrg': 0.00, 'newbalanceOrig': 0.3, 'oldbalanceDest': 0.27, 'newbalanceDest': 0.3}\n",
    "\n",
    "# Sort the training set by each column\n",
    "sorted_train = X_train.sort_values(by=cols_with_outliers)\n",
    "\n",
    "# Replace the upper-end outliers with the trimmed means\n",
    "for col_name in cols_with_outliers:\n",
    "    if trim_props[col_name] == 0:\n",
    "        continue\n",
    "    upper_percentile = np.percentile(sorted_train[col_name], 100*(1-trim_props[col_name]))\n",
    "    lower_percentile = np.percentile(sorted_train[col_name], trim_props[col_name]*100)\n",
    "    trimmed_mean = train_trimmed_means[col_name]\n",
    "    \n",
    "    #Symmetric trimming for amount\n",
    "    if col_name == 'amount':\n",
    "        sorted_train[col_name] = np.where(sorted_train[col_name] > upper_percentile, trimmed_mean, sorted_train[col_name])\n",
    "        sorted_train[col_name] = np.where(sorted_train[col_name] < lower_percentile, trimmed_mean, sorted_train[col_name])\n",
    "    else:\n",
    "        sorted_train[col_name] = np.where(sorted_train[col_name] > upper_percentile, trimmed_mean, sorted_train[col_name])\n",
    "\n",
    "# Reorder the rows in the training set to their original order\n",
    "X_train = sorted_train.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358784f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # save the trimmed train to new files\n",
    "X_train.to_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\trainAFTERHANDLINGOUTLIERS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d40270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the columns of interest\n",
    "columns_to_trim = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "# Define the threshold for outliers\n",
    "threshold = 2\n",
    "\n",
    "# Loop over the columns of interest and calculate the number of outliers for each column in the train set\n",
    "for column in columns_to_trim:\n",
    "    # Calculate the median and MAD for the column in the train set\n",
    "    median_train = np.median(X_train[column])\n",
    "    abs_deviation_train = np.abs(X_train[column] - median_train)\n",
    "    mad_train = np.median(abs_deviation_train)\n",
    "\n",
    "    # Calculate the upper and lower thresholds based on the MAD\n",
    "    upper_threshold = median_train + threshold * mad_train\n",
    "    lower_threshold = median_train - threshold * mad_train\n",
    "\n",
    "    # Identify the number of outliers in the train set for each threshold\n",
    "    num_upper_outliers_train = np.sum(X_train[column] > upper_threshold)\n",
    "    num_lower_outliers_train = np.sum(X_train[column] < lower_threshold)\n",
    "\n",
    "    print(f\"Number of upper outliers in {column} in train set: {num_upper_outliers_train}\")\n",
    "    print(f\"Number of lower outliers in {column} in train set: {num_lower_outliers_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd9e65",
   "metadata": {},
   "source": [
    "# To calculate bootstrap confidence interval & p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f6d96",
   "metadata": {},
   "source": [
    "# Handle outliers-Winsorized bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafd6cd5",
   "metadata": {},
   "source": [
    "# Feature Selection-It is generally recommended to perform feature selection after splitting the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00cbc99",
   "metadata": {},
   "source": [
    "Yes, you should perform feature selection on your training set, not on your test set. The purpose of feature selection is to identify a subset of features that are most relevant to predicting the target variable, which can help to improve model performance and reduce overfitting.\n",
    "\n",
    "If you perform feature selection on your test set, you risk overfitting to the test set and introducing bias into your model. This is because the test set should be used solely for evaluating model performance, not for making decisions about which features to include in your model.\n",
    "\n",
    "Instead, you should split your data into training and test sets, perform feature selection on the training set, and then use the selected features to train your model on the training set. You can then evaluate the performance of your model on the test set to see how well it generalizes to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2b891",
   "metadata": {},
   "source": [
    "# Feature Selection using random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35692974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234dea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier and fit it to the training data\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances from the random forest\n",
    "importances = rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23733dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the features in decreasing order of importance\n",
    "indices = importances.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5dc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names and importance scores in two separate arrays\n",
    "feature_names = X_train.columns\n",
    "feature_importances = importances[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca7e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative importance scores\n",
    "cumulative_importances = np.cumsum(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variable importance scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(feature_importances)), feature_importances, align='center')\n",
    "plt.xticks(range(len(feature_importances)), feature_names[indices], rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Variable Importance - Mean Decrease in Gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8018c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative importance scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(feature_importances)), cumulative_importances)\n",
    "plt.xticks(range(len(feature_importances)), feature_names[indices], rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Cumulative Importance Score')\n",
    "plt.title('Cumulative Variable Importance - Mean Decrease in Gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean decrease in accuracy for each feature\n",
    "perm_importances = rfc.feature_importances_\n",
    "perm_scores = []\n",
    "for i in X_train.columns:\n",
    "    X_train_perm = X_train.copy()\n",
    "    X_train_perm[i] = np.random.permutation(X_train_perm[i])\n",
    "    perm_score = rfc.score(X_train_perm, y_train)\n",
    "    perm_scores.append(perm_score)\n",
    "    \n",
    "mean_decrease_accuracy = np.array(perm_scores) - rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the features in decreasing order of importance\n",
    "indices = mean_decrease_accuracy.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names and importance scores in two separate arrays\n",
    "feature_names = X_train.columns\n",
    "feature_importances = mean_decrease_accuracy[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb5632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative importance scores\n",
    "cumulative_importances = np.cumsum(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variable importance scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(feature_importances)), feature_importances, align='center')\n",
    "plt.xticks(range(len(feature_importances)), feature_names[indices], rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Variable Importance - Mean Decrease in Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdca1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative importance scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(feature_importances)), cumulative_importances)\n",
    "plt.xticks(range(len(feature_importances)), feature_names[indices], rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Cumulative Importance Score')\n",
    "plt.title('Cumulative Variable Importance - Mean Decrease in Accuracy')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ba9eb",
   "metadata": {},
   "source": [
    "# Feature selection using Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771a91f",
   "metadata": {},
   "source": [
    "# Feature selection using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484591bf",
   "metadata": {},
   "source": [
    "# Handle class imbalance during training using threshold moving algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1218c17",
   "metadata": {},
   "source": [
    "# Cost Sensitive Learning to handle class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b72457",
   "metadata": {},
   "source": [
    "### Even with random forest, I can use feature selection as we have irrelevant features like Customer ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
