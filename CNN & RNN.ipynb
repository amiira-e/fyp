{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2bbe5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca576dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949ab2e",
   "metadata": {},
   "source": [
    "## Separate remaining data into transfer learning data and Out-sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23377b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def reservoir_sampling(iterable, k, header=True):\n",
    "    reservoir = []\n",
    "    for i, item in enumerate(iterable):\n",
    "        if i < k:\n",
    "            reservoir.append(item)\n",
    "        else:\n",
    "            j = random.randint(0, i)\n",
    "            if j < k:\n",
    "                reservoir[j] = item\n",
    "    return reservoir\n",
    "\n",
    "# Open the input CSV file\n",
    "with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\FraudDetectionData.csv\") as f:\n",
    "    # Check if header line exists\n",
    "    header = True\n",
    "    first_line = f.readline()\n",
    "    if not first_line.startswith('step,type,amount,nameOrig,oldbalanceOrg,newbalanceOrig,nameDest,oldbalanceDest,newbalanceDest,isFraud,isFlaggedFraud'):\n",
    "        header = False\n",
    "        f.seek(0)  # Rewind file pointer to beginning\n",
    "\n",
    "    # Sample from remaining lines\n",
    "    sampled_lines = reservoir_sampling(f, k=2500000, header=header)\n",
    "\n",
    "# Open the output CSV file and write the subsample to it\n",
    "with open(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\transfer_learning.csv\", mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    if header:\n",
    "        writer.writerow(first_line.strip().split(','))\n",
    "    for line in sampled_lines:\n",
    "        writer.writerow(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329a5aa",
   "metadata": {},
   "source": [
    "## Pre-process larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ed453d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_big=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\transfer_learning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "caf9f6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 11)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_big.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "846a5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample_big['type'])\n",
    "label\n",
    "df_sample_big.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample_big[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample_big['nameDest'])\n",
    "label\n",
    "df_sample_big.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample_big[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample_big['nameOrig'])\n",
    "label\n",
    "df_sample_big.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample_big[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a4fdb235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.9987\n",
      "1    0.0013\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.9987\n",
      "1    0.0013\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.9987\n",
      "1    0.0013\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample_big.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample_big['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "865f7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4a30f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f1a4de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e882ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b1506ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1561314, 10)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8027782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step         amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0         256  107845.070000   48043.992650             0.0    15386.950991   \n",
      "1          95   36629.510000    6309.610000             0.0        0.000000   \n",
      "2         282   14903.000000       0.000000             0.0        0.000000   \n",
      "3         133   51303.560000       0.000000             0.0    15386.950991   \n",
      "4         371  121823.470000   67062.000000             0.0    15386.950991   \n",
      "...       ...            ...            ...             ...             ...   \n",
      "1561309   236  121823.470000   48043.992650             0.0        0.000000   \n",
      "1561310   434  121823.470000   48043.992650             0.0    15386.950991   \n",
      "1561311   149  312745.914508   48043.992650             0.0        0.000000   \n",
      "1561312   274   19410.857831   19410.857831             0.0        0.000000   \n",
      "1561313   381  121823.470000   48043.992650             0.0        0.000000   \n",
      "\n",
      "         newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "0            160264.125               0     1  205458.0     30107  \n",
      "1                 0.000               0     3  294208.5    554354  \n",
      "2                 0.000               0     3  294208.5    830243  \n",
      "3            160264.125               0     1  222216.0    261861  \n",
      "4            160264.125               0     1  114115.0    900673  \n",
      "...                 ...             ...   ...       ...       ...  \n",
      "1561309           0.000               0     1  135650.0   1195993  \n",
      "1561310      160264.125               0     1  104679.0    398524  \n",
      "1561311           0.000               0     1  194199.0    681616  \n",
      "1561312           0.000               0     1  313616.0    923295  \n",
      "1561313           0.000               0     1  107470.0    872771  \n",
      "\n",
      "[1561314 rows x 10 columns]\n",
      "         step     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "2327183   188   37915.51           0.00             0.0       131079.93   \n",
      "2115284   331  141048.53       20063.00             0.0       131079.93   \n",
      "524689    394   51139.01           0.00             0.0       131079.93   \n",
      "187448    256  102696.12           0.00             0.0       278610.52   \n",
      "1450539   140  112284.98       14452.34             0.0            0.00   \n",
      "...       ...        ...            ...             ...             ...   \n",
      "1280245   135    5240.02       16374.00             0.0            0.00   \n",
      "381930    212   74581.47           0.00             0.0       131079.93   \n",
      "1936943   302   74581.47       14452.34             0.0            0.00   \n",
      "2315369   188   36646.93       14452.34             0.0       131079.93   \n",
      "1833654   163   19823.39           0.00             0.0            0.00   \n",
      "\n",
      "         newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "2327183       213184.43               0     1    409381    890858  \n",
      "2115284       213184.43               0     1    413011   1323909  \n",
      "524689        609318.76               0     1     48816    575330  \n",
      "187448        381306.64               0     1    338051   1703093  \n",
      "1450539       112284.98               0     1    418121     18729  \n",
      "...                 ...             ...   ...       ...       ...  \n",
      "1280245            0.00               0     3    339464   1304309  \n",
      "381930        213184.43               0     1    340614   1104868  \n",
      "1936943       289103.28               0     1    334127    113588  \n",
      "2315369       213184.43               0     0    423613   1008077  \n",
      "1833654            0.00               0     3    339464   1059589  \n",
      "\n",
      "[250000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# convert X_test to a pandas dataframe\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "# define a function to replace outliers with MAD for a single column\n",
    "def replace_outliers_with_mad(column):\n",
    "    median = np.median(column)\n",
    "    mad = np.median(np.abs(column - median))\n",
    "    threshold = 2.5 * mad\n",
    "    column[np.abs(column - median) > threshold] = median\n",
    "    return column\n",
    "\n",
    "# apply the function to all columns of X_train_resampled_final\n",
    "for i in range(X_train_resampled_final.shape[1]):\n",
    "    X_train_resampled_final.iloc[:, i] = replace_outliers_with_mad(X_train_resampled_final.iloc[:, i])\n",
    "\n",
    "# apply the function to all columns of X_test\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test.iloc[:, i] = replace_outliers_with_mad(X_test.iloc[:, i])\n",
    "\n",
    "# convert the numpy arrays back to pandas dataframes\n",
    "X_train_resampled_final = pd.DataFrame(X_train_resampled_final, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "\n",
    "# print the modified dataframes\n",
    "print(X_train_resampled_final)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9ca43564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5dd34545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "da522fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_big = df_sample_big.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1c38e",
   "metadata": {},
   "source": [
    "### Big dataset: Pre-train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0384fea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015B9596CC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015B9596CC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015B9596CC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6822/6822 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9195WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000015B81CD0318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000015B81CD0318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000015B81CD0318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6822/6822 [==============================] - 24s 3ms/step - loss: 0.1820 - accuracy: 0.9195 - val_loss: 0.1474 - val_accuracy: 0.9350\n",
      "Epoch 2/10\n",
      "6822/6822 [==============================] - 23s 3ms/step - loss: 0.1353 - accuracy: 0.9416 - val_loss: 0.1279 - val_accuracy: 0.9443\n",
      "Epoch 3/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.1199 - accuracy: 0.9502 - val_loss: 0.1139 - val_accuracy: 0.9545\n",
      "Epoch 4/10\n",
      "6822/6822 [==============================] - 22s 3ms/step - loss: 0.1092 - accuracy: 0.9564 - val_loss: 0.1065 - val_accuracy: 0.9582\n",
      "Epoch 5/10\n",
      "6822/6822 [==============================] - 22s 3ms/step - loss: 0.1025 - accuracy: 0.9600 - val_loss: 0.1007 - val_accuracy: 0.9617\n",
      "Epoch 6/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.0966 - accuracy: 0.9632 - val_loss: 0.0944 - val_accuracy: 0.9641\n",
      "Epoch 7/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.0923 - accuracy: 0.9656 - val_loss: 0.0905 - val_accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "6822/6822 [==============================] - 22s 3ms/step - loss: 0.0889 - accuracy: 0.9669 - val_loss: 0.0894 - val_accuracy: 0.9654\n",
      "Epoch 9/10\n",
      "6822/6822 [==============================] - 24s 4ms/step - loss: 0.0861 - accuracy: 0.9683 - val_loss: 0.0853 - val_accuracy: 0.9693\n",
      "Epoch 10/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.0840 - accuracy: 0.9695 - val_loss: 0.0829 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 elapsed time: 221.80 seconds\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015B8212BC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015B8212BC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015B8212BC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6815/6822 [============================>.] - ETA: 0s - loss: 0.1817 - accuracy: 0.9191WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000015B96C2E318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000015B96C2E318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000015B96C2E318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.1816 - accuracy: 0.9191 - val_loss: 0.1436 - val_accuracy: 0.9368\n",
      "Epoch 2/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.1352 - accuracy: 0.9412 - val_loss: 0.1239 - val_accuracy: 0.9470\n",
      "Epoch 3/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.1191 - accuracy: 0.9502 - val_loss: 0.1119 - val_accuracy: 0.9545\n",
      "Epoch 4/10\n",
      "6822/6822 [==============================] - 22s 3ms/step - loss: 0.1090 - accuracy: 0.9556 - val_loss: 0.1033 - val_accuracy: 0.9593\n",
      "Epoch 5/10\n",
      "6822/6822 [==============================] - 20s 3ms/step - loss: 0.1014 - accuracy: 0.9600 - val_loss: 0.0976 - val_accuracy: 0.9627\n",
      "Epoch 6/10\n",
      "6822/6822 [==============================] - 22s 3ms/step - loss: 0.0960 - accuracy: 0.9632 - val_loss: 0.0928 - val_accuracy: 0.9639\n",
      "Epoch 7/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.0918 - accuracy: 0.9655 - val_loss: 0.0883 - val_accuracy: 0.9669\n",
      "Epoch 8/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.0885 - accuracy: 0.9669 - val_loss: 0.0861 - val_accuracy: 0.9677\n",
      "Epoch 9/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.0858 - accuracy: 0.9681 - val_loss: 0.0844 - val_accuracy: 0.9690\n",
      "Epoch 10/10\n",
      "6822/6822 [==============================] - 21s 3ms/step - loss: 0.0837 - accuracy: 0.9693 - val_loss: 0.0814 - val_accuracy: 0.9705\n",
      "Fold 2 elapsed time: 211.19 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define number of folds for cross-validation\n",
    "num_folds = 2\n",
    "\n",
    "# create KFold cross-validation object\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# create arrays to store training and validation loss for each epoch\n",
    "train_losses = np.zeros((num_folds, 10))\n",
    "val_losses = np.zeros((num_folds, 10))\n",
    "\n",
    "import time\n",
    "\n",
    "# loop over the folds\n",
    "fold_no = 1\n",
    "for train, val in kfold.split(X_train_resampled_final, y_train_resampled_final):\n",
    "    \n",
    "    # To add window\n",
    "    # pre_trained_model.add(Conv1D(filters=32, (3,3)), input_shape=)\n",
    "    \n",
    "    # Can add Activation layer before Pooling layer\n",
    "    # pre_trained_model.add(Activation(\"relu\"))\n",
    "    \n",
    "    # create model\n",
    "    pre_trained_model = Sequential()\n",
    "    # add convolutional layer\n",
    "    # pre_trained_model.add(Conv1D(filters=32, kernel_size=3, activation='tanh', input_shape=(10, 1)))\n",
    "    # pre_trained_model.add(Conv1D(filters=32, kernel_size=3, activation='tanh', input_shape=(10, 1), data_format='channels_last'))\n",
    "\n",
    "    pre_trained_model.add(Conv1D(filters=40, kernel_size=4, activation='relu', input_shape=(10, 1)))\n",
    "\n",
    "\n",
    "    # add pooling layer\n",
    "    pre_trained_model.add(MaxPooling1D(pool_size=2))\n",
    "    # flatten output to feed into fully connected layer\n",
    "    pre_trained_model.add(Flatten()) \n",
    "    # add fully connected layer\n",
    "    pre_trained_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    opt_new = Adam(lr=0.00033)\n",
    "    # compile model\n",
    "    pre_trained_model.compile(loss='binary_crossentropy', optimizer=opt_new, metrics=['accuracy'])\n",
    "    \n",
    "    # record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # train model for each fold\n",
    "    history = pre_trained_model.fit(X_train_resampled_final[train], y_train_resampled_final[train],\n",
    "                                     epochs=10, batch_size=32, validation_data=(X_train_resampled_final[val], y_train_resampled_final[val]))\n",
    "    \n",
    "    # record end time and calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f'Fold {fold_no} elapsed time: {elapsed_time:.2f} seconds')\n",
    "    \n",
    "    # store training and validation loss for each epoch\n",
    "    train_losses[fold_no-1] = history.history['loss']\n",
    "    val_losses[fold_no-1] = history.history['val_loss']\n",
    "    \n",
    "    # increment fold number\n",
    "    fold_no += 1\n",
    "    \n",
    "# # calculate mean training and validation loss across all folds for each epoch\n",
    "# mean_train_loss = np.mean(train_losses, axis=0)\n",
    "# mean_val_loss = np.mean(val_losses, axis=0)\n",
    "\n",
    "# # plot training and validation loss curves for each epoch\n",
    "# plt.plot(mean_train_loss, label='Training Loss')\n",
    "# plt.plot(mean_val_loss, label='Validation Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f263b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.save('pre_trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8e673e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "pre_trained_model = load_model('pretrained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7f0d0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 8, 32)             128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 4, 32)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 257\n",
      "Trainable params: 257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "print(pre_trained_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1728b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Conv1D, LSTM, Dense, Activation\n",
    "# from keras.models import Model\n",
    "\n",
    "# # Define input shape\n",
    "# n_features = F.shape[1]  # number of input features\n",
    "# input_shape = (None, n_features)\n",
    "\n",
    "# # Define input layer\n",
    "# inputs = Input(shape=input_shape)\n",
    "\n",
    "# # Define autoencoder to encode input features\n",
    "# encoded_features = []\n",
    "# for i in range(n_features):\n",
    "#     feature_input = Input(shape=(1,))\n",
    "#     encoded = Dense(32, activation='relu')(feature_input)\n",
    "#     decoded = Dense(1, activation='linear')(encoded)\n",
    "#     autoencoder = Model(feature_input, decoded)\n",
    "#     autoencoder.compile(optimizer='adam', loss='mse')\n",
    "#     autoencoder.fit(F[:,i], F[:,i], epochs=10, batch_size=32)\n",
    "#     encoded_feature_i = autoencoder.encoder(F[:,i])\n",
    "#     encoded_features.append(encoded_feature_i)\n",
    "\n",
    "# # Add a CNN layer for each encoded feature\n",
    "# cnn_features = []\n",
    "# for i in range(n_features):\n",
    "#     cnn_i = Conv1D(filters=32, kernel_size=3, padding='same')(encoded_features[i])\n",
    "#     cnn_features.append(cnn_i)\n",
    "\n",
    "# # Concatenate the CNN features\n",
    "# concatenated_features = keras.layers.concatenate(cnn_features, axis=2)\n",
    "\n",
    "# # LSTM layer to capture temporal dependencies\n",
    "# lstm_features = []\n",
    "# for i in range(n_features):\n",
    "#     lstm_i = LSTM(units=64, return_sequences=True)(concatenated_features[:, :, i])\n",
    "#     lstm_features.append(lstm_i)\n",
    "\n",
    "# # Concatenate the LSTM features\n",
    "# concatenated_lstm = keras.layers.concatenate(lstm_features, axis=2)\n",
    "\n",
    "# # Fully connected layer with ReLU activation function\n",
    "# fc_layer = Dense(units=128, activation='relu')(concatenated_lstm)\n",
    "\n",
    "# # Output layer with sigmoid activation function\n",
    "# output_layer = Dense(units=1, activation='sigmoid')(fc_layer)\n",
    "\n",
    "# # Define model\n",
    "# model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "# # Compile model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train model\n",
    "# model.fit(x_train, y_train, epochs=1, batch_size=32)\n",
    "\n",
    "# # Evaluate model\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "# from sklearn.model_selection import KFold\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # define number of folds for cross-validation\n",
    "# num_folds = 3\n",
    "\n",
    "# # create KFold cross-validation object\n",
    "# kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# # create arrays to store training and validation loss for each epoch\n",
    "# train_losses = np.zeros((num_folds, 10))\n",
    "# val_losses = np.zeros((num_folds, 10))\n",
    "\n",
    "# import time\n",
    "\n",
    "# # loop over the folds\n",
    "# fold_no = 1\n",
    "# for train, val in kfold.split(X_train_resampled_final, y_train_resampled_final):\n",
    "    \n",
    "#     # create model\n",
    "#     pre_trained_model = Sequential()\n",
    "#     # add convolutional layer\n",
    "#     pre_trained_model.add(Conv1D(filters=32, kernel_size=3, activation='tanh', input_shape=(10, 1)))\n",
    "#     # add pooling layer\n",
    "#     pre_trained_model.add(MaxPooling1D(pool_size=2))\n",
    "#     # flatten output to feed into fully connected layer\n",
    "#     pre_trained_model.add(Flatten())\n",
    "#     # add fully connected layer\n",
    "#     pre_trained_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     opt_new = Adam(lr=0.00033)\n",
    "#     # compile model\n",
    "#     pre_trained_model.compile(loss='binary_crossentropy', optimizer=opt_new, metrics=['accuracy'])\n",
    "    \n",
    "#     # record start time\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     # train model for each fold\n",
    "#     history = pre_trained_model.fit(X_train_resampled_final[train], y_train_resampled_final[train],\n",
    "#                                      epochs=10, batch_size=32, validation_data=(X_train_resampled_final[val], y_train_resampled_final[val]))\n",
    "    \n",
    "#     # record end time and calculate elapsed time\n",
    "#     end_time = time.time()\n",
    "#     elapsed_time = end_time - start_time\n",
    "    \n",
    "#     print(f'Fold {fold_no} elapsed time: {elapsed_time:.2f} seconds')\n",
    "    \n",
    "#     # store training and validation loss for each epoch\n",
    "#     train_losses[fold_no-1] = history.history['loss']\n",
    "#     val_losses[fold_no-1] = history.history['val_loss']\n",
    "    \n",
    "#     # increment fold number\n",
    "#     fold_no += 1\n",
    "    \n",
    "# # calculate mean training and validation loss across all folds for each epoch\n",
    "# mean_train_loss = np.mean(train_losses, axis=0)\n",
    "# mean_val_loss = np.mean(val_losses, axis=0)\n",
    "\n",
    "# # plot training and validation loss curves for each epoch\n",
    "# plt.plot(mean_train_loss, label='Training Loss')\n",
    "# plt.plot(mean_val_loss, label='Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7bd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# # create model\n",
    "# pre_trained_model = Sequential()\n",
    "# # add convolutional layer\n",
    "# pre_trained_model.add(Conv1D(filters=32, kernel_size=3, activation='tanh', input_shape=(10, 1)))\n",
    "# # add pooling layer\n",
    "# pre_trained_model.add(MaxPooling1D(pool_size=2))\n",
    "# # flatten output to feed into fully connected layer\n",
    "# pre_trained_model.add(Flatten())\n",
    "# # add fully connected layer\n",
    "# pre_trained_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# opt_new=Adam(lr=0.00033)\n",
    "# # compile model\n",
    "# pre_trained_model.compile(loss='binary_crossentropy', optimizer=opt_new, metrics=['accuracy'])\n",
    "\n",
    "# # train model\n",
    "# pre_trained_model.fit(X_train_resampled_final, y_train_resampled_final, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f73a8",
   "metadata": {},
   "source": [
    "## Go back to smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c088a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_sample=pd.read_csv(r\"C:\\Users\\23059\\OneDrive\\Desktop\\Amiira\\Y3S1\\fyp\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7f2bdbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "837a8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['type'])\n",
    "label\n",
    "df_sample.drop(\"type\", axis=1, inplace=True)\n",
    "df_sample[\"type\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameDest'])\n",
    "label\n",
    "df_sample.drop(\"nameDest\", axis=1, inplace=True)\n",
    "df_sample[\"nameDest\"] = label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(df_sample['nameOrig'])\n",
    "label\n",
    "df_sample.drop(\"nameOrig\", axis=1, inplace=True)\n",
    "df_sample[\"nameOrig\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "036edbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n",
      "0    0.998743\n",
      "1    0.001257\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample.drop('isFraud', axis=1)\n",
    "# Separate the target variable\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Print class distribution before split\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X contains your features and y contains your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=2)\n",
    "\n",
    "# Print class distribution after split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "39800044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Upsampling via SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=0)\n",
    "\n",
    "#Downsample via RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.4, random_state=0)\n",
    "\n",
    "#Application of the resampling methods\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d689efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Resample using TomekLinks first\n",
    "tomek_links = TomekLinks(sampling_strategy='majority')\n",
    "X_train_resampled, y_train_resampled = tomek_links.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6fbaa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours,OneSidedSelection\n",
    "# resample the output of TomekLinks using EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_resampled_new, y_train_resampled_new = enn.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d6b3ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import OneSidedSelection\n",
    "# resample the output of EditedNearestNeighbours using One-Sided Selection\n",
    "oss = OneSidedSelection(sampling_strategy='majority')\n",
    "X_train_resampled_final, y_train_resampled_final = oss.fit_resample(X_train_resampled_new, y_train_resampled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "29beb78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        step         amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0        276  293528.440000   41298.000000             0.0         8620.05   \n",
      "1        138   44423.330000   41298.000000             0.0         8620.05   \n",
      "2        325  121966.869065    4564.000000             0.0         8620.05   \n",
      "3        308  300712.340000   51474.000000             0.0         8620.05   \n",
      "4        349   47243.760000   11262.000000             0.0            0.00   \n",
      "...      ...            ...            ...             ...             ...   \n",
      "423664   276  111168.880136  111168.880136             0.0         8620.05   \n",
      "423665   274  121966.869065   41298.000000             0.0         8620.05   \n",
      "423666    60  121966.869065   41298.000000             0.0            0.00   \n",
      "423667   449   44882.356239   44882.356239             0.0            0.00   \n",
      "423668   220   39953.091459   29059.334627             0.0         8620.05   \n",
      "\n",
      "        newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "0          3848.800000               0     0    104685    474552  \n",
      "1        153279.760000               0     0     92881    180374  \n",
      "2        153279.760000               0     1     80756    482539  \n",
      "3        153279.760000               0     1    175711    597630  \n",
      "4             0.000000               0     3    169128     26253  \n",
      "...                ...             ...   ...       ...       ...  \n",
      "423664   153279.760000               0     1     90379    472585  \n",
      "423665   153279.760000               0     1    112071    494845  \n",
      "423666        0.000000               0     1    154830    240268  \n",
      "423667    36237.626509               0     1    122579     88980  \n",
      "423668   153279.760000               0     1     93537    130866  \n",
      "\n",
      "[423669 rows x 10 columns]\n",
      "         step     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "485376  278.0   22928.58            0.0             0.0           0.000   \n",
      "642214   45.0    8606.90         5764.0             0.0           0.000   \n",
      "192982  237.0  220046.83            0.0             0.0      130797.505   \n",
      "99091   328.0   83938.53        13653.5             0.0      130797.505   \n",
      "203398  307.0   74636.86            0.0             0.0      130797.505   \n",
      "...       ...        ...            ...             ...             ...   \n",
      "230877  154.0  195805.05        31725.0             0.0           0.000   \n",
      "315026  301.0   36352.03        13653.5             0.0           0.000   \n",
      "661254  238.5  163969.90        13653.5             0.0      130797.505   \n",
      "688112  280.0    3092.79            0.0             0.0           0.000   \n",
      "642560   35.0   74636.86        30807.0             0.0      130797.505   \n",
      "\n",
      "        newbalanceDest  isFlaggedFraud  type  nameDest  nameOrig  \n",
      "485376           0.000               0     3    291184    424837  \n",
      "642214           0.000               0     3    363649    442961  \n",
      "192982      214326.245               0     1      1853    410946  \n",
      "99091       537297.070               0     0    252825    347652  \n",
      "203398      214326.245               0     1    201182    417173  \n",
      "...                ...             ...   ...       ...       ...  \n",
      "230877      195805.050               0     1    181881    192704  \n",
      "315026           0.000               0     3    458861    630843  \n",
      "661254      706564.020               0     0     37270    676511  \n",
      "688112           0.000               0     3    455345    152073  \n",
      "642560      214326.245               0     1    214954    689599  \n",
      "\n",
      "[70000 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23059\\anaconda3\\envs\\test2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# convert X_test to a pandas dataframe\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "# define a function to replace outliers with MAD for a single column\n",
    "def replace_outliers_with_mad(column):\n",
    "    median = np.median(column)\n",
    "    mad = np.median(np.abs(column - median))\n",
    "    threshold = 2.5 * mad\n",
    "    column[np.abs(column - median) > threshold] = median\n",
    "    return column\n",
    "\n",
    "# apply the function to all columns of X_train_resampled_final\n",
    "for i in range(X_train_resampled_final.shape[1]):\n",
    "     X_train_resampled_final.iloc[:, i] = replace_outliers_with_mad(X_train_resampled_final.iloc[:, i])\n",
    "   # X_train_resampled_final[:, i] = replace_outliers_with_mad(X_train_resampled_final[:, i])\n",
    "\n",
    "# apply the function to all columns of X_test\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test.iloc[:, i] = replace_outliers_with_mad(X_test.iloc[:, i])\n",
    "\n",
    "# convert the numpy arrays back to pandas dataframes\n",
    "X_train_resampled_final = pd.DataFrame(X_train_resampled_final, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "\n",
    "# print the modified dataframes\n",
    "print(X_train_resampled_final)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0811d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_train_resampled_final)\n",
    "X_train_resampled_final = model.transform(X_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ed77df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(X_test)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511d411",
   "metadata": {},
   "source": [
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "61c62a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# encoding_dim = 10\n",
    "# num_hidden = 10\n",
    "# num_features = 10\n",
    "# num_filters = 16\n",
    "# num_units = 32\n",
    "\n",
    "# # Define the autoencoder to encode each feature\n",
    "# input_shape = (10,)  # N is the number of input features\n",
    "\n",
    "# encoder = tf.keras.layers.Dense(units=10, activation='relu', input_shape=input_shape)\n",
    "# first_hidden_layer = tf.keras.layers.Dense(units=6, activation='relu')\n",
    "# decoder = tf.keras.layers.Dense(units=10, activation='sigmoid')\n",
    "\n",
    "# autoencoder = tf.keras.Sequential([encoder, first_hidden_layer, decoder])\n",
    "\n",
    "# # Load the pre-trained CNN\n",
    "# CNN = tf.keras.models.load_model('pre_trained_model.h5')\n",
    "\n",
    "# # Freeze all layers in CNN\n",
    "# CNN.trainable = False\n",
    "\n",
    "# V = np.zeros((num_features, num_hidden))\n",
    "# # V =np.zeros ((32, 10, 10))\n",
    "\n",
    "# for i in range(num_features):\n",
    "#     #V[i] = encoder.predict(X_train_resampled_final[i:i+1])[0]\n",
    "#     V[i] = autoencoder.predict(X_train_resampled_final[i:i+1])[0][0:encoding_dim]\n",
    "#     print(\"value:\", V[i])\n",
    "# # V = np.expand_dims(V, axis=-1)  # Add a new dimension to V\n",
    "# C = CNN(V)\n",
    "# C = np.expand_dims(C, axis=0)  # Add a new dimension to C\n",
    "# C = np.repeat(C, num_features, axis=0)  # Repeat C num_features times\n",
    "# print(\"C:\" , C.shape) # C: (10, 1)\n",
    "\n",
    "# # Define the LSTM layer with the appropriate input shape\n",
    "# LSTM = tf.keras.layers.LSTM(units=num_units, use_bias=True, kernel_initializer=\"glorot_uniform\", input_shape=(1, num_hidden))\n",
    "\n",
    "# # Reshape V to have shape (num_features, 1, num_hidden) to add the timesteps dimension\n",
    "# V = np.reshape(V, (num_features, 1, num_hidden))\n",
    "\n",
    "# # Pass the vector representations through the LSTM layer\n",
    "# O = LSTM(V)\n",
    "\n",
    "# # Define the final classification layer\n",
    "# FL = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "# # Connect it to the output of the LSTM layer\n",
    "# O = FL(O)\n",
    "\n",
    "\n",
    "# # # Define the model and compile it\n",
    "# # model = tf.keras.models.Model(inputs=encoder.input, outputs=O)\n",
    "# # model.build((None, num_features, num_hidden))\n",
    "# # model.compile(optimizer=optimizer, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "16873b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015B932DD438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015B932DD438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015B932DD438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "encoding_dim = 10\n",
    "num_hidden = 10\n",
    "num_features = 10\n",
    "num_filters = 16\n",
    "num_units = 32\n",
    "\n",
    "# Define the autoencoder to encode each feature\n",
    "input_shape = (10,)  # N is the number of input features\n",
    "\n",
    "encoder = tf.keras.layers.Dense(units=10, activation='relu', input_shape=input_shape)\n",
    "first_hidden_layer = tf.keras.layers.Dense(units=6, activation='relu')\n",
    "decoder = tf.keras.layers.Dense(units=10, activation='sigmoid')\n",
    "\n",
    "autoencoder = tf.keras.Sequential([encoder, first_hidden_layer, decoder])\n",
    "\n",
    "# Load the pre-trained CNN\n",
    "CNN = tf.keras.models.load_model('pre_trained_model.h5')\n",
    "\n",
    "# Freeze all layers in CNN\n",
    "CNN.trainable = False\n",
    "\n",
    "V = np.zeros((num_features, num_hidden))\n",
    "# V =np.zeros ((32, 10, 10))\n",
    "\n",
    "for i in range(num_features):\n",
    "    #V[i] = encoder.predict(X_train_resampled_final[i:i+1])[0]\n",
    "    V[i] = autoencoder.predict(X_train_resampled_final[i:i+1])[0][0:encoding_dim]\n",
    "\n",
    "C = CNN(V)\n",
    "C = np.expand_dims(C, axis=0)  # Add a new dimension to C\n",
    "C = np.repeat(C, num_features, axis=0)  # Repeat C num_features times\n",
    "\n",
    "# Define the LSTM layer with the appropriate input shape\n",
    "LSTM = tf.keras.layers.LSTM(units=num_units, use_bias=True, kernel_initializer=\"glorot_uniform\", input_shape=(1, num_hidden))\n",
    "\n",
    "# Reshape V to have shape (num_features, 1, num_hidden) to add the timesteps dimension\n",
    "V = np.reshape(V, (num_features, 1, num_hidden))\n",
    "\n",
    "# Pass the vector representations through the LSTM layer\n",
    "O = LSTM(V)\n",
    "\n",
    "# Define the final classification layer\n",
    "FL = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "# Connect it to the output of the LSTM layer\n",
    "O = FL(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480275fa",
   "metadata": {},
   "source": [
    "## Adding changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3bfd9202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015B95964D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015B95964D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015B95964D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "encoding_dim = 10\n",
    "num_hidden = 10\n",
    "num_features = 10\n",
    "num_filters = 16\n",
    "num_units = 32\n",
    "\n",
    "# Define the autoencoder to encode each feature\n",
    "input_shape = (10,)  # N is the number of input features\n",
    "\n",
    "encoder = tf.keras.layers.Dense(units=10, activation='relu', input_shape=input_shape)\n",
    "first_hidden_layer = tf.keras.layers.Dense(units=6, activation='relu')\n",
    "decoder = tf.keras.layers.Dense(units=10, activation='sigmoid')\n",
    "\n",
    "autoencoder = tf.keras.Sequential([encoder, first_hidden_layer, decoder])\n",
    "\n",
    "# Load the pre-trained CNN\n",
    "CNN = tf.keras.models.load_model('pre_trained_model.h5')\n",
    "\n",
    "# Freeze all layers in CNN\n",
    "CNN.trainable = False\n",
    "\n",
    "V = np.zeros((num_features, num_hidden))\n",
    "\n",
    "# 1st for loop: Encoding\n",
    "for i in range(num_features):\n",
    "    V[i] = autoencoder.predict(X_train_resampled_final[i:i+1])[0][0:encoding_dim]\n",
    "\n",
    "# CNN model is applied to all the encoded features in a single step, by passing the matrix V \n",
    "# with shape (num_features, num_hidden) to the CNN model. This is achieved by calling\n",
    "# the CNN function on V, which applies the CNN model to all the encoded features in V at once.\n",
    "C = CNN(V)\n",
    "C = np.expand_dims(C, axis=0)  # Add a new dimension to C\n",
    "C = np.repeat(C, num_features, axis=0)  # Repeat C num_features times\n",
    "\n",
    "# Define the LSTM layer with the appropriate input shape\n",
    "LSTM = tf.keras.layers.LSTM(units=num_units, use_bias=True, kernel_initializer=\"glorot_uniform\", input_shape=(1, num_hidden))\n",
    "\n",
    "# Reshape V to have shape (num_features, 1, num_hidden) to add the timesteps dimension\n",
    "V = np.reshape(V, (num_features, 1, num_hidden))\n",
    "\n",
    "# Pass the vector representations through the LSTM layer\n",
    "O = LSTM(V)\n",
    "\n",
    "# Define the final classification layer\n",
    "FL = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "# Connect it to the output of the LSTM layer\n",
    "O = FL(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b52ce739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the flatten layer of the pre-trained CNN\n",
    "# flatten_layer = CNN.layers[2]\n",
    "# flatten_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1fcd3816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the final classification layer\n",
    "# FL = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "# # Reshape V to have shape (1, num_timesteps, num_features) to add the batch size dimension\n",
    "# V = np.transpose(V, (0, 2, 1))\n",
    "# V = np.reshape(V, (1, num_timesteps, num_features))\n",
    "\n",
    "# # Pass the vector representations through the LSTM layer\n",
    "# L = LSTM(V)\n",
    "\n",
    "# # Define the fully connected layer\n",
    "# FC = tf.keras.layers.Dense(units=num_units, activation='relu')\n",
    "\n",
    "# # Pass the output of the LSTM layer through the fully connected layer\n",
    "# L = FC(L)\n",
    "\n",
    "# # Define the dropout layer\n",
    "# dropout = tf.keras.layers.Dropout(rate=0.5)\n",
    "\n",
    "# # Apply dropout to the output of the fully connected layer\n",
    "# L = dropout(L)\n",
    "\n",
    "# # Connect the output of the dropout layer to the final classification layer\n",
    "# output_layer = FL(L)\n",
    "\n",
    "# # Define the model as a sequence of layers\n",
    "# model = tf.keras.Sequential([\n",
    "#     pre_trained_model.layers[0],\n",
    "#     pre_trained_model.layers[1],\n",
    "#     pre_trained_model.layers[2],\n",
    "#     pre_trained_model.layers[3],\n",
    "#     LSTM,\n",
    "#     FC,\n",
    "#     dropout,\n",
    "#     output_layer\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1c1aaf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the final classification layer\n",
    "# FL = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "# # Reshape V to have shape (1, num_features, num_hidden) to add the batch size dimension\n",
    "# V = np.reshape(V, (1, num_features, num_hidden))\n",
    "\n",
    "# # Define the reshape layer to reshape V to the correct input shape for the LSTM layer\n",
    "# reshape_layer = tf.keras.layers.Reshape((num_features, num_hidden))\n",
    "\n",
    "# # Pass the vector representations through the reshape layer\n",
    "# V = reshape_layer(V)\n",
    "\n",
    "# # Pass the vector representations through the LSTM layer\n",
    "# LSTM = tf.keras.layers.LSTM(units=num_units, return_sequences=False)(V)\n",
    "\n",
    "# # Define the fully connected layer\n",
    "# FC = tf.keras.layers.Dense(units=num_units, activation='relu')\n",
    "\n",
    "# # Pass the output of the LSTM layer through the fully connected layer\n",
    "# L = FC(LSTM)\n",
    "\n",
    "# # Define the dropout layer\n",
    "# dropout = tf.keras.layers.Dropout(rate=0.5)\n",
    "\n",
    "# # Apply dropout to the output of the fully connected layer\n",
    "# L = dropout(L)\n",
    "\n",
    "# # Connect the output of the dropout layer to the final classification layer\n",
    "# output_layer = FL(L)\n",
    "\n",
    "# # Define the model as a sequence of layers\n",
    "# model = tf.keras.Sequential([\n",
    "#     pre_trained_model.layers[0],\n",
    "#     pre_trained_model.layers[1],\n",
    "#     pre_trained_model.layers[2],\n",
    "#     pre_trained_model.layers[3],\n",
    "#     reshape_layer,\n",
    "#     LSTM,\n",
    "#     FC,\n",
    "#     dropout,\n",
    "#     output_layer\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1a6030b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"lstm_117\" (type LSTM).\n\nShape (120, None) must have rank at least 3\n\nCall arguments received by layer \"lstm_117\" (type LSTM):\n  • inputs=tf.Tensor(shape=(None, 120), dtype=float32)\n  • mask=None\n  • training=None\n  • initial_state=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16776\\773842931.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpre_trained_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpre_trained_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m ])\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[0;32m   4792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4793\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflatted_inputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4794\u001b[1;33m         \u001b[0minput_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_rank_at_least\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"lstm_117\" (type LSTM).\n\nShape (120, None) must have rank at least 3\n\nCall arguments received by layer \"lstm_117\" (type LSTM):\n  • inputs=tf.Tensor(shape=(None, 120), dtype=float32)\n  • mask=None\n  • training=None\n  • initial_state=None"
     ]
    }
   ],
   "source": [
    "# Define the model as a sequence of layers\n",
    "model = tf.keras.Sequential([\n",
    "    pre_trained_model.layers[0],\n",
    "    pre_trained_model.layers[1],\n",
    "    pre_trained_model.layers[2],\n",
    "    LSTM\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9110b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_43 (Conv1D)          (None, 7, 40)             200       \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 3, 40)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 120)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ee165494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 10, 10)]          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1, 10)             0         \n",
      "                                                                 \n",
      " lstm_97 (LSTM)              (None, 32)                5504      \n",
      "                                                                 \n",
      " dense_448 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,855\n",
      "Trainable params: 6,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "60058085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the model architecture\n",
    "plot_model(combined_model, to_file='combined_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8bda5624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015BA124B948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015BA124B948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015BA124B948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "encoding_dim = 10\n",
    "num_hidden = 10\n",
    "num_features = 10\n",
    "num_filters = 16\n",
    "num_units = 32\n",
    "\n",
    "# Define the autoencoder to encode each feature\n",
    "input_shape = (10,)  # N is the number of input features\n",
    "\n",
    "encoder = tf.keras.layers.Dense(units=10, activation='relu', input_shape=input_shape)\n",
    "first_hidden_layer = tf.keras.layers.Dense(units=6, activation='relu')\n",
    "decoder = tf.keras.layers.Dense(units=10, activation='sigmoid')\n",
    "\n",
    "autoencoder = tf.keras.Sequential([encoder, first_hidden_layer, decoder])\n",
    "\n",
    "# Load the pre-trained CNN\n",
    "CNN = tf.keras.models.load_model('pre_trained_model.h5')\n",
    "\n",
    "# Freeze all layers in CNN\n",
    "CNN.trainable = False\n",
    "\n",
    "V = np.zeros((num_features, num_hidden))\n",
    "\n",
    "# 1st for loop: Encoding\n",
    "for i in range(num_features):\n",
    "    V[i] = autoencoder.predict(X_train_resampled_final[i:i+1])[0][0:encoding_dim]\n",
    "\n",
    "C = CNN(V)\n",
    "C = np.expand_dims(C, axis=0)  # Add a new dimension to C\n",
    "C = np.repeat(C, num_features, axis=0)  # Repeat C num_features times\n",
    "\n",
    "# Define the LSTM layer with the appropriate input shape\n",
    "LSTM = tf.keras.layers.LSTM(units=num_units, use_bias=True, kernel_initializer=\"glorot_uniform\", input_shape=(1, num_hidden))\n",
    "\n",
    "# Reshape V to have shape (num_features, 1, num_hidden) to add the timesteps dimension\n",
    "V = np.reshape(V, (num_features, 1, num_hidden))\n",
    "\n",
    "# Pass the vector representations through the LSTM layer\n",
    "O = LSTM(V)\n",
    "\n",
    "# Define the final classification layer\n",
    "FL = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "# Connect it to the output of the LSTM layer\n",
    "O = FL(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5a5d1675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_382 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 6)                 66        \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 10)                70        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 246\n",
      "Trainable params: 246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0ba7419e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the model architecture\n",
    "plot_model(autoencoder, to_file='auto.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ae9cbd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the model architecture\n",
    "plot_model(CNN, to_file='cnn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "985dcf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([LSTM])\n",
    "model.build(input_shape=(None, 1, num_hidden))\n",
    "\n",
    "# Plot the model architecture\n",
    "plot_model(model, to_file='lstm.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2795f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(autoencoder, to_file='autoencoder_last.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "460777ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAIECAIAAADJlkGIAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO2dX2wcx33HZylRSK26dBWVsh3JFvqgJjECAnmISRd2IUWFURV7QFrJ9CmilRaUsHyzIj00whKEKkFtgGOkBwMRjkSLlICPpPR0hyIvOhbSg+4QwMBdGwMmH4QeRQu+s9DeGWgRWLW2D79wMpzd29vb29s/N9/PE3dud/Y3f76zs7PL/WqWZTEAgHoMRR0AACAaIH4AFAXiB0BRIH4AFGW3PenUqVPhxwEA6Cu3b9+WUhyu/Hfu3Nna2golHtUpl8vlcjnqKPrC1tbWnTt3oo4CMNa+LTT7oz5N01ZWVt55551QAlMammTZh+QBYHV1dXJyEg+S40C7tsA9PwCKAvEDoCgQPwCKAvEDoCgQPwCKMjjibzQay8vLqVTKfbfZ2dnZ2dlwQuoHSY9fQhOQfmo0GvPz85FEFSvm5+dbrZaU6FJv3om7+FutVrlcXlhY6Kjqubm5dDpdKBTCCawdrVarl/aInEjityxLehDVaDTm5ub27t1L/ds+3mk7CTFYxjp1y0KhkEqlUqlUV72xXZ7Hjx+fmppqNBpior3G/GDZYIytrKzY0yPBNE3TNNuFKuFxt76Sz+e9x3Dy5MmTJ0/2NZ5u6Sp+F1ZWVnw3WbPZ1HW9VCrR37lcjjFmmqa0W71eZ4zV6/Xeo+0Wl26Zy+V0XW82m81m0zCMbDbbe56lUonylNI9dvh2bRF38RNJET/12uSKv9v4XehF/JlMRpI67ZbL5eyH9xhnL9iDr9VqjDEatizLqlQqjLFKpdJLnoRhGJlMxuPOEu3awv+0v9VqLS8v06RrYWGhXTpNV8Qb8kKhoGlaKpXa3Nwsl8v2ydv8/Dxtbm5ueowhlUptbGx0jFlaF2gXFf1EkzfG2MLCgqZpMzMzdAopWnEzk8nQTK9Pc9Hw4w9/iaHRaFy6dOno0aNSeiaTSafTy8vLLsd21ffEM1KXS6VSa2trvQT/4MEDxtjLL79Mmy+99BJj7Fe/+lUveRKnTp26dOmSNPnvFcexx8uVX9d1PjwbhsH/1nWdpjr1el3XdZqu0PWEbQ+KNEAahmFZVrFYZLZJnWma4njZLlRd1w3DoOkQTQ4ddxP3F/dxiYrXD598GobBGFtfX6fZJs+EjmI7b8M61h7R7ZU//PhpLuo9Qo7vKz/dd9RqNWk3CobtvJBKx3bb9/ieNKegruj9Qm0PnipZ2kfXdY8ZOuZJUNj5fN7LzhIBT/tJafx2i+5JrO3qE9PZ9mxNClTcpEbltzTNZtNx1ifFQL1kfX2dH+WlLlzCkDaln2gKR1Mv70e542PaH6v4XfAtfuoM9t0s4a6EN7q4p7++Rz1Z/Mn7YGcP3ktKt3kS1L2lmX804m93ZyiNfBQxjQsuDUD9kt/RFYtFafR1LKTjKNs/8YspSRR/P+J3wbf4HQPgKTRt0XWdRC7u6a/v8XmBiMcyegm+2/p02d935gGLv91Z/XU4y7JokkZ/24fedh3CR13ESjwQv8dGFFPoUkFTepeqsPpfXvux9osiE24x/OXp8pPH4ANe8KNCVqtVx3RpWYKGZHdOnz5dKBTK5fLm5ub3vvc9f1GFgJeyxJmkx88YGxsby+fzhUIhk8mI6b77HmPMy2qxF6QYaFnxu9/9biCZB05P4r916xa9e7S5uTkzM8MYO336NGPs4cOHtBv96uXTQMeOHWOM/eIXv3jw4MFbb73lJYZsNsucBqA+Qf3jxIkT4ZwucJISP0na/k6bCC3RXbt2TUz01/eoFy0tLdH+Pb5W+Pbbb4sxPH78mCcGAn8RIBgcZxcdp/20RsozMQyD1mBoSYbfkuVyOZrz8BVmWtXji3PiGxpUMPvDTL6z9JIDrX/quk4rw7Tew1xnWTwMOq97VPQ3rUTQGiS/MeEr59b2whI/L1VLvV63F8ROt9P+8OOPw2p/u5d5pKVBf32P/8qhU9MY5LLy365bZrNZegJlf8nHd55WrFb7Lcuq1+tU+6Zp8tVXSqfRlHoeFUOsXPsmQfdyYlbSnvai1mo16seGYfBnNi6vfLmH4bhZqVRID9lsljdJrVajRGoM8bxUCtM0vbx51q34w48/fPGTGvl7Mi6tT5FLx/roe7VajXqyYRh80DFN0zCMdk/pmA3xVxq/dF0vFotiei950hgtdSrHOrGT7Df8IsFjzfZCX9/wCyF+F3p8w8/LvCkEunpE39c8TdOM0Rt+APSJ6enpe/fuRf5p03K5fPny5TjkWa1Wq9Xq9PR0sMFA/M7wBduAX6gMi0THPzIysri4eP369dBWc+2sra3t27dvfHw88jw3NjZu3bq1uLg4MjISYDDM8bv9Scf9pXrL6ebKzoEDB/gfHg+JFcmKn5pMjHN0dHRpaWlxcXFsbCySkOjxUxzyLBQKV65cGR0dFRMD+c+RARR/IH09/oJxJynxu8Q5MjJy8eLFMIOJJ46VEEj7YtoPgKJA/AAoCsQPgKJA/AAoCsQPgKI4G3VGEgoAoH/Yle78qO/999+fmJjofzyqc+PGDcbYhQsXog4keEql0s2bN+nFUhAt1Bb2dGfxT0xMwKI7BMice1Cr+ubNm4NatMThKH7c8wOgKBA/AIoC8QOgKBA/AIoC8QOgKBA/iBJYdHckSRbdmo3AT8F2OkmHc8bEEYjZdjiO3eJHqQhYdHP6Z9Ed/P/zW5bVarVeeOEFxliz2Qz88yPE/fv3xTM2Gg36fEX/zpg4xCqKNpNuabVa09PTly9fHh8fT6fTv/zlL9PpNGPs6tWrfB/e6PV6XfrQRQjQd3ilb4cTy8vLH3744dLSEmPs7/7u7z777LNz5871kufY2Njly5enp6eXlpYC7tv2z/qxID7g2S7zQHB0ku7rGftE/z7gGYjZdi+ZwKLbGmCLbu/EwQm71WpR/jSH5K7MBL+3lNzB7ebNPOBWqzUzMxOafbWj+bT3KkqQYzcsuh2Jl0W3O2Lm4ThhtysOQdnW63Xx7PQtdMnkg7s+OJo3i2WpVCpd2bDZ8X7ldzSf9l5FQdWz98/4w6Kb7zNoFt0dkcJy2ZR+8u0k7V4R5Jdg35NutHhXq1QqfG7ZzryZDrd7qvjAo/j9mU+7N0G/Hbth0d0upds8iRhZdHfEt/jFlADFT9RqNe7uSCmkAe6plMlk+EDQzrzZtx7seBS/P/Np9yaw/NazR2DR7VKcrvLsPXOI38pms7qur6+vS3tSp+Hmah0z9K0HOx7FH0gVBVXPHoFFN99n0Cy6+02ATtJkH7y8vHz+/PkPPvjgyJEjjuf65S9/ef/+/bNnz0q/BmXe3Au9mE+7k0THblh0B0XsxB+sk3S5XP6zP/szxhg9KH7llVfs+4yNjRmGkU6nFxYWRDeVYM2be8G38bkLsXXshkW3C7Gw6HZHchoOwUlaWrIm6BBavKX9a7Uan/aLhqe0p+imbLUxb3Y8kW88TvvbmU9b3VRRIPUcyWo/LLqtpKz224aXHUg78M1enKTdz0i5ifvTyr/0MImWA6Sy2M2bebaB+Ld6f9TnaD5tdWO23Xs9W6GIHxbdjnkOpkW3xwL0FWmpLzT6atEtEXI9w6I72Dxh0d0vVldXe7yFBgECi26JwbTojtZJenZ2lr/M2w9X1viQLMduWHSLDKxFd7RO0rT4n81mPf7fVXKJuWO3Bovu9gysRXe0HfHcuXMDL3sihoInXAKDRTcBi24AQMBA/AAoCsQPgKJA/AAoivOCH3/HE/SVra0txtjq6mrUgQQPdaGBLFriaCdnWHQDoAQOSo/tQyDQb8hCFxdnZcE9PwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKAvEDoCgQPwCKsjvqAEB43L9/v1Qq8c1PPvmEMfbTn/6Up0xMTLz11lsRRAaiQLMsK+oYQEgUi8Xjx48PDw8PDckzvmfPnj19+vTu3bvf//73I4kNhA/ErxDPnj178cUXP//8c8df9+/f/9lnn+3atSvkqEBU4J5fIYaGhn74wx/u2bPH/tOePXvOnDkD5SsFxK8W6XT6yy+/tKd/+eWX6XQ6/HhAhGDarxyHDx+u1WpS4qFDh2q1mqZpkYQEIgFXfuWYmpoaHh4WU4aHh3/0ox9B+aqBK79yfPLJJ9/61rekxF//+tevvfZaJPGAqMCVXzm++c1vvvbaa+J1/tvf/jaUryAQv4q89957fGF/eHj47Nmz0cYDIgHTfhV59OjRq6++Sk2vadrDhw8PHz4cdVAgbHDlV5FDhw69/vrrQ0NDQ0NDr7/+OpSvJhC/okxNTWmaNjQ0NDU1FXUsIBow7VeUJ0+evPjii4yxx48fj46ORh0OiAKrn5w8eTLq8gGQVE6ePNlXefb9X3rHx8cvXLjQ77PEjcnJyffff39iYiLqQNy4f/++pmlvvvlmV0fduHGDMaZgm4YM1XNf6bv4Dx48+M477/T7LHFjcnJyYmIi5gX/i7/4C8bY888/39VRt2/fZozFvGgDANVzX8HHPNSlW9mDAQOr/QAoCsQPgKJA/AAoCsQPgKJA/J1pNBrLy8upVKqvZ5mdnZ2dne3rKSKh0WjMz89HHUX0zM/Pt1qtqKPYgbrib7Va5XJ5YWGho6rn5ubS6XShUAgnsD7RarXC/1xHo9GYm5vbu3evpmmaptlHN20nIYfn3gcKhUIqlUqlUl01fbs8jx8/PjU11Wg0eg06QPr6CtHJkyf7/ZaSb0zTNE3TYyV0W1eMsZWVlR6iC558Ph9Ic3tv02azqet6qVSiv3O5HGPMNE1pt3q9zhir1+u9x9YtLn0gl8vput5sNpvNpmEY2Wy29zxLpRLl6SWfELSjrvgJRcRPOgxZ/JlMRpI6VWMul5P27PdFyB1749I3DmnYsiyrUqkwxiqVSi95EoZhZDIZLzmEoJ04Tvtbrdby8jLNAxcWFtql0wxKvCEvFAqapqVSqc3NzXK5bJ9Pzs/P0+bm5qbHGFKp1MbGRt/K+lukZYV2haKfaDrKGFtYWNA0bWZmhiKUCituZjIZmrvylH4vMTQajUuXLh09elRKz2Qy6XR6eXnZ5diuGlo8I7VvKpVaW1vrJfgHDx4wxl5++WXafOmllxhjv/rVr3rJkzh16tSlS5fiMvnv69Dib/TSdZ1fMQzD4H/ruk6zr3q9rus6zaDogsa2x2kasw3DsCyrWCwy2zzTNE1xCG9XCbquG4ZBMzSar3ZVV6zLKz8vhbRpLxRvOD6dNgyDMba+vk7zZ54J/0SvY0lpduo9Qo7HNqW7jFqtJiZSADQrllpB3K3bhuZ70pyC2t37hdreuFSl0j66rnvM0DFPgsLO5/Mdc1Bx2k9K43eAdJtkbbeomM62J5BSRYub1M/4XVaz2XSciEoxUMddX1/nR/Vb/O6lkDaln2hSSpNJ70f5xmObUs1LiZTClcxrWNzTX0NTtxF/8j602WvGS0q3eRLUl7zM/FUUf7tbU2kwpkqkccGlT5Aw+E1msViULgiOjeQ48MdW/GJKfMTveDqeQpMUXddJ5OKe/hqazwtEPJYoTPF7z0rFe/52j1Vu3bolbo6MjLjszBkbG9N1/cMPP6TNf/u3fxsbG+sYg3QuEDijo6OVSqVQKExPT0tPv/01NO0gdW7f4TkOJTQqDRKxEz/Ve7VadUyXVkq8tMfp06cLhUK5XN7c3Pze974XXKTxInFdc2xsLJ/PFwqFTCYjpvtuaMZYUEuzUgy0rPjd7343kMzjQ0zFf+vWLbogbG5uzszMMMZOnz7NGHv48CHtRr+eOnWqY4bHjh1jjP3iF7948OCBR/P5bDbLnAageEI9/sSJE1EHsgOStPs7bbREd+3aNTHRX0NTky0tLdH+Pb5W+Pbbb4sxPH78mCcGAn8RIGL6elPh476Flm15eIZh0LIQrRLxu8RcLkcrvXyJm1b1+OKc+NII1bV9lYXvLL13QUuyuq7TYjUtQTFhbbkjrMt7fl4KCtu9UPQ3LWTQEiZfiOYr/9b2UhkPm2q1Xq9TPYS/2t/uZR5padBfQ/NfOXRqGoNcVv7b9YFsNkuPe+wv+fjO08Jqf0fq9Tp1CNM0+YIwpdMAT12falYayBzHNVr2E7OynG4IxV9rtRoJyTAM/hjJ+1to3YrfvRSOm5VKhfSczWZ5J6vVapRI3UsMmyrBNE3a7Lf4SY38PRmXqqY4pWN9NHStVqNuYxgGH3RM0zQMo91TOvc+QOOXruvFYlFM7yVPGpG9dKQQxN/fr/fSbC2EDxLFDU3TVlZW+vStK3pLp68N54L3NqWJ98WLF/seUydSqRQpOfI8Z2dnX3jhBS91EoJ2YnfPDwaG6enpe/fulcvlaMMol8uXL1+OQ57VarVarU5PTwcbjG8g/oTBl6Dj8opoe0ZGRhYXF69fvx7h0una2tq+ffvGx8cjz3NjY+PWrVuLi4v08DIOQPwJ48CBA9IfcWZ0dHRpaenu3btRBXDs2LEjR47EIc9CoXDlypVY+aPg670JI6pbfd+MjIzE4bY/cmJYCbjyA6AoED8AigLxA6AoED8AitL3Bb+tra3V1dV+nyWG8LdrB4ytrS3GmJptGiZbW1sHDx7s7zn6+v4gLLoB8E3iLbpPnjyJ13sHCWVf2Q4ZL/+x2iO45wdAUSB+ABQF4gdAUSB+ABQF4gdAUSB+ABQF4gf9BRbdBCy6O1Aul2dnZ7mdc7VabTQafXJubmelrDkxPz9fKBTi0HiBOG2HZtcdc4tutu3DTQ5/7g6CIo1Gg3dU6Sj63jR5KIqWgbDodoO+i8g/s1mv1/k30voRm4uVsvShWMuy6GuZ/JOyHWF9c+kNxGm7l0wGyaJb/A6v6HrmTr1e5x8mpULxo5rNJn06lZdX/FAvLLqdEb8/LUJvyAcd1+9oN7jY00XTSC/Z9kP8gTht95jJIFl0S63MvLlxcuXbM5G+yW3vRbGy6I6F+EnhUp1yePXx0ZQxls1m+Qfbc7kctRn/1nKtVpP+r4Zy4OYw/NPO3sVvbX/A38tH1z2K37FEUszipmT2QJMjKjt965pPnbxnYnX5Ge+uPt0tffSabZt5SPqXqrqrhhbPSJnbP7bdDtpftP317u3LQ2XtTUGZzetBsiF1QRXxU3fsWCNhWnQ7plNLe7Hu8Ch+xxJ5d9rmAg7TrnvALLopmFKp1JUvA8GdAiRLCIJ6i3SpgGmHLYg2ChQJ06LbR7p9t47i91cil5+sUOy6B8+im0ZM0zQ93o0TfDxlbVYKisWi/SYRFt22IDz0xTAtun2k23frKH5/JXIXv5gSrfgdT8FT4mPRnclkyBSIVp260r9lWZVKhYY50c+Lh+R4J+sxNlXET+3tXu/+erllWTRvpL/tV4OuRO5+gycd3lH8geg2oeK3tsdl0ltUJaL5AnW89fV1Rw13hA6Uzp7L5dplFR/xx+I5PznM/ud//qfLPnGw6P7oo48YY0ePHu0lE04vXtTuJMKuOw4W3el0mjFGLhrkg3D+/PmucmCM2b/hX61WP/7443PnznWbVcjEQvx0cb5165b9p83NTXo/LEyLbkcajcbNmzd1XacMe8d3iVyIj113Iiy6xZsFGgIcbx/coTPyxxONRuPu3btXr16lzWq1Sh7zIrDo3gGt1oov+VjbnrN0WximRbc9vR8v+bQrkdWN0zb9FKZd9yBZdNPiItUeVRF/RuhyoK7rmUyG8qc657UnGcwT4to+Vvudobej+ASPnvdIvScEi257OmMsk8m0ew3BES/ib1ciqxunbTo2TLvuQbLotiyrWCxyL3bx7QCXA0VzXqljON6eiB0PFt2DT2jf8Avfrlspi+7Avb1h0Q2UIOkW3YF7e8OiGwRGzO26E23RHbi3Nyy6QZDE3647uRbdgXt7w6IbBEmYt/q+gUU3EcNKwJUfAEWB+AFQFIgfAEWB+AFQlL4v+JXL5RAsB2PIjRs3BvLtJnpur2abhkm5XA7wQaMj/RX/xMREX/OPLYnwJv+P//gPxth3vvOdro7qd48ExPj4eL/l09/Xe0GcobePV1dXow4ERAPu+QFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFIgfAEWB+AFQFM2yrKhjACHxL//yLz/72c+++uor2nzy5AljbP/+/bS5a9euH//4x++9915k8YFwgfgVYmNj40/+5E9cdlhfXz9y5Eho8YBowbRfIY4cOTI2NqZpmv0nTdPGxsagfKWA+NXivffe27Vrlz199+7dZ8+eDT8eECGY9qvF48ePDx069OzZMyld07RHjx594xvfiCQqEAm48qvFyy+//MYbbwwN7Wj3oaGhP/3TP4XyVQPiV46pqSkpRdM0LPIrCKb9yvHf//3fBw4cePr0KU/ZvXv3Z5999vWvfz3CqED44MqvHH/4h3/453/+53zZb9euXW+//TaUryAQv4qcOXOGr/lZlnXmzJlo4wGRgGm/ivzv//7v17/+9d/85jeMsa997WtPnjzZu3dv1EGBsMGVX0Wee+65H/zgB8PDw8PDwz/4wQ+gfDWB+BXl9OnTT58+ffr06enTp6OOBUTDbnFja2vrwYMHUYUCwuSrr7567rnnLMv64osvVldXow4HhMEbb7xx8ODB321bAisrK9EFBgDoLysrK6Led9v3wBJg3FhdXZ2cnAy8Xe7du6dp2ltvvRVstt2iadrKyso777wTbRgDj/0fuhzEDxThzTffjDoEECUQv7pIb/gD1UDzA6AoED8AigLxA6AoED8AiqK0+BuNxvLyciqV4imzs7Ozs7MRBhAgIZclHBqNxvz8fNRRRM/8/Hyr1eoxE6XFPzc3l06nC4VCsNm2Wq1yubywsNBR1X0KIBxarZbjt0D7R6PRmJub27t3r6ZpmqbZhzZtJ2HGRhQKhVQqpWlaKpVaXl72eFSj0ZidnaWYpaM2NzdnZmY0TZuZmVlbW+Ppx48fn5qaajQaPYVrf8PPUgl7JfSOaZqmaXrM2ctu8WyXfD4fSFTM9uaZI81mU9f1UqlEf+dyOcaYaZrSbvV6nTFWr9d7D6xbMpkMY6xSqViWValUGGOZTKbjUfV6nQplWRYVih/VbDbz+bwllJc2iVKppOt6s9n0GJ69niH+4MXfVc4JFT9JMUzxZzIZSepUdblczp5h71H5QGpKxpiu6x2P4sq3ZyJK3Z6/ZVmGYXgZX/jhvYq/Xq/ncjkqFY39hmHUajVre9zim0Sz2cxmsxS3aZo0JEtTj3YzEfup8/k8nZryNAxjfX1dPBfFwBjLZrPi8N/uJ/GkYtEcS6rruli0YrFIAshkMvZLTbvi8Eh0XV9fX++T+L2XxaVWpUYRN/nURkyxX4e94EX8dD0vFovSgXSxlfQv1ZVj03ds3Hq9Tpnrui6dtx20P4m5Vqux7VmAd5rNJnOazvByGYYhphSLReZ5mhOA+Km784KVSiWKSSyzGKJhGBSf9BP1M94Suq53rCne1fjcjzLn+td1PZvN8gzFSVG7n8TOzYsmbToWjXoM/cT7Fts58DtWpq7rhmHQ2fmB7gX3IX7vZXGpVZIcz4SOksYCfsa+ip9qWxSntS1yGobEziPVlWPTuzcu7UljCgnMo4wpmFKplMvlur31qNVqdLh4PePQuCDNBShsKbEdAYjfcpreuGyapsnrVPqJjwuOV04vpxbvrKRRkEYlsf0cf+qqLC5dn9lu8BxVTZ2Yty61aD/E30tZxFr1fpRvvIifVGE/0BJuQHitinv6a3oalMWfvI9r1KtN0/R+N24JA6u9I/GC2O/wqf94nPlHIH6iVqvRpEj8iS4sNPv1Er1j5jyFKp2nU73QvM7lJ9/il/J0CUxEOqrdbhIhi19MiYn4Hc/FU3hH4jeVfB9/Tc/nBSJeypLJZHK5XLPZNE2zq9U4olKp0DBHUxURvtgp4T02ez2HIf5sNtvu/paGWMdSeTm11b6b+vvJ+yZdHuka4ri0266/tovEBYi/XWXyv6kJSG/uvbF/RaPOTIKn3m7XcEfayaRdVt5Dtddz38VPNUJ3a9JPNOGnGYG/ab8lrILQaC3m4+Wnrsoibebzeb4m5Ljm7Nhf2/VFFyIRf8f6iZX4re1bKukGwV/T09/eJ6T2HDze0HXMx9qeDnjc2T3bsMXv0l3oUkn3bNIypsdT0zBJCx7SJIJqn9ZpXX7yXZZ8Pu8+qXNsFVrmlFan4iZ+sVZjIn4aZKUKt5/dvoDqr+mpmfh9O12lOhZEevbJvD3qk6AI+bVEOnWlUpGUwjyvRwQgfr4CzOuFNvm6vbhpbddIrVbj85l6vU43Rbwt3Z9wSAXgVcPvrHgmtJZLp87lcrya2v3kHrxUUj6W259WEoZh8FLznaX+Sus6/KkSLUcx2yMcCX+P+roti2Otis9TaLWM2eZT1DtDXu1v9zKPdOXv2PSOFcJ/5dCpxdd47FBrUjVSXfFnhC4H6rqeyWQof6p8Xo300EGKRFzbD3u1X4yj46a1fTNGT/hp5V9c2HTMs+PZK5UKVUo2mxXVVa/X+TsFtO7i/lNXZZE2eQwi0sMzx0LVajVSFA0WdMvgftfjQ/w+iuZYq7VajRKph4nRii1rhfKcn1/AXaqXgpSO7bbpLeHBm/jeCnVgl+t5sVjkjSu+HeByII1rRCaTEde/KCsJ8WaEhpjwnvNHi2NjR8L6+rr02JmmNv04V7/bJdpa9SJ+y7JoeSiEeK7UcZcAABz/SURBVDriYzLf44HtME2zlzf8lP7HHt8sLy8fOXLklVdeERMPHDggvu0DgmV6evrevXvlcjnaMMrl8uXLl8M8sB3VarVarU5PT/vOIUni5//D1Os/M/XMhx9+uLCwsLm5yVM2NjZWV1fffffdCKPyR3xq1Z2RkZHFxcXr169Xq9WoYlhbW9u3b9/4+HhoB7ZjY2Pj1q1bi4uLIyMjvjOJnfi19hw4cID24X9ExdLS0vPPP/8P//AP/H9Lt7a2zp07F21U/ohPrXZkdHR0aWnp7t27UQVw7NixI0eOhHlgOwqFwpUrV0ZHR3vJJHZf77WcFszixsjIyLvvvvvuu+/+/Oc/jzqWXklEhXNGRkYuXrwYdRTRE0glxO7KDwAIB4gfAEWB+AFQFIgfAEVxWPA7depU+HEAF7a2tthAt8uNGzdu374ddRTKgSs/AIricOXHGBw3yKJ7UNtF07QLFy7Aorvf2L9ljis/AIoC8QOgKBA/AIoC8QOgKBA/AIqilvgjt+UFPQKXXiIyl17x32wdP65QLpd7N0u1/0tvKpVaWFjo5d/OQ7bldfzH5Pn5+UKh0HvLBUUgZrvhOPbG36WXs7Cw4D2AhLn08u/wOX55kn97rEezVLtdlIufkUfspe4dF1te6UOR1vbH//gnJb3Q1894BWK220smbFBcejn0dUOPFZJIl162bZMofcrO0ZzHN1I+1LQev/PtJcMAaZezPd1uJehO/8QfiNluj5l4FH/8XXoJ+gKv926WJJdeMS/RtYaTy+UcRz5/dr32fMSURNjyOqbTZ549fnTZe7s4ltqxSmlTMtuNxLHX3intJMKll6C+0a4zuBN3l14xL8vJfM7RDsXya9cr5UO1w49NhC2vY7pUEHe8t4tjqb2b7fJChenY60X8SXHpLRaLlKEP8SfDpZfnZW1XDZ+6VCoVRzsUy69dL+1JVc8nVHS6RNjy+ki347Fd/JXavQZCcOz1Iv5EuPSSQYA9Ny8kxqWX58X/4KrmddSu8N3a9bKdmKbJx+BE2PL6SLfjsV38ldq9BsSUCMXvmD9PiYlLr+il6a9CEuDSy/OiP7gVJ91HucTkw67XpWzeu6nLT943/dnytkv37lBm+fVQtHzpNpBMusLeKR33secvpkTu0pvP58W7Et8VEqZLbwAv+bzxxhuMsQcPHqytrdHfjiwvL58/f/6DDz6wf8O40Wh8+umnmUxmYmLC+6NLGp6l/Wmkd/nJN2NjY/l8/tNPP6UnzLlcrpcvqH700UeMsaNHj/YSkkQ/Sh1gJn2FWqdQKPB5JdFLnWxsbHgPIJVKvfrqq9IrBj7eNbCro1qtfvzxx335MLw4Evi78lvbt2TildCeuZgi/epi12vPh5MIW17HdL7y5JKbiMd28Vdq9xoIwbGXDYpLrxSbvwqJtUsvj4kJ6yg06eJ343avXsuXXa/knSqRCFtee3r/XvJxqRDvZrv0U5iOvV7EnwiXXqlQbOflrd2BSXLptWwyoERpJd++Q7d2ve3yEYm5La9jKSQnVi90NSg7Voh3s106NkzHXjZALr1iocTA4NKbbMK05ZUIs10c5dTvM8Kl1x9w6Q0D2PJGDlx6JdRy6Y2QQbLldSHOjr1w6RUZTJfeeDJItrwuxNyxFy69nMF06Y0ng2TL64LVac01cuDSS8ClFwDgH4gfAEWB+AFQFIgfAEWB+AFQFIfV/mg/ewraMcDtMjk5OTk5GXUUyqGJT3e2trYePHgQYTQgTG7cuMEYu3DhQtSBgJB44403Dh48yDe1+D/aBX2CXLFXV1ejDgREA+75AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARYH4AVAUiB8ARdkddQAgPJ48efLFF1/wzf/5n/9hjD18+JCn/MEf/MH+/fsjiAxEgWZZVtQxgJD453/+57/927912eGf/umf/uZv/ia0eEC0QPwK0Wq1/uiP/ujp06eOvw4PD3/++ecjIyMhRwWiAvf8CjEyMnLixIndux3u9Xbv3v2Xf/mXUL5SQPxqcebMma+++sqe/uzZszNnzoQfD4gQTPvV4je/+c3+/ftpqU/kueeee/Lkye/93u9FEhWIBFz51eJrX/vaX/3VXw0PD4uJw8PDJ0+ehPJVA+JXjtOnT0trfk+fPj19+nRU8YCowLRfOf7v//7vwIED//Vf/8VTXnjhhc8//9xxIRAMMLjyK8fu3bvT6TSf+Q8PD585cwbKVxCIX0XS6TSf+T99+jSdTkcbD4gETPtVxLKsQ4cOffrpp4yxl1566dNPP9U0LeqgQNjgyq8imqZNTU3t2bNnz549Z8+ehfLVBFd+Rfn3f//3sbEx+uM73/lO1OGACAh1madUKv3sZz8L84zAhd///d9njP393/991IGA3/LjH/94YmIitNOFOu1/9OjRnTt3wjxjOGxtbSWxXK+++urhw4c77nbnzp2tra3+h6M6d+7cefToUZhnjOABz+3bt8M/aV9ZXV2dnJxMXLnoP/n/+I//2H03TdMuXLjwzjvvhBKUuoS/8oKnu+rSUfZgsMFqPwCKAvEDoCgQPwCKAvEDoChxF3+5XJ6ZmdE07a//+q9/8pOfpFKpqCMKjNnZ2dnZ2aijCJhGozE/Px91FNEzPz/farWijqIDsRb/2traxMTET37yE8uy1tbW/vEf/7FQKHQ8qtVqiU9NpE11CL/gjUZjbm5u7969mqZpmmYf2rSdhBmbxMLCgvcAGo3G7Owsxby8vCz+tLm5SRenmZmZtbU1nn78+PGpqalGoxFk0IFjhcjKykpXZzQMQ9zfY8D5fF7cTdrsB92WKxyCKjhjbGVlpeNuzWZT1/VSqUR/53I5xphpmtJu9XqdMVav13sPzDeVSsV756/X61Qoy7KoUJlMhjabzWY+n7eE8tImUSqVdF1vNpseo/JYzwESa/FLLeSlwagL8t2kzT4RQ/EHWHCPnTKTyUhSp/bK5XL2DHuPyjfNZtM0Te/i58onxANFqVtO/dMwDD5SdATi/y2OMxSpcpvNZjabpUTTNOliwtuVp9unOfV6PZPJMMZ0XS8Wi5SSy+V0Xbe2L5i6rtdqtcDLxRHP6B5AvV7P5/P0E5XXMIz19XWxlqRKs9cDpdivw17w0inpek6VKR5I9SzpX6orftlkjGWzWWrHji1ib0SPZDIZitbHGNRsNpnTdIaXyzAMMaVYLDLP0xyIfwfuV366KajX67VaTax396Pq9bqu69QdqW0qlQpdJBljNMxLGQZeLsuy+BmlTXsAXMB8Rk0FX19flzoxHSWNBfyMfRU/6VMaLsVhqFKpSOliVWSzWWu7aWiq7N4ijo3opSzFYpEy9CH+Wq1GZaGRV4LGBWkuQGFLie2A+HfgLmPTNB0F734UXWTEX0kS7kcFWy4vcbqUiG5ZaT7p/SjfeOmUpAr7gZZwA8I1I+4pXRtLpRLbnim4FK1dI7pTr9dplLFn3hE+sDLhnl+kWCza7/BpRPA484f4d+BFkLVajaZ/HsXPLykiHs8VVLm8xOkuYy9hhyl+x3PxFJqh6LpOIhf3lNZ0SS0023cpWrtGdIcrv13AHalUKjTMiVnxkKTVgW5PBPHvoKMgs9msruvr6+vexd+uMSB+lzh7FL+1PVuha6N7PfepaPl8Xrwr8V05UmcjcrmcfTjo9kThiz/Wz/ndWV5ePn/+/AcffHDkyJFuj93Y2OhHSGFC18ykMDY2ls/nC4UCn6YRdA2Xnod7LFpXjZhKpV599VXpFQMf7xrYO1u1Wv3444/PnTvXbVaRk2Dx0zdnX3nlla6OogXzpaUlegEriW+kUac/ceJE1IH8DpK0+ztttER37do1MZHMQujLAjyHU6dOuZ/ORyPaL7NMmF94h87IH080Go27d+9evXqVNqvV6szMjHSI9OQlRoQ5zehqeszfxKCFIr6yzReH6KJRq9X4TIx+onR6FGTf5PlwarUaT6QFG5qaMs8Pafw96hNP4R4A/U3LYPSYmj8j5Cv/1vZqGdteFZcKHvJqf7uXeaSlQVoO5MsBuVyOgnevEMdGtCyLxiAvK/9S53c5UNf1TCZD+VPl82qkhw5SJOLaPlb7f0cvz/lFaB8aHegJP638UwuJ6fZNS3hmww+RMrefK6hyORbQ4yZ/JJnNZvmqcq1Wo0TqYXR1dSx4CM/5+YqXY3tx+MjFj+Xva+RyOSpaxxaxN6K1/QBIyr9docTAXA6kcY3IZDLiqp7j7Yn4IJCGYzznt6xYvgkXCP0ul/dhqE9n9/iGn/e32fqKF/EHe2A7TNOM8xt+Cb7nB7Fienr63r175XI52jDK5fLly5fDPLAd1Wq1Wq1OT08HmGewQPxxh6+Ex/xfxEZGRhYXF69fv16tVqOKYW1tbd++fePj46Ed2I6NjY1bt24tLi6OjIwElWfgQPxx58CBA9IfsWV0dHRpaenu3btRBXDs2DEfz317ObAdhULhypUro6OjAeYZOPh6b9yxun8cFSEjIyMXL16MOoroSUQl4MoPgKJA/AAoCsQPgKJA/AAoCsQPgKJEsNo/qN/SHdRyMcYmJycnJyejjgIETATip5dhB4lSqXTz5s3BKxcxOTn5/vvvh+kbrybhD68RiH8gzZ5v3rw5kOVijE1OTk5MTAxq6eJD+OLHPT8AigLxA6AoED8AigLxA6AoED8AipIw8TcajeXl5UEy6h5skvh9VH8kwpNbInbi11yZm5tLp9NKGXUHEnkkxY+5Y3er1SqXywsLC/ZrSTvjbaJQKKRSKU3TUqkUd+xOhie3RJjfDPP4rTv+qVYxkXydLM8ftAvTqLuv3/ALJPJeMmG+vi0Xf8du+qKpvTu5G2+L3/kVfdOs7j25JfzVcy/EUfyWqwOMF/GHbNTdP/EHEnmPmfjrlElx7LZ3J3fjbfum+NnPrjy57ZFA/JblVMXtfoqDUbf3cjnaUUuBiZtS5JHYdfvolAly7LaL376D6NdMZxG9g8Wv/XflyW0/EcRvWTubhKrY8ScrHkbd3svlaEft3WmbCzhMu24fnTIpjt1WJ/E7Gm9TEUqlErdI4HTl0mGPBOK3LKev1kk/8c04GHV7LJc/O2r3kEKw6/bRKRPh2G3Px46j8ba1fckxTbMXT257JBC/ZXVz5ef7RGjU7bFc/uyoO4bkJfiQxe94Op4SE8dul1A5jsbbmUyGnIXIN03Sv++qhvh/i72l2/1kxcCo22O5AtHtAIjfioFjt3uohKPxNs0ySPDU5aR9EiT+2D3nd8Rq//nqBBl192JH7U6y7LpZDBy7O9LOeJu8ocmKg5wUzp8/H+B5wyQZ4nchQUbd/uyo3YmhXTdLgmO3Oy7G2+ItBg0B9puO+HpyS4Q5zej2JR/7Qks8jbq9l8vRjtrqxmmbfgrTrpsFsdofT8dux57mbrxNS5JU/1TJ4pNFrPa3xYtI3Icne3ocjLq9r2U42lFb3Tht07Fh2nX76JSJcOxu19M6Gm8Xi0XaxzAM6Z2Crjy57fGoLv4kEma5vAxGgZ/R3xt+SXfs9kFXntwS4Ys/8ff8IJ4k3bHbB/H35JaA+JNEUuy6WcIdu32QCE9uCYg/SSTIrpsl2bHbB4nw5JaARXeSsNq/7xBP1HHsTmIxceUHQFEgfgAUBeIHQFEgfgAUJYIFv9XV1fBP2lfova7BKxeHvywMBoow3ygaVB9bAAIh5Df8NCtpT49AUJDx7gBPWIA7uOcHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFEgfgAUBeIHQFF2Rx0ACI/79++XSiW++cknnzDGfvrTn/KUiYmJt956K4LIQBRolmVFHQMIiWKxePz48eHh4aEhecb37Nmzp0+f3r179/vf/34ksYHwgfgV4tmzZy+++OLnn3/u+Ov+/fs/++yzXbt2hRwViArc8yvE0NDQD3/4wz179th/2rNnz5kzZ6B8pYD41SKdTn/55Zf29C+//DKdTocfD4gQTPuV4/Dhw7VaTUo8dOhQrVbTNC2SkEAk4MqvHFNTU8PDw2LK8PDwj370IyhfNXDlV45PPvnkW9/6lpT461//+rXXXoskHhAVuPIrxze/+c3XXntNvM5/+9vfhvIVBOJXkffee48v7A8PD589ezbaeEAkYNqvIo8ePXr11Vep6TVNe/jw4eHDh6MOCoQNrvwqcujQoddff31oaGhoaOj111+H8tUE4leUqakpTdOGhoampqaijgVEA6b9ivLkyZMXX3yRMfb48ePR0dGowwEREAvx4wkzUI046C4u/9L7/vvvT0xMRB1FT5RKpZs3b66srEQdiFfu37+vadqbb77pZefJyckBaKM4QP0k6igYY4xZMYAxtrKyEnUUvUKyjzqKLvjiiy+++OILjzsPRhvFgfj0k7hc+UH4PP/881GHAKIEq/0AKArED4CiQPwAKArED4CiJFv8jUZjeXk5lUpFHYh/ZmdnZ2dno44iYBqNxvz8fNRRhMH8/Hyr1Yo6Cp8kW/xzc3PpdLpQKEQdSHxptVohv0PVaDTm5ub27t2raZqmafahTdtJmLExxlqtVrlcXlhYsF8zNjc3Z2ZmNE2bmZlZW1uTfi0UCqlUStO0VCq1vLxMicePH5+ammo0GmGEHjhRP2u0rN6eIcenFPF5fiuSz+cDicpjGzWbTV3XS6US/Z3L5RhjpmlKu9XrdcZYvV7vPbBuMU3TNE17t2k2m/l83hLCpk0ik8kwxiqVimVZlUqFMZbJZOinUqmk63qz2fQYQHz6STyCgPj7A0kxTPFnMhlJ6tRAuVzOnmHvUfnG3m1Eqdt3sG/qus43DcPgY0FH4tNPkjftb7Vay8vLNPva2NgQf6JbTfqJpm3iokChUKCfNjc3+SG0/8LCQqPR4FNQez59QlqzcIm20WjQtJMxtrCwQFNTKr40fxY3M5kM3RPxlL4uMTQajUuXLh09elRKz2Qy6XSaT5Ud4c3Km4N5aL4AW4pGSRHDMMQiMMbK5TJjjAK4evUq//XUqVOXLl1K3uQ/6tHHsrq88uu6bhgGzbJoekalqNfruq7TFaZYLDLGKpUKb1GaiNJXaw3DoKwymUytVrMsq9ls0lSwXT5eAvMxovPwpE17tLy9+Iyauub6+jpNoXkm/Mu8tCm1Mk16uwqS59OxjegWg6pUPJDOK9WkVFe6rmezWWu7/mki7d58vlvK6jRhbDabbOe0nxehVCrlcjnphoUCk/ZvR3yu/PEIwrP4qXutr6/TJjUSVSUNBGKe1MulZpaEwVuRJOSST0f8NapLePZoxZ/EO0/vR/nGSxvxAVQ60BJuQHjbiXuSdHlbkKEgqdqlaL5byp6tRLFYdLyNpwHXNE3pJ+qHHmf+EP8OvIufal86llLs0zYm/OOkfX+eWy6XE9uyXT4dCVn8YkpMxO94Lp5Cw6uu6yRycU+pWUlLdFPtUjTfLdUuVA5fsxTJZDLUVUzTtA8N/e4n/SAeQXgWv3cBtDtE3FxfX+cdiA/bvtUC8buL39qerZByXEpt9b9oLsfmcjm6AZESGWMk+PX1dcaYtE8SxZ+8BT93pCVAd44cOZLP5yuVimEYly5dEt9L6SqfCBEXpeLP2NhYPp8vFAq0fsahIVhaMPNYtGBbqlqtfvzxx+fOnZPSyctsZGSEMXbgwAHG2Pnz5wM8byQkTPzZbJYxVq1W2/20tLREb1x5eclM07RWqzU2Nvbzn/+8UqlcunTJXz6RQJ3+xIkTUQfyO0jS7m+80RLdtWvXxMTTp08zxh4+fEiblMOpU6fcTxd4SzUajbt37/Jl/Gq1OjMzw8Pmu9EQYL/p4K8PJIaopx6W1c20n5ZVdV2nJWVaKGKMGYbBF705tVqNJ9KEjS8Q8ttO0zQpq1qtRjN/x3y8xOZjOsfPRfF0jJZtL4PxO0/Kh6/8W9urZWx7VZz6aL1ep9KFvNrf7mUeaWmQlgP5ckAul6Pg3SukXUuJL+Q4wvMR79vp2YGUIV/Ap55GlU81XCwW+bFY7fePd/FbllWr1aivk+DpSkK9oVarUa8yDIP6gTTM2TdJFWznUq09Hy/4aNSO4dk3+fPLbDbL+26tVqNE6n9indBttmmatNlX8ZMa+VKZJCRpZ/ElGTqWruRMWIJ1rxCrTUuZpmkYhpS/WBDHwBzvMvizCcuyisUi73ii8q3t4cDjC4sQ/w68dKz40+9GdZRQaHhso0wm4/1dt77STvz9wDRNvOEHVGd6evrevXv0JlyElMvly5cvh3OuarVarVanp6fDOV2AQPzJgK+Ex/wd0pGRkcXFxevXrzsuyobD2travn37xsfHQzjXxsbGrVu3FhcXaRUwWUD8yYAeL4l/xJbR0dGlpaW7d+9GFcCxY8eOHDkSzrkKhcKVK1cS6nqCr/cmAysGHg/eGRkZuXjxYtRRhEGii4krPwCKAvEDoCgQPwCKAvEDoChxWfDjL6UmFyrC6upq1IH0iwFoozgQn2qERTcAERAH3cVl2o/Xe2POYLRRHIiPiXtcxA8ACBmIHwBFgfgBUBSIHwBFgfgBUBSIHwBFgfhB2MT2m6guJNqKux3JEL/mxPz8fKFQGLwmcSQQp+3w7brtJNTAO9lW3G1Ihvgt24dcLcs6fvz4wsLC4DWJI/fv349JJr3QarWmp6fPnj1Lbov0DW9J/9bOb/6GHGEmk/nXf/3X8+fPk8EpZ2xs7PLly9PT04N0sUmG+Blj/GMp/HtJY2Nji4uLjLEBaxI7rVZrYWEhDpn0yOLi4tjYGH1ga2Rk5N1332WMXbt2TTLwpbaO5PM4V69eFe13RcbHx7/xjW9QlxsQInzPkcO8vTrqGDB9UF38ZDr/Greu6/SJ5Xq9nsvl6HOu9G15/uV/gvbPZrPcrtMxH3e8v95LFz0qDp3UEi5xYmGZYHHLqdfr+XyeikOfuzYMgz4y7T0Tq8vPeHtsIxeobqWaZNtWH/RJfDFd3HSssY7N2m0Limd3bErJUNQf8XkNPB5B9CB+MmBwt20Ox6jbe6M62lF7d9rmAg7Trrt38Q+AgXdX5hztgPh30Iv4pfQIjbo9Nqo/O2qXn6xQ7Lp7F/8AGHh3ZcXdDoh/BwGKP0Kjbo+N6s+O2l38Ykpsxe94dp6SFAPvXuqQgPh30Iv4qSvwQb1d27j0kqCMuj02aiC6HTzxWwkx8B4k8Sdmtb8dH330EWPs6NGjYmKcjbp7saN2J1l23Xbib+A9YCRb/I1G4+bNm7quHzt2jFLib9Ttz47anRjaddtJuoE3J3lW3O2IeuphWd6mlHZbZVrG53eJRIRG3R6nc+3sqK1unLbppzDtur20kTuJNvAmsNofPB07luOwlclkuBu0SFRG3d4b1dGO2urGaZuODdOuu3fxJ9rAm+jKirsdEP8Oeu9YcSDMRnUUTL/P2HsbJd3Auysr7nbER/zJvucHySLRBt7JteJuB8SfPJJi120nuQbeibbibgfEnzwSZNdtJ6EG3om24m5HXBx7gHesGPg99EISDbwTF7AXcOUHQFEgfgAUBeIHQFEgfgAUJS4uvePj4wcPHow6kJ7Y2toql8snT56MOpC+cOfOnQFoozhA/SQWuotDED3+WwsAieP27dtRhxAP8QMAwgf3/AAoCsQPgKJA/AAoCsQPgKL8P1N/vjqVuEM0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(pre_trained_model, to_file='pre_trained_cnn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f231a4",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def create_model(filters=32, kernel_size=3, activation='tanh', dropout_rate=0.2, loss='binary_crossentropy', opt='adam'):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, input_shape=(10, 1)))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation=activation))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(64, activation=activation))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# keras_model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# param_grid = {\n",
    "#     'filters': [16, 32, 64],\n",
    "#     'kernel_size': [3, 5],\n",
    "#     'activation': ['tanh', 'relu'],\n",
    "#     'dropout_rate': [0.2, 0.5],\n",
    "#     'loss': ['binary_crossentropy', 'mse'],\n",
    "#     'opt': ['adam', 'sgd']\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(X_train_resampled_final, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6df8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# def create_model(filters=32, kernel_size=3, activation='tanh', dropout_rate=0.2, loss='binary_crossentropy', opt='adam'):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, input_shape=(10, 1)))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.add(Flatten())\n",
    "#     model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# keras_model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# param_dist = {\n",
    "#     'filters': randint(16, 64),\n",
    "#     'kernel_size': [3, 5],\n",
    "#     'activation': ['tanh', 'relu'],\n",
    "#     'dropout_rate': [0.2, 0.5],\n",
    "# }\n",
    "\n",
    "# n_iter_search = 10\n",
    "# random_search = RandomizedSearchCV(estimator=keras_model, param_distributions=param_dist, n_iter=n_iter_search, cv=3)\n",
    "# random_search_result = random_search.fit(X_train_resampled_final, y_train_resampled_final)\n",
    "# print(\"Best hyperparameters: \", random_search_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb783f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Conv1D, LSTM, Dense, Activation\n",
    "# from keras.models import Model\n",
    "\n",
    "# # Define input shape\n",
    "# n_features = 10  # number of input features\n",
    "# input_shape = (None, n_features)\n",
    "\n",
    "# # Define input layer\n",
    "# inputs = Input(shape=input_shape)\n",
    "\n",
    "# # Define autoencoder to encode input features\n",
    "# encoded_features = []\n",
    "# for i in range(n_features):\n",
    "#     feature_input = Input(shape=(1,))\n",
    "#     encoded = Dense(32, activation='relu')(feature_input)\n",
    "#     decoded = Dense(1, activation='linear')(encoded)\n",
    "#     autoencoder = Model(feature_input, decoded)\n",
    "#     autoencoder.compile(optimizer='adam', loss='mse')\n",
    "#     autoencoder.fit(X_train_resampled_final[:,i], X_train_resampled_final[:,i], epochs=1, batch_size=32)\n",
    "#     encoded_feature_i = autoencoder.predict(X_train_resampled_final[:,i].reshape(-1, 1))\n",
    "#     encoded_features.append(encoded_feature_i)\n",
    "\n",
    "# # Convolutional layer to extract relevant features\n",
    "# conv_layer = Conv1D(filters=32, kernel_size=3, padding='same')(encoded_features)\n",
    "\n",
    "# # LSTM layer to capture temporal dependencies\n",
    "# lstm_layer = LSTM(units=64, return_sequences=True)(conv_layer)\n",
    "\n",
    "# # Fully connected layer with ReLU activation function\n",
    "# fc_layer = Dense(units=128, activation='relu')(lstm_layer)\n",
    "\n",
    "# # Output layer with sigmoid activation function\n",
    "# output_layer = Dense(units=1, activation='sigmoid')(fc_layer)\n",
    "\n",
    "# # Define model\n",
    "# model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "# # Compile model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train model\n",
    "# model.fit(x_train, y_train, epochs=1, batch_size=32)\n",
    "\n",
    "# # Evaluate model\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7f9ff",
   "metadata": {},
   "source": [
    "# New CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_dim = 10\n",
    "\n",
    "# Define a custom scaling function\n",
    "def scale(x):\n",
    "    mean = K.mean(x)\n",
    "    std = K.std(x)\n",
    "    return (x - mean) / std\n",
    "\n",
    "# Create K-fold cross-validator\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store training and validation loss for each fold\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "# Loop over each fold\n",
    "for fold, (train_index, val_index) in enumerate(kfold.split(X_train_resampled_final, y_train_resampled_final)):\n",
    "    print(f'Fold {fold + 1}...')\n",
    "    \n",
    "    # Split data into training and validation sets for this fold\n",
    "    X_train_fold = X_train_resampled_final.iloc[train_index]\n",
    "    y_train_fold = y_train_resampled_final.iloc[train_index]\n",
    "    X_val_fold = X_train_resampled_final.iloc[val_index]\n",
    "    y_val_fold = y_train_resampled_final.iloc[val_index]\n",
    "    \n",
    "    # Create model\n",
    "    model_new = Sequential()\n",
    "    model_new.add(Lambda(scale, input_shape=(input_dim,)))\n",
    "    model_new.add(Dense(32, activation='tanh', kernel_regularizer=regularizers.l1(0.000811)))\n",
    "    model_new.add(Dense(1, activation='sigmoid'))\n",
    "    opt_new = Adam(lr=0.00033)\n",
    "    model_new.compile(loss='binary_crossentropy', optimizer=opt_new, metrics=['accuracy'])\n",
    "    \n",
    "    # Train model on this fold's training data\n",
    "    history = model_new.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, verbose=1, validation_data=(X_val_fold, y_val_fold))\n",
    "    \n",
    "    # Append this fold's training and validation loss to the lists\n",
    "    train_loss.append(history.history['loss'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    \n",
    "    # Plot this fold's training and validation loss\n",
    "    plt.plot(history.history['loss'], label=f'Fold {fold + 1} Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label=f'Fold {fold + 1} Validation Loss')\n",
    "    \n",
    "# Plot the average training and validation loss across all folds\n",
    "plt.plot(np.mean(train_loss, axis=0), label='Average Training Loss', color='black', linewidth=2)\n",
    "plt.plot(np.mean(val_loss, axis=0), label='Average Validation Loss', color='red', linewidth=2)\n",
    "\n",
    "# Add labels and legend to the plot\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Across Folds')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25681a",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.save('pre_trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efac9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "pre_trained_model = load_model('pretrained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f56a0a0",
   "metadata": {},
   "source": [
    "## Extract learnt weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_weights = pre_trained_model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9984974",
   "metadata": {},
   "source": [
    "## Transfer learnt weights to the new CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9349452",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.layers[0].set_weights(cnn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765efa8",
   "metadata": {},
   "source": [
    "## Create LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "\n",
    "# Define LSTM model\n",
    "LSTM_model = Sequential()\n",
    "LSTM_model.add(LSTM(units=50, return_sequences=True, dropout=0.2, recurrent_dropout=0.2,input_shape=(X_train_resampled_final.shape[1], 1))\n",
    "        )\n",
    "# Add drop out layer\n",
    "LSTM_model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "LSTM_model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model.fit(X_train_resampled_final, y_train_resampled_final, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610752f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = LSTM_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1dd046",
   "metadata": {},
   "source": [
    "# New steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a041765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-train CNN model\n",
    "pretrained_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "pretrained_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "pretrained_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Transfer learning to create new CNN\n",
    "new_cnn = Sequential(pretrained_cnn.layers[:-2])\n",
    "for layer in new_cnn.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "# The TimeDistributed layer is used to apply the same CNN layers to every time step of the input sequence. The output of this layer is \n",
    "# then passed to an LSTM layer, which is followed by a Dense layer with a softmax activation function to predict the class labels.\n",
    "# Add RNN layers to create CNN-RNN model\n",
    "cnn_rnn = Sequential([\n",
    "    TimeDistributed(new_cnn, input_shape=input_shape),\n",
    "    LSTM(64),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Train CNN-RNN model\n",
    "cnn_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_rnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Thaw CNN model\n",
    "for layer in new_cnn.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add attention layer\n",
    "attention = Sequential([\n",
    "    Dense(1, activation='tanh'),\n",
    "    Flatten(),\n",
    "    Activation('softmax')\n",
    "])\n",
    "cnn_rnn_attention = Sequential([\n",
    "    TimeDistributed(new_cnn, input_shape=input_shape),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    TimeDistributed(attention),\n",
    "    Dot(axes=1),\n",
    "    Flatten(),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Train CNN-RNN-Attention model\n",
    "cnn_rnn_attention.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_rnn_attention.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e600620a",
   "metadata": {},
   "source": [
    "## Soidisant feature fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab87643",
   "metadata": {},
   "source": [
    "https://www.bing.com/videos/search?&q=feature+fusion+deep+learning&docid=603484746686478091&mid=ED175C063F17E1FDCFCEED175C063F17E1FDCFCE&view=detail&FORM=VDRVRV&rvsmid=083DA2472C6F7DD33EE1083DA2472C6F7DD33EE1&ajaxhist=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67aeb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "# Pre-train CNN model\n",
    "pretrained_cnn = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "pretrained_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "pretrained_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Transfer learning to create new CNN\n",
    "new_cnn = Sequential(pretrained_cnn.layers[:-2])\n",
    "for layer in new_cnn.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add RNN layers to create CNN-RNN model\n",
    "cnn_rnn = Sequential([\n",
    "    TimeDistributed(new_cnn, input_shape=input_shape),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "# Add merge layer\n",
    "merged = concatenate([cnn_rnn.output, new_cnn.output])\n",
    "\n",
    "# Add dense layer for classification\n",
    "output_layer = Dense(num_classes, activation='softmax')(merged)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[cnn_rnn.input, new_cnn.input], outputs=output_layer)\n",
    "\n",
    "# Train model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit([x_train, x_train], y_train, batch_size=batch_size, epochs=epochs, validation_data=([x_test, x_test], y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce39c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the objective function\n",
    "def objective_function(X, y):\n",
    "    # Initialize theta with zeros\n",
    "    n_features = X.shape[1]\n",
    "    theta = np.zeros(n_features)\n",
    "    \n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    J = -1/m * np.sum(y*np.log(h) + (1-y)*np.log(1-h))\n",
    "    return J\n",
    "\n",
    "# Define the MBOA function\n",
    "def MBOA(dim, maxiter, Bf, c, a, p, x,y):\n",
    "    # Initialization\n",
    "\n",
    "    n = len(df.columns)\n",
    "    X = np.random.rand(n, dim)\n",
    "    I = np.zeros(n)\n",
    "    F = np.zeros(n)\n",
    "\n",
    "    # Step 1: Set the initial generation/iteration number G=0\n",
    "    G = 0\n",
    "\n",
    "    # Step 2: Generate initial population of n butterflies 𝑋𝑖 = (i=1,2,..,n)\n",
    "\n",
    "    # define the size of the population\n",
    "    n = 10000\n",
    "\n",
    "    # extract the variables of interest\n",
    "    variables = X_train_resampled_final.iloc[:, :dim]\n",
    "\n",
    "    # define the ranges for each variable\n",
    "    ranges = [(0, 10000)]*dim\n",
    "\n",
    "    # generate the initial population\n",
    "    population = []\n",
    "    for i in range(n):\n",
    "        butterfly = []\n",
    "        for j in range(variables.shape[0]):\n",
    "            var_range = ranges[j]\n",
    "            var_value = np.random.uniform(var_range[0], var_range[1])\n",
    "            butterfly.append(var_value)\n",
    "        population.append(butterfly)\n",
    "\n",
    "\n",
    "    # Main loop\n",
    "    while G < maxiter:\n",
    "        # Calculate stimulus intensity for each butterfly\n",
    "        for i in range(Bf):\n",
    "            I[i] = objective_function(X[:, i], y)\n",
    "            F[i] = c * I[i]**a\n",
    "\n",
    "        # Find the best butterfly\n",
    "        best_butterfly = X[:, np.argmin(I)]\n",
    "\n",
    "        # Update each butterfly in the population\n",
    "        for i in range(n):\n",
    "            r = np.random.rand()\n",
    "            if r < p:\n",
    "                # Move towards the best butterfly\n",
    "                X[:, i] += np.random.rand(dim) * (best_butterfly - X[:, i])\n",
    "                # Determine mutual relationship vector and update butterfly positions\n",
    "                j = np.random.randint(n)\n",
    "                if i != j:\n",
    "                    MutualVector = (X[:, i] - X[:, j]) / np.linalg.norm(X[:, i] - X[:, j])\n",
    "                    X[:, i] += np.random.rand(dim) * MutualVector\n",
    "                    X[:, j] += np.random.rand(dim) * MutualVector\n",
    "                   # Calculate fitness value of the new butterfly\n",
    "                    I[i] = fitness(X[:, i], fun)\n",
    "                    # Update the best butterfly if a new one is found\n",
    "                    if I[i] < best_fitness:\n",
    "                        best_butterfly = X[:, i]\n",
    "                        best_fitness = I[i]\n",
    "\n",
    "                    # Update the mutation probability\n",
    "                    p = p * alpha\n",
    "\n",
    "                    # Store the best fitness value of this iteration\n",
    "                    best_fitness_values.append(best_fitness)\n",
    "\n",
    "\n",
    "    # Return the best butterfly and its fitness value\n",
    "    return best_butterfly, best_fitness, best_fitness_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b439111",
   "metadata": {},
   "source": [
    "## Freeze layer in NEW CNN (DO NOT FREEZE IN PRE-TRAINED CNN): To be done b4 training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers in the pre-trained model\n",
    "for layer in model_new.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a72a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the objective function\n",
    "def objective_function(X, y):\n",
    "    # Initialize theta with zeros\n",
    "    n_features = X.shape[1]\n",
    "    theta = np.zeros(n_features)\n",
    "    \n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    J = -1/m * np.sum(y*np.log(h) + (1-y)*np.log(1-h))\n",
    "    return J\n",
    "\n",
    "# Define the MBOA function\n",
    "def MBOA(dim, maxiter, Bf, c, a, p, x, y):\n",
    "    \n",
    "    # Initialization\n",
    "    \n",
    "    I = np.zeros(Bf)\n",
    "    F = np.zeros(Bf)\n",
    "    best_fitness_values = []\n",
    "    \n",
    "    # Step 1: Set the initial generation/iteration number G=0\n",
    "    G = 0\n",
    "    \n",
    "    # Step 2: Generate initial population of n butterflies 𝑋𝑖 = (i=1,2,..,n)\n",
    "    \n",
    "    # define the size of the population\n",
    "    n = 10000\n",
    "\n",
    "    # extract the variables of interest\n",
    "    variables = X_train_resampled_final.iloc[:, :dim]\n",
    "\n",
    "    # define the ranges for each variable\n",
    "    ranges = [(0, 10000)]*dim\n",
    "\n",
    "    # generate the initial population\n",
    "    population = []\n",
    "    for i in range(n):\n",
    "        butterfly = []\n",
    "        for j in range(variables.shape[0]):\n",
    "            var_range = ranges[j]\n",
    "            var_value = np.random.uniform(var_range[0], var_range[1])\n",
    "            butterfly.append(var_value)\n",
    "        population.append(butterfly)\n",
    "\n",
    "\n",
    "    # Main loop\n",
    "    while G < maxiter:\n",
    "        # Calculate stimulus intensity for each butterfly\n",
    "        for i in range(Bf):\n",
    "            I[i] = objective_function(X[:, i], y)\n",
    "            F[i] = c * I[i]**a\n",
    "        \n",
    "        # Find the best butterfly\n",
    "        best_butterfly = X[:, np.argmin(I)]\n",
    "\n",
    "        # Update each butterfly in the population\n",
    "        for i in range(n):\n",
    "            r = np.random.rand()\n",
    "            if r < p:\n",
    "                # Move towards the best butterfly\n",
    "                X[:, i] += np.random.rand(dim) * (best_butterfly - X[:, i])\n",
    "                # Determine mutual relationship vector and update butterfly positions\n",
    "                j = np.random.randint(n)\n",
    "                if i != j:\n",
    "                    MutualVector = (X[:, i] - X[:, j]) / np.linalg.norm(X[:, i] - X[:, j])\n",
    "                    X[:, i] += np.random.rand(dim) * MutualVector\n",
    "                    X[:, j] += np.random.rand(dim) * MutualVector\n",
    "                   # Calculate fitness value of the new butterfly\n",
    "                    I[i] = fitness(X[:, i], fun)\n",
    "                    # Update the best butterfly if a new one is found\n",
    "                    if I[i] < best_fitness:\n",
    "                        best_butterfly = X[:, i]\n",
    "                        best_fitness = I[i]\n",
    "\n",
    "                    # Update the mutation probability\n",
    "                    p = p * alpha\n",
    "\n",
    "                    # Store the best fitness value of this iteration\n",
    "                    best_fitness_values.append(best_fitness)\n",
    "\n",
    "        # Increment the generation number\n",
    "        G += 1\n",
    "\n",
    "\n",
    "    # Return the best butterfly and its fitness value\n",
    "    return best_butterfly, best_fitness, best_fitness_values\n",
    "\n",
    "# Call the function\n",
    "best_butterfly, best_fitness = MBOA(objective_function, 5, 50, 10, 1, 2, 0.8, X_train_resampled_final)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Objective function\n",
    "def f(X):\n",
    "    return sum([x**2 for x in X])\n",
    "\n",
    "# Butterfly Optimization Algorithm\n",
    "def butterfly_optimization(f, dim, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    # Initialize\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    \n",
    "    G = 0\n",
    "    n = Bf\n",
    "    \n",
    "    # Generate initial population of n butterflies 𝑋𝑖 = (i=1,2,..,n)\n",
    "    \n",
    "    X = [[random.uniform(-5,5) for _ in range(dim)] for _ in range(n)]\n",
    "    I = [f(x) for x in X]\n",
    "    best_index = I.index(min(I))\n",
    "    best = X[best_index]\n",
    "    while G < Maxiter:\n",
    "        # Calculate fragrance\n",
    "        F = [c * I[i]**a for i in range(n)]\n",
    "        # Find the best butterfly\n",
    "        best_index = F.index(max(F))\n",
    "        best = X[best_index]\n",
    "        # Update each butterfly\n",
    "        for i in range(n):\n",
    "            # Move towards best butterfly\n",
    "            if random.random() < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j])\n",
    "            # Mutual relationship\n",
    "            else:\n",
    "                j = random.randint(0,n-1)\n",
    "                while j == i:\n",
    "                    j = random.randint(0,n-1)\n",
    "                MutVect = [random.uniform(-1,1) for _ in range(dim)]\n",
    "                # Collaboration strategy\n",
    "                X[i] = [X[i][k] + random.uniform(0,1) * MutVect[k] * abs(X[j][k] - X[i][k]) for k in range(dim)]\n",
    "            # Update fitness value\n",
    "            I[i] = f(X[i])\n",
    "        # Update the best value\n",
    "        if min(I) < f(best):\n",
    "            best_index = I.index(min(I))\n",
    "            best = X[best_index]\n",
    "        G += 1\n",
    "    return best, f(best)\n",
    "\n",
    "# Call the function\n",
    "best_butterfly, best_fitness = butterfly_optimization(f, dim=5, Maxiter=50, Bf=10, c=1, a=2, p=0.8)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Butterfly Optimization Algorithm\n",
    "# def butterfly_optimization(f, dim, Maxiter, Bf, c, a, p, X_train):\n",
    "#     # Initialize\n",
    "#     G = 0\n",
    "#     n = Bf\n",
    "#     if len(X_train) < n:\n",
    "#         n = len(X_train)\n",
    "    \n",
    "#     X = [X_train[i] for i in range(n)]\n",
    "    \n",
    "#     I = [f(x) for x in X]\n",
    "#     best_index = I.index(min(I))\n",
    "#     best = X[best_index]\n",
    "#     while G < Maxiter:\n",
    "#         # Calculate fragrance\n",
    "#         F = [c * I[i]**a for i in range(n)]\n",
    "#         # Find the best butterfly\n",
    "#         best_index = F.index(max(F))\n",
    "#         best = X[best_index]\n",
    "#         # Update each butterfly\n",
    "#         for i in range(n):\n",
    "#             # Move towards best butterfly\n",
    "#             if random.random() < p:\n",
    "#                 for j in range(dim):\n",
    "#                     X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j])\n",
    "#             # Mutual relationship\n",
    "#             else:\n",
    "#                 j = random.randint(0,n-1)\n",
    "#                 while j == i:\n",
    "#                     j = random.randint(0,n-1)\n",
    "#                 MutVect = [random.uniform(-1,1) for _ in range(dim)]\n",
    "#                 # Collaboration strategy\n",
    "#                 X[i] = [X[i][k] + random.uniform(0,1) * MutVect[k] * abs(X[j][k] - X[i][k]) for k in range(dim)]\n",
    "#             # Update fitness value\n",
    "#             I[i] = f(X[i])\n",
    "#         # Update the best value\n",
    "#         if min(I) < f(best):\n",
    "#             best_index = I.index(min(I))\n",
    "#             best = X[best_index]\n",
    "#         G += 1\n",
    "#     return best, f(best)\n",
    "\n",
    "# # X_train_resampled_final = X_train_resampled_final.values.tolist()\n",
    "\n",
    "# # Call the function\n",
    "# best_butterfly, best_fitness = butterfly_optimization(f, dim=5, Maxiter=50, Bf=10, c=1, a=2, p=0.8, X_train=X_train_resampled_final)\n",
    "\n",
    "# # Print the best butterfly and its fitness value\n",
    "# print(\"Best butterfly:\", best_butterfly)\n",
    "# print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa284d65",
   "metadata": {},
   "source": [
    "# Work refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d612d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function\n",
    "def f(X):\n",
    "    return sum([x**2 for x in X])\n",
    "\n",
    "def butterfly_optimization(f, X, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    # Initialization\n",
    "    \n",
    "    n = len(X) # Obtain length of X_train_resampled_final\n",
    "    print(\"n\",n)\n",
    "    \n",
    "    dim = len(X[0])\n",
    "    print(\"dim\",dim)\n",
    "    \n",
    "    I = [f(x) for x in X]\n",
    "    best_index = I.index(min(I))\n",
    "    best = X[best_index]\n",
    "    G = 0\n",
    "    while G < Maxiter:\n",
    "        # Calculate fragrance\n",
    "        F = [c * I[i]**a for i in range(n)]\n",
    "        # Find the best butterfly\n",
    "        best_index = F.index(max(F))\n",
    "        best = X[best_index]\n",
    "        # Update each butterfly\n",
    "        for i in range(n):\n",
    "            # Move towards best butterfly\n",
    "            if random.random() < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j])\n",
    "            # Mutual relationship\n",
    "            else:\n",
    "                j = random.randint(0,n-1)\n",
    "                while j == i:\n",
    "                    j = random.randint(0,n-1)\n",
    "                MutVect = [random.uniform(-1,1) for _ in range(dim)]\n",
    "                # Collaboration strategy\n",
    "                X[i] = [X[i][k] + random.uniform(0,1) * MutVect[k] * abs(X[j][k] - X[i][k]) for k in range(dim)]\n",
    "            # Update fitness value\n",
    "            I[i] = f(X[i])\n",
    "        # Update the best value\n",
    "        if min(I) < f(best):\n",
    "            best_index = I.index(min(I))\n",
    "            best = X[best_index]\n",
    "        G += 1\n",
    "    return best, f(best)\n",
    "\n",
    "# Convert Pandas DataFrame to list of lists\n",
    "X_train_resampled_final_list = X_train_resampled_final.values.tolist()\n",
    "\n",
    "# Call the function with the modified input data\n",
    "best_butterfly, best_fitness = butterfly_optimization(f, X_train_resampled_final_list, Maxiter=3, Bf=10, c=1, a=2, p=0.8)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c16e2d",
   "metadata": {},
   "source": [
    "# Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5810f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# @ Input 1: Objective function\n",
    "\n",
    "def f(X):\n",
    "    return sum([x**2 for x in X])\n",
    "\n",
    "# @ Input 2: 𝑋𝑖 = (𝑋1, 𝑋2,𝑋3, … … , 𝑋𝑑𝑖𝑚),\n",
    "\n",
    "# X_train_resampled_final_list = X_train_resampled_final.tolist()\n",
    "X_train_resampled_final_list = X_train_resampled_final.values.tolist()\n",
    "\n",
    "def butterfly_optimization(f, X, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    # Initialization\n",
    "    \n",
    "    n = len(X) # Obtain length of X_train_resampled_final\n",
    "    \n",
    "    # @ Input 3: dim= no. of dimensions \n",
    "\n",
    "    dim = len(X[0])\n",
    "    \n",
    "    I = [f(x) for x in X]\n",
    "    \n",
    "    best_index = I.index(min(I))\n",
    "    \n",
    "    best = X[best_index]\n",
    "    \n",
    "    G = 0\n",
    "    \n",
    "    while G < Maxiter:\n",
    "        \n",
    "        # Calculate fragrance\n",
    "        F = [c * I[i]**a for i in range(n)] # Equation(8)\n",
    "        \n",
    "        print(type(F))\n",
    "\n",
    "        # Find the best butterfly\n",
    "        best_index = F.index(max(F))\n",
    "        best = X[best_index]\n",
    "        \n",
    "        # Update each butterfly\n",
    "        \n",
    "        for i in range(n):\n",
    "            \n",
    "            # Move towards best butterfly\n",
    "            if random.random() < p:\n",
    "                for j in range(dim):\n",
    "                    #X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j]) # Equation (9)\n",
    "                    X[i][j] += random.uniform(-1,1) * abs(best[j] - X[i][j]) # Equation (9)\n",
    "                    #X[i][j] += pow(random.uniform(-1, 1),2) * abs(best[j] - X[i][j]) * F[i]\n",
    "\n",
    "            # Mutual relationship\n",
    "            else:\n",
    "                j = random.randint(0,n-1)\n",
    "                while j == i:\n",
    "                    j = random.randint(0,n-1)\n",
    "                MutVect = [random.uniform(-1,1) for _ in range(dim)]\n",
    "                \n",
    "                # Collaboration strategy\n",
    "                X[i] = [X[i][k] + random.uniform(0,1) * MutVect[k] * abs(X[j][k] - X[i][k]) for k in range(dim)]\n",
    "            # Update fitness value\n",
    "            I[i] = f(X[i])\n",
    "        # Update the best value\n",
    "        if min(I) < f(best):\n",
    "            best_index = I.index(min(I))\n",
    "            best = X[best_index]\n",
    "        G += 1\n",
    "    return best, f(best)\n",
    "\n",
    "    \n",
    "# Call the function with the modified input data\n",
    "# Define sensor modality c, power exponent a and switch probability p \n",
    "best_butterfly, best_fitness = butterfly_optimization(f, X_train_resampled_final_list, Maxiter=3, Bf=10, c=1, a=2, p=0.8)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8dd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def f(X):\n",
    "    # Calculate the mutual information between each feature and the target variable\n",
    "    scores = mutual_info_classif(X, y_train_resampled)\n",
    "    # Return the sum of the scores as the fitness value\n",
    "    return sum(scores)\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    n = len(X)\n",
    "    dim = X.shape[1]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    #F = [decimal.Decimal(random.uniform(0, 1)) for i in range(n)]\n",
    "    F = [c * I[i]**a for i in range(n)]\n",
    "    fitness = [mutual_info_classif(X[i], y)[0] for i in range(n)]\n",
    "    best = X[fitness.index(max(fitness))]\n",
    "    best_fitness = max(fitness)\n",
    "    for t in range(Maxiter):\n",
    "        for i in range(n):\n",
    "            eps = decimal.Decimal(random.gauss(0, 1))\n",
    "            for j in range(dim):\n",
    "                X[i][j] += eps * F[i] * abs(best[j] - X[i][j])\n",
    "            score = mutual_info_classif(X[i], y)[0]\n",
    "            if score > fitness[i]:\n",
    "                fitness[i] = score\n",
    "                if score > best_fitness:\n",
    "                    best_fitness = score\n",
    "                    best = X[i]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "            F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * t), 1.5))\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def f(X):\n",
    "    # Calculate the mutual information between each feature and the target variable\n",
    "    scores = mutual_info_classif(X, y_train_resampled)\n",
    "    # Return the sum of the scores as the fitness value\n",
    "    return sum(scores)\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    n = len(X)\n",
    "    dim = X.shape[1]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    #F = [decimal.Decimal(random.uniform(0, 1)) for i in range(n)]\n",
    "    F = [c * I[i]**a for i in range(n)]\n",
    "    fitness = [mutual_info_classif(X[i], y)[0] for i in range(n)]\n",
    "    best = X[fitness.index(max(fitness))]\n",
    "    best_fitness = max(fitness)\n",
    "    for t in range(Maxiter):\n",
    "        for i in range(n):\n",
    "            eps = decimal.Decimal(random.gauss(0, 1))\n",
    "            for j in range(dim):\n",
    "                X[i][j] += eps * F[i] * abs(best[j] - X[i][j])\n",
    "            score = mutual_info_classif(X[i], y)[0]\n",
    "            if score > fitness[i]:\n",
    "                fitness[i] = score\n",
    "                if score > best_fitness:\n",
    "                    best_fitness = score\n",
    "                    best = X[i]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "            F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * t), 1.5))\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "# Call the function with the modified input data\n",
    "# Define sensor modality c, power exponent a and switch probability p \n",
    "best_butterfly, best_fitness = butterfly_optimization(f, X_train_resampled_final_list, Maxiter=3, Bf=10, c=1, a=2, p=0.8)\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4394805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "\n",
    "# Objective function: Sphere function\n",
    "def f(X):\n",
    "    return sum([x**2 for x in X])\n",
    "\n",
    "# # Rosenbrock\n",
    "# def f(X):\n",
    "#     # return sum([100 * (X[i+1] - X[i]**2)**2 + (1 - X[i])**2 for i in range(len(X)-1)])\n",
    "    \n",
    "#     f(x,y)=(1-x)^2+100(y-x^2)^2 \n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    dim =10\n",
    "    n=10\n",
    "    \n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # calculate initial stimulus intensity for each butterfly\n",
    "    I = np.zeros(Bf)\n",
    "    for i in range(Bf):\n",
    "        I[i] = f(X[i])\n",
    "        \n",
    "    #I = [f(x) for x in X]\n",
    "    \n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "    #F = [decimal.Decimal(random.uniform(0, 1)) for i in range(n)]\n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "    # Find the best butterfly\n",
    "    best_index = F.index(max(F))\n",
    "    best = X[best_index]\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    #for G in range(Maxiter):\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "            F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * G), 1.5))\n",
    "            G=G+1\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "# Call the function with the modified input data\n",
    "# Define sensor modality c, power exponent a and switch probability p \n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final_list, y_train_resampled, Maxiter=1000, Bf=10, c=3, a=4, p=0.85)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "\n",
    "# Objective function: KNN classification with feature selection\n",
    "# def fitness(X, y, k=5, alpha=0.5):\n",
    "#     # X: feature matrix (num_samples x num_features)\n",
    "#     # y: target vector (num_samples,)\n",
    "#     # k: number of nearest neighbors to consider in KNN\n",
    "#     # alpha: importance of classification quality vs subset length (0 <= alpha <= 1)\n",
    "    \n",
    "#     from sklearn.neighbors import KNeighborsClassifier\n",
    "#     from sklearn.metrics import accuracy_score\n",
    "    \n",
    "#     clf = KNeighborsClassifier(n_neighbors=k)\n",
    "#     clf.fit(X, y)\n",
    "    \n",
    "#     # Calculate classification error rate\n",
    "#     y_pred = clf.predict(X)\n",
    "#     error_rate = 1 - accuracy_score(y, y_pred)\n",
    "    \n",
    "#     # Calculate fitness\n",
    "#     num_selected = X.shape[1]\n",
    "#     num_total = X.shape[1]\n",
    "#     fitness_value = alpha * (1 - error_rate) + (1 - alpha) * (num_selected / num_total)\n",
    "    \n",
    "#     return fitness_value\n",
    "\n",
    "def fitness(X, y, k=5, alpha=0.5):\n",
    "    # X: feature matrix (num_samples x num_features)\n",
    "    # y: target vector (num_samples,)\n",
    "    # k: number of nearest neighbors to consider in KNN\n",
    "    # alpha: importance of classification quality vs subset length (0 <= alpha <= 1)\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Calculate classification error rate\n",
    "    y_pred = clf.predict(X)\n",
    "    error_rate = 1 - accuracy_score(y, y_pred)\n",
    "\n",
    "    # Calculate fitness\n",
    "    num_selected = X.shape[1]\n",
    "    num_total = X.shape[1]\n",
    "    fitness_value = alpha * (1 - error_rate) + (1 - alpha) * (num_selected / num_total)\n",
    "\n",
    "    return fitness_value\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    dim = X.shape[1]\n",
    "    n = Bf\n",
    "    \n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # Initialize butterfly positions and calculate initial stimulus intensity for each butterfly\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)]\n",
    "    I = [fitness(X[i], y) for i in range(n)]\n",
    "    \n",
    "    # Initialize stimulus strength and find the best butterfly\n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])**decimal.Decimal(a) for i in range(n)]\n",
    "    best_index = I.index(max(I))\n",
    "    best = X[best_index]\n",
    "    best_fitness = I[best_index]\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "            I[i] = fitness(X[i], y)\n",
    "            if I[i] > best_fitness:\n",
    "                best = X[i]\n",
    "                best_fitness = I[i]\n",
    "            F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * G), 1.5))\n",
    "            G=G+1\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8fbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    dim = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # Load the KNN classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "        \n",
    "    # calculate initial stimulus intensity for each butterfly\n",
    "#     I = np.zeros(Bf)\n",
    "#     for i in range(Bf):\n",
    "#         I[i] = f(X[i])\n",
    "     # In the butterfly optimization function, modify the calculation of initial stimulus intensity for each butterfly to include the fitness function\n",
    "    I = np.zeros(Bf)\n",
    "    for i in range(Bf):\n",
    "         I[i] = fitness(X[i], y, k)\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "    #F = [decimal.Decimal(random.uniform(0, 1)) for i in range(n)]\n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "    # Find the best butterfly\n",
    "    best_index = F.index(max(F))\n",
    "    best = X[best_index]\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    #for G in range(Maxiter):\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                \n",
    "            # Convert X to numpy array and select the features\n",
    "            X_selected = np.array(X)[i,:]\n",
    "            X_selected = X[:, X_selected > 0]\n",
    "            \n",
    "            # Fit the KNN classifier on the training set\n",
    "            clf.fit(X_train[:, X_selected], y_train)\n",
    "            \n",
    "            # Predict the labels of the validation set\n",
    "            y_pred = clf.predict(X_val[:, X_selected])\n",
    "            \n",
    "            # Calculate the classification error rate\n",
    "            error_rate = sum(y_pred != y_val) / len(y_val)\n",
    "            \n",
    "            # Calculate the number of selected features\n",
    "            num_selected = sum(selected_features)\n",
    "\n",
    "            # Calculate the fitness value\n",
    "            fitness = alpha * (1 - error_rate) + beta * num_selected / num_features\n",
    "\n",
    "            # Append the fitness value to the list of fitness values\n",
    "            fitness_values.append(fitness)\n",
    "\n",
    "            # Return the fitness value\n",
    "            return fitness\n",
    "\n",
    "           \n",
    "\n",
    "            # Modify the while loop to update the best butterfly and its fitness value at each generation\n",
    "            while G < Maxiter:\n",
    "                for i in range(Bf):\n",
    "                        # Generate a random number r from [0,1]\n",
    "                        r = random.uniform(0, 1)\n",
    "                        if r < p:\n",
    "                            for j in range(dim):\n",
    "                                X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "                        else:\n",
    "                            j = random.randint(0, n-1)\n",
    "                            for k in range(dim):\n",
    "                                X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "                        for j in range(dim):\n",
    "                            X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                            X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                        F[i] = decimal.Decimal(c) / decimal.Decimal(pow((1 + a * G), 1.5))\n",
    "\n",
    "                        # Calculate the fitness value for the updated butterfly\n",
    "                        fitness_val = fitness(X[i], y, k)\n",
    "\n",
    "                        # Update the best butterfly and its fitness value if necessary\n",
    "                        if fitness_val > best_fitness:\n",
    "                            best_fitness = fitness_val\n",
    "                            best = X[i]\n",
    "\n",
    "                        G=G+1\n",
    "    best = [float(best[i]) for i in range(dim)] # Convert best values back to float\n",
    "    return best, best_fitness\n",
    "\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fitness(X, y, k):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "    # Load the KNN classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Fit the KNN classifier on the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels of the validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    # Calculate the classification error rate\n",
    "    error_rate = sum(y_pred != y_val) / len(y_val)\n",
    "\n",
    "    # Calculate the number of selected features\n",
    "    num_selected = sum(X > 0)\n",
    "\n",
    "    # Calculate the fitness value\n",
    "    fitness = (1 - error_rate) * (1 + num_selected)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p, k):\n",
    "    \n",
    "    dim = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # calculate initial stimulus intensity for each butterfly\n",
    "    I = np.zeros(Bf)\n",
    "    for i in range(Bf):\n",
    "         #I[i] = fitness(X[i], y, k)\n",
    "        I[i] = fitness(X[i,:], y, k)\n",
    "\n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "    # Find the best butterfly\n",
    "    best_index = F.index(max(F))\n",
    "    best = X[best_index]\n",
    "    best_fitness = fitness(best, y, k)\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                \n",
    "            # Convert X to numpy array and select the features\n",
    "            X_selected = np.array(X)[i,:]\n",
    "            X_selected = np.where(X_selected > 0)[0]\n",
    "            \n",
    "            if len(X_selected) == 0:\n",
    "                fitness_val = decimal.Decimal('-inf')\n",
    "            else:\n",
    "                fitness_val = fitness(X_selected, y, k)\n",
    "\n",
    "            # Update the stimulus intensity\n",
    "            if fitness_val > I[i]:\n",
    "                I[i] = fitness_val\n",
    "            \n",
    "            # Check if the updated butterfly is better than the previous best\n",
    "            if fitness_val > best_fitness:\n",
    "                best = X[i]\n",
    "                best_fitness = fitness_val\n",
    "            \n",
    "        # Update the generation/iteration number\n",
    "        G += 1\n",
    "        \n",
    "        # Update the functional response F\n",
    "        F = [decimal.Decimal(c) * decimal.Decimal(I[i])**decimal.Decimal(a) for i in range(n)]\n",
    "        \n",
    "        # Print the current best fitness value after every 10 iterations\n",
    "        if G % 10 == 0:\n",
    "            print(\"Iteration {}: Best Fitness Value = {}\".format(G, best_fitness))\n",
    "    \n",
    "    # Convert the best solution to numpy array and select the features\n",
    "    best_selected = np.array(best)\n",
    "    best_selected = np.where(best_selected > 0)[0]\n",
    "    \n",
    "    return best_fitness, best_selected\n",
    "\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5,k=3)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fitness(X, y, k):\n",
    "#     # Split the data into training and validation sets\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "#     # Load the KNN classifier\n",
    "#     clf = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "#     # Fit the KNN classifier on the training set\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     # Predict the labels of the validation set\n",
    "#     y_pred = clf.predict(X_val)\n",
    "\n",
    "#     # Calculate the classification error rate\n",
    "#     error_rate = sum(y_pred != y_val) / len(y_val)\n",
    "\n",
    "#     # Calculate the number of selected features\n",
    "#     num_selected = sum(X > 0)\n",
    "\n",
    "#     # Calculate the fitness value\n",
    "#     fitness = (1 - error_rate) * (1 + num_selected)\n",
    "\n",
    "#     return fitness\n",
    "\n",
    "# def butterfly_optimization(X, y, Maxiter, Bf, c, a, p, k):\n",
    "    \n",
    "#     dim = X.shape[1]\n",
    "#     n = X.shape[0]\n",
    "#     decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "#     # calculate initial stimulus intensity for each butterfly\n",
    "#     I = np.zeros(Bf)\n",
    "#     for i in range(Bf):\n",
    "#         X[i] = np.where(X[i] > 0, 1, 0)\n",
    "#         I[i] = fitness(X[i], y, k)\n",
    "\n",
    "#     X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "#     F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "#     # Find the best butterfly\n",
    "#     best_index = F.index(max(F))\n",
    "#     best = X[best_index]\n",
    "#     best_fitness = fitness(np.where(best > 0, 1, 0), y, k)\n",
    "    \n",
    "#     # Set the initial generation/iteration number G=0\n",
    "#     G=0\n",
    "#     while G < Maxiter:\n",
    "#         for i in range(Bf):\n",
    "                    \n",
    "#             # Generate a random number r from [0,1]\n",
    "#             r = random.uniform(0, 1)\n",
    "            \n",
    "#             if r < p:\n",
    "#                 for j in range(dim):\n",
    "#                     X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "#             else:\n",
    "#                 j = random.randint(0, n-1)\n",
    "#                 for k in range(dim):\n",
    "#                     X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "                    \n",
    "#             for j in range(dim):\n",
    "#                 X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "#                 X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                \n",
    "#             # Convert X to numpy array and select the features\n",
    "#             X = [[float(X[i][j]) for j in range(dim)] for i in range(n)]\n",
    "#             X = np.array(X)\n",
    "#             X = np.where(X > 0, 1, 0)\n",
    "            \n",
    "#             # Calculate the fitness values of all butterflies\n",
    "# I = [fitness(X[i], y, k) for i in range(Bf)]\n",
    "\n",
    "# # Find the best butterfly\n",
    "# best_index = I.index(max(I))\n",
    "# best = X[best_index]\n",
    "# best_fitness = I[best_index]\n",
    "\n",
    "# # Set the initial generation/iteration number G=0\n",
    "# G = 0\n",
    "\n",
    "# # Create an empty list to store the best fitness value at each generation\n",
    "# best_fitness_list = []\n",
    "\n",
    "# # Run the optimization loop for Maxiter iterations\n",
    "# while G < Maxiter:\n",
    "    \n",
    "#     # Calculate the stimulus intensity of all butterflies\n",
    "#     F = [c * I[i]**a for i in range(Bf)]\n",
    "    \n",
    "#     # Generate a new population of butterflies\n",
    "#     X_new = np.zeros((Bf, dim))\n",
    "#     for i in range(Bf):\n",
    "        \n",
    "#         # Generate a random number r from [0,1]\n",
    "#         r = random.uniform(0, 1)\n",
    "        \n",
    "#         # Calculate the new position of the butterfly based on the random number and the best butterfly\n",
    "#         if r < p:\n",
    "#             for j in range(dim):\n",
    "#                 X_new[i][j] = X[i][j] + (r**2) * abs(best[j] - X[i][j]) * F[i]\n",
    "#         else:\n",
    "#             j = random.randint(0, Bf-1)\n",
    "#             for k in range(dim):\n",
    "#                 X_new[i][k] = X[i][k] + (r**2) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "        \n",
    "#         # Clamp the position of the butterfly to the search space\n",
    "#         for j in range(dim):\n",
    "#             X_new[i][j] = max(X_new[i][j], -Bf)\n",
    "#             X_new[i][j] = min(X_new[i][j], Bf)\n",
    "    \n",
    "#     # Select the features for each butterfly\n",
    "#     X_new = np.where(X_new > 0, 1, 0)\n",
    "    \n",
    "#     # Calculate the fitness values of the new population of butterflies\n",
    "#     I_new = [fitness(X_new[i], y, k) for i in range(Bf)]\n",
    "    \n",
    "#     # Update the best butterfly if there is a better one in the new population\n",
    "#     if max(I_new) > best_fitness:\n",
    "#         best_index = I_new.index(max(I_new))\n",
    "#         best = X_new[best_index]\n",
    "#         best_fitness = I_new[best_index]\n",
    "    \n",
    "#     # Update the population of butterflies if there is a better one in the new population\n",
    "#     if max(I_new) > max(I):\n",
    "#         X = X_new\n",
    "#         I = I_new\n",
    "    \n",
    "#     # Append the best fitness value to the list of best fitness values\n",
    "#     best_fitness_list.append(best_fitness)\n",
    "    \n",
    "#     # Increment the generation/iteration number\n",
    "#     G += 1\n",
    "\n",
    "# return best, best_fitness, best_fitness_list\n",
    "\n",
    "\n",
    "# best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5,k=3)\n",
    "\n",
    "# # Print the best butterfly and its fitness value\n",
    "# print(\"Best butterfly:\", best_butterfly)\n",
    "# print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa33694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import decimal\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fitness(X, y, k):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    X_selected = X[:, X.sum(axis=0) > 0]\n",
    "    clf.fit(X_train[:, X_selected], y_train)\n",
    "    y_pred = clf.predict(X_val[:, X_selected])\n",
    "    error_rate = sum(y_pred != y_val) / len(y_val)\n",
    "    num_selected = X_selected.shape[1]\n",
    "    fitness = 1 - error_rate + num_selected / X.shape[1]\n",
    "    return fitness\n",
    "\n",
    "def butterfly_optimization(X, y, Maxiter, Bf, c, a, p, k):\n",
    "    \n",
    "    dim = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    decimal.getcontext().prec = 28 # Set the precision of the decimal module\n",
    "    \n",
    "    # Calculate initial stimulus intensity for each butterfly\n",
    "    I = np.zeros(Bf)\n",
    "    for i in range(Bf):\n",
    "        I[i] = fitness(X[i], y, k)\n",
    "        \n",
    "    X = [[decimal.Decimal(str(X[i][j])) for j in range(dim)] for i in range(n)] # Convert all values to Decimal\n",
    "    \n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "\n",
    "    # Find the best butterfly\n",
    "    best_index = F.index(max(F))\n",
    "    best = X[best_index]\n",
    "    best_fitness = fitness(best, y, k)\n",
    "    \n",
    "    # Set the initial generation/iteration number G=0\n",
    "    G=0\n",
    "    fitness_values = []\n",
    "    while G < Maxiter:\n",
    "        for i in range(Bf):\n",
    "                    \n",
    "            # Generate a random number r from [0,1]\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += decimal.Decimal(pow(float(r), 2)) * abs(best[j] - X[i][j]) * F[i]\n",
    "            else:\n",
    "                j = random.randint(0, n-1)\n",
    "                for k in range(dim):\n",
    "                    X[i][k] += decimal.Decimal(pow(float(r), 2)) * abs(X[j][k] - X[i][k]) * F[i]\n",
    "            for j in range(dim):\n",
    "                X[i][j] = max(X[i][j], decimal.Decimal(-Bf))\n",
    "                X[i][j] = min(X[i][j], decimal.Decimal(Bf))\n",
    "                \n",
    "            # Convert X to numpy array and select the features\n",
    "            X_selected = np.array(X)[i,:]\n",
    "            X_selected = X[:, X.sum(axis=0) > 0]\n",
    "            \n",
    "                    # Evaluate the fitness of the new butterfly\n",
    "        fitness_value = fitness(X_selected, y, k)\n",
    "        \n",
    "        # Update the intensity of the butterfly if its fitness improves\n",
    "        if fitness_value > I[i]:\n",
    "            I[i] = fitness_value\n",
    "            \n",
    "        # Update the global best if the new butterfly is better\n",
    "        if fitness_value > best_fitness:\n",
    "            best = X[i]\n",
    "            best_fitness = fitness_value\n",
    "    \n",
    "    # Update the value of F for the next generation\n",
    "    F = [decimal.Decimal(c) * decimal.Decimal(I[i])** decimal.Decimal(a) for i in range(n)]\n",
    "    \n",
    "    # Add the best fitness value of the current generation to the list of fitness values\n",
    "    fitness_values.append(best_fitness)\n",
    "    \n",
    "    # Increase the generation/iteration number\n",
    "    G += 1\n",
    "\n",
    "    return best, best_fitness, fitness_values\n",
    "\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final, y_train_resampled_final, Maxiter=30, Bf=10, c=3, a=1, p=0.5,k=3)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)\n",
    "\n",
    "# Print the values of the best butterfly to check if they are close to zero\n",
    "print(\"Values of best butterfly:\", [round(x, 5) for x in best_butterfly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# @ Input 1: Objective function\n",
    "def f(X, X_train, y_train):\n",
    "    X_train_subset = X_train[:, X.astype(bool)]\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    scores = cross_val_score(clf, X_train_subset, y_train, cv=5)\n",
    "    return -np.mean(scores)\n",
    "\n",
    "# @ Input 2: X = training set\n",
    "# @ Input 3: Maxiter = Maximum number of iterations\n",
    "# @ Input 4: Bf = Butterfly population factor\n",
    "# @ Input 5: c = Constant factor\n",
    "# @ Input 6: a = Exponent factor\n",
    "# @ Input 7: p = Probability factor\n",
    "\n",
    "def butterfly_optimization(X_train, y_train, Maxiter, Bf, c, a, p):\n",
    "    \n",
    "    # Initialization\n",
    "    \n",
    "    n, dim = X.shape\n",
    "    \n",
    "    I = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        I[i] = f(X[i], X_train_resampled_final_array, y_train_resampled)\n",
    "        \n",
    "    best_index = np.argmin(I)\n",
    "    \n",
    "    best = X[best_index]\n",
    "    \n",
    "    G = 0\n",
    "    \n",
    "    while G < Maxiter:\n",
    "        \n",
    "        # Calculate fragrance\n",
    "        F = [c * I[i]**a for i in range(n)]\n",
    "        \n",
    "        # Find the best butterfly\n",
    "        best_index = np.argmax(F)\n",
    "        best = X[best_index]\n",
    "        \n",
    "        # Update each butterfly\n",
    "        for i in range(n):\n",
    "            \n",
    "            # Move towards best butterfly\n",
    "            if np.random.random() < p:\n",
    "                for j in range(dim):\n",
    "                    X[i][j] += np.random.uniform(-1,1) * abs(best[j] - X[i][j])\n",
    "                    \n",
    "            # Mutual relationship\n",
    "            else:\n",
    "                j = np.random.randint(0,n-1)\n",
    "                while j == i:\n",
    "                    j = np.random.randint(0,n-1)\n",
    "                MutVect = np.random.uniform(-1,1,dim)\n",
    "                # Collaboration strategy\n",
    "                X[i] = X[i] + np.random.uniform(0,1) * MutVect * abs(X[j] - X[i])\n",
    "                \n",
    "            # Update fitness value\n",
    "            I[i] = f(X[i], X_train_resampled_final_array, y_train_resampled)\n",
    "        \n",
    "        # Update the best value\n",
    "        if min(I) < f(best, X_train_resampled_final_array, y_train_resampled):\n",
    "            best_index = np.argmin(I)\n",
    "            best = X[best_index]\n",
    "            \n",
    "        G += 1\n",
    "    \n",
    "    # Get the index of the important features in the best butterfly\n",
    "    important_features_index = np.where(best > 0.5)[0]\n",
    "    \n",
    "    # Print the important features\n",
    "    print(\"Important features:\")\n",
    "    for index in important_features_index:\n",
    "        print(\"Feature\", index+1)\n",
    "    \n",
    "    return best, f(best, X_train_resampled_final, y_train_resampled)\n",
    "\n",
    "X_train_resampled_final_array = np.array(X_train_resampled_final)\n",
    "best_butterfly, best_fitness = butterfly_optimization(X_train_resampled_final_array, y_train_resampled, 100, 10, 0.8, 2, 0.5)\n",
    "\n",
    "# Print the best butterfly and its fitness value\n",
    "print(\"Best butterfly:\", best_butterfly)\n",
    "print(\"Fitness value of best butterfly:\", best_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b20db",
   "metadata": {},
   "source": [
    "## Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from sklearn_genetic import GASearchCV\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "_, axes = plot.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for axis, image, label in zip(axes, data.images, data.target):\n",
    "    axis.set_axis_off()\n",
    "    axis.imshow(image, cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "    axis.set_title('Training: %i' % label)\n",
    "    param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "              'bootstrap': Categorical([True, False]),\n",
    "              'max_depth': Integer(2, 30),\n",
    "              'max_leaf_nodes': Integer(2, 35),\n",
    "              'n_estimators': Integer(100, 300)}\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# The main class from sklearn-genetic-opt\n",
    "evolved_estimator = GASearchCV(estimator=classifier,\n",
    "                              cv=cv,\n",
    "                              scoring='accuracy',\n",
    "                              param_grid=param_grid,\n",
    "                              verbose=True)\n",
    "\n",
    "evolved_estimator.fit(X_train_pca, y_train_resampled_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c32f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pds\n",
    "import numpy as num\n",
    "\n",
    "estimators = DecisionTreeClassifier()\n",
    "models = GeneticSelectionCV(\n",
    "    estimators, cv=3, verbose=0,\n",
    "    scoring=\"accuracy\", max_features=5,\n",
    "    n_population=70, crossover_proba=0.5,\n",
    "    mutation_proba=0.2, n_generations=50,\n",
    "    crossover_independent_proba=0.5,\n",
    "    mutation_independent_proba=0.04,\n",
    "    tournament_size=3, n_gen_no_change=10,\n",
    "    caching=True, n_jobs=-1)\n",
    "models = models.fit(X_train_resampled_final, y_train_resampled_final)\n",
    "# Convert X_train_resampled_final to a pandas DataFrame\n",
    "X_train_df = pd.DataFrame(X_train_resampled_final, columns=X_train_resampled_final.columns)\n",
    "print('Feature Selection:', X_train_df.columns[models.support_])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
